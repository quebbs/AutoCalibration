% Encoding: UTF-8

@Article{Zheng2015,
  author    = {Yi Zheng and Feng Han},
  title     = {{Markov} Chain {Monte} {Carlo} ({MCMC}) uncertainty analysis for watershed water quality modeling and management},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {1},
  pages     = {293--308},
  month     = {jun},
  crossref  = {bis},
  doi       = {10.1007/s00477-015-1091-8},
  file      = {:Hydrology\\Markov Chain Monte Carlo (MCMC) uncertainty analysis for watershed water quality modeling and management.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1091-8},
}


@Article{Anderson2006,
  Title                    = {Snow Accumulation and Ablation Model - SNOW-17},
  Author                   = {Eric Anderson},
  Year                     = {2006},

  Abstract                 = {The SNOW-17 snow accumulation and ablation model was first described by Anderson
[1973] as a component of the National Weather Service River Forecast System
(NWSRFS). SNOW-17 evolved from two earlier snow models [Anderson and Crawford
(1964) and Anderson (1968)]. A few minor changes and the addition of snow depth
computations have been made to the SNOW-17 model since 1973. This document
describes the current version of SNOW-17. Besides just describing the model, this
document also provides some insights into the reasoning and logic used by the author in
developing the model. Hopefully this information will be helpful to future users.},
  File                     = {:Snow Accumulation and Ablation Model - SNOW-17.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Article{Anderson1978,
  Title                    = {Initial Parameter Values for the SNOW-17 Model},
  Author                   = {Eric Anderson},
  Year                     = {1978},

  File                     = {:Initial Parameter Values for the SNOW-17 Model.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@TechReport{Anderson1973,
  Title                    = {NOAA Technical Memorandum NWS-HYDRO-17},
  Author                   = {Eric Anderson},
  Institution              = {NOAA},
  Year                     = {1973},

  Keywords                 = {SNOW-17},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Article{Anderson2001,
  Title                    = {An Ensemble Adjustment Kalman Filter for Data Assimilation},
  Author                   = {Jeffrey L. Anderson},
  Journal                  = {Monthly Weather Review},
  Year                     = {2001},

  Abstract                 = {A theory for estimating the probability distribution of the state of a model given a set of observations exists.
This nonlinear filtering theory unifies the data assimilation and ensemble generation problem that have been
key foci of prediction and predictability research for numerical weather and ocean prediction applications. A
new algorithm, referred to as an ensemble adjustment Kalman filter, and the more traditional implementation
of the ensemble Kalman filter in which ‘‘perturbed observations’’ are used, are derived as Monte Carlo approximations to the nonlinear filter. Both ensemble Kalman filter methods produce assimilations with small
ensemble mean errors while providing reasonable measures of uncertainty in the assimilated variables. The
ensemble methods can assimilate observations with a nonlinear relation to model state variables and can also
use observations to estimate the value of imprecisely known model parameters. These ensemble filter methods
are shown to have significant advantages over four-dimensional variational assimilation in low-order models
and scale easily to much larger applications. Heuristic modifications to the filtering algorithms allow them to
be applied efficiently to very large models by sequentially processing observations and computing the impact
of each observation on each state variable in an independent calculation. The ensemble adjustment Kalman filter
is applied to a nondivergent barotropic model on the sphere to demonstrate the capabilities of the filters in
models with state spaces that are much larger than the ensemble size.
When observations are assimilated in the traditional ensemble Kalman filter, the resulting updated ensemble
has a mean that is consistent with the value given by filtering theory, but only the expected value of the covariance
of the updated ensemble is consistent with the theory. The ensemble adjustment Kalman filter computes a linear
operator that is applied to the prior ensemble estimate of the state, resulting in an updated ensemble whose
mean and also covariance are consistent with the theory. In the cases compared here, the ensemble adjustment
Kalman filter performs significantly better than the traditional ensemble Kalman filter, apparently because noise
introduced into the assimilated ensemble through perturbed observations in the traditional filter limits its relative
performance. This superior performance may not occur for all problems and is expected to be most notable for
small ensembles. Still, the results suggest that careful study of the capabilities of different varieties of ensemble
Kalman filters is appropriate when exploring new applications.},
  File                     = {:An Ensemble Adjustment Kalman Filter for Data Assimilation.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Baker2004,
  Title                    = {A New Flashiness Index: Characteristics and Applications to Midwestern Rivers and Streams},
  Author                   = {David B. Baker and R. Peter Richards and Timothy T. Loftus and Jack W. Kramer},
  Journal                  = {Journal of the American Water Resources Association},
  Year                     = {2004},
  Number                   = {2},
  Pages                    = {503-522},
  Volume                   = {40},

  Abstract                 = {The term flashiness reflects the frequency and rapidity of short term changes in streamflow, especially during runoff
events. Flashiness is an important component of a stream’s hydrologic regime. A variety of land use and land management changes
may lead to increased or decreased flashiness, often to the detriment of aquatic life. This paper presents a newly developed flashiness index, which is based on mean daily flows. The index is calculated by dividing the pathlength of flow oscillations for a time
interval (i.e., the sum of the absolute values of day-to-day changes
in mean daily flow) by total discharge during that time interval.
This index has low interannual variability, relative to most flow
regime indicators, and thus greater power to detect trends. Index
values were calculated for 515 Midwestern streams for the 27-year
period from 1975 through 2001. Statistically significant increases
were present in 22 percent of the streams, primarily in the eastern
portion of the study area, while decreases were present in 9 percent, primarily in the western portion. Index values tend to
decrease with increasing watershed area and with increasing unit
area ground water inputs. Area compensated index values often
shift at ecoregion boundaries. Potential index applications include
evaluation of programs to restore more natural flow regimes.
(KEY TERMS: stream flashiness; flashiness index; Indicators of
Hydrological Alteration; surface water hydrology; watershed management; stormwater management; agricultural hydrology.)},
  File                     = {:A New Flashiness Index- Characteristics and Applications to Midwestern Rivers and Streams.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Article{Bardossy1998,
  Title                    = {Generating precipitation time series using simulated annealing},
  Author                   = {Andras Bardossy},
  Journal                  = {Water Resources Research},
  Year                     = {1998},
  Number                   = {7},
  Pages                    = {1737-1744},
  Volume                   = {34},

  Abstract                 = {Long, high time resolution precipitation time series are often needed in hydrology. In most cases available measurements are not sufficient, because of a coarse time resolution and/or because observations are taken at differing locations. Often generated time series are used. These series are usually obtained from stochastic precipitation models that reproduce properties of the observed series. The purpose of this paper is to present a different methodology, one in which precipitation series can be generated by directly using their properties. The method uses simulated annealing, based on the Metropolis-Hastings algorithm. An objective function including all desired properties is formulated. The method generates series with the desired properties. The advantage of this formulation is that properties of the precipitation that are important for the target application can directly be incorporated. The method can also be applied for generating precipitation series in a changed climate. For this purpose, changes of the statistical properties of the series have to be assessed.},
  Doi                      = {10.1029/98WR00981},
  File                     = {:Generating precipitation time series using simulated annealing.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Bardossy2009,
  Title                    = {Copula based multisite model for daily precipitation simulation},
  Author                   = {A. Bardossy and G. G. S. Pegram},
  Journal                  = {Hydrol. Earth Syst. Sci.},
  Year                     = {2009},
  Pages                    = {2299–2314},
  Volume                   = {13},

  Abstract                 = {From the point of view of multisite stochastic
daily rainfall modelling, there are two new ideas introduced
in this paper. The first is the use of asymmetrical copulas
to model the spatial interdependence structure of the rainfall
amounts together with the rainfall occurrences in one relationship.
The second is in the evaluation of the (necessary
but often ignored) congregating behaviour of the higher values
of simulated rainfall; this evaluation is performed by calculating
the entropy of the observations at all the near equilateral
triangles that can be formed from the sequences at the
gauge sites, as a function of their mutual separation distance.
It turns out that the model captures the qualities desired and
offers a fresh approach to a relatively mature problem in hydrometeorology.},
  File                     = {:Hydrology\\Copula based multisite model for daily precipitation simulation.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.04.04}
}

@Article{Bickenbach2003,
  Title                    = {Evaluating the Markov Property in Studies of Economic Convergence},
  Author                   = {Frank Bickenbach and Eckhardt Bode},
  Journal                  = {INTERNATIONAL REGIONAL SCIENCE REVIEW},
  Year                     = {2003},
  Number                   = {3},
  Pages                    = {363-392},
  Volume                   = {26},

  Abstract                 = {Markov chain theory, which has frequently been applied to analyze income convergence,
imposes restrictive assumptions on the data-generating process. In most empirical studies, it
is taken for granted that per capita income follows a stationary first-order Markov process. To
examine the reliability of estimated Markov transition matrices, the authors propose Pearson
χ
2
and likelihood ratio tests of the Markov property, spatial independence, and homogeneity
over time and space. As an illustration, it is shown that per capita income in the forty-eight contiguous U.S. states did clearly not follow a common stationary first-order Markov process from
1929 to 2000.},
  File                     = {:Statistics\\Evaluating the Markov Property in Studies of Economic Convergence.pdf:PDF},
  Keywords                 = {Markov chain theory; per capita income; convergence analysis; tests of homogeneity and independence},
  Owner                    = {jaq},
  Timestamp                = {2016.01.26}
}

@Article{Bowles2004,
  author    = {David S. Bowles and J. Dean Mathias and Sanjay S. Chauhan and Joseph D. Countryman},
  title     = {Reservoir Release Forecast Model for Flood Operation of the Folsom Project Including Pre-Releases},
  year      = {2004},
  file      = {:Risk\\Reservoir Release Forecast Model for Flood Operation of the Folsom Project Including Pre-Releases.pdf:PDF;:Risk\\USSD 2004 RRFM Prnt.pdf:PDF},
  owner     = {jaq},
  timestamp = {2016.05.12},
}

@Article{Brandsma1998,
  Title                    = {Simulation of extreme precipitation in the Rhine basin by nearest-neighbor resampling},
  Author                   = {T. Brandsma and T. A. Buishand},
  Journal                  = {Hydrology and Earth System Sciences Discussions},
  Year                     = {1998},
  Number                   = {2/3},
  Pages                    = {195-209},
  Volume                   = {2},

  Abstract                 = {The use of the nonparametric nearest-neighbour resampling technique is studied for generating time series of daily rainfall and temperature for seven stations in the German part of the Rhine basin. The emphasis is on the reproduction of extreme N -day precipitation amounts. The daily temperatures are used to determine snow accumulation and melt in winter. Two versions of the resampling method, conditional on the atmospheric circulation and unconditional, show comparable results. For precipitation, the autocorrelation properties are well reproduced, whereas for temperature the autocorrelation coefficients are systematically underpredicted. The distributions of the N -day annual maximum precipitation amounts are adequately preserved. Despite the systematic underprediction of the temperature autocorrelation, the distributions of N -day maximum snowmelt are well reproduced. A 1000-year simulation for the seven stations shows that unprecedented rainfall situations can be generated.},
  File                     = {:Simulation of extreme precipitation in the Rhine basin by nearest-neighbor resampling.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Brier1950,
  Title                    = {Verification of Forecasts Expressed in Terms of Probability},
  Author                   = {Glenn W. Brier},
  Journal                  = {Monthly Weather Review},
  Year                     = {1950},
  Number                   = {1},
  Volume                   = {78},

  File                     = {:Verification of Forecasts Expressed in Terms of Probability.pdf:PDF},
  Keywords                 = {Brier Score},
  Owner                    = {jaq},
  Timestamp                = {2016.02.12}
}

@Book{Brockwell2002,
  Title                    = {Introduction to Time Series and Forecasting},
  Author                   = {Peter J. Brockwell and Richard A. Davis},
  Publisher                = {Springer},
  Year                     = {2002},
  Edition                  = {2nd},

  Keywords                 = {statistics},
  Owner                    = {quebbs},
  Timestamp                = {2015.03.02}
}

@TechReport{Brougher2012,
  Title                    = {Reallocation of water storage at Federal WaterProjects for Municipal and Industrial water supply},
  Author                   = {Cynthia Brougher and Nicole T. Carter},
  Institution              = {Congressional Research Service},
  Year                     = {2012},

  File                     = {:Reservoirs\\Reallocation of water storage at Federal WaterProjects for Municipal and Industrial water supply.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.03.28}
}

@Article{Brown2012,
  author    = {Casey Brown and Yonas Ghile and Mikaela Lverty and Ke Li},
  title     = {Decision Scaling: Linking bottom-up vulnerability analysis with climate projections in the water sector},
  journal   = {Water Resources Research},
  year      = {2012},
  volume    = {48},
  file      = {:Climate\\Decision Scaling- Linking bottom-up vulnerability analysis with climate projections in the water sector.pdf:PDF},
  owner     = {jaq},
  timestamp = {2016-12-22},
}

@Article{Brown2012a,
  Title                    = {An alternate approach to assessing climate risks},
  Author                   = {Brown, Casey and Wilby, Robert L.},
  Journal                  = {Eos, Transactions American Geophysical Union},
  Year                     = {2012},
  Number                   = {41},
  Pages                    = {401--402},
  Volume                   = {93},

  Abstract                 = {U.S. federal agencies are now required to review the potential impacts of climate change on their assets and missions. Similar arrangements are also in place in the United Kingdom under reporting powers for key infrastructure providers (http://www.defra.gov.uk/environment/climate/sectors/reporting-authorities/reporting-authorities-reports/). These requirements reflect growing concern about climate resilience and the management of long-lived assets. At one level, analyzing climate risks is a matter of due diligence, given mounting scientific evidence. However, there is no consensus about the means for doing so nor about whether climate models are even ft for the purpose; in addition, several important issues are often overlooked when incorporating climate information into adaptation decisions. An alternative to the scenarioled strategy, such as an approach based on a vulnerability analysis (“stress test”), may identify practical options for resource managers.},
  Doi                      = {10.1029/2012EO410001},
  File                     = {:Hydrology\\An alternate approach to assessing climate risks.pdf:PDF},
  ISSN                     = {2324-9250},
  Keywords                 = {Global climate models, Risk, Climate impact, Decision making under uncertainty, Project evaluation, climate change, risk assessment, water resources, decision making},
  Owner                    = {jaq},
  Timestamp                = {2016.05.12},
  Url                      = {http://dx.doi.org/10.1029/2012EO410001}
}

@Article{Buishand1996,
  Title                    = {Statistical tests for comparison of daily variability in observed and simulated climates},
  Author                   = {T. Adri Buishand and Jules J. Beersma},
  Journal                  = {Journal of Climate},
  Year                     = {1996},
  Pages                    = {2538-2550},
  Volume                   = {9},

  Abstract                 = {Tests for differences in daily variability based on the jackknife are presented. These tests properly account for the effect of autocorrelation in the data and are reasonably robust against departures from normality. Three measures for the daily variability are considered: process, within-month, and innovation variance. The jackknife statistic compares the logarithm of these measures. The standard errors of this logarithm are obtained by recomputing the variance estimates for all subsamples wherein one month is omitted from the complete simple. A simple extension of the jackknife procedure is given to obtain a powerful multivariate test in situations that the differences in variance have the same sign across the region considered or over the year.

As an illustration the tests are applied to near-surface temperatures over Europe simulated by the coupled ECHAM/LSG model. It is shown that the control run of the model significantly overestimates the process variance in winter and spring and the within-month variance in all seasons. Significant differences are also found for the innovation variances of the daily temperatures, but the sign of the differences varies over the yew. In a perturbed run with enhanced atmospheric greenhouse gas concentrations the daily temperature variability over Europe significantly decreases in winter and spring compared with the control run.},
  File                     = {:Hydrology\\Statistical tests for comparison of daily variability in observed and simulated climates.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.27}
}

@Article{Buishand2001,
  Title                    = {Multisite simulation of daily precipitation and temperature in the Rhine basin by nearest-neighbor resampling},
  Author                   = {Buishand, T. A and Brandsma, Theo},
  Journal                  = {Water Resources Research},
  Year                     = {2001},
  Number                   = {11},
  Pages                    = {2761-2776},
  Volume                   = {37},

  Abstract                 = {The method of nearest-neighbor resampling is extended to simultaneous simulation of daily precipitation and temperature at multiple locations over a large area (25 stations in the German part of the Rhine basin). Nearest neighbors refer here to historical days for which the observed weather is closest to that of the simulated weather for a given day. Resampling is done from these nearest neighbors to obtain the weather variables for the next day. The nearest neighbors are defined in terms of a weighted Euclidean distance to a feature vector containing summary statistics of the daily precipitation and temperature fields (spatial averages, fraction of stations with precipitation, and principal components). The inclusion of atmospheric circulation variables in the feature vector is also studied. There is a weak tendency to underestimate the standard deviations and autocorrelation coefficients of daily precipitation and temperature and the standard deviations of the monthly precipitation totals and monthly mean temperatures. However, the underprediction of these second-order moment statistics is not statistically significant if the number k of nearest neighbors in the resampling procedure is small (k ≈ 5) and the dimension q of the feature vector is low (q ≈ 3). A small systematic underprediction is also observed for the quantiles of the distributions of the N-day winter maximum precipitation amounts. The spatial dependence of these extremes and the distributions of N-day maximum snowmelt are adequately reproduced. Long-duration simulations show that realistic unprecedented multiday precipitation amounts can be generated.},
  File                     = {:Multisite simulation of daily precipitation and temperature in the Rhine basin by nearest-neighbor resampling.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Castelletti2010,
  Title                    = {Tree-based reinforcement learning for optimal water reservoir operation},
  Author                   = {Castelletti, A. and Galelli, S. and Restelli, M. and Soncini-Sessa, R.},
  Journal                  = {Water Resources Research},
  Year                     = {2010},
  Note                     = {W09507},
  Number                   = {9},
  Pages                    = {n/a--n/a},
  Volume                   = {46},

  Abstract                 = {Although being one of the most popular and extensively studied approaches to
design water reservoir operations, Stochastic Dynamic Programming is plagued by a dual
curse that makes it unsuitable to cope with large water systems: the computational
requirement grows exponentially with the number of state variables considered (curse of
dimensionality) and an explicit model must be available to describe every system transition
and the associated rewards/costs (curse of modeling). A variety of simplifications and
approximations have been devised in the past, which, in many cases, make the resulting
operating policies inefficient and of scarce relevance in practical contexts. In this paper, a
reinforcement‐learning approach, called fitted Q‐iteration, is presented: it combines the
principle of continuous approximation of the value functions with a process of learning
off‐line from experience to design daily, cyclostationary operating policies. The
continuous approximation, performed via tree‐based regression, makes it possible to
mitigate the curse of dimensionality by adopting a very coarse discretization grid with
respect to the dense grid required to design an equally performing policy via Stochastic
Dynamic Programming. The learning experience, in the form of a data set generated
combining historical observations and model simulations, allows us to overcome the curse
of modeling. Lake Como water system (Italy) is used as study site to infer general
guidelines on the appropriate setting for the algorithm parameters and to demonstrate the
advantages of the approach in terms of accuracy and computational effectiveness
compared to traditional Stochastic Dynamic Programming.},
  Doi                      = {10.1029/2009WR008898},
  File                     = {:Tree‐based reinforcement learning for optimal water reservoir operation.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Water management, Hydrology: Reservoirs (surface), System operation and management, Decision making under uncertainty, reservoir operation, reinforcement learning, tree-based regression},
  Owner                    = {jaq},
  Timestamp                = {2016.02.23},
  Url                      = {http://dx.doi.org/10.1029/2009WR008898}
}

@Article{Chandler2002,
  Title                    = {Analysis of rainfall variability using generalized linear models: A case study from the west of Ireland},
  Author                   = {Richard E. Chandler and Howard S. Wheater},
  Journal                  = {Water Resources Research},
  Year                     = {2002},
  Number                   = {10},
  Pages                    = {10-1,10-11},
  Volume                   = {38},

  Abstract                 = {In the early 1990s a cluster of extreme flood events occurred in the south Galway region of western Ireland, and this led to speculation of changing rainfall patterns in the area. In this paper we illustrate the use of generalized linear models (GLMs) to test for such changes and quantify their structure. GLMs, long established in the statistical literature, provide a flexible and rigorous formal framework within which to distinguish between possible climate change scenarios and are able to deal with high levels of variability, such as those typically associated with daily rainfall sequences. The study indicates that the GLM approach provides a powerful tool for interpreting historical rainfall records.},
  File                     = {:Analysis of rainfall variability using generalized linear models- A case study from the west of Ireland.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.12}
}

@Book{Christensen2011,
  Title                    = {Bayesian Ideas and Data Analysis},
  Author                   = {Ronald Christensen and Wesley Johnson and Adam Branscum and Timoth E. Hanson},
  Publisher                = {CRC Press},
  Year                     = {2011},

  Owner                    = {jaq},
  Timestamp                = {2016.02.12}
}

@Article{Clark2008,
  Title                    = {Hydrological data assimilation with the ensemble Kalman filter: Use of streamflow observations to update states in a distributed hydrological model},
  Author                   = {Martyn P. Clark and David E. Rupp and Ross A. Woods and Xiaogu Zheng and Richard P. Ibbitt and Andrew G. Slater and Jochen Schmidt and Michael J. Uddstrom},
  Journal                  = {Advances in Water Resources},
  Year                     = {2008},
  Pages                    = {1309-1324},
  Volume                   = {31},

  Abstract                 = {This paper describes an application of the ensemble Kalman filter (EnKF) in which streamflow observations are used to update states in a distributed hydrological model. We demonstrate that the standard
implementation of the EnKF is inappropriate because of non-linear relationships between model states
and observations. Transforming streamflow into log space before computing error covariances improves
filter performance. We also demonstrate that model simulations improve when we use a variant of the
EnKF that does not require perturbed observations. Our attempt to propagate information to neighbouring basins was unsuccessful, largely due to inadequacies in modelling the spatial variability of hydrological processes. New methods are needed to produce ensemble simulations that both reflect total model
error and adequately simulate the spatial variability of hydrological states and fluxes.},
  File                     = {:Hydrological data assimilation with the ensemble Kalman filter- Use of streamflow observations to update states in a distributed hydrological model.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Book{Cressie1993,
  Title                    = {Statistics for Spatial Data},
  Author                   = {Noel A. C. Cressie},
  Publisher                = {Wiley},
  Year                     = {1993},

  File                     = {:Statistics for Spatial Data.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.25}
}

@Article{Cunnane1978,
  Title                    = {Unbiased Plotting Positions - A Review},
  Author                   = {C. Cunnane},
  Journal                  = {Journal of Hydrology},
  Year                     = {1978},
  Number                   = {3-4},
  Volume                   = {37},

  Abstract                 = {The existing attitude that the criterion for choice of plotting position is arbitrary is rebuked and it is shown that a worthwhile criterion can be based on desired statistical properties of the plot, rather than on comparison of plotting positions with estimates of probability for individual sample values. These properties are that any quantile estimate made from the plot should be unbiased and should have smallest mean square error among all such estimates. This leads to specification of plotting position initially in terms of reduced variate rather than probability value. The unbiased plotting position is E(y(i)), the mean of the ith order statistic in samples from the reduced variate population, which differs from one distribution to another. A good approximation for each distribution is available in the probability domain. These take the general form (i − α)(N + 1 − 2α) with α = 38 in the normal case and α = 0.44 in the extreme-value type-1 (EV1) and exponential cases. The Weibull formula, α = 0, is correct for the uniform distribution alone and is shown to be biased for other distributions. Hazen's formula α = 12 shows up much better in terms of bias than many would expect. If a single simple distribution free formula were required then α = 25 would be the best compromise. The plotting position postulates which have supported the Weibull formula for many years are examined and some are seen to be unreasonable in view of statistical facts.},
  File                     = {:Statistics\\Unbiased Plotting Positions - A Review.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.06.27}
}

@Article{Darsono2007,
  Title                    = {Neural-optimal control algorithm for real-time regulation of in-line storage in combined sewer systems},
  Author                   = {Suseno Darsono and John W. Labadie},
  Journal                  = {Environmental Modelling and Software},
  Year                     = {2007},
  Pages                    = {1349-1361},
  Volume                   = {22},

  Abstract                 = {Attempts at implementing real-time control systems as a cost-effective means of minimizing the pollution impacts of untreated combined
sewer overflows have largely been unsustained due to the complexity of the real-time control problem. Optimal real-time regulation of flows
and in-line storage in combined sewer systems is challenging due to the need for complex optimization models integrated with urban stormwater
runoff prediction and fully dynamic routing of sewer flows within 5e15 min computational time increments. A neural-optimal control algorithm
is presented that fully incorporates the complexities of dynamic, unsteady hydraulic modeling of combined sewer system flows and optimal
coordinated, system-wide regulation of in-line storage. The neural-optimal control module is based on a recurrent Jordan neural network architecture that is trained using optimal policies produced by a dynamic optimal control module. The neural-optimal control algorithm is demonstrated in a simulated real-time control experiment for the King County combined sewer system, Seattle, Washington, USA. The algorithm
exhibits an effective adaptive learning capability that results in near-optimal performance of the control system while satisfying the time constraints of real-time implementation.},
  File                     = {:Optimization\\Optimal integrated operation of reservoir-assisted stormwater treatment areas for estuarine habitat restoration.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.05.10}
}

@Article{Darsow1992,
  Title                    = {Copulas and Markov processes},
  Author                   = {Illiam F. Darsow and Bao Nguyen and Elwood T. Olsen},
  Journal                  = {Illinois Journal of Mathematics},
  Year                     = {1992},

  File                     = {:Copulas and Markov processes.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Deb2002,
  Title                    = {A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II},
  Author                   = {Kalyanmoy Deb and Amrit Pratap and Sameer Agarwal and T. Meyarivan},
  Journal                  = {IEEE Transactions on Evolutionary Computation},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {182-197},
  Volume                   = {6},

  Abstract                 = {Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN3) computational complexity (where M is the number of objectives and N is the population size); (2) their non-elitism approach; and (3) the need to specify a sharing parameter. In this paper, we suggest a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all of the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN2) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best N solutions (with respect to fitness and spread). Simulation results on difficult test problems show that NSGA-II is able, for most problems, to find a much better spread of solutions and better convergence near the true Pareto-optimal front compared to the Pareto-archived evolution strategy and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multi-objective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective, seven-constraint nonlinear problem, are compared with another constrained multi-objective optimizer, and the much better performance of NSGA-II is observed},
  Doi                      = {10.1109/4235.996017},
  File                     = {:A Fast and Elitist Multiobjective Genetic Algorithm- NSGAII.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.28}
}

@TechReport{Dorigo1991,
  Title                    = {Positive feedback as a search strategy},
  Author                   = {M. Dorigo and V. Maniezzo and A. Colorni},
  Institution              = {Dipartimento Di Elettronica - Politecnico Di Milano},
  Year                     = {1991},
  Number                   = {91-016},

  Abstract                 = {A combination of distributed computation, positive
feedback and constructive greedy heuristic is proposed as a new
approach to stochastic optimization and problem solving.
Positive feedback accounts for rapid discovery of very good
solutions, distributed computation avoids premature convergence,
and greedy heuristic helps the procedure to find acceptable
solutions in the early stages of the search process. An
application of the proposed methodology to the classical
travelling salesman problem shows that the system can rapidly
provide very good, if not optimal, solutions. We report on many
simulation results and discuss the working of the algorithm.
Some hints about how this approach can be applied to a variety
of optimization problems are also given.},
  File                     = {:Optimization\\Positive feedback as a search strategy.pdf:PDF},
  Keywords                 = {ant colony optimization, ant swarm, Ant Systems, Ant Colonies, Adaptive Systems, Artificial Life, Combinatorial Optimization, Parallel Algorithms},
  Owner                    = {jaq},
  Timestamp                = {2016.03.29}
}

@Book{Efron1998,
  Title                    = {An Introduction to the Bootstrap},
  Author                   = {Bradley Efron and Robert Tibshirani},
  Year                     = {1998},

  File                     = {:An Introduction to the Bootstrap.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Entekhabi1989,
  author    = {Dara Entekhabi and Ignacio Rodriquez-Iturbe and Peter S. Eagleson},
  title     = {Probabilistic representation of the temporal rainfall process by a modified Neyman-Scott Rectangular Pulses Model: Parameter estimation and validation},
  journal   = {Water Resources Research},
  year      = {1989},
  volume    = {25},
  number    = {2},
  pages     = {295-302},
  abstract  = {The capability of the Neyman-Scott clustered stochastic point process model of rainfall to preserve various observed statistics is considered. Randomization of the cell duration parameter from storm to storm is shown to considerably improve the wet-dry period, joint distribution, and extreme value statistics. A simple procedure for parameter estimation is introduced and applied.},
  file      = {:Hydrology\\Probabilistic representation of the temporal rainfall process by a modified Neyman-Scott Rectangular Pulses Model- Parameter estimation and validation.pdf:PDF},
  owner     = {jaq},
  timestamp = {2016.07.27},
}

@Book{Evensen2009,
  Title                    = {Data Assimilation - The Ensemble Kalman Filter},
  Author                   = {Geir Evensen},
  Publisher                = {Springer},
  Year                     = {2009},
  Edition                  = {2nd},

  Doi                      = {10.1007/978-3-642-03711-5},
  File                     = {:Data Assimilation - The Ensemble Kalman Filter.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Evensen2003,
  Title                    = {The Ensemble Kalman Filter: theoretical formulation and practical implementation},
  Author                   = {Geir Evensen},
  Journal                  = {Ocean Dynamics},
  Year                     = {2003},
  Pages                    = {343-367},
  Volume                   = {53},

  Abstract                 = {The purpose of this paper is to provide a
comprehensive presentation and interpretation of the
Ensemble Kalman Filter (EnKF) and its numerical
implementation. The EnKF has a large user group,
and numerous publications have discussed applications
and theoretical aspects of it. This paper reviews the
important results from these studies and also presents
new ideas and alternative interpretations which further
explain the success of the EnKF. In addition to providing the theoretical framework needed for using the
EnKF, there is also a focus on the algorithmic formulation and optimal numerical implementation. A
program listing is given for some of the key subroutines. The paper also touches upon specific issues such
as the use of nonlinear measurements, in situ profiles
of temperature and salinity, and data which are
available with high frequency in time. An ensemble based optimal interpolation (EnOI) scheme is
presented as a cost-effective approach which may serve
as an alternative to the EnKF in some applications. A
fairly extensive discussion is devoted to the use of time
correlated model errors and the estimation of model
bias.},
  File                     = {:The Ensemble Kalman Filter- theoretical formulation and practical implementation.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Farmer2016,
  Title                    = {On the deterministic and stochastic use of hydrologic models},
  Author                   = {William H. Farmer and Richard M. Vogel},
  Journal                  = {Water Resources Research},
  Year                     = {2016},
  Volume                   = {52},

  Abstract                 = {Environmental simulation models, such as precipitation-runoff watershed models, are
increasingly used in a deterministic manner for environmental and water resources design, planning, and
management. In operational hydrology, simulated responses are now routinely used to plan, design, and
manage a very wide class of water resource systems. However, all such models are calibrated to existing
data sets and retain some residual error. This residual, typically unknown in practice, is often ignored,
implicitly trusting simulated responses as if they are deterministic quantities. In general, ignoring the
residuals will result in simulated responses with distributional properties that do not mimic those of the
observed responses. This discrepancy has major implications for the operational use of environmental
simulation models as is shown here. Both a simple linear model and a distributed-parameter
precipitation-runoff model are used to document the expected bias in the distributional properties of
simulated responses when the residuals are ignored. The systematic reintroduction of residuals into
simulated responses in a manner that produces stochastic output is shown to improve the distributional
properties of the simulated responses. Every effort should be made to understand the distributional
behavior of simulation residuals and to use environmental simulation models in a stochastic manner.},
  File                     = {:Hydrology\\On the deterministic and stochastic use of hydrologic models.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.08.16}
}

@Article{Feng2011,
  Title                    = {Bootstrap estimated seasonal potential predictability of global temperature and precipitation},
  Author                   = {X. Feng and T. DelSole and P. Houser},
  Journal                  = {Geophysical Research Letters},
  Year                     = {2011},

  Abstract                 = {Potential predictability of seasonal mean temperature and
precipitation is assessed using a moving blocks bootstrap
method. The bootstrap method allows the potential
predictability of seasonal means to be assessed even for
autocorrelated, highly non‐Gaussian, intermittent data. The
results reveal that the largest fraction of predictable variance
for both temperature and precipitation occur mainly over
the tropics where El Niño/Southern Oscillation dominates
the interannual variability. Statistically significant potential
predictability also is found in extratropics for temperature,
particularly over most oceans and appreciable land areas.
The potential predictability of temperature is generally smaller
over land than over ocean and displays a significant annual
cycle. Potential predictability of precipitation displays spotty
and less continuous spatial patterns over extratropical regions
and also undergoes a significant annual cycle. The potential
predictability estimates are generally consistent with previous
studies, but some inconsistency is also observed, such as the
lack of significant potential predictability for temperature over
North American winter},
  Doi                      = {10.1029/2010GL046511},
  File                     = {:Bootstrap estimated seasonal potential predictability of global temperature and precipitation.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Unpublished{Finley2014b,
  Title                    = {Using JAGS in R with the rjags package},
  Author                   = {Andrew O. Finley},
  Note                     = {ordinary linear regression model},

  File                     = {:Using JAGS in R with the rjags package.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Unpublished{Finley2014c,
  Title                    = {Hierarchical Modeling for Multivariate Spatial Data in R: LiDAR and Stand Characteristics Example},
  Author                   = {Andrew O. Finley},

  File                     = {:Hierarchical Modeling for Multivariate Spatial Data in R- LiDAR and Stand Characteristics.pdf:PDF},
  Keywords                 = {spBayes, forest inventory},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Unpublished{Finley2014d,
  Title                    = {Hierarchical Modeling for Univariate Spatial Data in R: LiDAR and Forest Biomass Example},
  Author                   = {Andrew O. Finley},

  File                     = {:Hierarchical Modeling for Univariate Spatial Data in R- LiDAR and Forest Biomass Example.pdf:PDF},
  Keywords                 = {spBayes},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Unpublished{Finley2014e,
  Title                    = {Analysis of forest biomass data using JAGS and R},
  Author                   = {Andrew O. Finley},

  File                     = {:Analysis of forest biomass data using JAGS and R.pdf:PDF},
  Keywords                 = {spBayes},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Unpublished{Finley2014f,
  Title                    = {Illustration of Adaptive MCMC},
  Author                   = {Andrew O. Finley},

  File                     = {:Illustration of Adaptive MCMC.pdf:PDF},
  Keywords                 = {spBayes},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Unpublished{Finley2014g,
  Title                    = {Hierarchical Modeling for Non-Gaussian Spatial Data in R},
  Author                   = {Andrew O. Finley},

  File                     = {:Hierarchical Modeling for Non-Gaussian Spatial Data in R.pdf:PDF},
  Keywords                 = {spBayes},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Unpublished{Finley2014,
  Title                    = {Bayesian Dynamic Modeling for Space-time Data in R},
  Author                   = {Andrew O. Finley and Sudipto Banerjee},

  File                     = {:Bayesian Dynamic Modeling for Space-time Data in R.pdf:PDF},
  Keywords                 = {library(spBayes), Dynamic spatio-temporal models},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Unpublished{Finley2014a,
  Title                    = {Hierarchical Modeling for Multivariate Spatial Data in R},
  Author                   = {Andrew O. Finley and Sudipto Banerjee},

  File                     = {:Hierarchical Modeling for Multivariate Spatial Data in R.pdf:PDF},
  Keywords                 = {spBayes},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Finley2015,
  Title                    = {spBayes for Large Univariate and Multivariate Point-Referenced Spatio-Temporal Data Models},
  Author                   = {Andrew O. Finley and Sudipto Banerjee and Alan E. Gelfand},
  Journal                  = {Journal of Statistical Software},
  Year                     = {2015},
  Volume                   = {63},

  Abstract                 = {In this paper we detail the reformulation and rewrite of core functions in the spBayes R
package. These efforts have focused on improving computational efficiency, flexibility, and
usability for point-referenced data models. Attention is given to algorithm and computing
developments that result in improved sampler convergence rate and efficiency by reducing
parameter space; decreased sampler run-time by avoiding expensive matrix computations,
and; increased scalability to large datasets by implementing a class of predictive process
models that attempt to overcome computational hurdles by representing spatial processes
in terms of lower-dimensional realizations. Beyond these general computational improvements
for existing model functions, we detail new functions for modeling data indexed in
both space and time. These new functions implement a class of dynamic spatio-temporal
models for settings where space is viewed as continuous and time is taken as discrete.},
  File                     = {:spBayes for Large Univariate and Multivariate Point-Referenced Spatio-Temporal Data Models.pdf:PDF},
  Keywords                 = {spatial, temporal, multivariate, Gaussian predictive process, Markov chain Monte
Carlo},
  Owner                    = {jaq},
  Timestamp                = {2016.03.14}
}

@Article{Finley2014h,
  Title                    = {Dynamic spatial regression models for space-varying forest stand tables},
  Author                   = {Finley, Andrew O. and Banerjee, Sudipto and Weiskittel, Aaron R. and Babcock, Chad and Cook, Bruce D.},
  Journal                  = {Environmetrics},
  Year                     = {2014},
  Number                   = {8},
  Pages                    = {596--609},
  Volume                   = {25},

  Abstract                 = {Many forest management planning decisions are based on information about the number of trees by species and diameter per unit area. This information is commonly summarized in a stand table, where a stand is defined as a group of forest trees of sufficiently uniform species composition, age, condition, or productivity to be considered a homogeneous unit for planning purposes. Typically, information used to construct stand tables is gleaned from observed subsets of the forest selected using a probability-based sampling design. Such sampling campaigns are expensive, and hence, only a small number of sample units are typically observed. This data paucity means that stand tables can only be estimated for relatively large areal units. Contemporary forest management planning and spatially explicit ecosystem models require stand table input at higher spatial resolution than can be affordably provided using traditional approaches. We propose a dynamic multivariate Poisson spatial regression model that accommodates both spatial correlation between observed diameter distributions and also correlation between tree counts across diameter classes within each location. To improve fit and prediction at unobserved locations, diameter specific intensities can be estimated using auxiliary data such as management history or remotely sensed information. The proposed model is used to analyze a diverse forest inventory dataset collected on the United States Forest Service Penobscot Experimental Forest in Bradley, Maine. Results demonstrate that explicitly modeling the residual spatial structure via a multivariate Gaussian process and incorporating information about forest structure from Light Detection and Ranging (LiDAR) covariates improve model fit and can provide high spatial resolution stand table maps with associated estimates of uncertainty. Copyright © 2014 John Wiley & Sons, Ltd.},
  Doi                      = {10.1002/env.2322},
  File                     = {:Dynamic spatial regression models for space-varying forest stand tables.pdf:PDF},
  ISSN                     = {1099-095X},
  Keywords                 = {Gaussian spatial process, MCMC, forestry, dynamic model},
  Owner                    = {jaq},
  Timestamp                = {2016.03.14},
  Url                      = {http://dx.doi.org/10.1002/env.2322}
}

@Article{Foufoula-Georgiou1987,
  author    = {Efi Foufoula-Georgiou and Dennis P. Lettenmaier},
  title     = {A Markov Renewal Model for rainfall occurrences},
  journal   = {Water Resources Research},
  year      = {1987},
  volume    = {23},
  number    = {5},
  abstract  = {A probabilistic model for the temporal description of daily rainfall occurrences at a single location is presented. By defining an event as a day with measurable precipitation the model is cast into the discrete-time point process framework. In the proposed model the sequence of times between events is formed by sampling from two geometric distributions, according to transition probabilities specified by a Markov chain. The model belongs to the class of Markov renewal processes and exhibits clustering relative to the independent Bernoulli process. As a special case, it reduces to a renewal model with a mixture distribution for the interarrival times. The rainfall occurrence model coupled with a mixed exponential distribution for the nonzero daily rainfall amounts was applied to the daily rainfall series for Snoqualmie Falls, Washington, and was successful in preserving the short-term structure of the occurrence process, as well as the distributional properties of the seasonal rainfall amounts.},
  file      = {:Hydrology\\A Markov Renewal Model for rainfall occurrences.pdf:PDF},
  owner     = {jaq},
  timestamp = {2017-03-22},
}

@TechReport{Fraley2013,
  Title                    = {ensembleBMA: An R Package for Probabilistic Forecasting using Ensembles and Bayesian Model Averaging},
  Author                   = {Chris Fraley and Adrian E. Raftery and Tilmann Gneiting and J. McLean Sloughter},
  Institution              = {Department of Statistics University of Washington},
  Year                     = {2013},

  Abstract                 = {ensembleBMA is a contributed R package for probabilistic forecasting using ensemble postprocessing
via Bayesian Model Averaging. It provides functions for modeling and forecasting
with data that may include missing ensemble member forecasts. The modeling can also
account for exchangeable ensemble members. The modeling functions estimate model parameters
from training data via the EM algorithm for normal mixture models (appropriate
for temperature or pressure), mixtures of gamma distributions (appropriate for maximum
wind speed), and mixtures of gamma distributions with a point mass at 0 (appropriate for
quantitative precipitation). Also included are functions for forecasting from these models,
as well as functions for verification to assess forecasting performance.},
  File                     = {:ensembleBMA- An R Package for Probabilistic Forecasting using Ensembles and Bayesian Model Averaging.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Frigessi2002,
  Title                    = {A Dynamic Mixture Model for Unsupervised Tail Estimation without Threshold Selection},
  Author                   = {Frigessi, A. and Haug, O. and Rue, H.},
  Journal                  = {Extremes},
  Year                     = {2002},
  Pages                    = {219-235},
  Volume                   = {5},

  File                     = {:A Dynamic Mixture Model for Unsupervised Tail Estimation without Threshold Selection.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Froehlich2008,
  Title                    = {Embankment Dam Breach Parameters and Their Uncertainties},
  Author                   = {David C. Froehlich},
  Journal                  = {Journal of Hydraulic Engineering},
  Year                     = {2008},

  File                     = {:Embankment Dam Breach Parameters and Their Uncertainties.pdf:PDF},
  Keywords                 = {Embankment; Dam failure; Parameters; Uncertainty principles; Floods},
  Owner                    = {jaq},
  Timestamp                = {2016.01.08}
}

@Article{Gelfand2003,
  Title                    = {Spatial Modeling with SpSpatial Varying Coefficient Processes},
  Author                   = {Alan E. Gelfand and Hyon-Jung Kim and C. F. Sirmans and Sudipto Banerjee},
  Journal                  = {Journal of American Statistical Association},
  Year                     = {2003},
  Number                   = {462},
  Pages                    = {387-396},
  Volume                   = {98},

  Abstract                 = {In many applications,the objective is to build regression modelsto explaina response variable over a region of interest under the assumption that the
responses are spatially correlated.In nearly all of this work,the regression coefficients are assumed to be constant over the region.
However, in some applications, coefficientsareexpectedto vary at the local or subregional level. Herewe focus on the local case. Although
parametric modeling of the spatial surface for the coefficient is possible, here we argue that it is more natural and flexible to view the
surface as a realization from a spatial process. We show how such modeling can be formalized in the context of Gaussian responses
providing attractive interpretation in terms of bot hrandom effects and explaining residuals. We also offer extensions to generalized linear
models andto spatio-temporal setting. We illustrate both static and dynamic modeling with a dataset that attempts to explain (log) selling
price of single-family houses.},
  File                     = {:Spatial Modeling with Spatially Varying Coefficient Processes.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.25}
}

@Book{Gelman2013,
  Title                    = {Bayesian Data Analysis},
  Author                   = {Andrew Gelman and John B. Carlin and Hal S. Stern and David B. Dunson and Aki Vehtari and Donald B. Rubin},
  Publisher                = {CRC Press},
  Year                     = {2013},
  Edition                  = {3rd},
  Series                   = {Chapman \& Hall/CRC Texts in Statistical Science},

  Owner                    = {jaq},
  Timestamp                = {2016.02.15}
}

@Article{Gelman1992,
  Title                    = {Inference from Iterative Simulation Using Multiple Sequences},
  Author                   = {Andrew Gelman and Donald B. Rubin},
  Journal                  = {Statistical Science},
  Year                     = {1992},
  Number                   = {4},
  Pages                    = {457-472},
  Volume                   = {7},

  Abstract                 = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  File                     = {:Inference from Iterative Simulation Using Multiple Sequences.pdf:PDF},
  Keywords                 = {Convergence, bayesian inference, stochastic, EM, ECM, Gibbs, metropolis, random effects, SIR},
  Owner                    = {jaq},
  Timestamp                = {2016.02.12}
}

@Article{Gringorten1963,
  Title                    = {A plotting rule for extreme probability paper},
  Author                   = {Irving I. Gringorten},
  Journal                  = {Journal of Geophysical Research},
  Year                     = {1963},
  Number                   = {3},
  Pages                    = {813-814},
  Volume                   = {68},

  File                     = {:Hydrology\\A plotting rule for extreme probability paper.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.27}
}

@Article{Guitouni1998,
  author    = {Adel Guitouni and Jean-Marc Martel},
  title     = {Tentative guidelines to help choosing an appropriate MCDA method},
  journal   = {European Journal of Operational Research},
  year      = {1998},
  volume    = {19},
  pages     = {501-521},
  abstract  = {Despite the development of a large number of re®ned multicriterion decision aid (MCDA) methods, none can be
considered as the `super method' appropriate to all decision making situations. Hence, how can one choose an appropriate
method to a speci®c decision situation? Recent experimental studies in psychology and behaviour have revealed,
on the one hand, that the human thinking is not to be modelled by logical rules and calculations, and, on the other
hand, that the response mode aects the preference formation as well as the use of compensatory or noncompensatory
strategies. The aim of this paper is to draw a conceptual framework for articulating tentative guidelines to choose an
appropriate MCDA method. This paper also presents the results of the comparison of well known multicriterion aggregation
procedures (MCAP) on the basis of these guidelines. In our opinion this study can constitute a ®rst step
for proposing a methodological approach to select an appropriate MCDA method to a speci®c decision making situation.
Such an approach should be validated and may be integrated into a decision support system. Moreover, the
framework suggested is helpful to develop useful methods and to address neglected issues within the ®eld},
  file      = {:Optimization\\MCDA\\Tentative guidelines to help choosing an appropriate MCDA.pdf:PDF},
  keywords  = {Multicriteria analysis; Decision making situation; Multicriterion decision aid method; Multicriterion aggregation procedure; Comparative analysis; Preferences modelling; Behavioural considerations},
  owner     = {jaq},
  timestamp = {2016.06.03},
}

@Article{Gupta2009,
  Title                    = {Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling},
  Author                   = {Hoshin V. Gupta and Harald Kling and Koray K. Yilmaz and Guillermo F. Martinez},
  Journal                  = {Journal of Hydrology},
  Year                     = {2009},
  Volume                   = {377},

  Abstract                 = {The mean squared error (MSE) and the related normalization, the Nash–Sutcliffe efficiency (NSE), are the
two criteria most widely used for calibration and evaluation of hydrological models with observed data.
Here, we present a diagnostically interesting decomposition of NSE (and hence MSE), which facilitates
analysis of the relative importance of its different components in the context of hydrological modelling,
and show how model calibration problems can arise due to interactions among these components. The
analysis is illustrated by calibrating a simple conceptual precipitation-runoff model to daily data for a
number of Austrian basins having a broad range of hydro-meteorological characteristics. Evaluation of
the results clearly demonstrates the problems that can be associated with any calibration based on the
NSE (or MSE) criterion. While we propose and test an alternative criterion that can help to reduce model
calibration problems, the primary purpose of this study is not to present an improved measure of model
performance. Instead, we seek to show that there are systematic problems inherent with any optimization
based on formulations related to the MSE. The analysis and results have implications to the manner
in which we calibrate and evaluate environmental models; we discuss these and suggest possible ways
forward that may move us towards an improved and diagnostically meaningful approach to model performance
evaluation and identification.},
  File                     = {:Decomposition of the mean squared error and NSE performance criteria-Implications for improving hydrological modelling.pdf:PDF},
  Keywords                 = {KGE, Kling-Gupta
Mean squared error
Nash–Sutcliffe efficiency
Model performance evaluation
Calibration
Multiple criteria
Criteria decomposition},
  Owner                    = {jaq},
  Timestamp                = {2016.02.12}
}

@Article{Haberlandt2008,
  Title                    = {A space-time hybrid hourly rainfall model for derived flood frequency analysis},
  Author                   = {U. Haberlandt and A.-D. Ebner von Eschenbach and I. Buchwald},
  Journal                  = {Hydrol. Earth Syst. Sci.},
  Year                     = {2008},
  Pages                    = {1353-1367},
  Volume                   = {12},

  Abstract                 = {For derived flood frequency analysis based on hydrological modelling long continuous precipitation time series with high temporal resolution are needed. Often, the observation network with recording rainfall gauges is poor, especially regarding the limited length of the available rainfall time series. Stochastic precipitation synthesis is a good alternative either to extend or to regionalise rainfall series to provide adequate input for long-term rainfall-runoff modelling with subsequent estimation of design floods. Here, a new two step procedure for stochastic synthesis of continuous hourly space-time rainfall is proposed and tested for the extension of short observed precipitation time series. 

First, a single-site alternating renewal model is presented to simulate independent hourly precipitation time series for several locations. The alternating renewal model describes wet spell durations, dry spell durations and wet spell intensities using univariate frequency distributions separately for two seasons. The dependence between wet spell intensity and duration is accounted for by 2-copulas. For disaggregation of the wet spells into hourly intensities a predefined profile is used. In the second step a multi-site resampling procedure is applied on the synthetic point rainfall event series to reproduce the spatial dependence structure of rainfall. Resampling is carried out successively on all synthetic event series using simulated annealing with an objective function considering three bivariate spatial rainfall characteristics. In a case study synthetic precipitation is generated for some locations with short observation records in two mesoscale catchments of the Bode river basin located in northern Germany. The synthetic rainfall data are then applied for derived flood frequency analysis using the hydrological model HEC-HMS. The results show good performance in reproducing average and extreme rainfall characteristics as well as in reproducing observed flood frequencies. The presented model has the potential to be used for ungauged locations through regionalisation of the model parameters.},
  File                     = {:A space-time hybrid hourly rainfall model for derived flood frequency analysis.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@TechReport{Hansen1998,
  Title                    = {Evaluating the quality of approximation to the non-dominated set},
  Author                   = {Michael Pilegaard Hansen and Andrzej Jaszkiewicz},
  Institution              = {IMM Technical Report},
  Year                     = {1998},
  Number                   = {IMM-REP-1998-7},

  Abstract                 = {The growing interest in hard multiple objective combinatorial and non-linear
problems resulted in a significant number of heuristic methods aiming at generating sets of
feasible solutions as approximations to the set of non-dominated solutions. The issue of
evaluating these approximations is addressed. Such evaluations are useful when performing
experimental comparisons of different multiple objective heuristic algorithms, when defining
stopping rules of multiple objective heuristic algorithms, and when adjusting parameters of
heuristic algorithms to a given problem. A family of outperformance relations that can be used
to compare approximations under very weak assumptions about a decision-maker’s
preferences is introduced. These outperformance relations define incomplete orders in the set
of all approximations. It is shown that in order to compare approximations, which are
incomparable according to the outperformance relations, much stronger assumptions about the
decision-maker's preferences are necessary. A general framework that can be used to compare
and evaluate approximations under the presence of various types of additional information is
proposed. Some particular comparison and evaluation methods based on this framework are
suggested. The proposed framework is also used to characterize some previously proposed
evaluation methods.},
  File                     = {:Evaluating the quality of approximation to the non-dominated set.pdf:PDF},
  Keywords                 = {Multiple objective optimization; Heuristics; Evaluation},
  Owner                    = {jaq},
  Timestamp                = {2016.03.23}
}

@TechReport{Hidalgo2008,
  Title                    = {Downscaling with Constructed Analogues: Daily Precipitation and Temperature Fields over the United States},
  Author                   = {Hidalgo, H G and Dettinger, M D and Cayan, D C},
  Institution              = {California Energy Commission Report},
  Year                     = {2008},

  File                     = {:Downscaling with Constructed Analogues- Daily Precipitation and Temperature Fields over the United States.PDF:PDF},
  Keywords                 = {BCCA},
  Owner                    = {jaq},
  Timestamp                = {2016.03.14}
}

@Article{Hosking1990,
  Title                    = {L-Moments: Analysis and Estimation of Distributions Using Linear Combinations of Order Statistics},
  Author                   = {J. R. M. Hosking},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Methodological)},
  Year                     = {1990},
  Number                   = {1},
  Pages                    = {105-124},
  Volume                   = {52},

  Abstract                 = {L-moments are expectations of certain linear combinations of order statistics. They can be
defined for any random variable whose mean exists and form the basis of a general theory
which covers the summarization and description of theoretical probability distributions, the
summarization and descriptionof observeddata samples,estimationof parametersand
quantilesofprobability distributions, andhypothesis testsforprobability distributions. The
theory involves such established procedures as the use of orderstatistics and Gini's mean
difference statistic,and gives rise to some promising innovations such as the measures of
skewness and kurtosis described in Section2, and new methods of parameter estimation for
several distributions. The theory of L-moments parallels the theory of (conventional)
moments, as this list of applications might suggest. The main advantage of L-moments over
conventional moments is that L-moments, being linear functions of the data, suffer less
from the effects of sampling variability: L-moments are more robust than conventional
moments to outliers in the data and enable more secure inferences to be made from small
samples about an underlying probability distribution. L-moments sometimes yield more
efficient parameter estimates than the maximum likelihood estimates.},
  File                     = {:L-Moments- Analysis and Estimation of Distributions Using Linear Combinations of Order Statistics.pdf:PDF},
  Keywords                 = {ESTIMATION; HYPOTHESIS TESTING; KURTOSIS; L-STATISTICS; MOMENTS; ORDER
STATISTICS; SKEWNESS},
  Owner                    = {jaq},
  Timestamp                = {2016.02.18}
}

@Article{Hosking1993,
  Title                    = {Some statistics useful in regional frequency analysis},
  Author                   = {Hosking, J. R. M. and Wallis, J. R.},
  Journal                  = {Water Resources Research},
  Year                     = {1993},
  Number                   = {2},
  Pages                    = {271--281},
  Volume                   = {29},

  Abstract                 = {Regional frequency analysis uses data from a number of measuring sites. A “region” is a group of sites each of which is assumed to have data drawn from the same frequency distribution. The analysis involves the assignment of sites to regions, testing whether the proposed regions are indeed homogeneous, and choice of suitable distributions to fit to each region's data. This paper describes three statistics useful in regional frequency analysis: a discordancy measure, for identifying unusual sites in a region; a heterogeneity measure, for assessing whether a proposed region is homogeneous; and a goodness-of-fit measure, for assessing whether a candidate distribution provides an adequate fit to the data. Tests based on the statistics provide objective backing for the decisions involved in regional frequency analysis. The statistics are based on the L moments [Hosking, 1990] of the at-site data.},
  Doi                      = {10.1029/92WR01980},
  File                     = {:Some Statistics Useful in Regional Frequency Analysis.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Precipitation, Streamflow, Instruments and techniques: modeling},
  Owner                    = {jaq},
  Timestamp                = {2016.02.18},
  Url                      = {http://dx.doi.org/10.1029/92WR01980}
}

@Article{Hossain2013,
  Title                    = {Intelligent Systems in Optimizing Reservoir Operation Policy: A Review},
  Author                   = {Shabbir Hossain and A. El-shafie},
  Journal                  = {Water Resources Management},
  Year                     = {2013},

  Abstract                 = {The paper presents a survey of several optimization techniques, mainly artificial
intelligences (AIs) which have been applied to the reservoir operation modelling whether its
single or multi-reservoir system. The reservoir system modeling is essential for any nations
and the optimal use of it is always asked. The main objective of this review article is to
discuss the potentiality of the evolutionary algorithms (EAs) and the ability to integrate with
other techniques which can provide the best results. Also the formulation of these types of
application has described on the ground of a well known benchmark problem regarding this
field. The traditional algorithms got some drawbacks. The study provides a complete
understanding to the EA users about next generation optimal search procedure and help to
overcome the drawbacks. Though the background of application number of swarm intelligences is less comparatively than the genetic algorithm (GA), it provides a great scope for
the researcher for further development. Also comparative results with other popular methods
(such as, linear programming, stochastic dynamic programming) are discussed on the basis
of past research results. Conclusions and suggestive remarks are made for the help of
researchers and the reservoir decision makers as well.},
  File                     = {:Optimization\\Intelligent Systems in Optimizing Reservoir Operation Policy.pdf:PDF},
  Keywords                 = {Reservoir operation . Genetic algorithm . Evolutionary computations . Swarm intelligence},
  Owner                    = {jaq},
  Timestamp                = {2016.01.15}
}

@Article{Houtekamer2005,
  Title                    = {Ensemble Kalman Filtering},
  Author                   = {P. L. Houtekamer And Herschel L. Mitchell},
  Journal                  = {Q. J. R. Meteorol. Soc.},
  Year                     = {2005},

  Abstract                 = {An ensemble Kalman filter (EnKF) has been implemented at the Canadian Meteorological Centre to provide
an ensemble of initial conditions for the medium-range ensemble prediction system. This demonstrates that the
EnKF can be used for operational atmospheric data assimilation.
We show how the EnKF relates to the Kalman filter. In particular, to make the ensemble approximation
feasible, we have to use a fairly small ensemble with many less members than either the number of model
coordinates, or the number of independent observations, or the (unknown) dimension of the dynamical system.
To nevertheless obtain good results, we must (i) counter the tendency of the ensemble spread to underestimate
the true error, and (ii) localize the ensemble covariances. The localization is severe and leads to imbalance in the
initial conditions.
The operational EnKF is used to investigate to what extent our system respects the underlying hypotheses
of both the Kalman filter and its ensemble approximation. In particular, we quantify the imbalance in the initial
conditions and the magnitude of the model-error component. The occurrence of imbalance constrains the ways in
which time interpolation can be performed and in which parametrized model error can be added. With this study
we hope to obtain and provide guidance for further improvements to the EnKF.b},
  File                     = {:Ensemble Kalman Filtering.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Huang1996,
  Title                    = {Spatio-temporal prediction of snow water equivalent using the Kalman filter},
  Author                   = {Hsin-Cheng Huang and Noel Cressie},
  Journal                  = {Computational Statistics \& Data Analysis},
  Year                     = {1996},
  Volume                   = {22},

  Abstract                 = {Consider a spatio-temporal stochastic process {Z(s; t): s e D; t = 1, 2.... } and suppose it is of
interest to predict {Z(s; to): s e D} at some fixed time point to. Purely spatial methods use data
Z(sl;to) ..... Z(s,;to) to construct a spatial predictor (e.g., kriging). But, when data {Z(si;t):
i = 1,..., n; t = 1, 2,..., to} are available, it is advantageous to treat the problem as one of spatiotemporal prediction. The US National Weather Service now use current snow water equivalent (SWE)
data and a purely spatial model to predict SWE at sites where no observations are available. To
improve SWE predictions, we introduce a spatio-temporal model that incorporates the SWE data
from the past, resulting in a Kalman-filter prediction algorithm. A simple procedure for estimating the
parameters in the model is developed and an example is presented for the Animas River basin in
southwest Colorado.},
  File                     = {:Spatio-temporal prediction of snow water equivalent using the Kalman filter.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.25}
}

@Article{Hundecha2009,
  Title                    = {Modeling of daily precipitation at multiple locations using a mixture of distributions to characterize the extremes},
  Author                   = {Hundecha, Yeshewatesfa and Pahlow, Markus and Schumann, Andreas},
  Journal                  = {Water Resources Research},
  Year                     = {2009},
  Number                   = {12},
  Pages                    = {n/a--n/a},
  Volume                   = {45},

  Abstract                 = {A stochastic model for the generation of daily time series of rainfall at multiple locations in which the amount of daily rainfall is modeled by a mixture of two different probability distribution functions is presented. A mixture model is implemented with the specific objective of characterizing extremes of daily precipitation. The approach is based on the assumption that the extremes within a time series have a different stochastic behavior compared to the normal regime of precipitation. A multivariate autoregressive model is used to model the local probability of occurrence of rainfall and the amount while keeping the intersite covariance structure using a truncated normal distribution. The amount simulated using the truncated normal distribution is further transformed so that it can be regarded as coming from the actual distribution fitted to the daily precipitation at each station using the probability integral transformation. The seasonal cycles of the amount as well as the temporal and spatial correlations of the daily precipitation are incorporated by fitting the model on the monthly basis. Application was made on 122 stations within the Unstrut catchment with an area of 6343 km2 in central eastern Germany. Results show that the model can fairly well reproduce a number of statistical features of daily precipitation including the extreme value distribution of the annual maximum daily and 3 day total precipitation, both at individual stations and at the catchment scale.},
  Doi                      = {10.1029/2008WR007453},
  File                     = {:Hydrology\\Modeling of daily precipitation at multiple locations using a mixture of distributions to characterize the extremes.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {daily precipitation, multisite rainfall generator, multivariate autoregressive model, mixed distribution, Unstrut, extreme precipitation},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07},
  Url                      = {http://dx.doi.org/10.1029/2008WR007453}
}

@Article{Hunt2007,
  Title                    = {Efficient data assimilation for spatiotemporal chaos: A local ensemble transform Kalman filter},
  Author                   = {Brian R. Hunt and Eric J. Kostelich and Istvan Szunyogh},
  Journal                  = {Physica D},
  Year                     = {2007},
  Pages                    = {112-126},
  Volume                   = {230},

  Abstract                 = {Data assimilation is an iterative approach to the problem of estimating the state of a dynamical system using both current and past observations
of the system together with a model for the system’s time evolution. Rather than solving the problem from scratch each time new observations
become available, one uses the model to “forecast” the current state, using a prior state estimate (which incorporates information from past data) as
the initial condition, then uses current data to correct the prior forecast to a current state estimate. This Bayesian approach is most effective when
the uncertainty in both the observations and in the state estimate, as it evolves over time, are accurately quantified. In this article, we describe a
practical method for data assimilation in large, spatiotemporally chaotic systems. The method is a type of “ensemble Kalman filter”, in which the
state estimate and its approximate uncertainty are represented at any given time by an ensemble of system states. We discuss both the mathematical
basis of this approach and its implementation; our primary emphasis is on ease of use and computational speed rather than improving accuracy
over previously published approaches to ensemble Kalman filtering. We include some numerical results demonstrating the efficiency and accuracy
of our implementation for assimilating real atmospheric data with the global forecast model used by the US National Weather Service.},
  File                     = {:Efficient data assimilation for spatiotemporal chaos- A local ensemble.pdf:PDF},
  Keywords                 = {Data assimilation; Spatiotemporal chaos; State estimation; Ensemble Kalman filtering},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Hutchinson1995,
  Title                    = {Stochastic space-time weather models from ground-based data},
  Author                   = {M.F. Hutchinson},
  Journal                  = {Agricultural and Forest Meteorology},
  Year                     = {1995},
  Number                   = {3-4},
  Volume                   = {73},

  Abstract                 = {The development of space-time stochastic weather models from data obtained from standard meteorological networks is examined. The approach adopted is first to identify appropriate stochastic point models whose parameters can be calibrated from point data and reliably spatially interpolated. Following standard statistical climatological practice, the space-time covariance structure of the resulting weather anomalies can then be used to develop space-time simulation models which generate correlated anomalies of rainfall and other variables. Two stochastic point daily rainfall models illustrate competing requirements of physical realism and economy of parameterisation. Weather model parameters can be accurately interpolated using statistical methods which incorporate spatially varying dependences on elevation. These methods can also apply objective data smoothing to incorporate serially incomplete data. The truncated power of normal distribution is shown to be a promising candidate for space-time simulation of rainfall, on both monthly and daily time scales, provided problems associated with systematic differences between occurrence-based and intensity-based correlations can be resolved. It is suggested that monthly space-time models, which are reasonably well determined from standard meteorological networks, are sufficient to resolve much ecological and hydrological behaviour, particularly at spatial resolutions of a few kilometres. They also form a useful precursor to daily space-time stochastic models.},
  File                     = {:Hydrology\\Stochastic space-time weather models from ground-based data.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.27}
}

@Conference{Kasprzyka2012,
  author    = {Joseph R. Kasprzyka and Shanthi Natarajb and Patrick M. Reeda and Robert J. Lempert},
  title     = {Many-Objective Robust Decision Making for Water Supply Portfolio Planning Under Deep Uncertainty},
  booktitle = {Managing Resources of a Limited Planet},
  year      = {2012},
  abstract  = {Portfolios of market-based instruments have been shown to improve the
reliability of water supplies, using simulations that utilize a single best estimate of
distributions of data to evaluate performance. However, the estimates of problem
information and likelihoods could be incorrect, especially when planning for climate
change, which can modify streamflow availability, or projecting the trajectories of
future water demands. These conditions are termed deep uncertainty, in which
decision makers cannot fully conceptualize or agree upon the full range of risks to
their system. This presentation will advance a new interactive framework that
combines robust decision making (RDM) with many-objective optimization using
evolutionary algorithms (MOEA) to confront deep uncertainty for water planning.
The framework is demonstrated using a case study that examines a single city's
water supply in the Lower Rio Grande Valley (LRGV) in Texas, USA. We use a
MOEA to develop a tradeoff set of water supply portfolios for the LRGV, and
develop a suite of values for key uncertainties using RDM that represent an
ensemble of “states of the world”. Each solution is tested under the ensemble of
plausible future states of the world, with interactive visualizations being used to
identify robust solutions for the system. Scenario discovery methods that use
statistical data mining algorithms are then used to identify what assumptions and
system conditions strongly control the cost-effectiveness, efficiency, and reliability
of the robust alternatives. The results suggest that combining robust decision
making, many-objective optimization, and visual analytics can dramatically improve
risk-based planning decisions.},
  file      = {:MCDA\\Many objective robust decision making for complex environmental systems undergoing change.pdf:PDF},
  keywords  = {robust decision making, many-objective optimization, water supply, interactive visual analytics},
  owner     = {jaq},
  timestamp = {2017-01-05},
}

@Article{Kelman1990,
  author    = {Jerson Kelman and Jery Stendinger and Lisa Cooper and Eric Hsu and Sun-Quan Yuan},
  title     = {Sampling Stochastic Dynamic Programming Applied to Reservoir Operation},
  journal   = {Water Resources Research},
  year      = {1990},
  volume    = {26},
  number    = {3},
  abstract  = {Most models for reservoir operation optimization have employed either deterministic optimization or stochastic dynamic programming algorithms. This paper develops sampling stochastic dynamic programming (SSDP), a technique that captures the complex temporal and spatial structure of the streamflow process by using a large number of sample streamflow sequences. The best inflow forecast can be included as a hydrologic state variable to improve the reservoir operating policy. A case study using the hydroelectric system on the North Fork of the Feather River in California illustrates the SSDP approach and its performance.},
  file      = {:Sampling Stochastic Dynamic Programming Applied to Reservoir Operation.pdf:PDF},
  owner     = {jaq},
  timestamp = {2016.01.13},
}

@Conference{Knowles2002,
  Title                    = {On metrics for comparing nondominated sets},
  Author                   = {Joshua Knowles and David Corne},
  Booktitle                = {Evolutionary Computation, 2002. CEC '02. Proceedings of the 2002 Congress on},
  Year                     = {2002},
  Pages                    = {711-716},
  Publisher                = {IEEE},
  Volume                   = {1},

  Abstract                 = {Evolutionary multiobjective optimization (EMO) boasts a proliferation of algorithms and benchmark problems. We need principled ways to compare the performance of different EMO algorithms, but this is complicated by the fact that the result of an EMO run is not a single scalar value, but a collection of vectors forming a nondominated set. Various metrics for nondominated sets have been suggested. We compare several, using the framework of 'outperformance relations' (Hansen and Jaszkiewicz, 1998). This enables us to criticize and contrast a variety of published metrics, leading to some recommendations on which seem most useful in practice},
  Doi                      = {10.1109/CEC.2002.1007013},
  File                     = {:On metrics for comparing nondominated sets.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.03.23}
}

@Book{Kutner2005,
  Title                    = {Applied Linear Statistical Models},
  Author                   = {Michael H. Kutner and Christopher J. Nachtsheim and John Neter and William Li},
  Publisher                = {McGraw-Hill},
  Year                     = {2005},
  Edition                  = {5th},

  Owner                    = {quebbs},
  Timestamp                = {2015.11.24}
}

@Article{Labadie2004,
  author    = {John W. Labadie},
  title     = {Optimal Operation of Multireservoir Systems: State-of-the-Art Review},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2004},
  volume    = {130},
  number    = {2},
  pages     = {93-111},
  abstract  = {With construction of new large-scale water storage projects on the wane in the U.S. and other developed countries, attention
must focus on improving the operational effectiveness and efficiency of existing reservoir systems for maximizing the beneficial uses of
these projects. Optimal coordination of the many facets of reservoir systems requires the assistance of computer modeling tools to provide
information for rational management and operational decisions. The purpose of this review is to assess the state-of-the-art in optimization
of reservoir system management and operations and consider future directions for additional research and application. Optimization
methods designed to prevail over the high-dimensional, dynamic, nonlinear, and stochastic characteristics of reservoir systems are
scrutinized, as well as extensions into multiobjective optimization. Application of heuristic programming methods using evolutionary and
genetic algorithms are described, along with application of neural networks and fuzzy rule-based systems for inferring reservoir system
operating rules.},
  file      = {:Optimization\\Optimal Operation of Multireservoir Systems- State of the art review.pdf:PDF},
  owner     = {jaq},
  timestamp = {2016.02.24},
}

@Article{Labadie2010,
  Title                    = {Fuzzy optimal control of reservoir-assisted stormwater treatment areas for aquatic ecosystem restoration},
  Author                   = {John W. Labadie and Yongshan Wan},
  Journal                  = {Environmental Modelling and Software},
  Year                     = {2010},
  Pages                    = {1692-1701},
  Volume                   = {25},

  Abstract                 = {Attachment of stormwater treatment areas (STAs) or constructed wetlands to stormwater retention
reservoirs can achieve substantial reductions in pollutant loadings if properly operated and maintained.
Besides water quality improvement, optimally operated reservoir-assisted STAs provide support for
ecosystem remediation, flood control, and supplemental water supply. An adaptive, multiobjective realtime control model is developed for reservoir-assisted STA systems that incorporates fuzzy rule-based
operating rules optimized using a genetic algorithm interacting with a simulation model of the system.
The model is applied to the North Fork reservoir-assisted STA located in the watershed of the St. Lucie
Estuary, Florida. Optimal daily feedback operational policies are developed for managing freshwater
discharges to the Estuary for coastal ecosystem restoration, maximizing the natural treatment efficiency
and of the STA, and providing supplemental water supply for irrigation. Testing and validation results
from application of the fuzzy optimal control model confirm achievement of multiple targets and criteria
for the North Fork project, while demonstrating potential for adaptive management of reservoir-assisted
STA systems throughout the coastal regions of south Florida.},
  File                     = {:Optimization\\Fuzzy optimal control of reservoir-assisted stormwater treatment areas for aquatic ecosystem restoration.pdf:PDF},
  Keywords                 = {Aquatic ecosystems
Constructed wetlands
Evolutionary algorithm
Fuzzy control
Real-time operations
Stormwater retention basins
Stormwater treatment areas},
  Owner                    = {jaq},
  Timestamp                = {2016.05.10}
}

@Article{Labadie2012,
  Title                    = {Optimal integrated operation of reservoir-assisted stormwater treatment areas for estuarine habitat restoration},
  Author                   = {John W. Labadie and Fawen Zheng and Yongshan Wan},
  Journal                  = {Environmental Modelling and Software},
  Year                     = {2012},
  Pages                    = {271-282},
  Volume                   = {38},

  Abstract                 = {Significant reductions in pollutant loadings can be achieved through coordinated operation of constructed wetlands or stormwater treatment areas (STAs) when connected to retention reservoirs for maintaining ideal water levels and hydraulic residence times in STAs that maximize treatment efficiency. Reservoir-assisted STA systems can provide additional benefits including maintenance of target frequency distributions of stormwater inflows into coastal estuarine systems for ecosystem rehabilitation, dry season flow augmentation in coastal riverine systems for maintaining the lower salinity zone, and supplemental water supply. An implicit stochastic optimization approach is applied to adaptive, multiobjective control of interconnected reservoir-assisted STAs that optimizes fuzzy rule-based operating rules using a genetic algorithm interacting with a simulation model of the stormwater drainage system. The model is applied to the four interconnected reservoir/STAs in the design configuration of the Indian River Lagoon-South project for the St. Lucie River watershed and estuary, South Florida. Results of
simulated long-term performance of the optimal operating rules show attainment of targets for remediation of the aquatic ecology of the St. Lucie estuary, riverine environmental protection, and reliable supplemental water supply.},
  File                     = {:Optimization\\Optimal integrated operation of reservoir-assisted stormwater treatment areas for estuarine habitat restoration.pdf:PDF},
  Keywords                 = {Coastal ecosystems
Constructed wetlands
Genetic algorithm
Fuzzy optimal control
Real-time operations
Stormwater retention basins
Stormwater treatment areas},
  Owner                    = {jaq},
  Timestamp                = {2016.05.10}
}

@Article{Lall1996,
  Title                    = {A nearest neighbor bootstrap for resampling hydrologic time series},
  Author                   = {Upmanu Lall and Ashish Sharma},
  Journal                  = {Water Resources Research},
  Year                     = {1996},
  Number                   = {3},
  Pages                    = {679-693},
  Volume                   = {32},

  Abstract                 = {A nonparametric method for resampling scalar or vector-valued time series is introduced. Multivariate nearest neighbor probability density estimation provides the basis for the resampling scheme developed. The motivation for this work comes from a desire to preserve the dependence structure of the time series while bootstrapping (resampling it with replacement). The method is data driven and is preferred where the investigator is uncomfortable with prior assumptions as to the form (e.g., linear or nonlinear) of dependence and the form of the probability density function (e.g., Gaussian). Such prior assumptions are often made in an ad hoc manner for analyzing hydrologic data. Connections of the nearest neighbor bootstrap to Markov processes as well as its utility in a general Monte Carlo setting are discussed. Applications to resampling monthly streamflow and some synthetic data are presented. The method is shown to be effective with time series generated by linear and nonlinear autoregressive models. The utility of the method for resampling monthly streamflow sequences with asymmetric and bimodal marginal probability densities is also demonstrated.},
  Doi                      = {10.1029/95WR02966},
  File                     = {:A nearest neighbor bootstrap for resampling hydrologic time series.pdf:PDF},
  Keywords                 = {GCV Score Generalized Cross Validation, Adaptive Shifted Histograms ASH},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Lambert1998,
  Title                    = {Seasonal generalized exponential probability models with application to interstorm and storm durations},
  Author                   = {Martin Lambert and George Kuczera},
  Journal                  = {Water Resources Research},
  Year                     = {1998},

  Month                    = {January},
  Number                   = {1},
  Pages                    = {143-148},
  Volume                   = {34},

  Abstract                 = {A simple generalization of the exponential probability model is presented which provides a flexible method for identifying and fitting probability distributions. When coupled with likelihood-based estimation, this approach enables a parsimonious description of seasonal dependence using harmonic functions. A case study involving modeling of interstorm and storm durations for several Australian state capitals illustrates practical issues in calibration and identification. Because the rainfall data were stored in a binned format consisting of rainfall depths accumulated over fixed time intervals, the start and end times of storms were known only to the resolution of the fixed time interval. A likelihood function is developed which properly makes use of such information. Likelihood ratio statistics along with monthly distribution plots are used to select the number of harmonics necessary to model seasonal dependence. It is shown for Melbourne that a single harmonic adequately describes seasonal dependence, thereby reducing the number of parameters from 48 to 6.},
  Doi                      = {10.1029/97WR02767},
  File                     = {:Hydrology\\Seasonal generalized exponential probability models with application to interstorm and storm durations.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.15}
}

@PhdThesis{Lamontagne2015,
  Title                    = {Representation of Uncertainty and Corridor DP for Hydropower Optimization},
  Author                   = {Jonathan Richard Lamontagne},
  School                   = {Cornell University},
  Year                     = {2015},

  Abstract                 = {This thesis focuses on optimization techniques for multi-reservoir hydropower
systems operation, with a particular concern with the representation and impact of
uncertainty. The thesis reports on three research investigations: 1) examination of the
impact of uncertainty representations, 2) efficient solution methods for multi-reservoir
stochastic dynamic programming (SDP) models, and 3) diagnostic analyses for
hydropower system operation.
The first investigation explores the value of sophistication in the representation
of forecast and inflow uncertainty in stochastic hydropower optimization models using
a sampling SDP (SSDP) model framework. SSDP models with different uncertainty
representation ranging in sophistication from simple deterministic to complex dynamic
stochastic models are employed when optimize a single reservoir systems [similar to
Faber and Stedinger, 2001]. The effect of uncertainty representation on simulated
system performance is examined with varying storage and powerhouse capacity, and
with random or mean energy prices. In many cases very simple uncertainty models
perform as well as more complex ones, but not always.
The second investigation develops a new and efficient algorithm for solving
multi-reservoir SDP models: Corridor SDP. Rather than employing a uniform grid
across the entire state space, Corridor SDP efficiently concentrates points in where the
system is likely to visit, as determined by historical operations or simulation. Radial
basis functions (RBFs) are used for interpolation. A greedy algorithm places points
where they are needed to achieve a good approximation. In a four-reservoir test case,
Corridor DP achieves the same accuracy as spline-DP and linear-DP with
approximately 1/10 and 1/1100 the number of discrete points, respectively. When
local curvature is more pronounced (due to minimum-flow constraints), Corridor DP
achieves the same accuracy as spline-DP and linear-DP with approximately 1/30 and
1/215 the number of points, respectively.
The third investigation explores three diagnostic approaches for analyzing
hydropower system operation. First, several simple diagnostic statistics describe
reservoir volume and powerhouse capacity in units of time, allowing scale-invariant
comparisons and classification of different reservoir systems and their operation.
Second, a regression analysis using optimal storage/release sequences identifies the
most useful hydrologic state variables . Finally spectral density estimation identifies
critical time scales for operation for several single-reservoir systems considering mean
and random energy prices.
Deregulation of energy markets has made optimization of hydropower
operations an active concern. Another development is publication of Extended
Streamflow Forecasts (ESP) by the National Weather Service (NWS) and others to
describe flow forecasts and their precision; the multivariate Sampling SDP models
employed here are appropriately structured to incorporate such information in
operational hydropower decisions. This research contributes to our ability to structure
and build effective hydropower optimization models.},
  File                     = {:Representation of Uncertainty and Corridor DP for Hydropower Optimization.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.13}
}

@Article{Lee2009,
  Title                    = {Large engineering project risk management using a Bayesian belief network},
  Author                   = {Eunchang Lee and Yongtae Park and Jong Gye Shin},
  Journal                  = {Expert Systems with Applications},
  Year                     = {2009},

  Abstract                 = {This paper presents a scheme for large engineering project risk management using a Bayesian belief network and applies it to the Korean shipbuilding industry. Twenty-six different risks were deduced from
expert interviews and a literature review. A survey analysis was conducted on 252 experts from 11 major
Korean shipbuilding companies in April 2007. The overall major risks were design change, design manpower, and raw material supply as internal risks, and exchange rate as external risk in both large-scale
and medium-sized shipbuilding companies. Differences of project performance risks between large-scale
and medium-sized shipbuilding companies were identified. Exceeding time schedule and specification
discontent were more important to large-scale shipbuilding companies, while exceeding budget and
exceeding time schedule were more important to medium-sized shipbuilding companies. The change
of project performance risks was measured by risk reduction activities of quality management, and
strikes at headquarters and subcontractors, in both large-scale and medium-sized shipbuilding companies. The research results should be valuable in enabling industrial participants to manage their large
engineering project risks and in extending our understanding of Korean shipbuilding risks.},
  File                     = {:Large engineering project risk management using a Bayesian belief network (1).pdf:PDF},
  Keywords                 = {Risk management in large engineering
projects
Shipbuilding industry
Bayesian belief network},
  Owner                    = {jaq},
  Timestamp                = {2016.01.19}
}

@Article{Lee2007,
  Title                    = {Stochastic optimization of multireservoir systems via reinforcement learning},
  Author                   = {Lee, Jin-Hee and Labadie, John W.},
  Journal                  = {Water Resources Research},
  Year                     = {2007},
  Note                     = {W11408},
  Number                   = {11},
  Pages                    = {n/a--n/a},
  Volume                   = {43},

  Abstract                 = {Although several variants of stochastic dynamic programming have been applied to optimal operation of multireservoir systems, they have been plagued by a high-dimensional state space and the inability to accurately incorporate the stochastic environment as characterized by temporally and spatially correlated hydrologic inflows. Reinforcement learning has emerged as an effective approach to solving sequential decision problems by combining concepts from artificial intelligence, cognitive science, and operations research. A reinforcement learning system has a mathematical foundation similar to dynamic programming and Markov decision processes, with the goal of maximizing the long-term reward or returns as conditioned on the state of the system environment and the immediate reward obtained from operational decisions. Reinforcement learning can include Monte Carlo simulation where transition probabilities and rewards are not explicitly known a priori. The Q-Learning method in reinforcement learning is demonstrated on the two-reservoir Geum River system, South Korea, and is shown to outperform implicit stochastic dynamic programming and sampling stochastic dynamic programming methods.},
  Doi                      = {10.1029/2006WR005627},
  File                     = {:Optimization\\Stochastic optimization of multireservoir systems via reinforcement learning.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Hydrology: Reservoirs (surface), Stochastic hydrology, Water management, System operation and management, stochastic optimization, dynamic programming, reinforcement learning},
  Owner                    = {jaq},
  Timestamp                = {2016.05.01},
  Url                      = {http://dx.doi.org/10.1029/2006WR005627}
}

@Article{Leith1973,
  Title                    = {The Standard Error of Time-Average Estimates of Climatic Means},
  Author                   = {C. E. Leith},
  Journal                  = {Journal of Applied Meteorology},
  Year                     = {1973},
  Pages                    = {1066-1069},
  Volume                   = {12},

  Abstract                 = {Climate change studies with general circulation models require the estimation of climatic means by calculation of finite-time averages. A simple stochastic model is used to estimate the standard error of such an estimation method as a function of averaging time. Consequences for long-range forecasting are also discussed.},
  File                     = {:The Standard Error of Time-Averaging Estimates of Climatic Means.pdf:PDF},
  Keywords                 = {characteristic timescale},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Mahmoud2000,
  Title                    = {Comparison of different multicriteria evaluation methods for the Red Bluff diversion dam},
  Author                   = {Mohamed Rami Mahmoud and Luis A. Garcia},
  Journal                  = {Environmental Modelling and Software},
  Year                     = {2000},
  Pages                    = {471-478},
  Volume                   = {15},

  File                     = {:Optimization\\MCDA\\Comparison of different multicriteria evaluation methods for the Red Bluff diversion dam.pdf:PDF},
  Keywords                 = {Mathematical modeling; Water management; Multi-criteria evaluation; Optimization; Multipurpose reservoir; Alternative selection and decision support system DSS},
  Owner                    = {jaq},
  Timestamp                = {2016.05.16}
}

@Article{Matheson1976,
  author    = {James E. Matheson and Robert L. Winkler},
  title     = {Scoring Rules for Continuous Probability Distributions},
  journal   = {Management Science},
  year      = {1976},
  volume    = {22},
  number    = {10},
  pages     = {1087-1096},
  file      = {:Statistics\\Scoring Rules for Continuous Probability Distributions.pdf:PDF},
  keywords  = {CRPS},
  owner     = {jaq},
  timestamp = {2017-03-30},
}

@Article{Mccrodden2010,
  Title                    = {Drought Management- Probability-Based Operating Rules Improve Water Supply Management},
  Author                   = {Brian Mccrodden and Steven Nebiker and Leslie Carreiro},
  Journal                  = {Opflow},
  Year                     = {2010},

  Abstract                 = {Adding excess capacity to prepare for droughts is a common but expensive
practice. A risk-based drought plan that incorporates forecasting offers a
less expensive and often more reliable alternative.},
  File                     = {:Drought Management- Probability-Based Operating Rules Improve Water Supply Management.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.25}
}

@Article{Mehrotra2006,
  Title                    = {A comparison of three stochastic multi-site precipitation occurence generators},
  Author                   = {R. Mehrotra and R. Srikanthan and Ashish Sharma},
  Journal                  = {Journal of Hydrology},
  Year                     = {2006},
  Pages                    = {280-292},
  Volume                   = {331},

  Abstract                 = {This paper presents a comparison of three multi-site stochastic weather generators for simulation of point rainfall occurrences at a network of 30 raingauge stations around Sydney, Australia. The approaches considered include a parametric hidden Markov model (HMM), a multi-site stochastic precipitation generation model (proposed by [Wilks, D.S., 1998. Multisite generalization of a daily stochastic precipitation model, J. Hydrol. 210, 178–191.]) and a non-parametric K-nearest neighbour (KNN) model. The HMM generates the precipitation distribution conditional on a discrete weather state representing certain identified spatial rainfall distribution patterns. The spatial dependence is maintained by assumption of a common weather state across all stations while the temporal dependence is simulated by assuming the weather state to be Markovian in nature. The Wilks model preserves serial dependence through the assumption of an order one Markov dependence at each location. The spatial dependence is simulated by prescribing a dependence pattern on the uniform random variates used to generate the rainfall occurrence at each location from the associated conditional probability distribution. The K-nearest neighbour approach simulates spatial dependence by simultaneously generating precipitation occurrence at all locations. Temporal persistence is simulated through Markovian assumptions on the rainfall occurrence process. The three methods are evaluated for their ability to model spatial and temporal dependence in the rainfall occurrence field and also the relative ease with which the assumptions of spatial and temporal dependence can be accommodated. Our results indicate that all the approaches are successful in reproducing spatial dependence in the multi-site rainfall occurrence field. However, the different orders of assumed Markovian dependence in the observed data limit their ability in representing temporal dependence at time scales longer than a few days. While each approach comes with its own advantages and disadvantages, the alternative proposed by Wilks has an overall advantage in offering a mechanism for modelling varying orders of serial dependence at each point location, while still maintaining the observed spatial dependence with sufficient accuracy.},
  File                     = {:A comparison of three stochastic multi-site precipitation occurence generators.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Micovic2016,
  Title                    = {A non-traditional approach to the analysis of flood hazard for dams},
  Author                   = {Zoran Micovic and Desmond N. D. Hartford and Melvin G. Schaefer and Bruce L. Barker},
  Journal                  = {Stochastic Environmental Research and Risk Assessment},
  Year                     = {2016},
  Pages                    = {559-581},
  Volume                   = {30},

  Abstract                 = {The traditional and still prevailing approach to
characterization of flood hazards to dams is the inflow
design flood (IDF). The IDF, defined either deterministically or probabilistically, is necessary for sizing a dam, its
discharge facilities and reservoir storage. However, within
the dam safety risk informed decision framework, the IDF
does not carry much relevance, no matter how accurately it
is characterized. In many cases, the probability of the
reservoir inflow tells us little about the probability of dam
overtopping. Typically, the reservoir inflow and its associated probability of occurrence is modified by the interplay of a number of factors (reservoir storage, reservoir
operating rules and various operational faults and natural
disturbances) on its way to becoming the reservoir outflow
and corresponding peak level—the two parameters that
represent hydrologic hazard acting upon the dam. To
properly manage flood risk, it is essential to change approach to flood hazard analysis for dam safety from the
currently prevailing focus on reservoir inflows and instead
focus on reservoir outflows and corresponding reservoir
levels. To demonstrate these points, this paper presents
stochastic simulation of floods on a cascade system of three
dams and shows progression from exceedance probabilities
of reservoir inflow to exceedance probabilities of peak
reservoir level depending on initial reservoir level, storage
availability, reservoir operating rules and availability of
discharge facilities on demand. The results show that the
dam overtopping is more likely to be caused by a combination of a smaller flood and a system component failure
than by an extreme flood on its own.},
  Doi                      = {10.1007/s00477-015-1052-2},
  File                     = {:Hydrology\\A non-traditional approach to the analysis of flood hazard for dams.pdf:PDF},
  Keywords                 = {Hydrologic hazard , Stochastic flood ,
Dam safety , Spillway gate reliability , Risk assessment},
  Owner                    = {jaq},
  Timestamp                = {2016.02.22}
}

@Article{Moody2013,
  Title                    = {Robustness indicators for evaluation under climate change: Application to the upper Great Lakes},
  Author                   = {Moody, Paul and Brown, Casey},
  Journal                  = {Water Resources Research},
  Year                     = {2013},
  Number                   = {6},
  Pages                    = {3576--3588},
  Volume                   = {49},

  Abstract                 = {Given the range of future uncertainty, there is increasing interest in developing and evaluating water management strategies that are robust to an uncertain future. As part of a process termed “decision scaling,” a climate response function was developed to isolate the impact of climate change on a water system in terms of hazards identified by stakeholders. The climate response function was then used to evaluate system performance over a wide range of climate conditions and to define robustness indicators. The robustness indicators, which measure system performance as a function of climate state, are conditioned on explicit assumptions about climate variable probability distributions. To illustrate this process, it is applied to the upper Great Lakes to evaluate system robustness related to water management decisions and assess the impact of climate probability assumptions. The robustness indicators were used to identify decisions that outperformed other courses of action regardless of assumptions of future climate probabilities.},
  Doi                      = {10.1002/wrcr.20228},
  File                     = {:Hydrology\\Robustness Indicators for Evaluation Under Climate Change- Application to the Upper Great Lakes.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Decision making under uncertainty, Impacts of global change, Water management, Large bodies of water (e.g., lakes and inland seas), robustness, climate change, Great Lakes, decision scaling},
  Owner                    = {jaq},
  Timestamp                = {2016.05.12},
  Url                      = {http://dx.doi.org/10.1002/wrcr.20228}
}

@Article{Moody2012,
  Title                    = {Modeling stakeholder-defined climate risk on the Upper Great Lakes},
  Author                   = {Moody, Paul and Brown, Casey},
  Journal                  = {Water Resources Research},
  Year                     = {2012},
  Note                     = {W10524},
  Number                   = {10},
  Pages                    = {n/a--n/a},
  Volume                   = {48},

  Abstract                 = {Climate change is believed to pose potential risks to the stakeholders of the Great Lakes due to changes in lake levels. This paper presents a model of stakeholder-defined risk as a function of climate change. It describes the development of a statistical model that links water resources system performance and climate changes developed for the Great Lakes of North America. The function is used in a process that links bottom-up water system vulnerability assessment to top-down climate change information. Vulnerabilities are defined based on input from stakeholders and resource experts and are used to determine system performance thresholds. These thresholds are used to measure performance over a wide range of climate changes mined from a large (55,590 year) stochastic data set. The performance and climate conditions are used to create a climate response function, a statistical model to predict lake performance based on climate statistics. This function facilitates exploration and analysis of performance over a wide range of climate conditions. It can also be used to estimate risk associated with change in climate mean and variability resulting from climate change. Problematic changes in climate can be identified and the probability of those conditions estimated using climate projections or other sources of climate information. The function can also be used to evaluate the robustness of a regulation plan and to compare performance of alternate plans. This paper demonstrates the utility of the climate response function as applied within the context of the International Upper Great Lakes Study.},
  Doi                      = {10.1029/2012WR012497},
  File                     = {:Hydrology\\Modeling stakeholder-defined climate risk on the Upper Great Lakes.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Impacts of global change, Mathematical and computer modeling, Climate impact, Decision making under uncertainty, Great Lakes, climate risk},
  Owner                    = {jaq},
  Timestamp                = {2016.05.12},
  Url                      = {http://dx.doi.org/10.1029/2012WR012497}
}

@Article{Moradkhani2005,
  Title                    = {Dual state–parameter estimation of hydrological models using ensemble Kalman filter},
  Author                   = {Hamid Moradkhani and Soroosh Sorooshian and Hoshin V. Gupta and Paul R. Houser},
  Journal                  = {Advances in Water Resources},
  Year                     = {2005},
  Pages                    = {135-147},
  Volume                   = {28},

  Abstract                 = {Hydrologic models are twofold: models for understanding physical processes and models for prediction. This study addresses the
latter, which modelers use to predict, for example, streamflow at some future time given knowledge of the current state of the system
and model parameters. In this respect, good estimates of the parameters and state variables are needed to enable the model to generate accurate forecasts. In this paper, a dual state–parameter estimation approach is presented based on the Ensemble Kalman Filter (EnKF) for sequential estimation of both parameters and state variables of a hydrologic model. A systematic approach for
identification of the perturbation factors used for ensemble generation and for selection of ensemble size is discussed. The dual
EnKF methodology introduces a number of novel features: (1) both model states and parameters can be estimated simultaneously;
(2) the algorithm is recursive and therefore does not require storage of all past information, as is the case in the batch calibration
procedures; and (3) the various sources of uncertainties can be properly addressed, including input, output, and parameter uncertainties. The applicability and usefulness of the dual EnKF approach for ensemble streamflow forecasting is demonstrated using a
conceptual rainfall-runoff model.},
  File                     = {:Dual state–parameter estimation of hydrological models using ensemble Kalman filter.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Book{Nelsen2006,
  Title                    = {An Introduction to Copulas},
  Author                   = {Roger B. Nelsen},
  Publisher                = {Springer},
  Year                     = {2006},
  Edition                  = {2nd},
  Series                   = {Springer Series in Statistics},

  File                     = {:Statistics\\An Introduction to Copulas.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Pan2006,
  Title                    = {Data Assimilation for Estimating the Terrestrial Water Budget Using a Constrained Ensemble Kalman Filter},
  Author                   = {Ming Pan And Eric F. Wood},
  Journal                  = {Journal of Hydrometeorology},
  Year                     = {2006},
  Volume                   = {7},

  Abstract                 = {A procedure is developed to incorporate equality constraints in Kalman filters, including the ensemble
Kalman filter (EnKF), and is referred to as the constrained ensemble Kalman filter (CEnKF). The constraint is carried out as a two-step filtering approach, with the first step being the standard (ensemble)
Kalman filter. The second step is the constraint step carried out by another Kalman filter that optimally
redistributes any imbalance from the first step. The CEnKF is implemented over a 75 000 km2 domain in
the southern Great Plains region of the United States, using the terrestrial water balance as the constraint.
The observations, consisting of gridded fields of the upper two soil moisture layers from the Oklahoma
Mesonet system, Atmospheric Radiation Measurement Program Cloud and Radiation Testbed (ARMCART) energy balance Bowen ratio (EBBR) latent heat estimates, and U.S. Geological Survey (USGS)
streamflow from unregulated basins, are assimilated into the Variable Infiltration Capacity (VIC) land
surface model. The water balance was applied at the domain scale, and estimates of the water balance
components for the domain are updated from the data assimilation step so as to assure closure.},
  File                     = {:Data Assimilation for Estimating the Terrestrial Water Budget Using a Constrained Ensemble Kalman Filter.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Book{Petris2009,
  Title                    = {Dynamic Linear Models with R},
  Author                   = {Giovanni Petris and Sonia Petrone and Patrizia Campagnoli},
  Publisher                = {Springer},
  Year                     = {2009},
  Series                   = {Use R!},

  File                     = {://Statistics/Dynamic Linear Models with R.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Article{Pfeifer1980,
  Title                    = {A Three-Stage Iterative Procedure for Space-Time Modeling},
  Author                   = {Phillip E. Pfeifer and Stuart Jay Deutsch},
  Journal                  = {Technometrics},
  Year                     = {1980},
  Number                   = {1},
  Pages                    = {35-47},
  Volume                   = {22},

  File                     = {:A Three-Stage Iterative Procedure for Space-Time Modeling.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.03.11}
}

@Book{Pickl2009,
  Title                    = {Optimization and Multiobjective Control of Time-Discrete Systems - Dynamic Networks and Multilayered Structures},
  Author                   = {Stefan Pickl and Dmitrii Lozovanu},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2009},

  Doi                      = {10.1007/978-3-540-85025-0},
  File                     = {:Optimization\\Optimization and Multiobjective Control of Time-Discrete Systems.pdf:PDF},
  Owner                    = {quebbs},
  Timestamp                = {2014.10.20}
}

@Article{Pierce2012,
  Title                    = {Probabilistic estimates of future changes in California temperature and precipitation using statistical and dynamical downscaling},
  Author                   = {Pierce, David W.
and Das, Tapash
and Cayan, Daniel R.
and Maurer, Edwin P.
and Miller, Norman L.
and Bao, Yan
and Kanamitsu, M.
and Yoshimura, Kei
and Snyder, Mark A.
and Sloan, Lisa C.
and Franco, Guido
and Tyree, Mary},
  Journal                  = {Climate Dynamics},
  Year                     = {2012},
  Number                   = {3},
  Pages                    = {839--856},
  Volume                   = {40},

  Abstract                 = {Sixteen global general circulation models were used to develop probabilistic projections of temperature (T) and precipitation (P) changes over California by the 2060s. The global models were downscaled with two statistical techniques and three nested dynamical regional climate models, although not all global models were downscaled with all techniques. Both monthly and daily timescale changes in T and P are addressed, the latter being important for a range of applications in energy use, water management, and agriculture. The T changes tend to agree more across downscaling techniques than the P changes. Year-to-year natural internal climate variability is roughly of similar magnitude to the projected T changes. In the monthly average, July temperatures shift enough that that the hottest July found in any simulation over the historical period becomes a modestly cool July in the future period. Januarys as cold as any found in the historical period are still found in the 2060s, but the median and maximum monthly average temperatures increase notably. Annual and seasonal P changes are small compared to interannual or intermodel variability. However, the annual change is composed of seasonally varying changes that are themselves much larger, but tend to cancel in the annual mean. Winters show modestly wetter conditions in the North of the state, while spring and autumn show less precipitation. The dynamical downscaling techniques project increasing precipitation in the Southeastern part of the state, which is influenced by the North American monsoon, a feature that is not captured by the statistical downscaling.},
  Doi                      = {10.1007/s00382-012-1337-9},
  File                     = {:Probabilistic Estimates of Future Changes in California temperature and precipitation using statistical and dynamical downscaling.pdf:PDF},
  ISSN                     = {1432-0894},
  Owner                    = {jaq},
  Timestamp                = {2016.03.14},
  Url                      = {http://dx.doi.org/10.1007/s00382-012-1337-9}
}

@Article{Price2012,
  Title                    = {Tradeoffs among watershed model calibration targets for parameter estimation},
  Author                   = {Price, Katie and Purucker, S. Thomas and Kraemer, Stephen R. and Babendreier, Justin E.},
  Journal                  = {Water Resources Research},
  Year                     = {2012},
  Note                     = {W10542},
  Number                   = {10},
  Pages                    = {n/a--n/a},
  Volume                   = {48},

  Abstract                 = {Hydrologic models are commonly calibrated by optimizing a single objective function target to compare simulated and observed flows, although individual targets are influenced by specific flow modes. Nash-Sutcliffe efficiency (NSE) emphasizes flood peaks in evaluating simulation fit, while modified Nash-Sutcliffe efficiency (MNS) emphasizes lower flows, and the ratio of the simulated to observed standard deviations (RSD) prioritizes flow variability. We investigated tradeoffs of calibrating streamflow on three standard objective functions (NSE, MNS, and RSD), as well as a multiobjective function aggregating these three targets to simultaneously address a range of flow conditions, for calibration of the Soil and Water Assessment Tool (SWAT) daily streamflow simulations in two watersheds. A suite of objective functions was explored to select a minimally redundant set of metrics addressing a range of flow characteristics. After each pass of 2001 simulations, an iterative informal likelihood procedure was used to subset parameter ranges. The ranges from each best-fit simulation set were used for model validation. Values for optimized parameters vary among calibrations using different objective functions, which underscores the importance of linking modeling objectives to calibration target selection. The simulation set approach yielded validated models of similar quality as seen with a single best-fit parameter set, with the added benefit of uncertainty estimations. Our approach represents a novel compromise between equifinality-based approaches and Pareto optimization. Combining the simulation set approach with the multiobjective function was demonstrated to be a practicable and flexible approach for model calibration, which can be readily modified to suit modeling goals, and is not model or location specific.},
  Doi                      = {10.1029/2012WR012005},
  File                     = {:Tradeoffs among watershed model calibration targets for parameter estimation.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Model calibration, Modeling, Streamflow, Uncertainty assessment, autocalibration, GLUE, SWAT, hydrologic model, multiple objective function, water quantity, KGE, Kling-Gupta},
  Owner                    = {jaq},
  Timestamp                = {2016.02.12},
  Url                      = {http://dx.doi.org/10.1029/2012WR012005}
}

@Article{Quebbeman2016,
  author    = {Jonathan A. Quebbeman and Jorge A. Ramirez},
  title     = {Optimal Allocation of Leaf-Level Nitrogen: Implications for Covariation of Vcmax and Jmax and Photosynthetic Downregulation},
  journal   = {Journal of Geophysical Research: Biogeosciences},
  year      = {2016},
  volume    = {121},
  number    = {9},
  pages     = {2464-2475},
  month     = {sep},
  abstract  = {The maximum rate of carboxylation, Vcmax, and the maximum rate of electron transport, Jmax, describe leaf-level capacities of the photosynthetic system and are critical in determining the net fluxes of carbon dioxide and water vapor in the terrestrial biosphere. Although both Vcmax and Jmax exhibit high spatial and temporal variability, most descriptions of photosynthesis in terrestrial biosphere models assume constant values for Vcmax and Jmax at a reference temperature ignoring intraseasonal, interannual, and water stress-induced variations. Although general patterns of variation of Vcmax and Jmax have been correlated across groups of species, climates, and nitrogen concentrations, scant theoretical support has been provided to explain these variations. We present a new approach to determine Vcmax and Jmax based on the assumption that a limited amount of leaf nitrogen is allocated optimally among the various components of the photosynthetic system in such a way that expected carbon assimilation is maximized. The optimal allocation is constrained by available nitrogen and responds dynamically to the near-term environmental conditions of light and water supply and to their variability. The resulting optimal allocations of a finite supply of nitrogen replicate observed relationships in nature, including the ratio of Jmax/Vcmax, the relationship of leaf nitrogen to Vcmax, and the changes in nitrogen allocation under varying water availability and light environments. This optimal allocation approach provides a mechanism to describe the response of leaf-level photosynthetic capacity to varying environmental and resource supply conditions that can be incorporated into terrestrial biosphere models providing improved estimates of carbon and water fluxes in the soil-plant-atmosphere continuum.},
  file      = {:Hydrology\\Optimal allocation of leaf-level nitrogen- Implications for covariation of Vcmax and Jmax and photosynthetic downregulation.pdf:PDF},
  owner     = {jaq},
  timestamp = {2017-02-23},
  url       = {http://onlinelibrary.wiley.com/doi/10.1002/2016JG003473/full},
}

@Article{Rajagopalan1999,
  Title                    = {A k-nearest-neighbor simulator for daily precipitation and other weather variables},
  Author                   = {Balaji Rajagopalan and Upmanu Lall},
  Journal                  = {Water Resources Research},
  Year                     = {1999},
  Number                   = {10},
  Pages                    = {3089-3101},
  Volume                   = {35},

  Abstract                 = {A multivariate, nonparametric time series simulation method is provided to generate random sequences of daily weather variables that “honor” the statistical properties of the historical data of the same weather variables at the site. A vector of weather variables (solar radiation, maximum temperature, minimum temperature, average dew point temperature, average wind speed, and precipitation) on a day of interest is resampled from the historical data by conditioning on the vector of the same variables (feature vector) on the preceding day. The resampling is done from the k nearest neighbors in state space of the feature vector using a weight function. This approach is equivalent to a nonparametric approximation of a multivariate, lag 1 Markov process. It does not require prior assumptions as to the form of the joint probability density function of the variables. An application of the resampling scheme with 30 years of daily weather data at Salt Lake City, Utah, is provided. Results are compared with those from the application of a multivariate autoregressive model similar to that of Richardson [1981].},
  Doi                      = {10.1029/1999WR900028},
  File                     = {:A k-nearest-neighbor simulator for daily precipitation and other weather variables.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Book{Rao2000,
  Title                    = {Flood Frequency Analysis},
  Author                   = {A. Ramachandra Rao and Khaled H. Hamed},
  Editor                   = {W.F. Chen},
  Publisher                = {CRC Press},
  Year                     = {2000},

  Owner                    = {jaq},
  Timestamp                = {2016.02.18}
}

@Article{Reichle2008,
  Title                    = {An adaptive ensemble Kalman filter for soil moisture data assimilation},
  Author                   = {Rolf H. Reichle and Wade T. Crow and Christian L. Keppenne},
  Journal                  = {Water Resources Research},
  Year                     = {2008},
  Volume                   = {44},

  Abstract                 = {In a 19-year twin experiment for the Red-Arkansas river basin we assimilate synthetic
surface soil moisture retrievals into the NASA Catchment land surface model. We
demonstrate how poorly specified model and observation error parameters affect the
quality of the assimilation products. In particular, soil moisture estimates from data
assimilation are sensitive to observation and model error variances and, for very poor input
error parameters, may even be worse than model estimates without data assimilation.
Estimates of surface heat fluxes and runoff are at best marginally improved through the
assimilation of surface soil moisture and tend to have large errors when the assimilation
system operates with poor input error parameters. We present a computationally
affordable, adaptive assimilation system that continually adjusts model and observation
error parameters in response to internal diagnostics. The adaptive filter can identify model
and observation error variances and provide generally improved assimilation estimates
when compared to the non-adaptive system.},
  File                     = {:An adaptive ensemble Kalman filter for soil moisture data assimilation.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Reichle2002,
  Title                    = {Hydrologic Data Assimilation with the Ensemble Kalman Filter},
  Author                   = {Rolf H. Reichle And Dennis B. Mclaughlin And Dara Entekhabi},
  Journal                  = {Monthly Weather Review},
  Year                     = {2002},
  Volume                   = {130},

  Abstract                 = {Soil moisture controls the partitioning of moisture and energy fluxes at the land surface and is a key variable
in weather and climate prediction. The performance of the ensemble Kalman filter (EnKF) for soil moisture
estimation is assessed by assimilating L-band (1.4 GHz) microwave radiobrightness observations into a land
surface model. An optimal smoother (a dynamic variational method) is used as a benchmark for evaluating the
filter’s performance. In a series of synthetic experiments the effect of ensemble size and non-Gaussian forecast
errors on the estimation accuracy of the EnKF is investigated. With a state vector dimension of 4608 and a
relatively small ensemble size of 30 (or 100; or 500), the actual errors in surface soil moisture at the final update
time are reduced by 55% (or 70%; or 80%) from the value obtained without assimilation (as compared to 84%
for the optimal smoother). For robust error variance estimates, an ensemble of at least 500 members is needed.
The dynamic evolution of the estimation error variances is dominated by wetting and drying events with high
variances during drydown and low variances when the soil is either very wet or very dry. Furthermore, the
ensemble distribution of soil moisture is typically symmetric except under very dry or wet conditions when the
effects of the nonlinearities in the model become significant. As a result, the actual errors are consistently larger
than ensemble-derived forecast and analysis error variances. This suggests that the update is suboptimal. However,
the degree of suboptimality is relatively small and results presented here indicate that the EnKF is a flexible
and robust data assimilation option that gives satisfactory estimates even for moderate ensemble sizes.},
  File                     = {:Hydrologic Data Assimilation with the Ensemble Kalman Filter.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Rey2001,
  Title                    = {Spatial Empirics for Economic Growth and Convergence},
  Author                   = {Sergio J. Rey},
  Journal                  = {Geographical Analysis},
  Year                     = {2001},
  Number                   = {3},
  Volume                   = {33},

  Abstract                 = {This paper suggests some new empirical strategies for analyzing the evolution of regional income distributions over time and space. These approaches are based on extensions to the classical Markov transition matrices that allow for a more comprehensive analysis of the geographical dimensions of the transitional dynamics. This is achieved by integrating some recently developed local spatial statistics within a Markov framework. Insights to not only the frequency with which one economy may transition across different classes in the income distribution, but also how those transitions may or may not be spatially dependent are provided by these new measures. A number of indices are suggested as ways to characterize the space-time dynamics and are illustrated in a case study of U. S. regional income dynamics over the 1929–1994 period.},
  File                     = {:Spatial Empirics for Economic Growth and Convergence.pdf:PDF},
  Keywords                 = {pysal},
  Owner                    = {jaq},
  Timestamp                = {2016.01.22}
}

@Article{Richardson1981,
  Title                    = {Stochastic simulation of daily precipitation, temperature, and solar radiation},
  Author                   = {C.W. Richardson},
  Journal                  = {Water Resources Research},
  Year                     = {1981},
  Number                   = {1},
  Pages                    = {182-190},
  Volume                   = {17},

  Abstract                 = {Long samples of weather data are frequently needed to evaluate the long-term effects of proposed hydrologic changes. The evaluations are often undertaken using deterministic mathematical models that require daily weather data as input. Stochastic generation of the required weather data offers an attractive alternative to the use of observed weather records. This paper presents an approach that may be used to generate long samples of daily precipitation, maximum temperature, minimum temperature, and solar radiation. Precipitation is generated independently of the other variables by using a Markov chain-exponential model. The other three variables are generated by using a multivariate model with the means and standard deviations of the variables conditioned on the wet or dry status of the day as determined by the precipitation model. Daily weather samples that are generated with this approach preserve the seasonal and statistical characteristics of each variable and the interrelations among the four variables that exist in the observed data.},
  File                     = {:Hydrology\\Stochastic simulation of daily precipitation, temperature, and solar radiation.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.27}
}

@Article{Rivera2016,
  Title                    = {Dynamic Reservoir Operations Support Sustainable Water Management},
  Author                   = {Megan Rivera and Steven Nebiker and And Ben Wright},
  Journal                  = {Opflow},
  Year                     = {2016},

  Month                    = {March},

  File                     = {:Dynamic Operating Rules_Opflow.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.25}
}

@Article{Rodriguez-Iturbe1987,
  Title                    = {Some Models for Rainfall Based on Stochastic Point Processes},
  Author                   = {Ignacio Rodriguez-Iturbe and D. R. Cox and Valerie Isham},
  Journal                  = {Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences},
  Year                     = {1987},
  Number                   = {1839},
  Volume                   = {410},

  Abstract                 = {Stochastic models are discussed for the variation of rainfall intensity at a fixed point in space. First, models are analysed in which storm events arise in a Poisson process, each such event being associated with a period of rainfall of random duration and constant but random intensity. Total rainfall intensity is formed by adding the contributions from all storm events. Then similar but more complex models are studied in which storms arise in a Poisson process, each storm giving rise to a cluster of rain cells and each cell being associated with a random period of rain. The main properties of these models are determined analytically. Analysis of some hourly rainfall data from Denver, Colorado shows the clustered models to be much the more satisfactory.},
  File                     = {:Hydrology\\Some Models for Rainfall Based on Stochastic Point Processes.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.27}
}

@Book{Salas1980,
  Title                    = {Applied Modeling of Hydrologic Time Series},
  Author                   = {J.D. Salas and J.W. Delleur and V. Yevjevich and W.L. Lane},
  Publisher                = {Water Resources Publications},
  Year                     = {1980},

  File                     = {:Statistics\\APPLIED MODELING OF HYDROLOGIC TIME SERIES.pdf:PDF},
  Owner                    = {quebbs},
  Timestamp                = {2014.11.06}
}

@Article{Salvadori2004,
  Title                    = {Analytical calculation of storm volume statistics involving Pareto-like intensity-duration marginals},
  Author                   = {G. Salvadori and C. De Michele},
  Journal                  = {Geophysical Research Letters},
  Year                     = {2004},
  Number                   = {4},
  Volume                   = {31},

  Abstract                 = {An analytical derivation of the storm volume distribution is given. The single storm is modeled as a rectangular pulse having non-independent random duration and intensity. The structure of the dependence between storm duration and intensity is given via a suitable 2-Copula, and the marginal distributions are endowed with Generalized Pareto laws, as recently pointed out in the hydrological Literature. The statistical properties of the rainfall volume are investigated, both analytically and using simulated samples; an application to rainfall data is also shown.},
  Doi                      = {10.1029/2003GL018767},
  File                     = {:Analytical calculation of storm volume statistics involving Pareto-like intensity-duration marginals.pdf:PDF},
  Keywords                 = {duration and intensity precipitation},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Samaniego2010,
  Title                    = {Multiscale parameter regionalization of a grid-based hydrologic model at the mesoscale},
  Author                   = {Luis Samaniego and Rohini Kumar and Sabine Attinger},
  Journal                  = {Water Resources Research},
  Year                     = {2010},
  Volume                   = {46},

  Abstract                 = {The requirements for hydrological models have increased considerably during the
previous decades to cope with the resolution of extensive remotely sensed data sets and a
number of demanding applications. Existing models exhibit deficiencies such as
overparameterization, the lack of an effective technique to integrate the spatial
heterogeneity of physiographic characteristics, and the nontransferability of parameters
across scales and locations. A multiscale parameter regionalization (MPR) technique is
proposed as a way to address these issues simultaneously. Using this technique, parameters
at a coarser scale, in which the dominant hydrological processes are represented, are
linked with their corresponding ones at a finer resolution in which input data sets are
available. The linkage is done with upscaling operators such as the harmonic mean, among
others. Parameters at the finer scale are regionalized through nonlinear transfer functions
which link basin predictors with global parameters to be determined through calibration.
MPR was compared with a standard regionalization (SR) method in which basin predictors
instead of model parameters are first aggregated. Both methods were tested in a basin
located in Germany using a distributed hydrologic model. Results indicate that MPR is
superior to SR in many respects, especially if global parameters are transferred from
coarser to finer scales. Furthermore, MPR, as opposed to SR, preserves the spatial
variability of state variables and conserves the mass balance with respect to a control scale.
Cross-validation tests indicate that the transferability of the global parameters to ungauged
locations is possible.},
  Doi                      = {10.1029/2008WR007327},
  File                     = {:Hydrology\\Multiscale parameter regionalization of a grid‐based hydrologic model at the mesoscale.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@TechReport{Santner1973,
  Title                    = {An introduction to Gumbel, or Extreme-Value Probability Paper},
  Author                   = {Joseph F. Santner},
  Institution              = {U.S. Environmental Protection Agency},
  Year                     = {1973},

  File                     = {:Statistics\\An introduction to Gumbel, or Extreme-Value Probability Paper.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.27}
}

@Article{Sax2013,
  Title                    = {Temporal Disaggregation of Time Series},
  Author                   = {Christoph Sax and Peter Steiner},
  Journal                  = {The R Journal},
  Year                     = {2013},

  Abstract                 = {Temporal disaggregation methods are used to disaggregate low frequency time series to
higher frequency series, where either the sum, the average, the first or the last value of the resulting
high frequency series is consistent with the low frequency series. Temporal disaggregation can be
performed with or without one or more high frequency indicator series. The package tempdisagg is a
collection of several methods for temporal disaggregation.},
  File                     = {:Temporal Disaggregation of Time Series.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Unpublished{Schaeffer2015,
  author    = {Mel Schaefer},
  title     = {Calculation Total Probability Illustration},
  note      = {MGS Engineering, SEFM, Stochastic},
  file      = {:Risk\\MGS_Calculation_TotalProbability_Illustration.pdf:PDF},
  owner     = {jaq},
  timestamp = {2016.05.12},
}

@Article{Schweizer1991,
  Title                    = {Thirty Years Of Copulas},
  Author                   = {Berthold Schweizer},
  Journal                  = {Advances in Probability Distributions with Given Marginals},
  Year                     = {1991},

  Abstract                 = {In 1959. in response to a query of M. Frechet. A. Sklar introduced copulas. These are functions that link multivariate distributions to their one-dimensional margins. Thus, if H is an n-dimensional cumulative distribution function with one-dimensional margins
Fl •••••F
n • then there exists an n-dimensional copula C (which is
unique when Fl •••••Fn are continuous) such that H(xl ••••• xn) =
C(Fl(xl) •••••Fn(xn)). During the years 1959 - 1974. most results concerning copulas were obtained in the course of the development of the
theory of probabilistic metric spaces. principally in connection with
the study of families of binary operations on the space of probability
distribution functions. Then it was discovered that two-dimensional
copulas could be used to define nonparametric measures of dependence
for pairs of random variables. In the ensuing years the copula concept
was rediscovered on several occasions and these functions began to play
an ever-more-important role in mathematical statistics. particularly in
matters involving questions of dependence. fixed marginals and functions
of random variables that are invariant under monotone transformations.
Today. in view of the fact that they are the higher dimensional analogues of uniform distributions on the unit interval. and as the result
of the efforts of a diverse group of scholars. the significance. ubiquity and utility of copulas is being recognized. This paper is devoted
to an historical overview and rather personal account of these developments and to a description of some recent results.},
  File                     = {:Thirty-years-of-copulas.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Scutari2010,
  Title                    = {Learning Bayesian Networks with the bnlearn R Package},
  Author                   = {Marco Scutari},
  Journal                  = {Journal of Statistical Software},
  Year                     = {2010},

  Month                    = {July},
  Number                   = {3},
  Volume                   = {35},

  Abstract                 = {bnlearn is an R package (R Development Core Team 2010) which includes several algorithms
for learning the structure of Bayesian networks with either discrete or continuous
variables. Both constraint-based and score-based algorithms are implemented, and can
use the functionality provided by the snow package (Tierney et al. 2008) to improve their
performance via parallel computing. Several network scores and conditional independence
algorithms are available for both the learning algorithms and independent use. Advanced
plotting options are provided by the Rgraphviz package (Gentry et al. 2010).},
  File                     = {:Learning Bayesian Networks with the bnlearn R Package.pdf:PDF},
  Keywords                 = {: bayesian networks, R, structure learning algorithms, constraint-based algorithms, score-based algorithms, conditional independence tests},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Article{Selek2014,
  Title                    = {Effects of climate change on surface water management of Seyhan basin, Turkey},
  Author                   = {Bulent Selek and I. Kaan Tuncok},
  Journal                  = {Environmental Ecology},
  Year                     = {2014},

  Abstract                 = {The goal of this study was to set-up the basis for climate change adaptation
of water resources management policies in Seyhan River basin. The first priority was to
identify the balances between water resources and water users with respect to existing
and planned projects. In this respect various aspects of Seyhan basin were evaluated,
including evaluation of existing water resources, determination of water demand of
existing and planned projects, and water resources supply-demand characteristics.
The global climate change model was downscaled to the basin scale, the results were
associated with hydrometeorological monitoring network and finally the impact of
climate change on surface water resources and demands were determined for specific
projection years. Water resources management scenarios were developed to evaluate
adaptation alternatives to climate change scenarios at the basin level. It was determined
that even though there was no water stress in Seyhan basin in 2010, many parts of the
basin were expected to suffer significant shortages over the coming years.},
  File                     = {:Effects of climate change on surface water management of Seyhan basin, Turkey.pdf:PDF},
  Keywords                 = {Basin management models · Climate change models · Irrigation policies · Water resources management},
  Owner                    = {jaq},
  Timestamp                = {2016.01.15}
}

@TechReport{Sheer2014,
  author      = {Daniel P. Sheer and Megan Wiley Rivera and Benjamen A. Wright and Gerald N. Day and Benjamin D. Stanford},
  title       = {Reservoir Operations Development Guide: The Theory and Practice of Developing Reservoir Operating Rules for Managing Multiple Objectives},
  institution = {HydroLogics, Inc.},
  year        = {2014},
  number      = {4306b},
  abstract    = {For over a century reservoirs have been used to buffer for hydrologic variability and
increase utilization of water resources. Reservoirs are generally operated using a set of written or
unwritten rules and procedures that modify the rate of release and/or diversion from a reservoir
based on the current state of the water supply system and its environment in order to achieve one
or more objectives. Tools and techniques have been developed to help create operating rules that
provide the desired mix of benefits to the extent possible for often competing objectives. This
project pulls together existing approaches to provide a thorough guide for reservoir operation
development.
This guide is a portion of a larger report titled Dynamic Reservoir Operations: Managing
for Climate Variability and Change also published by the Water Research Foundation. Dynamic
Reservoir Operations (DRO) are operating rules that change based on the present state of a system,
such as storage levels, current inflow, and/or forecasted conditions. Dynamic operations tend to
be effective because they depend on a diverse group of variables that result in a more robust
operational framework, providing utilities more information for operating their system to meet
objectives under varying conditions. The primary objectives of the full project were 1) to
demonstrate the potential value of dynamic reservoir operations in improving system reliability,
resilience, and performance under challenging climate conditions and 2) to provide utilities with
practical guidance to decide if and how to implement DRO. The Reservoir Operations
Development Guide was created to help meet the second objective.
This guide includes rule forms that address different management objectives and step-bystep guidelines for developing effective rules. Developing DRO is not a cookie-cutter process; it
is a blend of art and science that requires an understanding of the system-specific physical
characteristics, hydrology, and management objectives. The guide provides potential rule forms
and examples to inform the development process.
The framework for operations development consists of four steps.
1. The first is to identify long term management objectives, which generally fall into one
of the following categories: hydrologic reliability; cost, financial stability, and
administration; environmental performance; recreation; aesthetics; flood control;
hydropower; and navigation.
2. The second step is to create displays that allow water managers and other stakeholders
to compare alternative operating strategies with regard to one or more management
objectives, called performance measures.
3. Step three is to develop operating rule forms. Potentially effective rule forms are best
informed by the management objectives and system-specific characteristics. Examples
of operating rules in other basins with similar management objectives and/or systemspecific characteristics can provide a starting point.
4. Finally, in step four, rule forms and their parameters are selected by comparing
simulated alternative operations using performance measure displays},
  file        = {:Reservoirs\\Reservoir Operations Guide.pdf:PDF},
  owner       = {jaq},
  timestamp   = {2016-10-18},
}

@Article{Singh2015,
  author    = {Riddhi Singh and Patrick M. Reed and Klaus Keller},
  title     = {Many-objective robust decision making for managing an ecosystem with a deeply uncertain threshold response},
  journal   = {Ecology and Society},
  year      = {2015},
  volume    = {20},
  number    = {3},
  abstract  = {Managing ecosystems with deeply uncertain threshold responses and multiple decision makers poses nontrivial decision
analytical challenges. The problem is imbued with deep uncertainties because decision makers do not know or cannot converge on a
single probability density function for each key parameter, a perfect model structure, or a single adequate objective. The existing
literature on managing multistate ecosystems has generally followed a normative decision-making approach based on expected utility
maximization (MEU). This approach has simple and intuitive axiomatic foundations, but faces at least two limitations. First, a
prespecified utility function is often unable to capture the preferences of diverse decision makers. Second, decision makers’ preferences
depart from MEU in the presence of deep uncertainty. Here, we introduce a framework that allows decision makers to pose multiple
objectives, explore the trade-offs between potentially conflicting preferences of diverse decision makers, and to identify strategies that
are robust to deep uncertainties. The framework, referred to as many-objective robust decision making (MORDM), employs
multiobjective evolutionary search to identify trade-offs between strategies, re-evaluates their performance under deep uncertainty, and
uses interactive visual analytics to support the selection of robust management strategies. We demonstrate MORDM on a stylized
decision problem posed by the management of a lake in which surpassing a pollution threshold causes eutrophication. Our results
illustrate how framing the lake problem in terms of MEU can fail to represent key trade-offs between phosphorus levels in the lake
and expected economic benefits. Moreover, the MEU strategy deteriorates severely in performance for all objectives under deep
uncertainties. Alternatively, the MORDM framework enables the discovery of strategies that balance multiple preferences and perform
well under deep uncertainty. This decision analytic framework allows the decision makers to select strategies with a better understanding
of their expected trade-offs (traditional uncertainty) as well as their robustness (deep uncertainty).},
  file      = {:MCDA\\Many-objective robust decision making for managing an ecosystem with a deeply uncertain threshold response.pdf:PDF},
  keywords  = {a posteriori decision making; deep uncertainty; lake eutrophication; many objective; robustness analysis; utility},
  owner     = {jaq},
  timestamp = {2016-12-22},
}

@Article{Spiegelhalter2002,
  Title                    = {Bayesian measures of model complexity and fit},
  Author                   = {David J. Spiegelhalter and Nicola G. Best and Bradley P. Carlin and Angelika van der Linde},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Statistical Methodology))},
  Year                     = {2002},
  Volume                   = {64},

  Abstract                 = {We consider the problem of comparing complex hierarchical models in which the
number of parameters is not clearly defined. Using an information theoretic argument we derive
a measure pD for the effective number of parameters in a model as the difference between
the posterior mean of the deviance and the deviance at the posterior means of the parameters
of interest. In general pD approximately corresponds to the trace of the product of Fisher’s
information and the posterior covariance, which in normal models is the trace of the ‘hat’ matrix
projecting observations onto fitted values. Its properties in exponential families are explored.
The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the
contributions of individual observations to the fit and complexity can give rise to a diagnostic
plot of deviance residuals against leverages. Adding pD to the posterior mean deviance gives
a deviance information criterion for comparing models, which is related to other information
criteria and has an approximate decision theoretic justification. The procedure is illustrated in
some examples, and comparisons are drawn with alternative Bayesian and classical proposals.
Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain
Monte Carlo analysis.},
  File                     = {:Bayesian measures of model complexity and fit.pdf:PDF},
  Keywords                 = {Bayesian model comparison; Decision theory; Deviance information criterion;
Effective number of parameters; Hierarchical models; Information theory; Leverage; Markov
chain Monte Carlo methods; Model dimension},
  Owner                    = {jaq},
  Timestamp                = {2016.02.12}
}

@Article{Steinschneider2013,
  Title                    = {A semiparametric multivariate, multisite weather generator with low-frequency variability for use in climate risk assessments},
  Author                   = {Steinschneider, Scott and Brown, Casey},
  Journal                  = {Water Resources Research},
  Year                     = {2013},
  Number                   = {11},
  Pages                    = {7205--7220},
  Volume                   = {49},

  Abstract                 = {A multivariate, multisite daily weather generator is presented for use in decision-centric vulnerability assessments under climate change. The tool is envisioned to be useful for a wide range of socioeconomic and biophysical systems sensitive to different aspects of climate variability and change. The proposed stochastic model has several components, including (1) a wavelet decomposition coupled to an autoregressive model to account for structured, low-frequency climate oscillations, (2) a Markov chain and k-nearest-neighbor (KNN) resampling scheme to simulate spatially distributed, multivariate weather variables over a region, and (3) a quantile mapping procedure to enforce long-term distributional shifts in weather variables that result from prescribed climate changes. The Markov chain is used to better represent wet and dry spell statistics, while the KNN bootstrap resampler preserves the covariance structure between the weather variables and across space. The wavelet-based autoregressive model is applied to annual climate over the region and used to modulate the Markov chain and KNN resampling, embedding appropriate low-frequency structure within the daily weather generation process. Parameters can be altered in any of the components of the proposed model to enable the generation of realistic time series of climate variables that exhibit changes to both lower-order and higher-order statistics at long-term (interannual), mid-term (seasonal), and short-term (daily) timescales. The tool can be coupled with impact models in a bottom-up risk assessment to efficiently and exhaustively explore the potential climate changes under which a system is most vulnerable. An application of the weather generator is presented for the Connecticut River basin to demonstrate the tool's ability to generate a wide range of possible climate sequences over an extensive spatial domain.},
  Doi                      = {10.1002/wrcr.20528},
  File                     = {:Hydrology\\A semiparametric multivariate, multisite weather generator with low-frequency variability for use in climate risk assessments.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Climate change and variability, Water management, Climate impact, weather generator, climate change, risk},
  Owner                    = {jaq},
  Timestamp                = {2016.04.04},
  Url                      = {http://dx.doi.org/10.1002/wrcr.20528}
}

@Article{Steinschneider2012,
  Title                    = {Toward a statistical framework to quantify the uncertainties of hydrologic response under climate change},
  Author                   = {Steinschneider, Scott and Polebitski, Austin and Brown, Casey and Letcher, Benjamin H.},
  Journal                  = {Water Resources Research},
  Year                     = {2012},
  Note                     = {W11525},
  Number                   = {11},
  Pages                    = {n/a--n/a},
  Volume                   = {48},

  Abstract                 = {The cascade of uncertainty that underscores climate impact assessments of regional hydrology undermines their value for long-term water resources planning and management. This study presents a statistical framework that quantifies and propagates the uncertainties of hydrologic model response through projections of future streamflow under climate change. Different sources of hydrologic model uncertainty are accounted for using Bayesian modeling. The distribution of model residuals is formally characterized to quantify predictive skill, and Markov chain Monte Carlo sampling is used to infer the posterior distributions of both hydrologic and error model parameters. Parameter and residual error uncertainties are integrated to develop reliable prediction intervals for streamflow estimates. The Bayesian hydrologic modeling framework is then extended to a climate change impact assessment. Ensembles of baseline and future climate are downscaled from global circulation models and are used to drive simulations of streamflow over parameters drawn from the posterior space. Time series of streamflow statistics are calculated from baseline and future ensembles of simulated flows. Uncertainties in hydrologic model response, sampling error, and the range of future climate projections are integrated to help determine the level of confidence associated with hydrologic alteration between baseline and future climate regimes. A case study is conducted on the White River in Vermont, USA. Results indicate that the framework can be used to present a reliable depiction of the range of hydrologic alterations that may occur in the future.},
  Doi                      = {10.1029/2011WR011318},
  File                     = {:Hydrology\\Toward a statistical framework to quantify the uncertainties of hydrologic response under climate change.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Computational hydrology, Climate impacts, Modeling, Uncertainty assessment, Bayesian statistics, climate impacts, computational hydrology, hydrologic scaling, modeling, uncertainty assessment},
  Owner                    = {jaq},
  Timestamp                = {2016.05.12},
  Url                      = {http://dx.doi.org/10.1029/2011WR011318}
}

@Article{Steinschneider2015,
  Title                    = {Combining regression and spatial proximity for catchment model regionalization: a comparative study},
  Author                   = {Scott Steinschneider and Yi-Chen E. Yang and Casey Brown},
  Journal                  = {Hydrological Sciences Journal},
  Year                     = {2015},
  Number                   = {6},
  Pages                    = {1026-1043},
  Volume                   = {60},

  Abstract                 = {Spatial error regression is employed to regionalize the parameters of a rainfall–runoff model. The approach combines regression on physiographic watershed characteristics with a spatial proximity technique that describes the spatial dependence of model parameters. The methodology is tested for the monthly abcd model at a network of gauges in southeast United States and compared against simpler regression and spatial proximity approaches. Unlike other comparative regionalization studies that only evaluate the skill of regionalized streamflow predictions in ungauged catchments, this study also examines the fit between regionalized parameters and their optimal (i.e. calibrated) values. Interestingly, the spatial error model produces parameter estimates that better resemble the optimal parameters than either of the simpler methods, but the spatial proximity method still yields better hydrologic simulations. The analysis suggests that the superior streamflow predictions of spatial proximity result from its ability to better preserve correlations between compensatory hydrological parameters.},
  Doi                      = {10.1080/02626667.2014.899701},
  File                     = {:Hydrology\\Combining regression and spatial proximity for catchment model regionalization- a comparative study.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.05.12}
}

@Book{Tango2010,
  Title                    = {Statistical Methods for Disease Clustering},
  Author                   = {Toshiro Tango},
  Publisher                = {Springer},
  Year                     = {2010},

  File                     = {:Statistical Methods for Disease Clustering.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.22}
}

@Article{Tolson2007,
  author    = {Bryan A. Tolson and Christine A. Shoemaker},
  title     = {Dynamically dimensioned search algorithm for computationally efficient watershed model calibration},
  journal   = {Water Resources Research},
  year      = {2007},
  volume    = {43},
  pages     = {W01413},
  abstract  = {A new global optimization algorithm, dynamically dimensioned search (DDS), is
introduced for automatic calibration of watershed simulation models. DDS is designed for
calibration problems with many parameters, requires no algorithm parameter tuning, and
automatically scales the search to find good solutions within the maximum number of
user-specified function (or model) evaluations. As a result, DDS is ideally suited for
computationally expensive optimization problems such as distributed watershed model
calibration. DDS performance is compared to the shuffled complex evolution (SCE)
algorithm for multiple optimization test functions as well as real and synthetic SWAT2000
model automatic calibration formulations. Algorithms are compared for optimization
problems ranging from 6 to 30 dimensions, and each problem is solved in 1000 to 10,000
total function evaluations per optimization trial. Results are presented so that future
modelers can assess algorithm performance at a computational scale relevant to their
modeling case study. In all four of the computationally expensive real SWAT2000
calibration formulations considered here (14, 14, 26, and 30 calibration parameters),
results show DDS to be more efficient and effective than SCE. In two cases, DDS requires
only 15–20% of the number of model evaluations used by SCE in order to find equally
good values of the objective function. Overall, the results also show that DDS rapidly
converges to good calibration solutions and easily avoids poor local optima. The
simplicity of the DDS algorithm allows for easy recoding and subsequent adoption into
any watershed modeling application framework.},
  doi       = {10.1029/2005WR004723},
  file      = {:Optimal_Control\\Dynamically dimensioned search algorithm for computationally efficient watershed model calibration.pdf:PDF},
  keywords  = {DDS},
  owner     = {quebbs},
  timestamp = {2017-03-27},
}

@Article{Vrac2007,
  Title                    = {Stochastic downscaling of precipitation: From dry events to heavy rainfalls},
  Author                   = {M. Vrac and P. Naveau},
  Journal                  = {Water Resources Research},
  Year                     = {2007},
  Number                   = {7},
  Volume                   = {43},

  Abstract                 = {Downscaling precipitation is a difficult challenge for the climate community. We propose and study a new stochastic weather typing approach to perform such a task. In addition to providing accurate small and medium precipitation, our procedure possesses built-in features that allow us to model adequately extreme precipitation distributions. First, we propose a new distribution for local precipitation via a probability mixture model of Gamma and Generalized Pareto (GP) distributions. The latter one stems from Extreme Value Theory (EVT). The performance of this mixture is tested on real and simulated data, and also compared to classical rainfall densities. Then our downscaling method, extending the recently developed nonhomogeneous stochastic weather typing approach, is presented. It can be summarized as a three-step program. First, regional weather precipitation patterns are constructed through a hierarchical ascending clustering method. Second, daily transitions among our precipitation patterns are represented by a nonhomogeneous Markov model influenced by large-scale atmospheric variables like NCEP reanalyses. Third, conditionally on these regional patterns, precipitation occurrence and intensity distributions are modeled as statistical mixtures. Precipitation amplitudes are assumed to follow our mixture of Gamma and GP densities. The proposed downscaling approach is applied to 37 weather stations in Illinois and compared to various possible parameterizations and to a direct modeling. Model selection procedures show that choosing one GP distribution shape parameter per pattern for all stations provides the best rainfall representation amongst all tested models. This work highlights the importance of EVT distributions to improve the modeling and downscaling of local extreme precipitations.},
  Doi                      = {10.1029/2006WR005308},
  File                     = {:Stochastic downscaling of precipitation- From dry events to heavy rainfalls.pdf:PDF;:Hydrology\\Stochastic downscaling of precipitation- From dry events to heavy rainfalls-errata.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Vrugt2003,
  Title                    = {Effective and efficient algorithm for multiobjective optimization of hydrologic models},
  Author                   = {Vrugt, Jasper A. and Gupta, Hoshin V. and Bastidas, Luis A. and Bouten, Willem and Sorooshian, Soroosh},
  Journal                  = {Water Resources Research},
  Year                     = {2003},
  Note                     = {1214},
  Number                   = {8},
  Pages                    = {n/a--n/a},
  Volume                   = {39},

  Abstract                 = {Practical experience with the calibration of hydrologic models suggests that any single-objective function, no matter how carefully chosen, is often inadequate to properly measure all of the characteristics of the observed data deemed to be important. One strategy to circumvent this problem is to define several optimization criteria (objective functions) that measure different (complementary) aspects of the system behavior and to use multicriteria optimization to identify the set of nondominated, efficient, or Pareto optimal solutions. In this paper, we present an efficient and effective Markov Chain Monte Carlo sampler, entitled the Multiobjective Shuffled Complex Evolution Metropolis (MOSCEM) algorithm, which is capable of solving the multiobjective optimization problem for hydrologic models. MOSCEM is an improvement over the Shuffled Complex Evolution Metropolis (SCEM-UA) global optimization algorithm, using the concept of Pareto dominance (rather than direct single-objective function evaluation) to evolve the initial population of points toward a set of solutions stemming from a stable distribution (Pareto set). The efficacy of the MOSCEM-UA algorithm is compared with the original MOCOM-UA algorithm for three hydrologic modeling case studies of increasing complexity.},
  Doi                      = {10.1029/2002WR001746},
  File                     = {:Effective and efficient algorithm for multiobjective optimization of hydrologic models.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Hydrology: Stochastic processes, Hydrology: Hydrologic budget, Hydrology: Instruments and techniques, parameter optimization, Markov chain Monte Carlo, multicriteria calibration, population diversity, Pareto ranking, hydrologic models},
  Owner                    = {jaq},
  Timestamp                = {2016.02.17},
  Url                      = {http://dx.doi.org/10.1029/2002WR001746}
}

@InBook{Wallace2003,
  Title                    = {Handbooks in OR \& MS},
  Author                   = {Stein W. Wallace and Stein-Erik Fleten},
  Chapter                  = {Stochastic Programming Models in Energy},
  Pages                    = {637-677},
  Publisher                = {Elsevier Science},
  Year                     = {2003},

  Abstract                 = {We give the reader a tour of good energy optimization models that explicitly
deal with uncertainty. The uncertainty usually stems from unpredictability of
demand and/or prices of energy, or from resource availability and prices. Since
most energy investments or operations involve irreversible decisions, a stochastic
programming approach is meaningful. Many of the models deal with electricity
investments and operations, but some oil and gas applications are also
presented. We consider both traditional cost minimization models and newer
models that reflect industry deregulation processes. The oldest research precedes
the development of linear programming, and most models within the market
paradigm have not yet found their final form.},
  File                     = {:Stochastic Programming Models in Energy.pdf:PDF},
  Keywords                 = {Stochastic programming, energy, regulated markets, deregulation, uncertainty, electricity, natural gas, oil.},
  Owner                    = {jaq},
  Timestamp                = {2016.01.13}
}

@Article{Walsh2015,
  Title                    = {Adaptation of water resource systems to an uncertain future.},
  Author                   = {C. L. Walsh and S. Blenkinsop and H. J. Fowler and A. Burton and R. J. Dawson and V. Glenis and L. J. Manning and C. G. Kilsby},
  Journal                  = {Hydrology and Earth System Sciences Discussions},
  Year                     = {2015},
  Pages                    = {8853-8889},
  Volume                   = {12},

  Abstract                 = {Globally, water resources management faces significant challenges from changing climate and growing populations. At local scales, the information provided by climate
models is insufficient to support the water sector in making future adaptation deci-
5 sions. Furthermore, projections of change in local water resources are wrought with
uncertainties surrounding natural variability, future greenhouse gas emissions, model
structure, population growth and water consumption habits. To analyse the magnitude
of these uncertainties, and their implications for local scale water resource planning,
we present a top-down approach for testing climate change adaptation options us-
10 ing probabilistic climate scenarios and demand projections. An integrated modelling
framework is developed which implements a new, gridded spatial weather generator,
coupled with a rainfall-runoff model and water resource management simulation model.
We use this to provide projections of the number of days, and associated uncertainty
that will require implementation of demand saving measures such as hose pipe bans
15 and drought orders. Results, which are demonstrated for the Thames basin, UK, indicate existing water supplies are sensitive to a changing climate and an increasing
population, and that the frequency of severe demand saving measures are projected
to increase. Considering both climate projections and population growth the median
number of drought order occurrences may increase five-fold. The effectiveness of a
20 range of demand management and supply options have been tested and shown to
provide significant benefits in terms of reducing the number of demand saving days.
We found that increased supply arising from various adaptation options may compensate for increasingly variable flows; however, without reductions in overall demand for
water resources such options will be insufficient on their own to adapt to uncertainties
25 in the projected changes in climate and population. For example, a 30 % reduction in
overall demand by 2050 has a greater impact on reducing the frequency of drought
orders than any of the individual or combinations of supply options; hence a portfolio
of measures are required.},
  File                     = {:Adaptation of water resource systems to an uncertain future..pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Article{Ward2013,
  Title                    = {Reservoir performance and dynamic management under plausible assumptions of future climate over seasons to decades},
  Author                   = {Ward, M. Neil
and Brown, Casey M.
and Baroang, Kye M.
and Kaheil, Yasir H.},
  Journal                  = {Climatic Change},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {307--320},
  Volume                   = {118},

  Abstract                 = {An analysis procedure is developed to explore the robustness and overall productivity of reservoir management under plausible assumptions about climate fluctuation and change. Results are presented based on a stylized version of a multi-use reservoir management model adapted from Angat Dam, Philippines. Analysis focuses on October-March, during which climatological inflow declines as the dry season arrives, and reservoir management becomes critical and challenging. Inflow is assumed to be impacted by climate fluctuations representing interannual variation (white noise), decadal to multidecadal variability (MDV, here represented by a stochastic autoregressive process) and global change (GC), here represented by a systematic linear trend in seasonal inflow total over the simulation period of 2008--2047. Stochastic (Monte Carlo) simulations are undertaken to explore reservoir performance. In this way, reservoir reliability and risk of extreme persistent water deficit are assessed in the presence of different combinations and magnitudes of GC and MDV. The effectiveness of dynamic management is then explored as a possible climate change adaptation practice, focusing on reservoir performance in the presence of a 20 {\%} downward inflow trend. In these dynamic management experiments, the October-March water allocation each year is adjusted based on seasonal forecasts and updated climate normals. The results illustrate how, in the near-term, MDV can be as significant as GC in impact for this kind of climate-related problem. The results also illustrate how dynamic management can mitigate the impacts. Overall, this type of analysis can deliver guidance on the expected benefits and risks of different management strategies and climate scenarios.},
  Doi                      = {10.1007/s10584-012-0616-0},
  ISSN                     = {1573-1480},
  Owner                    = {jaq},
  Timestamp                = {2016.05.12},
  Url                      = {http://dx.doi.org/10.1007/s10584-012-0616-0}
}

@Article{Weaver2013,
  Title                    = {Improving the contribution of climate model information to decision making: the value and demands of robust decision frameworks},
  Author                   = {Christopher P. Weaver and Robert J. Lempert and Casey Brown and John A. Hall and David Revell and Daniel Sarewitz},
  Year                     = {2013},

  Abstract                 = {In this paper, we review the need for, use of, and demands on climate modeling
to support so-called ‘robust’ decision frameworks, in the context of improving the
contribution of climate information to effective decision making. Such frameworks
seek to identify policy vulnerabilities under deep uncertainty about the future
and propose strategies for minimizing regret in the event of broken assumptions.
We argue that currently there is a severe underutilization of climate models
as tools for supporting decision making, and that this is slowing progress in
developing informed adaptation and mitigation responses to climate change. This
underutilization stems from two root causes, about which there is a growing body
of literature: one, a widespread, but limiting, conception that the usefulness of
climate models in planning begins and ends with regional-scale predictions of
multidecadal climate change; two, the general failure so far to incorporate learning
from the decision and social sciences into climate-related decision support in
key sectors. We further argue that addressing these root causes will require
expanding the conception of climate models; not simply as prediction machines
within ‘predict-then-act’ decision frameworks, but as scenario generators, sources
of insight into complex system behavior, and aids to critical thinking within robust
decision frameworks. Such a shift, however, would have implications for how
users perceive and use information from climate models and, ultimately, the types
of information they will demand from these models—and thus for the types of
simulations and numerical experiments that will have the most value for informing
decision making.},
  Doi                      = {10.1002/wcc.202},
  File                     = {:Improving the contribution of climate model information to decision making- the value and demands of robust decision frameworks.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Book{West1997,
  Title                    = {Bayesian Forecasting and Dynamic Models},
  Author                   = {Mike West and Jeff Harrison},
  Publisher                = {Springer-Verlag, New York, Inc.},
  Year                     = {1997},
  Edition                  = {2nd},

  Abstract                 = {This text is concerned with Bayesian learning, inference and forecasting in dynamic environments. We describe the structure and theory of classes of dynamic models and their uses in forecasting and time series analysis. The principles, models and methods of Bayesian forecasting and time - ries analysis have been developed extensively during the last thirty years. Thisdevelopmenthasinvolvedthoroughinvestigationofmathematicaland statistical aspects of forecasting models and related techniques. With this has come experience with applications in a variety of areas in commercial, industrial, scienti?c, and socio-economic ?elds. Much of the technical - velopment has been driven by the needs of forecasting practitioners and applied researchers. As a result, there now exists a relatively complete statistical and mathematical framework, presented and illustrated here. In writing and revising this book, our primary goals have been to present a reasonably comprehensive view of Bayesian ideas and methods in m- elling and forecasting, particularly to provide a solid reference source for advanced university students and research workers},
  File                     = {:Statistics\\Bayesian Forecasting and Dynamic Models.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Article{Whateley2016,
  Title                    = {Selecting Stochastic Climate Realizations to Efficiently Explore a Wide Range of Climate Risk to Water Resource Systems},
  Author                   = {Sarah Whateley and Scott Steinschneider and Casey Brown},
  Journal                  = {Journal of Water Resources Planning and Management},
  Year                     = {2016},

  Abstract                 = {There are significant computational requirements for assessing climate change impacts on water resource system reliability and
vulnerability, particularly when analyzing a wide range of plausible scenarios. These requirements often deter analysts from exhaustively
identifying climate hazards. This technical note investigates two approaches for generating a subset of stochastic climate realizations that
efficiently explore a range of risk to water supply systems. In both methods, a large ensemble of stochastic weather time series is generated to
simulate the natural variability of the local climate system, and a selected subset of these sequences is used in the impacts assessment. Method
1 selects the subset by first passing the entire ensemble through a rainfall-runoff model and then screening the hydrologic sequences using the
sequent peak algorithm. Method 2 selects a subset of climate sequences based on climate statistics alone, prior to hydrological modeling. Both
methods provide insight for identifying the climate statistics that best relate to the vulnerability of the water system and can be used to reduce
the computational burden of modeling climate variability and change impacts.},
  File                     = {:Hydrology\\Selecting Stochastic Climate Realizations to Efficiently Explore a Wide Range of Climate Risk to Water Resource Systems.pdf:PDF},
  Keywords                 = {Water management; Climate change; Monte Carlo simulation; Sequent peak algorithm},
  Owner                    = {jaq},
  Timestamp                = {2016.04.04}
}

@Article{Whateley2014,
  Title                    = {A climate change range-based method for estimating robustness for water resources supply},
  Author                   = {Sarah Whateley and Scott Steinschneider and Casey Brown},
  Journal                  = {Water Resoures Research},
  Year                     = {2014},
  Volume                   = {50},

  Abstract                 = {Many water planning and operation decisions are affected by climate uncertainty. Given concerns about the effects of uncertainty on the outcomes of long-term decisions, many water planners seek adaptation alternatives that are robust given a wide range of possible climate futures. However, there is no
standardized paradigm for quantifying robustness in the water sector. This study uses a new framework for
assessing the impact of future climate change and uncertainty on water supply systems and defines and
demonstrates a new metric for quantifying climate robustness. The metric is based on the range of climate
change space over which an alternative provides acceptable performance. The metric is independent of
assumptions regarding future climate; however, GCM-based (or other) climate projections can be used to
create a ‘‘climate-informed’’ version of the metric. The method is demonstrated for a water supply system in
the northeast United States to evaluate the additional robustness that can be attained through optimal
operational changes, by comparing optimal reservoir operations with current reservoir operations. Results
show the additional robustness gained through adaptation. They also reveal the additional insight regarding robust adaptation gained from the decision-scaling approach that would not be discerned using a GCM projection-based analysis.},
  Doi                      = {10.1002/2014WR015956},
  File                     = {:A climate change range-based method for estimating robustness for water resources supply.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Article{Wheater2005,
  Title                    = {Spatial-temporal rainfall modelling for flood risk estimation},
  Author                   = {Wheater, H.S. and Chandler, R.E. and Onof, C.J. and Isham, V.S. and Bellone, E. and Yang, C. and Lekkas, D. and Lourmas, G. and Segond, M.-L.},
  Journal                  = {Stochastic Environmental Research and Risk Assessment},
  Year                     = {2005},
  Number                   = {6},
  Pages                    = {403-416},
  Volume                   = {19},

  Doi                      = {10.1007/s00477-005-0011-8},
  File                     = {:Spatial-temporal rainfall modelling for flood risk estimation.pdf:PDF},
  ISSN                     = {1436-3240},
  Keywords                 = {Rainfall simulation; Poisson cluster processes; Generalized linear models; Spatial-temporal disaggregation},
  Language                 = {English},
  Owner                    = {jaq},
  Publisher                = {Springer-Verlag},
  Timestamp                = {2016.01.07},
  Url                      = {http://dx.doi.org/10.1007/s00477-005-0011-8}
}

@Article{Wi2015,
  author    = {Wi, S. and Yang, Y. C. E. and Steinschneider, S. and Khalil, A. and Brown, C. M.},
  title     = {Calibration approaches for distributed hydrologic models in poorly gaged basins: implication for streamflow projections under climate change},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2015},
  volume    = {19},
  number    = {2},
  pages     = {857--876},
  abstract  = {This study tests the performance and uncertainty
of calibration strategies for a spatially distributed hydrologic
model in order to improve model simulation accuracy and
understand prediction uncertainty at interior ungaged sites of
a sparsely gaged watershed. The study is conducted using a
distributed version of the HYMOD hydrologic model (HYMOD_DS) applied to the Kabul River basin. Several calibration experiments are conducted to understand the benefits and costs associated with different calibration choices,
including (1) whether multisite gaged data should be used
simultaneously or in a stepwise manner during model fitting, (2) the effects of increasing parameter complexity, and
(3) the potential to estimate interior watershed flows using
only gaged data at the basin outlet. The implications of the
different calibration strategies are considered in the context
of hydrologic projections under climate change. To address
the research questions, high-performance computing is utilized to manage the computational burden that results from
high-dimensional optimization problems. Several interesting
results emerge from the study. The simultaneous use of multisite data is shown to improve the calibration over a stepwise approach, and both multisite approaches far exceed a
calibration based on only the basin outlet. The basin outlet calibration can lead to projections of mid-21st century
streamflow that deviate substantially from projections under
multisite calibration strategies, supporting the use of caution
when using distributed models in data-scarce regions for climate change impact assessments. Surprisingly, increased parameter complexity does not substantially increase the uncertainty in streamflow projections, even though parameter
equifinality does emerge. The results suggest that increased
(excessive) parameter complexity does not always lead to increased predictive uncertainty if structural uncertainties are
present. The largest uncertainty in future streamflow results
from variations in projected climate between climate models,
which substantially outweighs the calibration uncertainty.},
  doi       = {10.5194/hess-19-857-2015},
  file      = {:Hydrology\\Calibration approaches for distributed hydrologic models in poorly gaged basins- implication for streamflow projections under climate change.pdf:PDF},
  owner     = {jaq},
  timestamp = {2017-01-02},
  url       = {http://www.hydrol-earth-syst-sci.net/19/857/2015/},
}

@Article{Wilks1999,
  author    = {D.S. Wilks},
  title     = {Multisite downscaling of daily precipitation with a stochastic weather generator},
  journal   = {Climate Research},
  year      = {1999},
  volume    = {11},
  pages     = {125-136},
  abstract  = {Stochastic models of daily precipitation are useful both for characterizing different precipitation
climates and for stochastic simulation of these climates in conjunction with agricultural,
hydrological, or other response models. A simple stochastic precipitation model is used to downscale—
i.e. disaggregate from area-average to individual station—precipitation statistics for 6 groups of 5 U.S.
stations, in a way that is consistent with observed relationships between the area-averaged series and
their constituent station series. Each group of stations is located within a General Circulation Model
grid-box-sized area, and collectively they exhibit a broad range of precipitation climates. The downscaling
procedure is validated using natural climate variability in the observed precipitation records as
an analog for climate change, by alternately considering collections of the driest and wettest seasons as
‘base’ and ‘future’ climates, and comparing the 2 sets of downscaled station parameters to those fit
directly to the respective withheld observations. The resulting downscaled stochastic model parameters
can be readily used for local-scale simulation of climate-change impacts.},
  comment   = {rainfall continuity measure},
  file      = {:Multisite downscaling of daily precipitation with a stochastic weather generator.pdf:PDF},
  keywords  = {Downscaling · Climate change · Precipitation · Stochastic modelling · United States},
  owner     = {jaq},
  timestamp = {2016.01.07},
}

@Article{Wilks1999a,
  Title                    = {Simultaneous stochastic simulation of daily precipitation, temperature and solar radiation at multiple sites in complex terrain},
  Author                   = {D.S. Wilks},
  Journal                  = {Agricultural and Forest Meteorology},
  Year                     = {1999},
  Pages                    = {85-101},
  Volume                   = {96},

  Abstract                 = {Stochastic generation of daily precipitation, maximum temperature, minimum temperature and solar radiation, simultaneously
at a collection of stations in a way that preserves realistic spatial correlations, is described and illustrated. The procedure is a
generalization of the familiar Richardson `WGEN' approach in that the same basic model structure and local parameter sets
are used. The precipitation model is extended to multiple sites by driving the local models with spatially correlated random
numbers. The nonprecipitation variables are generated using a high-dimensional autoregression that is a direct extension of the
conventional formulation. The necessary spatial correlations for both components are speci®ed as functions of horizontal and
vertical distances between stations so that the procedure can be applied to arbitrarily located station networks, for example at a
set of regular gridpoints. Results are illustrated for a network of 62 stations in an area of varied terrain in the western United
States.},
  File                     = {:Simultaneous stochastic simulation of daily precipitation, temperature and solar radiation at multiple sites in complex terrain.pdf:PDF},
  Keywords                 = {Markov-chain; Precipitation; Rain generator; Weather generator; Spatial variations},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Wilks1998,
  Title                    = {Multisite generalization of a daily stochastic precipitation generation model},
  Author                   = {D.S. Wilks},
  Journal                  = {Journal of Hydrology},
  Year                     = {1998},
  Volume                   = {210},

  Abstract                 = {The familiar chain-dependent-process stochastic model of daily precipitation, consisting of a two-state, first-order Markov
chain for occurrences and a mixed exponential distribution for nonzero amounts, is extended to simultaneous simulation at
multiple locations by driving a collection of individual models with serially independent but spatially correlated random
numbers. The procedure is illustrated for a network of 25 locations in New York state, with interstation separations ranging
approximately from 10 to 500 km. The resulting process reasonably reproduces various aspects of the joint distribution of daily
precipitation observations at the modeled locations. The mixed exponential distributions, in addition to providing substantially
better fits than the more conventional gamma distributions, are convenient for representing the tendency for smaller amounts at
locations near the edges of wet areas. Means, variances, and interstation correlations of monthly precipitation totals are also well
reproduced. In addition, the use of mixed exponential rather than gamma distributions yields interannual variability in the
synthetic series that is much closer to the observed.},
  File                     = {:Multisite generalization of a daily stochastic precipitation generation model.pdf:PDF},
  Keywords                 = {Markov chain; Monte Carlo methods; Precipitation; Spatial variations; Stochastic processes; Time series analysis},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07}
}

@Article{Wlostowski2016,
  Title                    = {Water Resources in a Changing Climate},
  Author                   = {Wlostowski, A. N. and E. M. Smull and J. Quebbeman},
  Journal                  = {Eos, Transactions, American Geophysical Union (EOS)},
  Year                     = {2016},

  Month                    = {January},
  Volume                   = {97},

  Doi                      = {10.1029/2016EO043385},
  File                     = {:Water Resources in a Changing Climate - Eos.pdf:PDF},
  Keywords                 = {Hydrology Days Conference Notes 2015},
  Owner                    = {jaq},
  Timestamp                = {2016.01.14}
}

@Article{Yang2005,
  Title                    = {Spatial-temporal rainfall simulation using generalized linear models},
  Author                   = {Yang, C. and Chandler, R. E. and Isham, V. S. and Wheater, H. S.},
  Journal                  = {Water Resources Research},
  Year                     = {2005},
  Note                     = {W11415},
  Number                   = {11},
  Pages                    = {n/a--n/a},
  Volume                   = {41},

  Abstract                 = {We consider the problem of simulating sequences of daily rainfall at a network of
sites in such a way as to reproduce a variety of properties realistically over a range of
spatial scales. The properties of interest will vary between applications but typically
will include some measures of ‘‘extreme’’ rainfall in addition to means, variances,
proportions of wet days, and autocorrelation structure. Our approach is to fit a generalized
linear model (GLM) to rain gauge data and, with appropriate incorporation of intersite
dependence structure, to use the GLM to generate simulated sequences. We illustrate the
methodology using a data set from southern England and show that the GLM is able
to reproduce many properties at spatial scales ranging from a single site to 2000 km2
(the limit of the available data).},
  Doi                      = {10.1029/2004WR003739},
  File                     = {:Spatial-temporal rainfall simulation using generalized linear models.pdf:PDF},
  ISSN                     = {1944-7973},
  Keywords                 = {Extreme events, Precipitation, Stochastic hydrology, Climate change and variability, North Atlantic Oscillation, beta binomial distribution, gamma distribution, logistic regression, weather generator},
  Owner                    = {jaq},
  Timestamp                = {2016.01.07},
  Url                      = {http://dx.doi.org/10.1029/2004WR003739}
}

@Article{Yapo1998,
  Title                    = {Multi-objective global optimization for hydrologic models},
  Author                   = {Patrice Ogou Yapo and Hoshin Vijai Gupta and Soroosh Sorooshian},
  Journal                  = {Journal of Hydrology},
  Year                     = {1998},
  Volume                   = {204},

  Abstract                 = {The development of automated (computer-based) calibration methods has focused mainly on the selection of a singleobjective measure of the distance between the model-simulated output and the data and the selection of an automatic
optimization algorithm to search for the parameter values which minimize that distance. However, practical experience
with model calibration suggests that no single-objective function is adequate to measure the ways in which the model fails
to match the important characteristics of the observed data. Given that some of the latest hydrologic models simulate several
of the watershed output fluxes (e.g. water, energy, chemical constituents, etc.), there is a need for effective and efficient multiobjective calibration procedures capable of exploiting all of the useful information about the physical system contained in the
measurement data time series. The MOCOM-UA algorithm, an effective and efficient methodology for solving the multipleobjective global optimization problem, is presented in this paper. The method is an extension of the successful SCE-UA
single-objective global optimization algorithm. The features and capabilities of MOCOM-UA are illustrated by means of a
simple hydrologic model calibration study.},
  File                     = {:Multi-objective global optimization for hydrologic models.pdf:PDF},
  Keywords                 = {Surface water; Watershed models; Parameter estimation; Calibration; Multiple objectives; Global optimization},
  Owner                    = {jaq},
  Timestamp                = {2016.02.17}
}

@Article{Young1994,
  Title                    = {A Multivariate Chain Model for Simulating Climatic Parameters from Daily Data},
  Author                   = {Kenneth C. Young},
  Journal                  = {Journal of Applied Meteorology},
  Year                     = {1994},
  Pages                    = {661-671},
  Volume                   = {33},

  Abstract                 = {A method is described for simultaneously simulating maximum and minimum temperatures and daily precipitation amounts in a physically consistent manner. The method “chains” actual days from a historical dataset by defining a “discriminant space” using multiple discriminant analysis. A set of analogous days is selected from discriminant space using a nearest-neighbor search. The next day in the chain is the day subsequent to a randomly selected day from the set of analogous days. The method was tested on data for Tucson and Safford, Arizona.

A high degree of similarity between the simulated and observed data was found. A slight tendency to underestimate the variance of monthly average temperatures was noted. The distribution of monthly temperature extremes was quite well reproduced with the exception of a tendency to be conservative in predicting the warmest minimum temperatures and the coolest maximum temperatures. Very little difference between the simulated and observed distributions of diurnal temperature range was found.

The median and 90th percentile of monthly precipitation totals were well reproduced. A tendency to underestimate the frequency of dry months was noted. The frequency of runs of wet and dry days of different lengths was found to be not significantly different for the simulated and observed data. Reproduction of wet-day run frequency for the first-order multivariate chain model was comparable to that using a two-state, first-order Markov chain.},
  File                     = {:Hydrology\\A Multivariate Chain Model for Simulating Climatic Parameters from Daily Data.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.07.27}
}

@Article{Yurtal2009,
  Title                    = {Hydropower Optimization for the Lower Seyhan System in Turkey using Dynamic Programming},
  Author                   = {Recep Yurtal and Galip Seckin and GaliMehmet Ardiclioglu},
  Journal                  = {Water International},
  Year                     = {2009},

  File                     = {:Hydropower Optimization for the Lower Seyhan System in Turkey using Dynamic Programming.pdf:PDF},
  Keywords                 = {reservoir optimization, reservoir operation, dynamic programming, water resources management, multi-reservoir optimization},
  Owner                    = {jaq},
  Timestamp                = {2016.01.15}
}

@Article{Zhao2011,
  Title                    = {A hydrologic post-processor for ensemble streamflow predictions},
  Author                   = {L. Zhao and Q. Duan and J. Schaake and A. Ye and J. Xia},
  Journal                  = {Advances in Geosciences},
  Year                     = {2011},
  Pages                    = {51-59},
  Volume                   = {29},

  Abstract                 = {This paper evaluates the performance of a statistical post-processor for imperfect hydrologic model forecasts. Assuming that the meteorological forecasts are well-calibrated, we employ a "General Linear Model (GLM)" to post-process simulations produced by a hydrologic model. For a particular forecast date, the observations and simulations from an "analysis window" and hydrologic model forecasts for a "forecast window", the GLM Post-Processor (GLMPP) is used to produce an ensemble of predictions of the streamflow observations that will occur during the "forecast window". The objectives of the GLMPP are to: (1) preserve any skill in the original hydrologic ensemble forecast; (2) correct systematic model biases; (3) retain the equal-likelihood assumption for the ensemble; (4) preserve temporal scale dependency relationships in streamflow hydrographs and the uncertainty in the predictions; and, (5) produce reliable ensemble predictions. 
Observed and simulated daily streamflow data from the Second Workshop on Model Parameter Estimation Experiment (MOPEX) are used to test how well these objectives are met when the GLMPP is applied to ensemble hydrologic forecasts driven by well calibrated meteorological forecasts. A 39-year hydrologic dataset from the French Broad basin is split into calibration and verification periods. The results show that the GLMPP built using data from the calibration period removes the mean bias when applied to hydrologic model simulations from both the calibration and verification periods. Probability distributions of the post-processed model simulations are shown to be closer to the climatological probability distributions of observed streamflow than the distributions of the unadjusted simulated flows. A number of experiments with different GLMPP configurations were also conducted to examine the effects of different configurations for forecast and analysis window lengths on the robustness of the results.},
  File                     = {:A hydrologic post-processor for ensemble streamflow predictions.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.12}
}

@PhdThesis{Zitzler1999,
  Title                    = {Evolutionary Algorithms for Multiobjective Optimization: Methods and Applications},
  Author                   = {Eckart Zitzler},
  School                   = {Swiss Federal Institute of Technology Zurich},
  Year                     = {1999},

  File                     = {:Optimization\\Evolutionary Algorithms for Multiobjective Optimization- Methods and Applications.pdf:PDF},
  Keywords                 = {c-metric, d-metric},
  Owner                    = {jaq},
  Timestamp                = {2016.03.28}
}

@Article{Zitzler2000,
  Title                    = {Comparison of Multiobjective Evolutionary Algorithms- Empirical Results},
  Author                   = {Eckart Zitzler and Kalyanmoy Deb and Lothar Thiele},
  Journal                  = {Evolutionary Computation},
  Year                     = {2000},
  Number                   = {2},
  Pages                    = {173-195},
  Volume                   = {8},

  Abstract                 = {In this paper, we provide a systematic comparison of various evolutionary approaches to
multiobjective optimization using six carefully chosen test functions. Each test function
involves a particular feature that is known to cause difficulty in the evolutionary optimization
process, mainly in converging to the Pareto-optimal front (e.g., multimodality and
deception). By investigating these different problem features separately, it is possible to
predict the kind of problems to which a certain technique is or is not well suited. However,
in contrast to what was suspected beforehand, the experimental results indicate a hierarchy
of the algorithms under consideration. Furthermore, the emerging effects are evidence
that the suggested test functions provide sufficient complexity to compare multiobjective
optimizers. Finally, elitism is shown to be an important factor for improving evolutionary
multiobjective search.},
  File                     = {:Optimization\\Comparison of Multiobjective Evolutionary Algorithms- Empirical Results.pdf:PDF},
  Keywords                 = {Evolutionary algorithms, multiobjective optimization, Pareto optimality, test functions,
elitism.},
  Owner                    = {jaq},
  Timestamp                = {2016.03.28}
}

@Book{Filho2015,
  Title                    = {Handbook of Climate Change Adaptation},
  Editor                   = {Walter Leal Filho},
  Publisher                = {Springer},
  Year                     = {2015},

  File                     = {:Handbook of Climate Change Adaptation.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Book{Kacprzyk2015,
  Title                    = {Springer Handbook of Computational Intelligence},
  Editor                   = {Janusz Kacprzyk and Witold Pedrycz},
  Publisher                = {Springer},
  Year                     = {2015},

  Abstract                 = {s
2 Many-Valued and Fuzzy Logics
Siegfried Gottwald .............................................................. 7
2.1 Basic Many-Valued Logics .............................................. 8
2.2 Fuzzy Sets ................................................................ 11
2.3 t-Norm-Based Logics ................................................... 13
2.4 Particular Fuzzy Logics .................................................. 16
2.5 Some Generalizations ................................................... 21
2.6 Extensions with Graded Notions of Inference ........................ 23
2.7 Some Complexity Results ............................................... 25
2.8 Concluding Remarks .................................................... 27
References ....................................................................... 27
3 Possibility Theory and Its Applications: Where Do We Stand?
Didier Dubois, Henry Prade ..................................................... 31
3.1 Historical Background................................................... 32
3.2 Basic Notions of Possibility Theory..................................... 33
3.3 Qualitative Possibility Theory........................................... 38
3.4 Quantitative Possibility Theory ......................................... 45
3.5 Some Applications....................................................... 49
3.6 Some Current Research Lines ........................................... 53
References ....................................................................... 54
4 Aggregation Functions on [0,1]
Radko Mesiar, Anna Kolesárová, Magda Komorníková ...................... 61
4.1 Historical and Introductory Remarks .................................. 61
4.2 Classification of Aggregation Functions................................ 63
4.3 Properties and Construction Methods ................................. 66
4.4 Concluding Remarks .................................................... 71
References ....................................................................... 72
5 Monotone Measures-Based Integrals
Erich P. Klement, Radko Mesiar ................................................ 75
5.1 Preliminaries, Choquet, and Sugeno Integrals........................ 76
5.2 Benvenuti Integral ...................................................... 80
5.3 Universal Integrals ...................................................... 82
5.4 General Integrals Which Are Not Universal ............................ 84
5.5 Concluding Remarks, Application Fields............................... 86
References ....................................................................... 87
6 The Origin of Fuzzy Extensions
Humberto Bustince, Edurne Barrenechea, Javier Fernández,
Miguel Pagola, Javier Montero ................................................. 89
6.1 Considerations Prior to the Concept of Extension of Fuzzy Sets ..... 90
6.2 Origin of the Extensions ................................................ 93
6.3 Type-2 Fuzzy Sets ....................................................... 94
6.4 Interval-Valued Fuzzy Sets ............................................. 98
6.5 Atanasssov’s Intuitionistic Fuzzy Sets or Bipolar Fuzzy Sets
of Type 2 or IF Fuzzy Sets ............................................... 103
6.6 Atanassov’s Interval-Valued Intuitionistic Fuzzy Sets ................ 105
6.7 Links Between the Extensions of Fuzzy Sets .......................... 106
6.8 Other Types of Sets ...................................................... 106
6.9 Conclusions .............................................................. 108
References ....................................................................... 108
7 F-Transform
Irina Perfilieva ................................................................... 113
7.1 Fuzzy Modeling .......................................................... 113
7.2 Fuzzy Partitions.......................................................... 114
7.3 Fuzzy Transform ......................................................... 117
7.4 Discrete F-Transform .................................................... 119
7.5 F-Transforms of Functions of Two Variables .......................... 120
7.6 F1-Transform............................................................. 121
7.7 Applications.............................................................. 122
7.8 Conclusions .............................................................. 129
References ....................................................................... 129
8 Fuzzy Linear Programming and Duality
Jaroslav Ramík, Milan Vlach.................................................... 131
8.1 Preliminaries............................................................. 132
8.2 Fuzzy Linear Programming.............................................. 135
8.3 Duality in Fuzzy Linear Programming.................................. 137
8.4 Conclusion ............................................................... 143
References ....................................................................... 143
9 Basic Solutions of Fuzzy Coalitional Games
Tomáš Kroupa, Milan Vlach..................................................... 145
9.1 Coalitional Games with Transferable Utility ........................... 146
9.2 Coalitional Games with Fuzzy Coalitions .............................. 150
9.3 Final Remarks............................................................ 155
References ....................................................................... 156
10 Basics of Fuzzy Sets
János C. Fodor, Imre J. Rudas .................................................. 159
10.1 Classical Mathematics and Logic ....................................... 160
10.2 Fuzzy Logic, Membership Functions, and Fuzzy Sets ................. 160
10.3 Connectives in Fuzzy Logic.............................................. 161
10.4 Concluding Remarks .................................................... 168
References ....................................................................... 168
11 Fuzzy Relations: Past, Present, and Future
Susana Montes, Ignacio Montes, Tania Iglesias .............................. 171
11.1 Fuzzy Relations .......................................................... 172
11.2 Cut Relations............................................................. 174
11.3 Fuzzy Binary Relations .................................................. 174
11.4 Particular Cases of Fuzzy Binary Relations............................. 179
11.5 Present and Future of Fuzzy Relations................................. 180
References ....................................................................... 180
12 Fuzzy Implications: Past, Present, and Future
Michał Baczynski, Balasubramaniam Jayaram, Sebastia Massanet,
Joan Torrens ..................................................................... 183
12.1 Fuzzy Implications: Examples, Properties, and Classes .............. 184
12.2 Current Research on Fuzzy Implications ............................... 187
12.3 Fuzzy Implications in Applications..................................... 193
12.4 Future of Fuzzy Implications ........................................... 198
References ....................................................................... 199
13 Fuzzy Rule-Based Systems
Luis Magdalena.................................................................. 203
13.1 Components of a Fuzzy Rule Based-System ........................... 204
13.2 Types of Fuzzy Rule-Based Systems .................................... 209
13.3 Hierarchical Fuzzy Rule-Based Systems................................ 213
13.4 Fuzzy Rule-Based Systems Design ..................................... 214
13.5 Conclusions .............................................................. 216
References ....................................................................... 217
14 Interpretability of Fuzzy Systems:
Current Research Trends and Prospects
Jose M. Alonso, Ciro Castiello, Corrado Mencar ................................ 219
14.1 The Quest for Interpretability........................................... 220
14.2 Interpretability Constraints and Criteria ............................... 224
14.3 Interpretability Assessment ............................................ 227
14.4 Designing Interpretable Fuzzy Systems ................................ 229
14.5 Interpretable Fuzzy Systems in the Real World ....................... 233
14.6 Future Research Trends on Interpretable Fuzzy Systems ............. 234
14.7 Conclusions .............................................................. 234
References ....................................................................... 235
XXX Contents
15 Fuzzy Clustering – Basic Ideas and Overview
Sadaaki Miyamoto .............................................................. 239
15.1 Fuzzy Clustering ......................................................... 239
15.2 Fuzzy c-Means........................................................... 239
15.3 Hierarchical Fuzzy Clustering ........................................... 245
15.4 Conclusion ............................................................... 246
References ....................................................................... 247
16 An Algebraic Model of Reasoning to Support Zadeh’s CWW
Enric Trillas....................................................................... 249
16.1 A View on Reasoning .................................................... 249
16.2 Models ................................................................... 250
16.3 Reasoning ................................................................ 251
16.4 Reasoning and Logic .................................................... 254
16.5 A Possible Scheme for an Algebraic Model
of Commonsense Reasoning............................................ 255
16.6 Weak and Strong Deduction: Refutations and Conjectures
in a BFA (with a Few Restrictions) ..................................... 260
16.7 Toward a Classification of Conjectures ................................. 262
16.8 Last Remarks............................................................. 264
16.9 Conclusions .............................................................. 265
References ....................................................................... 266
17 Fuzzy Control
Christian Moewes, Ralf Mikut, Rudolf Kruse................................... 269
17.1 Knowledge-Driven Control ............................................. 269
17.2 Classical Control Engineering ........................................... 270
17.3 Using Fuzzy Rules for Control ........................................... 271
17.4 A Glance at Some Industrial Applications ............................. 276
17.5 Automatic Learning of Fuzzy Controllers............................... 279
17.6 Conclusions .............................................................. 281
References ....................................................................... 281
18 Interval Type-2 Fuzzy PID Controllers
Tufan Kumbasar, Hani Hagras.................................................. 285
18.1 Fuzzy Control Background .............................................. 285
18.2 The General Fuzzy PID Controller Structure ............................ 286
18.3 Simulation Studies ...................................................... 291
18.4 Conclusion ............................................................... 292
References ....................................................................... 293
19 Soft Computing in Database and Information Management
Guy De Tré, Sławomir Zadrożny................................................. 295
19.1 Challenges for Modern Information Systems .......................... 295
19.2 Some Preliminaries...................................................... 296
19.3 Soft Computing in Information Modeling ............................. 298
19.4 Soft Computing in Querying ............................................ 302
19.5 Conclusions .............................................................. 309
References ....................................................................... 309
20 Application of Fuzzy Techniques to Autonomous Robots
Ismael Rodríguez Fdez, Manuel Mucientes, Alberto Bugarín Diz ............ 313
20.1 Robotics and Fuzzy Logic ............................................... 313
20.2 Wall-Following .......................................................... 314
20.3 Navigation ............................................................... 315
20.4 Trajectory Tracking....................................................... 317
20.5 Moving Target Tracking .................................................. 318
20.6 Perception ............................................................... 319
20.7 Planning ................................................................. 319
20.8 SLAM ...................................................................... 320
20.9 Cooperation .............................................................. 320
20.10 Legged Robots ........................................................... 321
20.11 Exoskeletons and Rehabilitation Robots .............................. 322
20.12 Emotional Robots ....................................................... 323
20.13 Fuzzy Modeling .......................................................... 323
20.14 Comments and Conclusions ............................................ 324
References ....................................................................... 325
Part C Rough Sets
21 Foundations of Rough Sets
Andrzej Skowron, Andrzej Jankowski, Roman W. Swiniarski ................ 331
21.1 Rough Sets: Comments on Development .............................. 331
21.2 Vague Concepts .......................................................... 332
21.3 Rough Set Philosophy ................................................... 333
21.4 Indiscernibility and Approximation.................................... 333
21.5 Decision Systems and Decision Rules .................................. 336
21.6 Dependencies............................................................ 337
21.7 Reduction of Attributes ................................................. 337
21.8 Rough Membership ..................................................... 338
21.9 Discernibility and Boolean Reasoning ................................. 339
21.10 Rough Sets and Induction .............................................. 340
21.11 Rough Set-Based Generalizations ..................................... 340
21.12 Rough Sets and Logic ................................................... 343
21.13 Conclusions .............................................................. 347
References ....................................................................... 347
22 Rough Set Methodology for Decision Aiding
Roman Słowiński, Salvatore Greco, Benedetto Matarazzo ................... 349
22.1 Data Inconsistency as a Reason for Using Rough Sets ................ 350
22.2 The Need for Replacing the Indiscernibility Relation
by the Dominance Relation when Reasoning About Ordinal Data .. 351
22.3 The Dominance-based Rough Set Approach
to Multi-Criteria Classification.......................................... 353
22.4 The Dominance-based Rough Set Approach to Multi-Criteria
Choice and Ranking ..................................................... 361
22.5 Important Extensions of DRSA .......................................... 366
22.6 DRSA to Operational Research Problems ............................... 366
22.7 Concluding Remarks on DRSA Applied to Multi-Criteria
Decision Problems....................................................... 367
References ....................................................................... 367
23 Rule Induction from Rough Approximations
Jerzy W. Grzymala-Busse ....................................................... 371
23.1 Complete and Consistent Data ......................................... 371
23.2 Inconsistent Data........................................................ 375
23.3 Decision Table with Numerical Attributes ............................. 377
23.4 Incomplete Data......................................................... 378
23.5 Conclusions .............................................................. 384
References ....................................................................... 384
24 Probabilistic Rough Sets
Yiyu Yao, Salvatore Greco, Roman Słowiński .................................. 387
24.1 Motivation for Studying Probabilistic Rough Sets..................... 388
24.2 Pawlak Rough Sets ...................................................... 388
24.3 A Basic Model of Probabilistic Rough Sets ............................. 390
24.4 Variants of Probabilistic Rough Sets ................................... 391
24.5 Three Fundamental Issues of Probabilistic Rough Sets............... 394
24.6 Dominance-Based Rough Set Approaches ............................ 398
24.7 A Basic Model of Dominance-Based Probabilistic Rough Sets ....... 399
24.8 Variants of Probabilistic Dominance-Based Rough Set Approach ... 400
24.9 Three Fundamental Issues of Probabilistic Dominance-Based
Rough Sets ............................................................... 403
24.10 Conclusions .............................................................. 409
References ....................................................................... 409
25 Generalized Rough Sets
JingTao Yao, Davide Ciucci, Yan Zhang ........................................ 413
25.1 Definition and Approximations of the Models ........................ 414
25.2 Theoretical Approaches ................................................. 420
25.3 Conclusion ............................................................... 422
References ....................................................................... 423
26 Fuzzy-Rough Hybridization
Masahiro Inuiguchi, Wei-Zhi Wu, Chris Cornelis, Nele Verbiest .............. 425
26.1 Introduction to Fuzzy-Rough Hybridization .......................... 425
26.2 Classification- Versus Approximation-Oriented
Fuzzy Rough Set Models ................................................ 427
26.3 Generalized Fuzzy Belief Structures with Application
in Fuzzy Information Systems .......................................... 437
26.4 Applications of Fuzzy Rough Sets ...................................... 444
References ....................................................................... 447
Part D Neural Networks
27 Artificial Neural Network Models
Peter Tino, Lubica Benuskova, Alessandro Sperduti .......................... 455
27.1 Biological Neurons ...................................................... 455
27.2 Perceptron ............................................................... 456
27.3 Multilayered Feed-Forward ANN Models .............................. 458
27.4 Recurrent ANN Models .................................................. 460
27.5 Radial Basis Function ANN Models ..................................... 464
27.6 Self-Organizing Maps ................................................... 465
27.7 Recursive Neural Networks ............................................. 467
27.8 Conclusion ............................................................... 469
References ....................................................................... 470
28 Deep and Modular Neural Networks
Ke Chen........................................................................... 473
28.1 Overview ................................................................. 473
28.2 Deep Neural Networks .................................................. 474
28.3 Modular Neural Networks............................................... 484
28.4 Concluding Remarks .................................................... 492
References ....................................................................... 492
29 Machine Learning
James T. Kwok, Zhi-Hua Zhou, Lei Xu ......................................... 495
29.1 Overview ................................................................. 495
29.2 Supervised Learning..................................................... 497
29.3 Unsupervised Learning.................................................. 502
29.4 Reinforcement Learning ................................................ 510
29.5 Semi-Supervised Learning.............................................. 513
29.6 Ensemble Methods ...................................................... 514
29.7 Feature Selection and Extraction....................................... 518
References ....................................................................... 519
30 Theoretical Methods in Machine Learning
Badong Chen, Weifeng Liu, José C. Principe................................... 523
30.1 Background Overview ................................................... 524
30.2 Reproducing Kernel Hilbert Spaces .................................... 525
30.3 Online Learning with Kernel Adaptive Filters ......................... 527
30.4 Illustration Examples.................................................... 538
30.5 Conclusion ............................................................... 542
References ....................................................................... 542
31 Probabilistic Modeling in Machine Learning
Davide Bacciu, Paulo J.G. Lisboa, Alessandro Sperduti, Thomas Villmann . 545
31.1 Probabilistic and Information-Theoretic Methods.................... 545
31.2 Graphical Models ........................................................ 552
31.3 Latent Variable Models.................................................. 560
31.4 Markov Models .......................................................... 565
31.5 Conclusion and Further Reading ....................................... 572
References ....................................................................... 573
XXXIV Contents
32 Kernel Methods
Marco Signoretto, Johan A. K. Suykens ........................................ 577
32.1 Background .............................................................. 578
32.2 Foundations of Statistical Learning .................................... 580
32.3 Primal–Dual Methods ................................................... 586
32.4 Gaussian Processes ...................................................... 593
32.5 Model Selection ......................................................... 596
32.6 More on Kernels ......................................................... 597
32.7 Applications.............................................................. 600
References ....................................................................... 601
33 Neurodynamics
Robert Kozma, Jun Wang, Zhigang Zeng...................................... 607
33.1 Dynamics of Attractor and Analog Networks .......................... 607
33.2 Synchrony, Oscillations, and Chaos in Neural Networks .............. 611
33.3 Memristive Neurodynamics............................................. 629
33.4 Neurodynamic Optimization............................................ 634
References ....................................................................... 639
34 Computational Neuroscience – Biophysical Modeling
of Neural Systems
Harrison Stratton, Jennie Si..................................................... 649
34.1 Anatomy and Physiology of the Nervous System ..................... 649
34.2 Cells and Signaling Among Cells........................................ 652
34.3 Modeling Biophysically Realistic Neurons ............................. 656
34.4 Reducing Computational Complexity
for Large Network Simulations ......................................... 660
34.5 Conclusions .............................................................. 662
References ....................................................................... 662
35 Computational Models of Cognitive and Motor Control
Ali A. Minai ...................................................................... 665
35.1 Overview ................................................................. 665
35.2 Motor Control ............................................................ 667
35.3 Cognitive Control and Working Memory ............................... 670
35.4 Conclusion ............................................................... 674
References ....................................................................... 674
36 Cognitive Architectures and Agents
Sebastien Hélie, Ron Sun ....................................................... 683
36.1 Background .............................................................. 683
36.2 Adaptive Control of Thought-Rational (ACT-R) ........................ 685
36.3 Soar....................................................................... 688
36.4 CLARION................................................................... 690
36.5 Cognitive Architectures as Models of Multi-Agent Interaction ....... 693
36.6 General Discussion ...................................................... 694
References ....................................................................... 695
Contents XXXV
37 Embodied Intelligence
Angelo Cangelosi, Josh Bongard, Martin H. Fischer, Stefano Nolfi .......... 697
37.1 Introduction to Embodied Intelligence ................................ 697
37.2 Morphological Computation for Body-Behavior Coadaptation ...... 698
37.3 Sensory–Motor Coordination in Evolving Robots ..................... 701
37.4 Developmental Robotics for Higher Order Embodied Cognitive
Capabilities .............................................................. 703
37.5 Conclusion ............................................................... 709
References ....................................................................... 711
38 Neuromorphic Engineering
Giacomo Indiveri ................................................................ 715
38.1 The Origins ............................................................... 715
38.2 Neural and Neuromorphic Computing ................................. 716
38.3 The Importance of Fundamental Neuroscience ....................... 717
38.4 Temporal Dynamics in Neuromorphic Architectures .................. 718
38.5 Synapse and Neuron Circuits ........................................... 719
38.6 Spike-Based Multichip Neuromorphic Systems ....................... 721
38.7 State-Dependent Computation in Neuromorphic Systems........... 722
38.8 Conclusions .............................................................. 722
References ....................................................................... 723
39 Neuroengineering
Damien Coyle, Ronen Sosnik ................................................... 727
39.1 Overview – Neuroengineering in General ............................. 728
39.2 Human Motor Control ................................................... 732
39.3 Modeling the Motor System – Internal Motor Models ................ 733
39.4 Sensorimotor Learning .................................................. 736
39.5 MRI and the Motor System – Structure and Function ................ 738
39.6 Electrocorticographic Motor Cortical Surface Potentials .............. 741
39.7 MEG and EEG – Extra Cerebral Magnetic and Electric Fields
of the Motor System..................................................... 745
39.8 Extracellular Recording – Decoding Hand Movements
from Spikes and Local Field Potential ................................. 748
39.9 Translating Brainwaves into Control Signals – BCIs ................... 754
39.10 Conclusion ............................................................... 762
References ....................................................................... 764
40 Evolving Connectionist Systems:
From Neuro-Fuzzy-, to Spiking- and Neuro-Genetic
Nikola Kasabov .................................................................. 771
40.1 Principles of Evolving Connectionist Systems (ECOS) .................. 771
40.2 Hybrid Systems and Evolving Neuro-Fuzzy Systems .................. 772
40.3 Evolving Spiking Neural Networks (eSNN) ............................. 775
40.4 Computational Neuro-Genetic Modeling (CNGM) ..................... 778
40.5 Conclusions and Further Directions .................................... 779
References ....................................................................... 780
XXXVI Contents
41 Machine Learning Applications
Piero P. Bonissone ............................................................... 783
41.1 Motivation ............................................................... 784
41.2 Machine Learning (ML) Functions ...................................... 786
41.3 CI/ML Applications in Industrial Domains:
Prognostics and Health Management (PHM) .......................... 787
41.4 CI/ML Applications in Financial Domains: Risk Management ........ 797
41.5 Model Ensembles and Fusion .......................................... 807
41.6 Summary and Future Research Challenges ............................ 812
References ....................................................................... 817
Part E Evolutionary Computation
42 Genetic Algorithms
Jonathan E. Rowe ............................................................... 825
42.1 Algorithmic Framework ................................................. 826
42.2 Selection Methods....................................................... 828
42.3 Replacement Methods .................................................. 831
42.4 Mutation Methods....................................................... 832
42.5 Selection–Mutation Balance ........................................... 834
42.6 Crossover Methods ...................................................... 836
42.7 Population Diversity..................................................... 838
42.8 Parallel Genetic Algorithms ............................................. 839
42.9 Populations as Solutions ............................................... 841
42.10 Conclusions .............................................................. 842
References ....................................................................... 843
43 Genetic Programming
James McDermott, Una-May O’Reilly .......................................... 845
43.1 Evolutionary Search for Executable Programs ......................... 845
43.2 History.................................................................... 846
43.3 Taxonomy of AI and GP ................................................. 848
43.4 Uses of GP ................................................................ 853
43.5 Research Topics .......................................................... 857
43.6 Practicalities ............................................................. 861
References ....................................................................... 862
44 Evolution Strategies
Nikolaus Hansen, Dirk V. Arnold, Anne Auger................................. 871
44.1 Overview ................................................................. 871
44.2 Main Principles .......................................................... 873
44.3 Parameter Control ....................................................... 877
44.4 Theory .................................................................... 886
References ....................................................................... 895
45 Estimation of Distribution Algorithms
Martin Pelikan, Mark W. Hauschild, Fernando G. Lobo ...................... 899
45.1 Basic EDA Procedure ..................................................... 900
Contents XXXVII
45.2 Taxonomy of EDA Models ............................................... 903
45.3 Overview of EDAs ........................................................ 908
45.4 EDA Theory ............................................................... 916
45.5 Efficiency Enhancement Techniques for EDAs ......................... 917
45.6 Starting Points for Obtaining Additional Information ................ 920
45.7 Summary and Conclusions.............................................. 921
References ....................................................................... 921
46 Parallel Evolutionary Algorithms
Dirk Sudholt...................................................................... 929
46.1 Parallel Models .......................................................... 931
46.2 Effects of Parallelization ................................................ 935
46.3 On the Spread of Information in Parallel EAs ......................... 938
46.4 Examples Where Parallel EAs Excel ..................................... 943
46.5 Speedups by Parallelization ............................................ 949
46.6 Conclusions .............................................................. 956
References ....................................................................... 957
47 Learning Classifier Systems
Martin V. Butz ................................................................... 961
47.1 Background .............................................................. 962
47.2 XCS ........................................................................ 965
47.3 XCSF ....................................................................... 970
47.4 Data Mining.............................................................. 972
47.5 Behavioral Learning ..................................................... 973
47.6 Conclusions .............................................................. 977
47.7 Books and Source Code ................................................. 978
References ....................................................................... 979
48 Indicator-Based Selection
Lothar Thiele ..................................................................... 983
48.1 Motivation ............................................................... 983
48.2 Basic Concepts ........................................................... 984
48.3 Selection Schemes....................................................... 987
48.4 Preference-Based Selection ............................................ 990
48.5 Concluding Remarks .................................................... 992
References ....................................................................... 993
49 Multi-Objective Evolutionary Algorithms
Kalyanmoy Deb .................................................................. 995
49.1 Preamble ................................................................. 995
49.2 Evolutionary Multi-Objective Optimization (EMO) .................... 996
49.3 A Brief Timeline for the Development of EMO Methodologies ....... 999
49.4 Elitist EMO: NSGA-II ..................................................... 1000
49.5 Applications of EMO ..................................................... 1002
49.6 Recent Developments in EMO .......................................... 1004
49.7 Conclusions .............................................................. 1010
References ....................................................................... 1011
XXXVIII Contents
50 Parallel Multiobjective Evolutionary Algorithms
Francisco Luna, Enrique Alba................................................... 1017
50.1 Multiobjective Optimization and Parallelism ......................... 1017
50.2 Parallel Models for Evolutionary Multi-Objective Algorithms ........ 1018
50.3 An Updated Review of the Literature .................................. 1020
50.4 Conclusions and Future Works ......................................... 1026
References ....................................................................... 1027
51 Many-Objective Problems: Challenges and Methods
Antonio López Jaimes, Carlos A. Coello Coello................................. 1033
51.1 Background .............................................................. 1033
51.2 Basic Concepts and Notation ........................................... 1034
51.3 Sources of Difficulty to Solve Many-Objective
Optimization Problems.................................................. 1036
51.4 Current Approaches to Deal with Many-Objective Problems......... 1038
51.5 Recombination Operators and Mating Restrictions ................... 1042
51.6 Scalarization Methods .................................................. 1043
51.7 Conclusions and Research Paths ....................................... 1043
References ....................................................................... 1044
52 Memetic and Hybrid Evolutionary Algorithms
Jhon Edgar Amaya, Carlos Cotta Porras, Antonio J. Fernández Leiva ....... 1047
52.1 Overview ................................................................. 1047
52.2 A Bird’s View of Evolutionary Algorithms.............................. 1049
52.3 From Hybrid Metaheuristics to Hybrid EAs ............................ 1050
52.4 Memetic Algorithms ..................................................... 1052
52.5 Cooperative Optimization Models ...................................... 1055
52.6 Conclusions .............................................................. 1056
References ....................................................................... 1056
53 Design of Representations and Search Operators
Franz Rothlauf................................................................... 1061
53.1 Representations ......................................................... 1061
53.2 Search Operators......................................................... 1065
53.3 Problem-Specific Design of Representations and Search Operators. 1071
53.4 Summary and Conclusions.............................................. 1079
References ....................................................................... 1080
54 Stochastic Local Search Algorithms: An Overview
Holger H. Hoos, Thomas Stützle ................................................ 1085
54.1 The Nature and Concept of SLS ......................................... 1086
54.2 Greedy Construction Heuristics and Iterative Improvement ......... 1089
54.3 Simple SLS Methods ..................................................... 1091
54.4 Hybrid SLS Methods ..................................................... 1094
54.5 Population-Based SLS Methods ........................................ 1095
54.6 Recent Research Directions ............................................. 1097
References ....................................................................... 1100
Contents XXXIX
55 Parallel Evolutionary Combinatorial Optimization
El-Ghazali Talbi ................................................................. 1107
55.1 Motivation ............................................................... 1107
55.2 Parallel Design of EAs ................................................... 1108
55.3 Parallel Implementation of EAs ........................................ 1113
55.4 Parallel EAs Under ParadisEO ........................................... 1122
55.5 Conclusions and Perspectives .......................................... 1123
References ....................................................................... 1124
56 How to Create Generalizable Results
Thomas Bartz-Beielstein........................................................ 1127
56.1 Test Problems in Computational Intelligence ......................... 1127
56.2 Features of Optimization Problems .................................... 1128
56.3 Algorithm Features ...................................................... 1130
56.4 Objective Functions ..................................................... 1131
56.5 Case Studies.............................................................. 1133
56.6 Summary and Outlook .................................................. 1141
References ....................................................................... 1142
57 Computational Intelligence in Industrial Applications
Ekaterina Vladislavleva, Guido Smits, Mark Kotanchek ...................... 1143
57.1 Intelligence and Computation ......................................... 1143
57.2 Computational Modeling for Predictive Analytics..................... 1144
57.3 Methods .................................................................. 1147
57.4 Workflows ................................................................ 1149
57.5 Examples ................................................................. 1150
57.6 Conclusions .............................................................. 1155
References ....................................................................... 1156
58 Solving Phase Equilibrium Problems
by Means of Avoidance-Based Multiobjectivization
Mike Preuss, Simon Wessing, Günter Rudolph, Gabriele Sadowski.......... 1159
58.1 Coping with Real-World Optimization Problems ..................... 1159
58.2 The Phase-Equilibrium Calculation Problem.......................... 1161
58.3 Multiobjectivization-Assisted Multimodal Optimization: MOAMO ... 1162
58.4 Solving General Phase-Equilibrium Problems ........................ 1165
58.5 Conclusions and Outlook ............................................... 1169
References ....................................................................... 1169
59 Modeling and Optimization of Machining Problems
Dirk Biermann, Petra Kersting, Tobias Wagner, Andreas Zabel .............. 1173
59.1 Elements of a Machining Process ...................................... 1174
59.2 Design Optimization..................................................... 1175
59.3 Computer-Aided Design and Manufacturing.......................... 1176
59.4 Modeling and Simulation of the Machining Process ................. 1177
59.5 Optimization of the Process Parameters ............................... 1178
59.6 Process Monitoring ...................................................... 1179
59.7 Visualization ............................................................. 1179
XL Contents
59.8 Summary and Outlook .................................................. 1180
References ....................................................................... 1180
60 Aerodynamic Design with Physics-Based Surrogates
Emiliano Iuliano, Domenico Quagliarella ..................................... 1185
60.1 The Aerodynamic Design Problem ..................................... 1186
60.2 Literature Review of Surrogate-Based Optimization.................. 1187
60.3 POD-Based Surrogates .................................................. 1190
60.4 Application Example of POD-Based Surrogates ....................... 1191
60.5 Strategies for Improving POD Model Quality: Adaptive Sampling.... 1199
60.6 Aerodynamic Shape Optimization by Surrogate Modeling
and Evolutionary Computing ........................................... 1201
60.7 Conclusions .............................................................. 1207
References ....................................................................... 1208
61 Knowledge Discovery in Bioinformatics
Julie Hamon, Julie Jacques, Laetitia Jourdan, Clarisse Dhaenens ........... 1211
61.1 Challenges in Bioinformatics ........................................... 1211
61.2 Association Rules by Evolutionary Algorithm in Bioinformatics ..... 1212
61.3 Feature Selection for Classification and Regression
by Evolutionary Algorithm in Bioinformatics.......................... 1215
61.4 Clustering by Evolutionary Algorithm in Bioinformatics.............. 1218
61.5 Conclusion ............................................................... 1220
References ....................................................................... 1221
62 Integration of Metaheuristics and Constraint Programming
Luca Di Gaspero.................................................................. 1225
62.1 Constraint Programming and Metaheuristics ......................... 1225
62.2 Constraint Programming Essentials .................................... 1226
62.3 Integration of Metaheuristics and CP .................................. 1230
62.4 Conclusions .............................................................. 1234
References ....................................................................... 1235
63 Graph Coloring and Recombination
Rhyd Lewis ....................................................................... 1239
63.1 Graph Coloring........................................................... 1239
63.2 Algorithms for Graph Coloring.......................................... 1240
63.3 Setup ..................................................................... 1244
63.4 Experiment 1 ............................................................ 1246
63.5 Experiment 2 ............................................................ 1249
63.6 Conclusions and Discussion ............................................ 1251
References ....................................................................... 1252
64 Metaheuristic Algorithms and Tree Decomposition
Thomas Hammerl, Nysret Musliu, Werner Schafhauser....................... 1255
64.1 Tree Decompositions .................................................... 1256
64.2 Generating Tree Decompositions by Metaheuristic Techniques...... 1258
64.3 Conclusion ............................................................... 1268
References ....................................................................... 1269
Contents XLI
65 Evolutionary Computation and Constraint Satisfaction
Jano I. van Hemert .............................................................. 1271
65.1 Informal Introduction to CSP ........................................... 1271
65.2 Formal Definitions ...................................................... 1272
65.3 Solving CSP with Evolutionary Algorithms ............................. 1273
65.4 Performance Indicators ................................................. 1275
65.5 Specific Constraint Satisfaction Problems.............................. 1277
65.6 Creating Rather than Solving Problems................................ 1283
65.7 Conclusions and Future Directions ..................................... 1284
References ....................................................................... 1284
Part F Swarm Intelligence
66 Swarm Intelligence in Optimization and Robotics
Christian Blum, Roderich Groß ................................................. 1291
66.1 Overview ................................................................. 1291
66.2 SI in Optimization ....................................................... 1292
66.3 SI in Robotics: Swarm Robotics......................................... 1296
66.4 Research Challenges..................................................... 1302
References ....................................................................... 1303
67 Preference-Based Multiobjective
Particle Swarm Optimization for Airfoil Design
Robert Carrese, Xiaodong Li .................................................... 1311
67.1 Airfoil Design ............................................................ 1311
67.2 Shape Parameterization and Flow Solver ............................. 1317
67.3 Optimization Algorithm ................................................. 1319
67.4 Case Study: Airfoil Shape Optimization ................................ 1323
67.5 Conclusion ............................................................... 1329
References ....................................................................... 1329
68 Ant Colony Optimization for the Minimum-Weight Rooted
Arborescence Problem
Christian Blum, Sergi Mateo Bellido ........................................... 1333
68.1 Introductiory Remarks .................................................. 1333
68.2 The Minimum-Weight Rooted Arborescence Problem ................ 1334
68.3 DP-Heur: A Heuristic Approach to the MWRA Problem............... 1335
68.4 Ant Colony Optimization for the MWRA Problem...................... 1335
68.5 Experimental Evaluation................................................ 1337
68.6 Conclusions and Future Work .......................................... 1343
References ....................................................................... 1343
69 An Intelligent Swarm of Markovian Agents
Dario Bruneo, Marco Scarpa, Andrea Bobbio, Davide Cerotti,
Marco Gribaudo ................................................................. 1345
69.1 Swarm Intelligence: A Modeling Perspective .......................... 1345
69.2 Markovian Agent Models................................................ 1346
69.3 A Consolidated Example: WSN Routing ................................ 1349
XLII Contents
69.4 Ant Colony Optimization ................................................ 1354
69.5 Conclusions .............................................................. 1358
References ....................................................................... 1359
70 Honey Bee Social Foraging Algorithm for Resource Allocation
Jairo Alonso Giraldo, Nicanor Quijano, Kevin M. Passino .................... 1361
70.1 Honey Bee Foraging Algorithm ......................................... 1363
70.2 Application in a Multizone Temperature Control Grid ................ 1365
70.3 Results.................................................................... 1371
70.4 Discussion................................................................ 1373
70.5 Conclusions .............................................................. 1374
References ....................................................................... 1374
71 Fundamental Collective Behaviors in Swarm Robotics
Vito Trianni, Alexandre Campo ................................................. 1377
71.1 Designing Swarm Behaviours........................................... 1378
71.2 Getting Together: Aggregation ......................................... 1379
71.3 Acting Together: Synchronization ...................................... 1381
71.4 Staying Together: Coordinated Motion................................. 1383
71.5 Searching Together: Collective Exploration ............................ 1386
71.6 Deciding Together: Collective Decision Making ....................... 1388
71.7 Conclusions .............................................................. 1390
References ....................................................................... 1391
72 Collective Manipulation and Construction
Lynne Parker ..................................................................... 1395
72.1 Object Transportation ................................................... 1395
72.2 Object Sorting and Clustering .......................................... 1401
72.3 Collective Construction and Wall Building............................. 1402
72.4 Conclusions .............................................................. 1404
References ....................................................................... 1404
73 Reconfigurable Robots
Kasper Støy....................................................................... 1407
73.1 Mechatronics System Integration ...................................... 1409
73.2 Connection Mechanisms ................................................ 1410
73.3 Energy .................................................................... 1411
73.4 Distributed Control ...................................................... 1412
73.5 Programmability and Debugging ...................................... 1417
73.6 Perspective............................................................... 1418
73.7 Further Reading ......................................................... 1419
References ....................................................................... 1419
74 Probabilistic Modeling of Swarming Systems
Nikolaus Correll, Heiko Hamann ............................................... 1423
74.1 From Bioligical to Artificial Swarms .................................... 1423
74.2 The Master Equation .................................................... 1424
74.3 Non-Spatial Probabilistic Models ...................................... 1424
Contents XLIII
74.4 Spatial Models: Collective Optimization ............................... 1428
74.5 Conclusion ............................................................... 1431
References ....................................................................... 1431
Part G Hybrid Systems
75 A Robust Evolving Cloud-Based Controller
Plamen P. Angelov, Igor Škrjanc, Sašo Blažič ................................. 1435
75.1 Overview of Some Adaptive and Evolving Control Approaches ...... 1435
75.2 Structure of the Cloud-Based Controller............................... 1437
75.3 Evolving Methodology for RECCo ....................................... 1439
75.4 Simulation Study ........................................................ 1442
75.5 Conclusions .............................................................. 1447
References ....................................................................... 1448
76 Evolving Embedded Fuzzy Controllers
Oscar H. Montiel Ross, Roberto Sepúlveda Cruz ............................... 1451
76.1 Overview ................................................................. 1452
76.2 Type-1 and Type-2 Fuzzy Controllers .................................. 1454
76.3 Host Technology ......................................................... 1457
76.4 Hardware Implementation Approaches ............................... 1458
76.5 Development of a Standalone IT2FC ................................... 1461
76.6 Developing of IT2FC Coprocessors ...................................... 1466
76.7 Implementing a GA in an FPGA ........................................ 1468
76.8 Evolving Fuzzy Controllers .............................................. 1470
References ....................................................................... 1475
77 Multiobjective Genetic Fuzzy Systems
Hisao Ishibuchi, Yusuke Nojima ................................................ 1479
77.1 Fuzzy System Design .................................................... 1479
77.2 Accuracy Maximization.................................................. 1482
77.3 Complexity Minimization ............................................... 1487
77.4 Single-Objective Approaches ........................................... 1489
77.5 Evolutionary Multiobjective Approaches .............................. 1491
77.6 Conclusion ............................................................... 1494
References ....................................................................... 1494
78 Bio-Inspired Optimization of Type-2 Fuzzy Controllers
Oscar Castillo..................................................................... 1499
78.1 Related Work in Type-2 Fuzzy Control ................................. 1499
78.2 Fuzzy Logic Systems ..................................................... 1500
78.3 Bio-Inspired Optimization Methods ................................... 1503
78.4 General Overview of the Area and Future Trends ..................... 1505
78.5 Conclusions .............................................................. 1506
References ....................................................................... 1506
XLIV Contents
79 Pattern Recognition with Modular Neural Networks
and Type-2 Fuzzy Logic
Patricia Melin .................................................................... 1509
79.1 Related Work in the Area ............................................... 1509
79.2 Overview of Fuzzy Edge Detectors ...................................... 1510
79.3 Experimental Setup ..................................................... 1512
79.4 Experimental Results.................................................... 1513
79.5 Conclusions .............................................................. 1515
References ....................................................................... 1515
80 Fuzzy Controllers for Autonomous Mobile Robots
Patricia Melin, Oscar Castillo ................................................... 1517
80.1 Fuzzy Control of Mobile Robots......................................... 1517
80.2 The Chemical Optimization Paradigm.................................. 1518
80.3 The Mobile Robot........................................................ 1521
80.4 Fuzzy Logic Controller ................................................... 1522
80.5 Experimental Results.................................................... 1523
80.6 Conclusions .............................................................. 1530
References ....................................................................... 1530
81 Bio-Inspired Optimization Methods
Fevrier Valdez .................................................................... 1533
81.1 Bio-Inspired Methods .................................................. 1533
81.2 Bio-Inspired Optimization Methods ................................... 1533
81.3 A Brief History of GPUs .................................................. 1535
81.4 Experimental Results.................................................... 1535
81.5 Conclusions .............................................................. 1538
References ....................................................................... 1538},
  File                     = {:Handbook of Computational Intelligence.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.15}
}

@Proceedings{Kasanicky2011,
  Title                    = {Ensemble Kalman Filter},
  Year                     = {2011},
  Editor                   = {I. Kasanicky and K. Eben},

  Abstract                 = {The ensemble Kalman filter (EnFK) has recently become one of the
most popular methods for high dimensional data assimilation and it is widely
used in many disciplines such as discretization of partial differential equations in
geophysics or image reconstruction. The EnKF has been originally proposed as
a Monte Carlo approximation to the extended Kalman filter, which is in practice
inapplicable when dimension of the input data is huge.
Numerous publications have studied applications and asymptotic results of the
EnKF, while properties of the Kalman filter (KF) and EnKF for the infinite
dimensional Hilbert spaces are still under the development.
The main purpose of this paper is a brief description of the high dimensional EnKF
with references to the most valuable publications. Also, a short introduction to
problems related with KF and EnKF on infinite dimensional Hilbert spaces is
included.},
  File                     = {:Ensemble Kalman Filter.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.20}
}

@Book{Kibaroglu2011,
  Title                    = {Turkey's Water Policy},
  Editor                   = {Aysegul Kibaroglu and Annika Kramer and Waltina Scheumann},
  Publisher                = {Springer},
  Year                     = {2011},

  File                     = {:Turkeys Water Policy.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.15}
}

@Book{Resende2006,
  Title                    = {Handbook of Optimization in Telecommunications},
  Editor                   = {Mauricio G. C. Resende and Panos M. Pardalos},
  Publisher                = {Springer},
  Year                     = {2006},

  File                     = {:Optimization\\Handbook of Optimization in Telecommunications.pdf:PDF},
  Keywords                 = {linear, simplex, shortest path, min cost network},
  Owner                    = {jaq},
  Timestamp                = {2016.04.14}
}

@Book{Sakawa2013,
  Title                    = {Linear and Multiobjective Programming with Fuzzy Stochastic Extensions},
  Editor                   = {Masatoshi Sakawa and Ichiro Nishizaki and Hitoshi Yano},
  Publisher                = {Springer},
  Year                     = {2013},

  Abstract                 = {1 Introduction .................................................................. 1
1.1 Linear Programming in Two Dimensions ............................. 1
1.2 Extensions of Linear Programming.................................... 3
Problems ....................................................................... 5
2 Linear Programming ........................................................ 7
2.1 Algebraic Approach to Two-Dimensional Linear Programming..... 7
2.2 Typical Examples of Linear Programming Problems................. 10
2.3 Standard Form of Linear Programming ............................... 12
2.4 Simplex Method ........................................................ 18
2.5 Two-Phase Method ..................................................... 28
2.6 Revised Simplex Method .............................................. 39
2.7 Duality .................................................................. 49
2.8 Dual Simplex Method .................................................. 55
Problems ....................................................................... 67
3 Multiobjective Linear Programming ...................................... 73
3.1 Problem Formulation and Solution Concepts ......................... 73
3.2 Scalarization Methods.................................................. 77
3.2.1 Weighting Method ............................................. 78
3.2.2 Constraint Method ............................................. 81
3.2.3 Weighted Minimax Method ................................... 83
3.3 Linear Goal Programming ............................................. 87
3.4 Compromise Programming ............................................ 92
3.5 Interactive Multiobjective Linear Programming ...................... 96
Problems ....................................................................... 102
4 Fuzzy Linear Programming ................................................ 105
4.1 Fuzzy Sets and Fuzzy Decision ........................................ 105
4.2 Fuzzy Linear Programming ............................................ 115
4.3 Fuzzy Multiobjective Linear Programming ........................... 119
4.4 Interactive Fuzzy Multiobjective Linear Programming............... 123
4.5 Interactive Fuzzy Linear Programming with Fuzzy Parameters ..... 131
Problems ....................................................................... 145
5 Stochastic Linear Programming ........................................... 149
5.1 Elementary Probability ................................................. 149
5.2 Two-Stage Programming............................................... 160
5.3 Chance Constrained Programming .................................... 164
5.3.1 Expectation Model ............................................. 168
5.3.2 Variance Model................................................. 171
5.3.3 Probability Model .............................................. 174
5.3.4 Fractile Model .................................................. 181
Problems ....................................................................... 191
6 Interactive Fuzzy Multiobjective Stochastic Linear Programming .... 197
6.1 Multiobjective Chance Constrained Programming ................... 197
6.1.1 Expectation Model ............................................. 199
6.1.2 Variance Model................................................. 205
6.1.3 Probability Model .............................................. 210
6.1.4 Fractile Model .................................................. 217
6.2 Multiobjective Simple Recourse Optimization ....................... 222
Problems ....................................................................... 229
7 Purchase and Transportation Planning for Food Retailing ............. 233
7.1 Linear Programming Formulation ..................................... 233
7.2 Multiobjective Linear Programming Formulation .................... 244
7.3 Fuzzy Multiobjective Linear Programming Formulation............. 251
7.4 Fuzzy Multiobjective Linear Stochastic Programming
Formulation ............................................................. 257
Problems ....................................................................... 269
A Linear Algebra ............................................................... 271
A.1 Vector ................................................................... 271
A.2 Matrix ................................................................... 274
B Nonlinear Programming .................................................... 281
B.1 Problem Formulation ................................................... 281
B.2 Basic Notions and Optimality Conditions............................. 284
C Usage of Excel Solver ........................................................ 289
C.1 Setup for Solver ........................................................ 289
C.2 Solving a Production Planning Problem .............................. 289
C.3 Solving a Diet Problem ................................................ 298
C.4 Solving a Nonlinear Programming Problem .......................... 301},
  File                     = {:Fuzzy Linear Programming.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.15}
}

@Book{Schumann2011,
  title         = {Flood Risk Assessment and Management: How to specify hydrological loads, their consequences and uncertainty},
  publisher     = {Springer},
  year          = {2011},
  editor        = {Andreas H. Schumann},
  __markedentry = {[quebbs:1]},
  abstract      = {1 Introduction – Hydrological Aspects of Risk Management . . . . 1
Andreas H. Schumann
2 Uncertainties in Weather Forecast – Reasons and Handling . . . . 11
Dirk Schüttemeyer and Clemens Simmer
3 Interpolation of Precipitation for Flood Modelling . . . . . . . . . 35
Uwe Haberlandt
4 Framing Uncertainties in Flood Forecasting with Ensembles . . . 53
Andreas H. Schumann, Yan Wang, and Jörg Dietrich
5 Design of Artificial Neural Networks for Flood Forecasting . . . . 77
Johannes Cullmann and Gerd H. Schmitz
6 Advances in Regionalising Flood Probabilities . . . . . . . . . . . 97
Ralf Merz
7 Rainfall Generators for Application in Flood Studies . . . . . . . 117
Uwe Haberlandt, Yeshewatesfa Hundecha, Markus Pahlow,
and Andreas H. Schumann
8 Copulas – New Risk Assessment Methodology
for Dam Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
Bastian Klein, Andreas H. Schumann, and Markus Pahlow
9 Hydraulic Modelling . . . . . . . . . . . . . . . . . . . . . . . . . 187
Mark Musall, Peter Oberle, and Franz Nestmann
10 Groundwater – The Subterranean Part of Flood Risk . . . . . . . 211
Thomas Sommer
11 Quantification of Socio-Economic Flood Risks . . . . . . . . . . . 229
Bruno Merz, Annegret Thieken, and Heidi Kreibich
12 Application of Scenarios and Multi-Criteria Decision
Making Tools in Flood Polder Planning . . . . . . . . . . . . . . . 249
Andreas H. Schumann and David Nijssen},
  doi           = {10.1007/978-90-481-9917-4},
  file          = {:Flood Risk Assessment and Management- How to specify hydrological loads, their consequences and uncertainty.pdf:PDF},
  owner         = {jaq},
  timestamp     = {2016.01.07},
}

@Book{Wang2014,
  title     = {Modern Water Resources Engineering},
  publisher = {Humana Press},
  year      = {2014},
  editor    = {Lawrence K. Wang and Chih Ted Yang},
  volume    = {Vol. 15},
  series    = {Handbook of Environmental Engineering},
  comment   = {Stochastic Dynamic Programming
Q-Learning
Reinforcement Learning},
  file      = {:Modern Water Resources Engineering.pdf:PDF},
  owner     = {jaq},
  timestamp = {2016.02.23},
}

@Book{Wang2016,
  Title                    = {Advances in Water Resources Management},
  Editor                   = {Lawrence K. Wang and Chih Ted Yang and Mu-Hao S. Wang},
  Publisher                = {Springer},
  Year                     = {2016},
  Series                   = {Handbook of Environmental Engineering},
  Volume                   = {Vol. 16},

  File                     = {:Advances in Water Resources Management.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.23}
}

@Manual{WUOT2013,
  Title                    = {Water Use Optimization Toolset Project: Development and Demonstration Phase Draft Report},

  File                     = {:WUOT.pdf:PDF},
  Keywords                 = {WUOT, DOE, hydropower},
  Owner                    = {jaq},
  Timestamp                = {2016.01.14}
}

@Proceedings{Paris2015,
  Title                    = {Framework Convention on Climate Change},
  Year                     = {2015},

  File                     = {:2015_Paris_Climate_Agreement.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.06}
}

@Proceedings{Stroulia2001,
  Title                    = {Advances in Artifical Intelligence
14th Biennial Conference of the Canadian Society
for Computational Studies of Intelligence, AI 2001
Ottawa, Canada, June 7-9, 2001
Proceedings},
  Year                     = {2001},

  Abstract                 = {A Case Study for Learning from Imbalanced Data Sets . . . . . . . . . . . . . . . . . 1
Aijun An, Nick Cercone, Xiangji Huang (University of Waterloo)
A Holonic Multi-agent Infrastructure for Electronic Procurement . . . . . . . . . 16
Andreas Gerber, Christian Russ (German Research Centre for
Artificial Intelligence - DFKI)
A Low-Scan Incremental Association Rule Maintenance Method Based on
the Apriori Property . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
Zequn Zhou, C.I. Ezeife (University of Windsor)
A Statistical Corpus-Based Term Extractor . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
Patrick Pantel, Dekang Lin (University of Alberta)
Body-Based Reasoning Using a Feeling-Based Lexicon, Mental Imagery,
and an Object-Oriented Metaphor Hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . 47
Eric G. Berkowitz (Roosevelt University), Peter H. Greene (Illinois
Institute of Technology)
Combinatorial Auctions, Knapsack Problems, and Hill-Climbing Search . . . 57
Robert C. Holte (University of Ottawa)
Concept-Learning in the Presence of Between-Class and Within-Class
Imbalances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
Nathalie Japkowicz (University of Ottawa)
Constraint Programming Lessons Learned from Crossword Puzzles . . . . . . . 78
Adam Beacham, Xinguang Chen, Jonathan Sillito, Peter van Beek
(University of Alberta)
Constraint-Based Vehicle Assembly Line Sequencing . . . . . . . . . . . . . . . . . . . . 88
Michael E. Bergen, Peter van Beek (University of Alberta),
Tom Carchrae (TigrSoft Inc.)
How AI Can Help SE; or: Randomized Search Not Considered Harmful . . . 100
Tim Menzies (University of British Columbia), Harhsinder Singh
(West Virginia University)
Imitation and Reinforcement Learning in Agents with
Heterogeneous Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
Bob Price (University of British Columbia), Craig Boutilier (University
of Toronto)
Knowledge and Planning in an Action-Based Multi-agent Framework:
A Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
Bradley Bart, James P. Delgrande (Simon Fraser University),
Oliver Schulte (University of Alberta)
Learning about Constraints by Reflection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
J. William Murdock, Ashok K. Goel (Georgia Institute of Technology)
Learning Bayesian Belief Network Classifiers: Algorithms and System . . . . . 141
Jie Cheng (Global Analytics, Canadian Imperial Bank of Commerce),
Russell Greiner (University of Alberta)
Local Score Computation in Learning Belief Networks . . . . . . . . . . . . . . . . . . 152
Y. Xiang, J. Lee (University of Guelph)
Personalized Contexts in Help Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
Vive S. Kumar, Gordon I. McCalla, Jim E. Greer (University of
Saskatchewan)
QA-LaSIE: A Natural Language Question Answering System . . . . . . . . . . . . 172
Sam Scott (Carleton University), Robert Gaizauskas (University of
Sheffield)
Search Techniques for Non-linear Constraint Satisfaction Problems with
Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
Marius-C˘ alin Silaghi, Djamila Sam-Haroud, Boi Faltings
(Swiss Federal Institute of Technology)
Searching for Macro Operators with Automatically Generated Heuristics . . 194
Istv´ an T. Hern´ adv¨ olgyi (University of Ottawa)
Solving Multiple-Instance and Multiple-Part Learning Problems with
Decision Trees and Rule Sets. Application to the Mutagenesis Problem . . . 204
Yann Chevaleyre, Jean-Daniel Zucker (LIP6-CNRS, University Paris
VI)
Stacking for Misclassification Cost Performance . . . . . . . . . . . . . . . . . . . . . . . . 215
Mike Cameron-Jones, Andrew Charman-Williams (University of
Tasmania)
Stratified Partial-Order Logic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
Mauricio Osorio (Universidad de las Americas, CENTIA),
Juan Carlos Nieves (Universidad Tecnologica de la Mixteca)
The Importance of Being Discrete: Learning Classes of Actions and
Outcomes through Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
Gary King (University of Massachusetts, Amherst ), Tim Oates (MIT)},
  File                     = {:Advances in Artifical Intelligence.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.01.19}
}

@Manual{USGS1969,
  Title                    = {Flow-Duration Curves 
Manual of Hydrology: Part 2. Low-Flow Techniques 
Report 1542-A},
  Edition                  = {3rd},
  Organization             = {United States Department of the Interior, Geological Survey},
  Year                     = {1969},

  File                     = {:Flow-Duration Curves.pdf:PDF},
  Owner                    = {jaq},
  Timestamp                = {2016.02.18}
}

@Article{Hajkowicz2008,
  author    = {Stefan Hajkowicz and Andrew Higgins},
  title     = {A comparison of multiple criteria analysis techniques for water resource management},
  journal   = {European Journal of Operational Research},
  year      = {2008},
  volume    = {184},
  number    = {1},
  pages     = {255--265},
  month     = {jan},
  doi       = {10.1016/j.ejor.2006.10.045},
  file      = {:MCDA\\A comparison of multiple criteria analysis techniques for water resources.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.ejor.2006.10.045},
}

@InProceedings{Phillips2006,
  author = {Lawrence D. Phillips},
  title  = {Chapter 19: Decision Conferencing},
  year   = {2006},
  file   = {:MCDA\\Decision Conferencing.pdf:PDF},
}

@Article{Georgopoulou1998,
  author   = {E. Georgopoulou and Y. Sarafidis and D. Diakoulak},
  title    = {Design and implementation of a group DSS and for sustaining and renewable energies exploitation},
  journal  = {European Journal of Operational Research},
  year     = {1998},
  volume   = {109},
  abstract = {The large scale exploitation of Renewable Energy Sources (RES) has to be based on a completely dierent conception of the energy planning procedure. The shift towards small-scale and dispersed units in the energy system brings up signi®cant diculties in the problem's analysis and in the decision making process. This paper presents the basic structural characteristics of a group DSS designed for assisting decision makers in the promotion of RES. Speci®c attention is paid to the description of the decision making procedure which basically consists in the multicriteria analysis of alternative RES penetration scenarios by means of the PROMETHEE II outranking method. Scenarios are evaluated by a group of actors directly or indirectly involved in energy decisions which arrive, through a systematic negotiations procedure, at a wide consensus. Results from a real-world application of the DSS in Greece are presented and conclusions about the system's eectiveness are drawn.},
  file     = {:MCDA/Design and implementation of a group DSS for sustaining.pdf:PDF},
  keywords = {Decision support systems; Energy planning; Multicriteria analysis; Renewable energies},
}

@Article{Franco2010,
  author    = {L. Alberto Franco and Gilberto Montibeller},
  title     = {Facilitated modelling in operational research},
  journal   = {European Journal of Operational Research},
  year      = {2010},
  volume    = {205},
  number    = {3},
  pages     = {489--500},
  month     = {sep},
  doi       = {10.1016/j.ejor.2009.09.030},
  file      = {:MCDA\\Facilitated modelling in operational research.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.ejor.2009.09.030},
}

@Article{Franco2016,
  author    = {L. A. Franco},
  title     = {Forms of Conversation and Problem Structuring Methods: A Conceptual Development},
  journal   = {The Journal of the Operational Research Society},
  year      = {2016},
  volume    = {57},
  number    = {7},
  pages     = {813-821},
  booktitle = {The Journal of the Operational Research Society},
  file      = {:MCDA\\Forms of conversation and problem structuring methods- A conceptual development.pdf:PDF},
}

@InBook{Montibeller2010a,
  chapter  = {Chapter 2 Multi-Criteria Decision Analysis for Strategic Decision Making},
  pages    = {25-48},
  title    = {Multi-Criteria Decision Analysis for Strategic Decision Making},
  year     = {2010},
  author   = {Gilberto Montibeller and Alberto Franco},
  abstract = {In this chapterwe discuss the use of MCDA for supportingstrategic decision making, particularly within strategy workshops. The chapter begins by exploring the nature of strategic decisions and the characteristics of the strategic decision making process. Speciﬁcally, we examine the technical issues associated with the content of strategic decisions, and the social aspects that characterise the processes withinwhichtheyarecreated.Thesefeaturesleadustoproposeanumberofadaptations to the standardMCDA approachif it were to be used at a more strategic level. We make suggestions on how to implement these proposals, and illustrate them with examples drawn from real-world interventions in which we have participated as strategic decision support analysts},
  file     = {:MCDA\\Multi-Criteria Decision Analysis for Strategic Decision Making.pdf:PDF},
}

@Book{Figueira2005,
  title     = {Multiple Criteria Decision Analysis: State of the Art Surveys},
  publisher = {Springer},
  year      = {2005},
  editor    = {José Figueira and Salvatore Greco and Matthias Ehrgott},
  file      = {:MCDA\\Multicriteria decision analysis- state of the art surveys.pdf:PDF},
}

@Book{Lu2007,
  title     = {Multi-Objective Group Decision Making: Methods, Software and Applications With Fuzzy Set Techniques},
  publisher = {Imperial College Press},
  year      = {2007},
  author    = {Jie Lu and Guangquan Zhan and Da Ruan and Fengjie Wu},
  file      = {:MCDA\\Multi-Objective Group Decision Making- Methods, Software and Applications with Fuzzy Set Techniques.pdf:PDF},
}

@Article{Macharis2004,
  author    = {Cathy Macharis and Johan Springael and Klaas De Brucker and Alain Verbeke},
  title     = {{PROMETHEE} and {AHP}: The design of operational synergies in multicriteria analysis},
  journal   = {European Journal of Operational Research},
  year      = {2004},
  volume    = {153},
  number    = {2},
  pages     = {307--317},
  month     = {mar},
  doi       = {10.1016/s0377-2217(03)00153-x},
  file      = {:MCDA\\PROMETHEE and AHP- The design of operational synergies in multicriteria analysis.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/S0377-2217(03)00153-X},
}

@Article{Keeney2005,
  author    = {Ralph L. Keeney and Robin S. Gregory},
  title     = {Selecting Attributes to Measure the Achievement of Objectives},
  journal   = {Operations Research},
  year      = {2005},
  volume    = {53},
  number    = {1},
  pages     = {1--11},
  month     = {feb},
  doi       = {10.1287/opre.1040.0158},
  file      = {:MCDA\\Selecting Attributes to Measure the Achievement of Objectives.pdf:PDF},
  publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
  url       = {http://dx.doi.org/10.1287/opre.1040.0158},
}

@Article{Rowe1982,
  author   = {Michael D. Rowe and Barbara L. Pierce},
  title    = {Sensitivity of the Weighting Summation Decision Method to Incorrect Application},
  journal  = {Socio-Economic Planning Science},
  year     = {1982},
  volume   = {16},
  number   = {4},
  pages    = {173-177},
  abstract = {The weighting summation decision method is commonly used and misused for multiobjective decisions.
The formal requirements of this method are outlined and someof the kinds of errors that are commonly made in
applyingit are discussed. Monte Carlo simulationis used to assess the potential that fiveclasses of errors have for
causing incorrect decisions. An index is developed which quantifies the complexity of decision problems. The
simulationsdemonstrate that complexity can be about twice as important to quality of decisions as are errors in
applying the weighting summation.},
  file     = {:MCDA\\Sensitivity of the weighting summation decision method to incorrect application.pdf:PDF},
}

@Book{Munda2008,
  title     = {Social Multi-Criteria Evaluation for a Sustainable Economy},
  publisher = {Springer},
  year      = {2008},
  author    = {Giuseppe Munda},
  comment   = {The real world is characterized by deep complexity. May be a rather unremarkable observation, yet it has important implications on the manner policy problems are represented and decision-making is framed. Is contemporary democracy compatible with science in real-world policy-making? This book gives answers in the affirmative. It also asserts that this congruence can have positive implications not only in terms of economic prosperity but also when dealing with the difficult sustainability policy problems of our millennium. To address contemporary issues economic science will have to expand its empirical relevance by introducing more and more realistic assumptions to its models. One of the most interesting research orientations in recent times in the field of public economics is the explicit attempt to take account of political constraints, interest groups and collusion effects. One of the main novelties of this book is its establishment of a clear relationship between social and public choice theories on one hand, and multiple criteria decision analysis on the other. The pioneering research developed by Arrow and Raynaud (1986) has shown that the relationships between multi-criteria decision theory and social choice are clear and relevant. The main directions of cross-fertilization between these research fields are twofold: 1. Multi-criteria decision theory can be an adequate framework for applied social (and public) choice. 2. Social choice can produce interesting theoretical results for ensuring the ax- matic consistency needed by multi-criterion aggregation conventions.},
  file      = {:MCDA\\Social Multi-Criteria Evaluation for a Sustainable Economy.pdf:PDF},
}

@Article{Checkland2000,
  author   = {Peter Checkland},
  title    = {Soft Systems Methodology: A Thirty Year Retrospective},
  journal  = {Systems Research and Behavioral Science},
  year     = {2000},
  volume   = {17},
  abstract = {Although the history of thought reveals a number
of holistic thinkers — Aristotle, Marx, Husserl
among them — it was only in the 1950s that any
version of holistic thinking became institutionalized. The kind of holistic thinking which
then came to the fore, and was the concern of a
newly created organization, was that which
makes explicit use of the concept of ‘system’, and
today it is ‘systems thinking’ in its various forms
which would be taken to be the very paradigm
of thinking holistically. In 1954, as recounted in
Chapter 3 of Systems Thinking, Systems Practice,
only one kind of systems thinking was on the
table: the development of a mathematically
expressed general theory of systems. It was supposed that this would provide a meta-level language and theory in which the problems of many
different disciplines could be expressed and
solved; and it was hoped that doing this would
help to promote the unity of science.
These were the aspirations of the pioneers, but
looking back from 1999 we can see that the project
has not succeeded. The literature contains very
little of the kind of outcomes anticipated by the
founders of the Society for General Systems
Research; and scholars in the many subject areas
to which a holistic approach is relevant have been
understandably reluctant to see their pet subject
as simply one more example of some broader
‘general system},
  doi      = {ng},
  file     = {:MCDA\\Soft Systems Methodology- A thirty year retrospective.pdf:PDF},
}

@InBook{Checkland2010,
  chapter   = {Chapter 5 Soft Systems Methodology},
  pages     = {191-242},
  title     = {Systems Approaches to Managing Change: A Practical Guide},
  publisher = {Springer-Verlag London},
  year      = {2010},
  author    = {Peter Checkland and John Poulter},
  editor    = {M. Reynolds and S. Holwell},
  abstract  = {Soft systems methodology (SSM) is an approach for tackling problematical, messy situations of all kinds. It is an action-oriented process of inquiry into problematic situations in which users learn their way from finding out about the situation,
to taking action to improve it. The learning emerges via an organised process in which
the situation is explored using a set of models of purposeful action (each built to
encapsulate a single worldview) as intellectual devices, or tools, to inform and structure discussion about a situation and how it might be improved. This paper, written
by the original developer Peter Checkland and practitioner John Poulter, gives a clear
and concise account of the approach that covers SSM’s specific techniques, the learning cycle process of the methodology and the craft skills which practitioners develop.
This concise but theoretically robust account nevertheless includes the fundamental
concepts, techniques, core tenets described through a wide range of settings.},
  doi       = {10.1007/978-1-84882-809-4_5},
  file      = {:MCDA\\Soft Systems Methodology.pdf:PDF},
}

@Article{Neves2009,
  author    = {L.P. Neves and L.C. Dias and C.H. Antunes and A.G. Martins},
  title     = {Structuring an {MCDA} model using {SSM}: A case study in energy efficiency},
  journal   = {European Journal of Operational Research},
  year      = {2009},
  volume    = {199},
  number    = {3},
  pages     = {834--845},
  month     = {dec},
  doi       = {10.1016/j.ejor.2009.01.053},
  file      = {:MCDA\\Structuring an MCDA model using SSM- a case study in energy efficiency.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.ejor.2009.01.053},
}

@Article{Scheubrein2006,
  author    = {Ralph Scheubrein and Stanley Zionts},
  title     = {A problem structuring front end for a multiple criteria decision support system},
  journal   = {Computers {\&} Operations Research},
  year      = {2006},
  volume    = {33},
  number    = {1},
  pages     = {18--31},
  month     = {jan},
  doi       = {10.1016/j.cor.2004.05.014},
  file      = {:MCDA\\A problem structuring front end for a multiple criteria decision support system.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.cor.2004.05.014},
}

@Article{Montibeller2006,
  author    = {Gilberto Montibeller and Haidee Gummer and Daniele Tumidei},
  title     = {Combining scenario planning and multi-criteria decision analysis in practice},
  journal   = {Journal of Multi-Criteria Decision Analysis},
  year      = {2006},
  volume    = {14},
  number    = {1-3},
  pages     = {5--20},
  month     = {jan},
  doi       = {10.1002/mcda.403},
  file      = {:MCDA\\Combining scenario planning and multi-criteria Decision Analysis in Practice.pdf:PDF},
  publisher = {Wiley-Blackwell},
  url       = {http://dx.doi.org/10.1002/mcda.403},
}

@Article{Gregory1994,
  author        = {Robin Gregory and Ralph L. Keeney},
  title         = {Creating Policy Alternatives Using Stakeholder Values},
  journal       = {Management Science},
  year          = {1994},
  volume        = {8},
  pages         = {1035-1048},
  __markedentry = {[quebbs:1]},
  abstract      = {Choices that require multiple stakeholders to balance conflicting objectives are among today's
most controversial decisions. Although many techniques exist for helping decision makers
to select among projects, little attention has been given to processes for identifying improved
alternatives based on clearly articulated stakeholder values. In this paper we describe a general
process to inform controversial social decisions by first structuring stakeholder objectives and
then using this information to create policy alternatives. We also report the results of a workshop
in Sabah, Malaysia which used the proposed approach as the basis for multiple stakeholder
negotiations.},
  editor        = {40},
  file          = {:MCDA\\Creating policy alternatives using stakeholder values.pdf:PDF},
  keywords      = {Values; Environmental Policy; Alternatives; Stakeholder Involvement},
}

@InBook{Phillips2006a,
  chapter   = {Chapter 19: Decision Conferencing},
  title     = {Decision Conferencing},
  publisher = {Operational Research Group, London School of Economics and Political Science},
  year      = {2006},
  author    = {Lawrence D. Phillips},
  abstract  = {This chapter presents the current status of the decision conference process, a way of helping a
group of key players to resolve important issues in their organization by working together, under
the guidance of an impartial facilitator, with the aid of a decision analysis model of participants’
perspectives on the issues, developed on-the-spot over a period of two days. The facilitator
serves as a process consultant, guiding the group through the stages of discussing the issues,
developing a model and exploring the results, without contributing to the content of discussions.
The model serves as a ‘tool for thinking,’ not as providing an optimal solution or ‘the right
answer.’ Participants are encouraged to express their sense of unease at any stage in the process,
for it is the discrepancy between model results and intuitive judgment that drives the dialectic in
the group. Exploration generates new insights and stimulates creative thinking, resulting in
changes to the model and to intuitions. As this process settles down, participants develop a
shared understanding of the issues, generate a sense of common purpose, and gain commitment
to the way forward. Two case studies illustrate a typical individual decision conference and how
sustained engagement with a client, decision conferencing, can lead to committed alignment in a
group. Research on decision conferences provides insights into why decision conferences work.},
  comment   = {the elements common to all decision conferences are clear: attendance by key players, impartial facilitation, on-the-spot modeling with continuous display of the developing model, and an interactive and iterative group process.
The Chatham House rule applies (RIIA, 1927): When a meeting, or part thereof, is held under the Chatham house rule, participants are free to use the information received, but neither the identity nor the affiliation of the speaker(s), nor that of any other participant, may be revealed.
On-the-spot modeling with continuous display of the developing model, the third element of a decision conference, ensures that every word and number input into the software is seen by participants, who are free to discuss, modify and edit the inputs.},
  file      = {:MCDA\\Decision Conferencing.pdf:PDF},
  keywords  = {decision conferences, decision conferencing, process consultancy, multi-criteria decision analysis, evaluation, prioritization, group processes, quality decisions, aligned commitment, requisite decision models, facilitation skills},
}

@Book{Kaner2007,
  title     = {Facilitator’s Guide to Participatory Decision-Making},
  publisher = {John Wiley \& Sons, Inc.},
  year      = {2007},
  author    = {Sam Kaner and Lenny Lind and Catherine Toldi and Sarah Fisk and Duane Berger},
  edition   = {2},
  file      = {:MCDA\\Facilitator’s Guide to Participatory Decision Making.pdf:PDF},
}

@InBook{Montibeller2010,
  chapter   = {Chapter 2 Multi-Criteria Decision Analysis for Strategic Decision Making},
  pages     = {25-48},
  title     = {Handbook of Multicriteria Analysis},
  publisher = {Springer-Verlag Berlin Heidelberg},
  year      = {2010},
  author    = {Gilberto Montibeller and Alberto Franco},
  abstract  = {In this chapter we discuss the use of MCDA for supporting strategic decision making, particularly within strategy workshops. The chapter begins by exploring the nature of strategic decisions and the characteristics of the strategic decision
making process. Specifically, we examine the technical issues associated with the
content of strategic decisions, and the social aspects that characterise the processes
within which they are created. These features lead us to propose a number of adaptations to the standard MCDA approach if it were to be used at a more strategic level.
We make suggestions on how to implement these proposals, and illustrate them
with examples drawn from real-world interventions in which we have participated
as strategic decision support analysts.},
  doi       = {10.1007/978-3-540-92828-7_2},
  file      = {:MCDA\\Multi-Criteria Decision Analysis for Strategic Decision Making.pdf:PDF},
}

@Article{Mingers2004,
  author    = {John Mingers and Jonathan Rosenhead},
  title     = {Problem structuring methods in action},
  journal   = {European Journal of Operational Research},
  year      = {2004},
  volume    = {152},
  number    = {3},
  pages     = {530--554},
  month     = {feb},
  abstract  = {This paper provides a review and evaluation of the use of problem structuring methods (PSMs) in practice. It starts
by describing the origins of PSMs, the type of problem situation for which they are suitable, and the characteristics of
some leading methods. An overview of the practice of PSMs is provided from a number of angles, including case studies
and surveys of applications. A number of issues in the application of PSMs are discussed, in particular an account of the
debate about evaluation of the success of PSMs; the selection of an appropriate method; multimethodology; and a
variety of aspects of the maintenance of relationships with the client organisation(s). Finally, some possible future
developments are suggested, especially through productive interactions with similar or related practices.},
  doi       = {10.1016/s0377-2217(03)00056-0},
  file      = {:MCDA\\Problem structuring methods in action.pdf:PDF},
  keywords  = {OR methodology; Problem structuring methods; Soft OR; OR applications; Multimethodology, Operations Research},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/S0377-2217(03)00056-0},
}

@Article{Wang2009,
  author    = {Jiang-Jiang Wang and You-Yin Jing and Chun-Fa Zhang and Jun-Hong Zhao},
  title     = {Review on multi-criteria decision analysis aid in sustainable energy decision-making},
  journal   = {Renewable and Sustainable Energy Reviews},
  year      = {2009},
  volume    = {13},
  number    = {9},
  pages     = {2263--2278},
  month     = {dec},
  doi       = {10.1016/j.rser.2009.06.021},
  file      = {:MCDA\\Review on multi-criteria decision analysis aid in sustainable energy decision-making.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.rser.2009.06.021},
}

@Article{Hodgkinson2006,
  author    = {Gerard P. Hodgkinson and Richard Whittington and Gerry Johnson and Mirela Schwarz},
  title     = {The Role of Strategy Workshops in Strategy Development Processes: Formality, Communication, Co-ordination and Inclusion},
  journal   = {Long Range Planning},
  year      = {2006},
  volume    = {39},
  number    = {5},
  pages     = {479--496},
  month     = {oct},
  doi       = {10.1016/j.lrp.2006.07.003},
  file      = {:MCDA\\The role of strategy workshops in strategy development processes- Formality, communication, co-ordination and inclusion.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.lrp.2006.07.003},
}

@Article{Beynon2002,
  author   = {Meurig Beynon and Suwanna Rasmequan and Steve Russ},
  title    = {A new paradigm for computer-based decision support},
  journal  = {Decision Support Systems},
  year     = {2002},
  volume   = {33},
  pages    = {127-142},
  file     = {:MCDA\\A new paradigm for computer-based decision support.pdf:PDF},
  keywords = {Decision support systems; Expert systems; Modelling; Observation; Dependency; Agency},
}

@TechReport{CEATI2014,
  author      = {CEATI},
  title       = {Review of Data Screening Methods for Discharge Inflow Time Series},
  institution = {CEATI HOPIG},
  year        = {2014},
  number      = {Advisor},
  file        = {:Statistics\\Review of Data Screening Methods for Discharge Inflow Time Series.pdf:PDF},
  keywords    = {Data screening, Discharge, Inflow, Streamflow, Error, Correction, Literature Review, Interview},
}

@TechReport{Draijer2016,
  author      = {Draijer, Simon and Quebbeman, Jonathan},
  title       = {Applied Statistical Analysis Techniques for Hydro Generation and Runoff},
  institution = {CEATI International Inc.},
  year        = {2016},
  number      = {No. 0426},
  address     = {1010 Sherbrooke Street West, Suite 2500 Montreal, Quebec, Canada H3A 2R7},
  file        = {:Statistics\\Applied Statistical Analysis Techniques for Hydro Generation and Runoff.pdf:PDF},
  timestamp   = {2016-11-10},
}

@Article{Guo2015,
  author    = {Hongyue Guo and Xiaodong Liu},
  title     = {Dynamic programming-based optimization for segmentation and clustering of hydrometeorological time series},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {7},
  pages     = {1875--1887},
  month     = {dec},
  doi       = {10.1007/s00477-015-1192-4},
  file      = {:Reservoirs\\Dynamic programming-based optimization for segmentation and clustering of hydrometeorological time series.pdf:PDF},
  publisher = {Springer Nature},
  url       = {http://dx.doi.org/10.1007/s00477-015-1192-4},
}

@Article{Yu2015,
  author    = {Hwa-Lung Yu and Shang-Chen Ku and Alexander Kolovos},
  title     = {A {GIS} tool for spatiotemporal modeling under a knowledge synthesis framework},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {2},
  pages     = {665--679},
  month     = {may},
  doi       = {10.1007/s00477-015-1078-5},
  file      = {:Statistics\\A GIS tool for spatiotemporal modeling under a knowledge synthesis framework.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1078-5},
}

@Article{Xie2015,
  author    = {Y. L. Xie and D. H. Xia and G. H. Huang and W. Li and Y. Xu},
  title     = {A multistage stochastic robust optimization model with fuzzy probability distribution for water supply management under uncertainty},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  month     = {oct},
  doi       = {10.1007/s00477-015-1164-8},
  file      = {:Reservoirs\\A multistage stochastic robust optimization model with fuzzy probability distribution for water supply management under uncertainty.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1164-8},
}

@Article{Stedinger2008,
  author   = {Jery R. Stedinger and Richard M. Vogel and Seung Uk Lee andRebecca Batchelder},
  title    = {Appraisal of the generalized likelihood uncertainty estimation (GLUE) method},
  journal  = {Water Resources Research},
  year     = {2008},
  volume   = {44},
  abstract = {Recent research documents that the widely accepted generalized likelihood
uncertainty estimation (GLUE) method for describing forecasting precision and the impact
of parameter uncertainty in rainfall/runoff watershed models fails to achieve the intended
purpose when used with an informal likelihood measure. In particular, GLUE generally
fails to produce intervals that capture the precision of estimated parameters, and the
difference between predictions and future observations. This paper illustrates these
problems with GLUE using a simple linear rainfall/runoff model so that model calibration
is a linear regression problem for which exact expressions for prediction precision and
parameter uncertainty are well known and understood. The simple regression example
enables us to clearly and simply illustrate GLUE deficiencies. Beven and others have
suggested that the choice of the likelihood measure used in a GLUE computation is
subjective and may be selected to reflect the goals of the modeler. If an arbitrary likelihood
is adopted that does not reasonably reflect the sampling distribution of the model
errors, then GLUE generates arbitrary results without statistical validity that should not be
used in scientific work. The traditional subjective likelihood measures that have been
used with GLUE also fail to reflect the nonnormality, heteroscedasticity, and serial
correlation among the residual errors generally found in real problems, and hence are poor
metrics for even simple sensitivity analyses and model calibration. Most previous
applications of GLUE only produce uncertainty intervals for the average model prediction,
which by construction should not be expected to include future observations with the
prescribed probability. We show how the GLUE methodology when properly
implemented with a statistically valid likelihood function can provide prediction intervals
for future observations which will agree with widely accepted and statistically valid
analyses.},
  file     = {:Statistics\\Appraisal of the generalized likelihood uncertainty estimation (GLUE) method.pdf:PDF},
}

@Article{Wang2015,
  author    = {Xiaoyan Wang and Tao Yang and Valentina Krysanova and Zhongbo Yu},
  title     = {Assessing the impact of climate change on flood in an alpine catchment using multiple hydrological models},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {29},
  number    = {8},
  pages     = {2143--2158},
  month     = {mar},
  doi       = {10.1007/s00477-015-1062-0},
  file      = {:Climate\\Assessing the impact of climate change on flood in an alpine catchment using multiple hydrological models.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1062-0},
}

@Article{Aronica2002,
  author    = {G. Aronica and P. D. Bates and M. S. Horritt},
  title     = {Assessing the uncertainty in distributed model predictions using observed binary pattern information within {GLUE}},
  journal   = {Hydrological Processes},
  year      = {2002},
  volume    = {16},
  number    = {10},
  pages     = {2001--2016},
  doi       = {10.1002/hyp.398},
  file      = {:Hydrology\\Assessing the uncertainty in distributed model predictions using observed binary pattern information within GLUE.pdf:PDF},
  publisher = {Wiley-Blackwell},
  url       = {http://dx.doi.org/10.1002/hyp.398},
}

@Article{Han2015,
  author    = {Longfei Han and Youpeng Xu and Liu Yang and Xiaojun Deng},
  title     = {Changing structure of precipitation evolution during 1957{\textendash}2013 in Yangtze River Delta, {China}},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {29},
  number    = {8},
  pages     = {2201--2212},
  month     = {feb},
  doi       = {10.1007/s00477-015-1034-4},
  file      = {:Hydrology\\Precipitation\\Changing structure of precipitation evolution during 1957–2013 in Yangte River Delta, China.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1034-4},
}

@Article{Romanowicz2006,
  author   = {Renata J. Romanowicz and Keith J. Beven},
  title    = {Comments on generalised likelihood uncertainty estimation},
  journal  = {Reliability Engineering and System Safety},
  year     = {2006},
  volume   = {91},
  pages    = {1315–1321},
  abstract = {The paper presents an application of the generalised likelihood uncertainty estimation methodology to the problem of estimating the
uncertainty of predictions produced by environmental models. The methodology is placed in a wider context of different approaches to
inverse modelling and, in particular, a comparison is made with Bayesian estimation techniques based on explicit structural assumptions
about model error. Using a simple example of a rainfall-flow model, different evaluation measures and their influence on the prediction
uncertainty and credibility intervals are demonstrated.},
  file     = {:Statistics\\Comments on generalised likelihood uncertainty estimation.pdf:PDF;:WaterResources\\Programmatic Approach to Impacts of Climate Risks on Water - Hydropower and Dams.pdf:PDF},
}

@Article{Cheng2015,
  author    = {Guanhui Cheng and Guohe Huang and Cong Dong},
  title     = {Convex contractive interval linear programming for resources and environmental systems management},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  month     = {nov},
  doi       = {10.1007/s00477-015-1187-1},
  file      = {:Optimization\\Convex contractive interval linear programming for resources and environmental systems management.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1187-1},
}

@Article{Nourani2016,
  author    = {Vahid Nourani and Bahram Saeidifarzad},
  title     = {Detection of land use/cover change effect on watershed's response in generating runoff using computational intelligence approaches},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2016},
  month     = {jan},
  doi       = {10.1007/s00477-016-1220-z},
  file      = {:Climate\\Detection of land use-cover change effect on watersheds response in generating runoff using computational intelligence approaches.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-016-1220-z},
}

@Article{Nikoloulopoulos2015,
  author    = {Aristidis K. Nikoloulopoulos},
  title     = {Efficient estimation of high-dimensional multivariate normal copula models with discrete spatial responses},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {2},
  pages     = {493--505},
  month     = {mar},
  doi       = {10.1007/s00477-015-1060-2},
  file      = {:Statistics\\Efficient estimation of high-dimensional multivariate normal copula models with discrete spatial responses.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1060-2},
}

@Article{Xu2014,
  author    = {Hongliang Xu and Chong-Yu Xu and Nils Roar S{\ae}lthun and Bin Zhou and Youpeng Xu},
  title     = {Evaluation of reanalysis and satellite-based precipitation datasets in driving hydrological models in a humid region of Southern {China}},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2014},
  volume    = {29},
  number    = {8},
  pages     = {2003--2020},
  month     = {dec},
  doi       = {10.1007/s00477-014-1007-z},
  file      = {:Hydrology\\Precipitation\\Evaluation of reanalysis and satellite-based precipitation datasets in driving hydrological models in a humid region of Southern China.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-014-1007-z},
}

@Article{Requena2015,
  author    = {Ana I. Requena and Isabel Flores and Luis Mediero and Luis Garrote},
  title     = {Extension of observed flood series by combining a distributed hydro-meteorological model and a copula-based model},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {5},
  pages     = {1363--1378},
  month     = {aug},
  doi       = {10.1007/s00477-015-1138-x},
  file      = {:Hydrology\\Extension of observed flood series by combining a distributed hydro-meteorological model and a copula-based model.pdf:PDF},
  publisher = {Springer Nature},
  url       = {http://dx.doi.org/10.1007/s00477-015-1138-x},
}

@Article{Blasone2008,
  author    = {Roberta-Serena Blasone and Jasper A. Vrugt and Henrik Madsen and Dan Rosbjerg and Bruce A. Robinson and George A. Zyvoloski},
  title     = {Generalized likelihood uncertainty estimation ({GLUE}) using adaptive {Markov} Chain {Monte} {Carlo} sampling},
  journal   = {Advances in Water Resources},
  year      = {2008},
  volume    = {31},
  number    = {4},
  pages     = {630--648},
  month     = {apr},
  doi       = {10.1016/j.advwatres.2007.12.003},
  file      = {:Statistics\\Generalized likelihood uncertainty estimation (GLUE) using adaptive Markov Chain Monte Carlo sampling.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.advwatres.2007.12.003},
}

@Article{Mantovan2006,
  author    = {Pietro Mantovan and Ezio Todini},
  title     = {Hydrological forecasting uncertainty assessment: Incoherence of the {GLUE} methodology},
  journal   = {Journal of Hydrology},
  year      = {2006},
  volume    = {330},
  number    = {1-2},
  pages     = {368--381},
  month     = {oct},
  doi       = {10.1016/j.jhydrol.2006.04.046},
  file      = {:Hydrology\\Hydrological forecasting uncertainty assessment- Incoherence of the GLUE methodology.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2006.04.046},
}

@Article{Montanari2005,
  author   = {Alberto Montanari},
  title    = {Large sample behaviors of the generalized likelihood uncertainty estimation (GLUE) in assessing the uncertainty of rainfall-runoff simulations},
  journal  = {Water Resources Research},
  year     = {2005},
  volume   = {41},
  abstract = {Several methods have been recently proposed for quantifying the uncertainty of
hydrological models. These techniques are based upon different hypotheses, are diverse in
nature, and produce outputs that can significantly differ in some cases. One of the favored
methods for uncertainty assessment in rainfall-runoff modeling is the generalized
likelihood uncertainty estimation (GLUE). However, some fundamental questions related
to its application remain unresolved. One such question is that GLUE relies on some
explicit and implicit assumptions, and it is not fully clear how these may affect the
uncertainty estimation when referring to large samples of data. The purpose of this study is
to address this issue by assessing how GLUE performs in detecting uncertainty in the
simulation of long series of synthetic river flows. The study aims to (1) discuss the
hypotheses underlying GLUE and derive indications about their effects on the uncertainty
estimation, and (2) compare the GLUE prediction limits with a large sample of data that is
to be simulated in the presence of known sources of uncertainty. The analysis shows
that the prediction limits provided by GLUE do not necessarily include a percentage close
to their confidence level of the observed data. In fact, in all the experiments, GLUE
underestimates the total uncertainty of the simulation provided by the hydrological model.},
  file     = {:Statistics\\Large sample behaviors of the generalized likelihood uncertainty estimation (GLUE) in assessing the uncertainty of rainfall-runoff simulations.pdf:PDF},
}

@Article{Neuman2003,
  author    = {S. P. Neuman},
  title     = {Maximum likelihood Bayesian averaging of uncertain model predictions},
  journal   = {Stochastic Environmental Research and Risk Assessment ({SERRA})},
  year      = {2003},
  volume    = {17},
  number    = {5},
  pages     = {291--305},
  month     = {nov},
  doi       = {10.1007/s00477-003-0151-7},
  file      = {:Statistics\\Maximum likelihood Bayesian averaging of uncertain model predictions.pdf:PDF},
  publisher = {Springer Nature},
  url       = {http://dx.doi.org/10.1007/s00477-003-0151-7},
}

@Article{Tu2015,
  author    = {Xinjun Tu and Vijay P. Singh and Xiaohong Chen and Mingwei Ma and Qiang Zhang and Yong Zhao},
  title     = {Uncertainty and variability in bivariate modeling of hydrological droughts},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {5},
  pages     = {1317--1334},
  month     = {nov},
  doi       = {10.1007/s00477-015-1185-3},
  file      = {:Hydrology\\Uncertainty and variability in bivariate modeling of hydrological droughts.pdf:PDF},
  publisher = {Springer Nature},
  url       = {http://dx.doi.org/10.1007/s00477-015-1185-3},
}

@Article{Yazdi2015,
  author    = {J. Yazdi and A. Doostparast Torshizi and B. Zahraie},
  title     = {Risk based optimal design of detention dams considering uncertain inflows},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {5},
  pages     = {1457--1471},
  month     = {oct},
  doi       = {10.1007/s00477-015-1171-9},
  file      = {:Hydrology\\Risk based optimal design of detention dams considering uncertain inflows.pdf:PDF},
  publisher = {Springer Nature},
  url       = {http://dx.doi.org/10.1007/s00477-015-1171-9},
}

@Article{Zhou2015,
  author    = {Yang Zhou and Gordon Huang and Shuo Wang and Yuanyuan Zhai and Xiaying Xin},
  title     = {Water resources management under dual uncertainties: a factorial fuzzy two-stage stochastic programming approach},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {3},
  pages     = {795--811},
  month     = {aug},
  doi       = {10.1007/s00477-015-1145-y},
  file      = {:Hydrology/Water resources management under dual uncertainties- a factorial fuzzy two-stage stochastic programming approach.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1145-y},
}

@Article{Ji2015,
  author    = {Yao Ji and Guohe Huang and Wei Sun and Yanfeng Li},
  title     = {Water quality management in a wetland system using an inexact left-hand-side chance-constrained fuzzy multi-objective approach},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {2},
  pages     = {621--633},
  month     = {aug},
  doi       = {10.1007/s00477-015-1094-5},
  file      = {:Hydrology\\Water quality management in a wetland system using an inexact left-hand-side chance-constrained fuzzy multi-objective approach.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1094-5},
}

@Article{Athira2015,
  author    = {P. Athira and K. P. Sudheer and R. Cibin and I. Chaubey},
  title     = {Predictions in ungauged basins: an approach for regionalization of hydrological models considering the probability distribution of model parameters},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {4},
  pages     = {1131--1149},
  month     = {nov},
  doi       = {10.1007/s00477-015-1190-6},
  file      = {:Hydrology\\Predictions in ungauged basins- an approach for regionalization of hydrological models considering the probability distribution of model parameters.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1190-6},
}

@Article{Wu2015,
  author    = {Xing Zheng Wu},
  title     = {Probabilistic solution of floodplain inundation equation},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {30},
  number    = {1},
  pages     = {47--58},
  month     = {jan},
  doi       = {10.1007/s00477-015-1025-5},
  file      = {:Hydrology\\Probabilistic solution of floodplain inundation equation.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1025-5},
}

@Article{Vera2016,
  author    = {J. Fernando Vera and Jos{\'{e}} M. Angulo and Juan A. Rold{\'{a}}n},
  title     = {Stability analysis in nonstationary spatial covariance estimation},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2016},
  month     = {feb},
  doi       = {10.1007/s00477-016-1228-4},
  file      = {:Statistics\\Stability analysis in nonstationary spatial covariance estimation.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-016-1228-4},
}

@Article{Abdi2016,
  author    = {Amin Abdi and Yousef Hassanzadeh and Siamak Talatahari and Ahmad Fakheri-Fard and Rasoul Mirabbasi},
  title     = {Regional bivariate modeling of droughts using L-comoments and copulas},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2016},
  month     = {jan},
  doi       = {10.1007/s00477-016-1222-x},
  file      = {:Hydrology\\Regional bivariate modeling of droughts using L-comoments and copulas.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-016-1222-x},
}

@Article{Shen2015,
  author    = {Jhih-Cyuan Shen and Che-Hao Chang and Shiang-Jen Wu and Chih-Tsung Hsu and Ho-Cheng Lien},
  title     = {Real-time correction of water stage forecast using combination of forecasted errors by time series models and {Kalman} filter method},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2015},
  volume    = {29},
  number    = {7},
  pages     = {1903--1920},
  month     = {may},
  doi       = {10.1007/s00477-015-1074-9},
  file      = {:Hydrology\\Real-time correction of water stage forecast using combination of forecasted errors by time series models and Kalman filter method.pdf:PDF},
  publisher = {Springer Science $\mathplus$ Business Media},
  url       = {http://dx.doi.org/10.1007/s00477-015-1074-9},
}

@Article{Jin2010,
  author    = {Xiaoli Jin and Chong-Yu Xu and Qi Zhang and V.P. Singh},
  title     = {Parameter and modeling uncertainty simulated by {GLUE} and a formal Bayesian method for a conceptual hydrological model},
  journal   = {Journal of Hydrology},
  year      = {2010},
  volume    = {383},
  number    = {3-4},
  pages     = {147--155},
  month     = {mar},
  doi       = {10.1016/j.jhydrol.2009.12.028},
  file      = {:Statistics\\Parameter and modeling uncertainty simulated by GLUE and a formal Bayesian method for a conceptual hydrological model.pdf:PDF},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2009.12.028},
}

@InProceedings{Kunz1979,
  author   = {Werner Kunz and Horst W. J. Rittel},
  title    = {Issues As Elements of Information Systems},
  year     = {1979},
  abstract = {Issue-Based Information Systems (IBIS) are meant to support
coordination and planning of political decision processes. IBIS guides
the identification, structuring, and settling of issues raised by
problem-solving groups, and provides information pertinent to the
discourse. It is linked to conventional documentation systems but also
activates other sources. Elements of the system are topics, issues,
questions of fact, positions, arguments, and model problems. The logic
of issues, the subsystems of IBIS, and their rules of operation are
outlined. Three manually operated versions of IBIS are in experimental
operation by governmental agencies; computerization of system
operations is in preparation.},
  file     = {:MCDA\\Issues as Elements of Information Systems.pdf:PDF},
  keywords = {IBIS},
}

@TechReport{Conklin1997,
  author      = {Jeff Conklin},
  title       = {Designing Organizational Memory: Preserving Intellectual Assets in a Knowledge Economy},
  institution = {CogNexus Institute},
  year        = {1997},
  abstract    = {Knowledge management is an essential capability in the
emerging knowledge economy. In particular, organizations
have a valuable asset in the informal knowledge that is the daily currency
of their knowledge workers, but this asset usually lives only in the
collective human memory, and thus is poorly preserved and managed.
There are significant technical and cultural barriers to capturing informal
knowledge and making it explicit. Groupware tools such as E-mail and
Lotus Notes™ tend to make informal knowledge explicit, but they
generally fail to create an accessible organizational memory. On the other
hand, attempts to build organizational memory systems have generally
failed because they required additional documentation effort with no clear
short term benefit, or, like groupware, they did not provide an effective
index or structure to the mass of information collected in the system. This
paper explores the design of a project memory system that overcomes the
barriers to capturing informal knowledge. The key component of this
design is the use of a display system that captures the key issues and
ideas during meetings. The emphasis in this approach is on improving
communication during meetings by creating shared understanding. The
paper briefly describes a commercially available display system which
uses hypertext to capture the thinking and learning in large, complex
projects. The paper ends with a few examples of this kind of
organizational memory system in action.},
  comment     = {jeff@cognexus.org},
  file        = {:MCDA\\Designing Organizational Memory- Preserving Intellectual Assets in a Knowledge Economy.pdf:PDF},
  keywords    = {organizational memory, corporate memory, organizational learning, knowledge management, teamwork, decision rationale, groupware, IBIS},
}

@TechReport{WMO2012,
  author      = {WMO},
  title       = {Guidelines on Ensemble Prediction Systems and Forecasting},
  institution = {World Meteorological Organization},
  year        = {2012},
  file        = {:Ensembles\\Guidelines on Ensemble Prediction Systems and Forecasting.pdf:PDF},
}

@Article{Micovic2015,
  author    = {Zoran Micovic and Melvin G. Schaefer and George H. Taylor},
  title     = {Uncertainty analysis for Probable Maximum Precipitation estimates},
  journal   = {Journal of Hydrology},
  year      = {2015},
  volume    = {521},
  pages     = {360--373},
  month     = {feb},
  abstract  = {An analysis of uncertainty associated with Probable Maximum Precipitation (PMP) estimates is
presented. The focus of the study is firmly on PMP estimates derived through meteorological analyses
and not on statistically derived PMPs. Theoretical PMP cannot be computed directly and operational
PMP estimates are developed through a stepwise procedure using a significant degree of subjective
professional judgment. This paper presents a methodology for portraying the uncertain nature of PMP
estimation by analyzing individual steps within the PMP derivation procedure whereby for each parameter requiring judgment, a set of possible values is specified and accompanied by expected probabilities.
The resulting range of possible PMP values can be compared with the previously derived operational single-value PMP, providing measures of the conservatism and variability of the original estimate. To our
knowledge, this is the first uncertainty analysis conducted for a PMP derived through meteorological
analyses. The methodology was tested on the La Joie Dam watershed in British Columbia. The results indicate that the commonly used single-value PMP estimate could be more than 40% higher when possible
changes in various meteorological variables used to derive the PMP are considered. The findings of this
study imply that PMP estimates should always be characterized as a range of values recognizing the
significant uncertainties involved in PMP estimation. In fact, we do not know at this time whether precipitation is actually upper-bounded, and if precipitation is upper-bounded, how closely PMP estimates
approach the theoretical limit.},
  doi       = {10.1016/j.jhydrol.2014.12.033},
  file      = {:Hydrology\\Precipitation\\Uncertainty analysis for Probable Maximum Precipitation estimates.pdf:PDF},
  keywords  = {likelihood function},
  publisher = {Elsevier {BV}},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2014.12.033},
}

@TechReport{ECMWF2015,
  author      = {ECMWF},
  title       = {User guide to ECMWF forecast products},
  institution = {ECMWF},
  year        = {2015},
  file        = {:Ensembles\\User guide to ECMWF forecast products.pdf:PDF},
  url         = {http://www.ecmwf.int/sites/default/files/User_Guide_V1.2_20151123.pdf},
}

@Article{SECTIO2005,
  author  = {Kristie Franz and Newsha Ajami},
  title   = {Hydrologic Ensemble Prediction Experiment Focuses on Reliable Forecasts},
  journal = {Eos, Transactions, American Geophysical Union (EOS)},
  year    = {2005},
  volume  = {25},
  pages   = {239},
  file    = {:Ensembles\\Hydrologic Ensemble Prediction Experiment Focuses on Reliable Forecasts.pdf:PDF},
}

@Article{Schaake2006,
  author   = {J. Schaake and K. Franz and A. Bradley and R. Buizza},
  title    = {The Hydrologic Ensemble Prediction EXperiment (HEPEX)},
  journal  = {Hydrology and Earth System Sciences Discussions},
  year     = {2006},
  pages    = {3321–3332},
  abstract = {Users of hydrologic predictions need reliable, quantitative forecast information, including estimates of uncertainty, for lead times ranging from less than an hour during flash
flooding events to more than a year for long-term water management. To meet this
5 need, operational agencies are developing hydrological ensemble forecast techniques
to account for sources of uncertainty such as future precipitation, initial hydrological
conditions, and hydrological model limitations including uncertain model parameters.
Research advances in areas such as hydrologic modeling, data assimilation, ensemble
prediction, and forecast verification need to be incorporated into operational forecasting
10 systems to assure that the state-of-the-art products are reaching the forecast user community. The Hydrologic Ensemble Prediction EXperiment (HEPEX) has been formed
to develop and demonstrate new hydrologic forecasting technologies, and to facilitate
the implementation of beneficial technologies into the operational environment.},
  file     = {:Ensembles\\The Hydrologic Ensemble Prediction EXperiment (HEPEX).pdf:PDF},
}

@TechReport{Nurmi2003,
  author      = {Pertti Nurmi},
  title       = {Recommendations on the verification of local weather forecasts},
  institution = {Finnish Meteorological Institute},
  year        = {2003},
  number      = {460},
  file        = {:Ensembles\\Recommendations on the verification of local weather forecasts.pdf:PDF},
}

@Article{Clark2004,
  author    = {Martyn Clark and Subhrendu Gangopadhyay and Lauren Hay and Balaji Rajagopalan and Robert Wilby},
  title     = {The Schaake and Shuffle: A and Method for Reconstructing and Space–Time Variability and in and Forecasted Precipitation and Temperature Fields},
  journal   = {Journal of Hydrometeorology},
  year      = {2004},
  volume    = {5},
  pages     = {243-262},
  abstract  = {A number of statistical methods that are used to provide local-scale ensemble forecasts of precipitation and
temperature do not contain realistic spatial covariability between neighboring stations or realistic temporal persistence for subsequent forecast lead times. To demonstrate this point, output from a global-scale numerical weather
prediction model is used in a stepwise multiple linear regression approach to downscale precipitation and temperature
to individual stations located in and around four study basins in the United States. Output from the forecast model
is downscaled for lead times up to 14 days. Residuals in the regression equation are modeled stochastically to
provide 100 ensemble forecasts. The precipitation and temperature ensembles from this approach have a poor
representation of the spatial variability and temporal persistence. The spatial correlations for downscaled output
are considerably lower than observed spatial correlations at short forecast lead times (e.g., less than 5 days) when
there is high accuracy in the forecasts. At longer forecast lead times, the downscaled spatial correlations are close
to zero. Similarly, the observed temporal persistence is only partly present at short forecast lead times.
A method is presented for reordering the ensemble output in order to recover the space–time variability in
precipitation and temperature fields. In this approach, the ensemble members for a given forecast day are ranked
and matched with the rank of precipitation and temperature data from days randomly selected from similar dates
in the historical record. The ensembles are then reordered to correspond to the original order of the selection
of historical data. Using this approach, the observed intersite correlations, intervariable correlations, and the
observed temporal persistence are almost entirely recovered. This reordering methodology also has applications
for recovering the space–time variability in modeled streamflow.},
  file      = {:schaake-shuffle-jhm.pdf:PDF},
  timestamp = {2016-11-01},
}

@TechReport{WMO2008,
  author      = {WMO},
  title       = {Guidelines on Communicating Forecast Uncertainty},
  institution = {WMO},
  year        = {2008},
  number      = {No. 4122},
  file        = {:Ensembles\\Guidelines on Communicating Forecast Uncertainty.pdf:PDF},
}

@TechReport{NWS2012,
  author      = {National Weather Service},
  title       = {Overview of the Hydrologic Ensemble Forecast Service (HEFS)},
  institution = {National Weather Service Office of Hydrologic Development},
  year        = {2012},
  file        = {:Ensembles\\Overview of the Hydrologic Ensemble Forecast Service (HEFS).pdf:PDF},
  timestamp   = {2016-10-18},
}

@Book{Wilks2006,
  title     = {Statistical Methods in the Atmospheric Sciences: An Introduction},
  publisher = {Elsevier},
  year      = {2006},
  author    = {D.S. Wilks},
  volume    = {91},
  series    = {International Geophysics Series},
  edition   = {2nd Edition},
  file      = {:Statistics\\Statistical Methods in the Atmospheric Sciences- An Introduction.pdf:PDF},
  timestamp = {2016-10-18},
}

@InBook{Porter2016,
  chapter   = {Handbook of Hydrometeorological Ensemble Forecasting},
  title     = {New York City’s Operations Support Tool: Utilizing Hydrologic Forecasts for Water Supply Management},
  year      = {2016},
  author    = {James Porter and Gerald Day and John C. Schaake and Lucien Wang},
  edition   = {DRAFT},
  abstract  = {The New York City Department of Environmental Protection (DEP) supplies over 1 billion gallons per day (BGD) of water to more than 9 million people in the New York City metropolitan area, making it one of the largest suppliers of surface water in the United States. DEP’s water supply system is as complex as it is large; it draws water from three distinct watersheds and features a number of interconnections and redundancies allowing for a large number of potential operating conditions. The system has a wide range of objectives – from supplying clean, reliable water for municipal demand to meeting environmental flow requirements for downstream stakeholders. Combined with the existing system complexity, these disparate objectives can make operational decision making a challenge.
In 2013, DEP launched the Operations Support Tool (OST) – a state-of-the-art model built to assist the utility in water supply operations decisions. OST consists of a system model (OASIS) to simulate water supply operations decisions and a linked hydrodynamic 2-dimentional water quality model (CE-QUAL-W2). The model is initialized using current system conditions (e.g., reservoir elevations, water quality conditions) and is driven forward in time using ensemble hydrologic forecasts. This setup gives DEP the ability to simulate a wide variety of operational strategies in near-real-time, allowing for objective alternatives analysis prior to making operational decisions. Ensemble hydrologic forecasts are a critical part of the success of this approach, as they enable DEP to evaluate decisions probabilistically by explicitly considering hydrologic uncertainty. 
This chapter provides an overview of the New York City water supply system, details the hydrologic forecasts used in OST, and reviews a handful of real operational applications of OST and the hydrologic forecast system.},
  keywords  = {Water resource management, applications of hydrologic ensemble forecasts, reservoir operations, decision support, water quality management, turbidity, probabilistic risk, system modeling, supply reliability, conservation releases, real-time modeling, data visualization, New York City water supply},
  timestamp = {2016-10-18},
}

@PhdThesis{Koskela2009,
  author    = {Jarkko Koskela},
  title     = {Studies on Long-term Inflow and Forecasting},
  school    = {Helsinki University of Technology},
  year      = {2009},
  abstract  = {This thesis aims to improve knowledge of long-term inflow and streamflow forecasts. A special focus is on the development of a new long-term forecast model and on the evaluation of long-term inflow forecasts.
In the first part of the work, a new categorical long-term forecast model is developed and its performance is investigated in four case studies. The forecasts are based only on the current hydrological state of the basin and thus,  weather  forecasts  are  not  utilised.  By  using  the  k-Nearest  Neighbour  Rule  (k-NRR)  or  the  minimum distance classifier (MDC), the forthcoming period is classified into a wetness class based on the hydrological state of the basin on the forecast date. Inflow forecast is finally based on this classification. The results show that  for  a lake  with a large  basin (Lake  Päijänne  case  study),  this  forecast  model  could  be used  in real-time inflow forecasting and the results are comparable with the forecast accuracy of the multiple linear regression models. For small basins (<10 km2) and in Lake Pyhäjärvi, the use of the new model for long-term discharge forecasting gave satisfactory results on April 1. On October 1, long-term forecasting turned out to be difficult irrespective of the forecast model.

In the second part of the work, long-term inflow forecasts are evaluated based on their length and accuracy. The study is based on two cases: a single multipurpose reservoir Lake Pyhäjärvi in Säkylä and a multipurpose lakeriver system, River Kymijoki. The evaluation method is based on artificially generated inflow forecasts and on the optimisation of the release sequences based on these forecasts. The results are in line with the outcome of similar international studies: if the live capacity  of the lake-river system compared with the annual inflow is small, short and accurate forecasts should be aimed at. For large systems, a long forecast period should be used without focusing as much on forecast accuracy. The main finding, however, is related to approximation of the potential hydropower production increase in Finland by supposing that forecast accuracy could be improved and the optimal forecast periods used. In the two case studies it was possible to increase hydropower production up to 0.7-9% compared with the status quo during the study period, if perfect inflow forecasts had been available. However,  the  realistic  possibilities  to  increase  hydropower  production  in  Finland  by  improving  forecast accuracy  were approximated to be 0.5-2% at the maximum. At the same time problems related to floods and droughts would decrease. Simulated annealing is used as the optimisation algorithm in the operation of the systems, and the evaluation of the performance of this algorithm was one of the special objectives of this study.  The algorithm was flexible and reliable.},
  file      = {:Ensembles\\Studies on Long-Term Inflow Forecasting.pdf:PDF},
  timestamp = {2016-11-01},
}

@MastersThesis{Barnard1989,
  author    = {Joanna Mary Barnard},
  title     = {The value of inflow forecasting in the operation of a hydroelectric reservoir},
  school    = {The University of British Columbia},
  year      = {1989},
  month     = {August},
  abstract  = {Analysis concludes that conceptual forecasting is most useful when the annual flow is significalty different from the average annual flow of the basin. Forecasting of either kind (deterministic or stochastic) is valuable for reservoir sizes greater than 25% of the mean annual flow, but the value decreases as the volume approaches 100% of the mean annual flow.},
  file      = {:Ensembles\\The value of inflow forecasting in the operation of a hydroelectric reservoir.pdf:PDF},
  keywords  = {Dynamic Programming, forecasting, hydropower},
  timestamp = {2016-10-18},
}

@Article{Schaake2007,
  author    = {Schaake, J. and Demargne, J. and Hartman, R. and Mullusky, M. and Welles, E. and Wu, L. and Herr, H. and Fan, X. and Seo, D. J.},
  title     = {Precipitation and temperature ensemble forecasts from single-value forecasts},
  journal   = {Hydrology and Earth System Sciences Discussions},
  year      = {2007},
  volume    = {4},
  pages     = {655--717},
  abstract  = {A procedure is presented to construct ensemble forecasts from single-value forecasts of precipitation and temperature. This involves dividing the spatial forecast domain and total forecast period into a number of parts that are treated as separate forecast events. The spatial domain is divided into hydrologic sub-basins. The total forecast period is divided into time periods, one for each model time step. For each event archived values of forecasts and corresponding observations are used to model the joint distribution of forecasts and observations. The conditional distribution of observations for a given single-value forecast is used to represent the corresponding probability distribution of events that may occur for that forecast. This conditional forecast distribution subsequently is used to create ensemble members that vary in space and time using the “Schaake Shuffle” (Clark et al, 2004). The resulting ensemble members have the same space-time patterns as historical observations so that space-time joint relationships between events that have a significant effect on hydrological response tend to be preserved. Forecast uncertainty is space and time-scale dependent. For a given lead time to the beginning of the valid period of an event, forecast uncertainty depends on the length of the forecast valid time period and the spatial area to which the forecast applies. Although the “Schaake Shuffle” procedure, when applied to construct ensemble members from a time-series of single value forecasts, may preserve some of this scale dependency, it may not be sufficient without additional constraint. To account more fully for the time-dependent structure of forecast uncertainty, events for additional “aggregate” forecast periods are defined as accumulations of different “base” forecast periods. The generated ensemble members can be ingested by an Ensemble Streamflow Prediction system to produce ensemble forecasts of streamflow and other hydrological variables that reflect the meteorological uncertainty. The methodology is illustrated by an application to generate temperature and precipitation ensemble forecasts for the American River in California. Parameter estimation and dependent validation results are presented based on operational single-value forecasts archives of short-range River Forecast Center (RFC) forecasts and medium-range ensemble mean forecasts from the National Weather Service (NWS) Global Forecast System (GFS).},
  doi       = {10.5194/hessd-4-655-2007},
  timestamp = {2016-10-18},
  url       = {http://www.hydrol-earth-syst-sci-discuss.net/4/655/2007/},
}

@Article{Brown2010a,
  author    = {James D. Brown and Dong-Jun Seo},
  title     = {A Nonparametric Postprocessor for Bias Correction of Hydrometeorological and Hydrologic Ensemble Forecasts},
  journal   = {J. Hydrometeor},
  year      = {2010},
  volume    = {11},
  number    = {3},
  pages     = {642--665},
  month     = {jun},
  abstract  = {This paper describes a technique for quantifying and removing biases from ensemble forecasts of hydrometeorological and hydrologic variables. The technique makes no a priori assumptions about the distributional form of the variables, which is often unknown or difficult to model parametrically. The aim is to
estimate the conditional cumulative distribution function (ccdf) of the observed variable given a (possibly
biased) real-time ensemble forecast. This ccdf represents the ‘‘true’’ probability distribution of the forecast
variable, subject to sampling uncertainties. In the absence of a known distributional form, the ccdf should be
estimated nonparametrically. It is noted that the probability of exceeding a threshold of the observed variable,
such as flood stage, is equivalent to the expectation of an indicator variable defined for that threshold. The
ccdf is then modeled through a linear combination of the indicator variables of the forecast ensemble
members. The technique is based on Bayesian optimal linear estimation of indicator variables and is analogous to indicator cokriging (ICK) in geostatistics. By developing linear estimators for the conditional expectation of the observed variable at many thresholds, ICK provides a discrete approximation of the full ccdf.
Since ICK minimizes the conditional error variance of the indicator variable at each threshold, it effectively
minimizes the continuous ranked probability score (CRPS) when infinitely many thresholds are employed.
The technique is used to bias-correct precipitation ensemble forecasts from the NCEP Global Ensemble
Forecast System (GEFS) and streamflow ensemble forecasts from the National Weather Service (NWS)
River Forecast Centers (RFCs). Split-sample validation results are presented for several attributes of
ensemble forecast quality, including reliability and discrimination. In general, the forecast biases were substantially reduced following ICK. Overall, the technique shows significant potential for bias-correcting ensemble forecasts whose distributional form is unknown or nonparametric.},
  doi       = {10.1175/2009jhm1188.1},
  file      = {:Ensembles\\A Nonparametric Postprocessor for Bias Correction of Hydrometeorological.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-12-23},
  url       = {http://dx.doi.org/10.1175/2009JHM1188.1},
}

@InProceedings{Seo2010,
  author    = {Dong-Jun Seo and Julie Demargne and Limin Wu and Yuqiong Liu and James D. Brown and Satish Regonda and Haksu Lee},
  title     = {Hydrologic Ensemble Prediction for Risk-based Water Resources Mangement and Hazard Mitigation},
  booktitle = {2nd Joint Federal Interagency Conference},
  year      = {2010},
  abstract  = {Hydrologic predictions are subject to various sources of error due to uncertainties in
the atmospheric forcing observations and predictions, hydrologic model initial conditions, 
parameters and structures, and streamflow regulations. To allow risk-based decision making in 
water resources and emergency management, quantification of predictive uncertainty in 
streamflow forecasts across short, medium and long ranges is necessary. To obtain reliable 
predictive uncertainty, it is necessary to account for both input (i.e. atmospheric) and hydrologic 
uncertainties accurately. To provide uncertainty-quantified streamflow forecast products 
operationally, the National Weather Service (NWS) Office of Hydrologic Development (OHD) 
and its partners have been developing a prototype hydrologic ensemble forecast system, the 
EXperimental Ensemble Forecast System (XEFS). The principal components of the prototype 
system are currently implemented in the Community Hydrologic Prediction System (CHPS). 
Testing and experimental operation of the XEFS components have begun in late 2009 at selected 
NWS River Forecast Centers (RFC). In this paper, we describe the progress and plans, 
evaluation results from hindcasting experiments, and challenges ahead.},
  file      = {:Ensembles\\Hydrologic Ensemble Prediction for Risk-based Water Resources Mangement and Hazard Mitigation.pdf:PDF},
  timestamp = {2016-11-22},
}

@Book{Driscoll2016,
  title     = {Python 201 - Intermediate Python},
  publisher = {Leanpub},
  year      = {2016},
  author    = {Michael Driscoll},
  file      = {:Programs\\python201.pdf:PDF},
  timestamp = {2016-10-18},
}

@Article{Mertens2004,
  author    = {J Mertens and H Madsen and L Feyen and D Jacques and J Feyen},
  title     = {Including prior information in the estimation of effective soil parameters in unsaturated zone modelling},
  journal   = {Journal of Hydrology},
  year      = {2004},
  volume    = {294},
  number    = {4},
  pages     = {251--269},
  month     = {jul},
  doi       = {10.1016/j.jhydrol.2004.02.011},
  file      = {:Optimization\\Including Prior Information in the Estimation of Effective Soil Parameters in Unsaturated Zone Modeling.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2004.02.011},
}

@Article{Efstratiadis2010,
  author    = {Andreas Efstratiadis and Demetris Koutsoyiannis},
  title     = {One decade of multi-objective calibration approaches in hydrological modelling: a review},
  journal   = {Hydrological Sciences Journal},
  year      = {2010},
  volume    = {55},
  number    = {1},
  pages     = {58--78},
  month     = {feb},
  doi       = {10.1080/02626660903526292},
  file      = {:Optimization\\One decade of multi-objective calibration approaches in hydrological modelling- a review.pdf:PDF},
  publisher = {Informa {UK} Limited},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1080/02626660903526292},
}

@Article{Parajka2007,
  author    = {J. Parajka and R. Merz and G. Blöschl},
  title     = {Uncertainty and multiple objective calibration in regional water balance modelling: case study in 320~{A}ustrian catchments},
  journal   = {Hydrological Processes},
  year      = {2007},
  volume    = {21},
  number    = {4},
  pages     = {435--446},
  doi       = {10.1002/hyp.6253},
  file      = {:Optimization\\Uncertainty and multiple objective calibration in regional water balance modelling case study in 320 Austrian catchments.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1002/hyp.6253},
}

@Article{Palmer2004,
  author    = {T. N. Palmer and A. Alessandri and U. Andersen and P. Cantelaube and M. Davey and P. Délécluse and M. Déqué and E. Díez and F. J. Doblas-Reyes and H. Feddersen and R. Graham and S. Gualdi and J.-F. Guérémy and R. Hagedorn and M. Hoshen and N. Keenlyside and M. Latif and A. Lazar and E. Maisonnave and V. Marletto and A. P. Morse and B. Orfila and P. Rogel and J.-M. Terres and M. C. Thomson},
  title     = {Development of a European multi-model ensemble system for seasonal to inter-annual prediction},
  journal   = {Bulletin of American Meteorological Society},
  year      = {2004},
  volume    = {85},
  pages     = {853--872},
  file      = {:Ensembles\\Development of a European multi-model ensemble system for seasonal to inter-annual prediction.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Weisheimer2009,
  author    = {A. Weisheimer and F. J. Doblas-Reyes and T. N. Palmer and A. Alessandri and A. Arribas and M. De ´que ´ and N. Keenlyside and M. MacVean and A. Navarra and P. Rogel},
  title     = {ENSEMBLES: A new multi-model ensemble for seasonal-to-annual predictions - Skill and progress beyond DEMETER in forecasting tropical Pacific SSTs},
  journal   = {Geophysical Research Letters},
  year      = {2009},
  volume    = {36},
  pages     = {L21711},
  abstract  = {A new 46-year hindcast dataset for seasonal-to-annual
ensemble predictions has been created using a multi-model
ensemble of 5 state-of-the-art coupled atmosphere-ocean
circulation models. The multi-model outperforms any of the
single-models in forecasting tropical Pacific SSTs because
of reduced RMS errors and enhanced ensemble dispersion
at all lead-times. Systematic errors are considerably reduced
over the previous generation (DEMETER). Probabilistic
skill scores show higher skill for the new multi-model
ensemble than for DEMETER in the 4–6 month forecast
range. However, substantially improved models would be
required to achieve strongly statistical significant skill
increases. The combination of ENSEMBLES and
DEMETER into a grand multi-model ensemble does not
improve the forecast skill further. Annual-range hindcasts
show anomaly correlation skill of 0.5 up to 14 months
ahead. A wide range of output from the multi-model
simulations is becoming publicly available and the
international community is invited to explore the full
scientific potential of these data.},
  file      = {:Ensembles\\ENSEMBLES- A new multi-model ensemble for seasonal-to-annual predictions - Skill and progress beyond DEMETER in forecasting tropical Pacific SSTs.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Doblas-Reyes2009,
  author    = {F. J. Doblas-Reyes and A. Weisheimer and M. D{\'{e}}qu{\'{e}} and N. Keenlyside and M. McVean and J. M. Murphy and P. Rogel and D. Smith and T. N. Palmer},
  title     = {Addressing model uncertainty in seasonal and annual dynamical ensemble forecasts},
  journal   = {Quarterly Journal of the Royal Meteorological Society},
  year      = {2009},
  volume    = {135},
  number    = {643},
  pages     = {1538--1559},
  month     = {jul},
  abstract  = {The relative merits of three forecast systems addressing the impact of model uncertainty on seasonal/annual
forecasts are described. One system consists of a multi-model, whereas two other systems sample uncertainties by perturbing
the parametrization of reference models through perturbed parameter and stochastic physics techniques. Ensemble reforecasts over 1991 to 2001 were performed with coupled climate models started from realistic initial conditions. Forecast
quality varies due to the different strategies for sampling uncertainties, but also to differences in initialisation methods and
in the reference forecast system. Both the stochastic-physics and perturbed-parameter ensembles improve the reliability
with respect to their reference forecast systems, but not the discrimination ability. Although the multi-model experiment has
an ensemble size larger than the other two experiments, most of the assessment was done using equally-sized ensembles.
The three ensembles show similar levels of skill: significant differences in performance typically range between 5 and
20%. However, a nine-member multi-model shows better results for seasonal predictions with lead times shorter than five
months, followed by the stochastic-physics and perturbed-parameter ensembles. Conversely, for seasonal predictions with
lead times longer than four months, the perturbed-parameter ensemble gives more often better results. All systems suggest
that spread cannot be considered a useful predictor of skill. Annual-mean predictions showed lower forecast quality than
seasonal predictions. Only small differences between the systems were found. The full multi-model ensemble has improved
quality with respect to all other systems, mainly from the larger ensemble size for lead times longer than four months and
annual predictions.},
  doi       = {10.1002/qj.464},
  file      = {:Ensembles\\Addressing model uncertainty in seasonal and annual dynamical ensemble forecasts.pdf:PDF},
  keywords  = {model uncertainty; ensemble forecast; probability forecasts; seasonal prediction; forecast quality},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1002/qj.464},
}

@Article{Yuan2015,
  author    = {Xing Yuan and Eric F. Wood and Zhuguo Ma},
  title     = {A review on climate-model-based seasonal hydrologic forecasting: physical understanding and system development},
  journal   = {Wiley Interdisciplinary Reviews: Water},
  year      = {2015},
  volume    = {2},
  number    = {5},
  pages     = {523--536},
  month     = {may},
  abstract  = {Climate-model-based seasonal hydrologic forecasting (CM-SHF) is an emerging area in recent decade because of the development of coupled atmosphere-ocean-land general circulation models (CGCMs) and land surface hydrologic models, and increasing needs for transferring the advances in climate research into hydrologic applications within the framework of climate services. In order to forecast terrestrial hydrology from monthly to seasonal time scales, a CM-SHF system should take advantage of important information from initial land surface conditions (ICs) as well as skillful seasonal predictions of atmospheric boundary conditions that mostly rely on the predictability of large-scale climate precursors such as the El Niño Southern Oscillation (ENSO). The progresses in the understanding of seasonal hydrologic predictability in terms of ICs and climate precursors are reviewed, and future emphases are discussed. Both the achievements and challenges of the CM-SHF system development, including multimodel ensemble prediction, seamless hydrologic forecasting, dynamical downscaling, hydrologic post-processing, and seasonal forecasting of hydrologic extremes with the hyper-resolution modeling framework that is able to address both the climate change and water resources management impacts on terrestrial hydrology, are presented. Regardless of great strides in CM-SHF, a grand challenge is the effective dissemination of the information provided by the seasonal hydrologic forecasting system to the decision-makers, which cannot be resolved without cross-disciplinary dialog and collaboration.},
  doi       = {10.1002/wat2.1088},
  file      = {:Ensembles\\A review on climate-model-based seasonal hydrologic forecasting- physical understanding and system development.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1002/wat2.1088},
}

@Article{Eum2011,
  author    = {Hyung-Il Eum and Young-Oh Kim and Richard N. Palmer},
  title     = {Optimal Drought Management Using Sampling Stochastic Dynamic Programming with a Hedging Rule},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2011},
  volume    = {137},
  number    = {1},
  pages     = {113-122},
  abstract  = {This study develops procedures that calculate optimal water release curtailments during droughts using a future value function
derived with a sampling stochastic dynamic programming model. Triggers that switch between a normal operating policy and an
emergency operating policy EOP are based on initial reservoir storage values representing a 95% water supply reliability and an
aggregate drought index that employs 6-month cumulative rainfall and 4-month cumulative streamflow. To verify the effectiveness of the
method, a cross-validation scheme using 2,100 combination sets is employed to simulate the Geum River basin system in Korea. The
simulation results demonstrate that the EOP approach: 1 reduces the maximum water shortage; 2 is most valuable when the initial
storages of the drawdown period are low; and 3 is superior to other approaches when explicitly considering forecast uncertainty.},
  file      = {:Optimization\\Optimal Drought Management Using Sampling Stochastic Dynamic Programming with a Hedging Rule.pdf:PDF},
  keywords  = {Stochastic processes; Droughts; Reservoirs; Korea, South; Sampling.},
  timestamp = {2016-10-25},
}

@Article{Tilmant2002,
  author    = {A. Tilmant and M. Vanclooster and L. Duckstein and E. Persoons},
  title     = {Comparison of Fuzzy and Nonfuzzy Optimal Reservoir Operating Policies},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2002},
  volume    = {128},
  number    = {6},
  abstract  = {This paper compares reservoir operating policies obtained from fuzzy and nonfuzzy explicit stochastic dynamic programming.
The reservoir operation problem for the Mansour Eddahbi dam in Morocco can be formulated as either a classical stochastic dynamic
programming ~SDP! problem, where the objective function stresses energy maximization with particular volumes being released for
irrigation, or a fuzzy stochastic dynamic programming ~FSDP! problem, in which both hydropower generation and irrigation are considered as fuzzy constraints and aggregated by the weighting method. System performance is estimated from simulation based on continuous
reoptimization models using either the cost-to-go function generated by the SDP algorithm, or the membership function generated by the
FSDP algorithm. Despite major differences in the mathematical representation of operating objectives and/or constraints, we show that
both formulations yield similar measures of system performance.},
  file      = {:Optimization\\Comparison of Fuzzy and Nonfuzzy Optimal Reservoir Operating Policies.pdf:PDF},
  keywords  = {Reservoir operation; Decision making; Optimization; Fuzzy sets; Stochastic processes},
  timestamp = {2016-10-25},
}

@Article{Jain1999,
  author    = {S. K. Jain and A. Das and D. K. Srivastava},
  title     = {Application of Ann for Reservoir Inflow Prediction and Operation},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {1999},
  volume    = {125},
  number    = {5},
  pages     = {263-271},
  abstract  = {Artificial neural networks (ANNs) are new computing architectures in the area of artificial intelligence. The present study aims at the application of ANNs for reservoir inflow prediction and operation. The
Upper Indravati multipurpose project, in the state of Orissa, India, has been selected as the focus area. The
project has primarily two objectives: To provide irrigation to 128,000,000 ha of agricultural land and to generate
600 MW of electric power. An autoregressive integrated moving average time-series model and an ANN-based
model were fitted to the monthly inflow data series and their performances were compared. The ANN was found
to model the high flows better, whereas low flows were better predicted through the autoregressive integrated
moving average model. Reservoir operation policies were formulated through dynamic programming. The optimal release was related with storage, inflow, and demand through linear and nonlinear regression and the ANN.
The results of intercomparison indicate that the ANN is a powerful tool for input-output mapping and can be
effectively used for reservoir inflow forecasting and operation.},
  file      = {:Optimization\\Application of ANN for Reservoir Inflow Prediction and Operation.pdf:PDF},
  publisher = {Downloaded from ascelibrary.org by Colorado State Univ Lbrs on 10/25/16. Copyright ASCE. For personal use only; all rights reserved. APPLICATION OF ANN FOR RESERVOIR INFLOW PREDICTION AND OPERATION},
  timestamp = {2016-10-25},
}

@Article{Tejada-Guibert1995,
  author        = {J. Alberto Tejada-Guibert and Sharon A. Johnson and Jery R. Stedinger},
  title         = {The value of hydrologicinformation in stochasticdynamic programming models of a multireservoir system},
  journal       = {Water Resources Research},
  year          = {1995},
  volume        = {31},
  number        = {10},
  pages         = {2571-2579},
  __markedentry = {[quebbs:1]},
  abstract      = {Reservoir operating policies can be derived using stochastic dynamic
programming (SDP) with different hydrologic state variables. Thispaperconsiders several
choices for such hydrologic state variables for SDP modelsof the Shasta-Trinity system in
northern California,for three differentbenefitfunctions.We comparehowwell SDP
modelspredicttheir policieswill perform,as well as how well these policies performed
when simulated. For a benefitfunctionstressing energy maximization, all policiesdid
nearly as well, and the choiceof the hydrologic state variablemattered very little. For a
benefit functionwith larger water and firm power targets and severe penalties on
corresponding shortages, predicted performance significantly overestimated simulated
performance, and policies that employed more complete hydrologic information
performed significantly better.},
  file          = {:Optimization\\The Value of Hydrologic Information in Stochastic Dynamic Programming Models of a Multireservoir System.pdf:PDF},
  timestamp     = {2016-10-25},
}

@Article{Kim2007,
  author    = {Young-Oh Kim and Hyung-Il Eum and Eun-Goo Lee and Ick Hwan Ko},
  title     = {Optimizing Operational Policies of a Korean Multireservoir System Using Sampling Stochastic Dynamic Programming with Ensemble Streamflow Prediction},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2007},
  volume    = {133},
  number    = {1},
  pages     = {4-14},
  abstract  = {This study presents state-of-the-art optimization techniques for enhancing reservoir operations which use sampling stochastic
dynamic programming SSDP with ensemble streamflow prediction ESP. SSDP used with historical inflow scenarios SSDP/Hist
derives an off-line optimal operating policy through a backward-moving solution procedure. In contrast, SSDP used with monthly
forecasts of ESP SSSDP/ESP reoptimizes the off-line policy. These stochastic models are used to derive a monthly joint operating policy
during the drawdown period of the Geum River multireservoir system in Korea. A cross-validation test of 1,900 simulation runs
demonstrates that: 1 proposed stochastic models that explicitly include inflow uncertainty are superior to those that do not; 2 updating
policy with ESP forecasts is appropriate in this reservoir system; 3 the lower dam of the Geum River multireservoir system should
maintain elevation of 66.5 m during the beginning of the drawdown period to avoid significant increase in the downstream water
shortages; and 4 forecasting accuracy may result in considerable effects on joint reservoir operations.},
  file      = {:Optimization\\Optimizing Operational Policies of a Korean Multireservoir System Using Sampling Stochastic Dynamic Programming with Ensemble Streamflow Prediction.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Forsythe2014,
  author    = {N. Forsythe and H.J. Fowler and S. Blenkinsop and A. Burton and C.G. Kilsby and D.R. Archer and C. Harpham and M.Z. Hashmi},
  title     = {Application of a stochastic weather generator to assess climate change impacts in a semi-arid climate: The Upper Indus Basin},
  journal   = {Journal of Hydrology},
  year      = {2014},
  volume    = {517},
  pages     = {1019--1034},
  month     = {sep},
  doi       = {10.1016/j.jhydrol.2014.06.031},
  file      = {:Hydrology\\Application of a stochastic weather generator to assess climate change impacts in a semi-arid climate- The Upper Indus Basin.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2014.06.031},
}

@Article{Sankarasubramanian2009,
  author    = {A. Sankarasubramanian and Upmanu Lall and Naresh Devineni and Susan Espinueva},
  title     = {The Role of Monthly Updated Climate Forecasts in Improving Intraseasonal Water Allocation},
  journal   = {Journal of Applied Meteorology and Climatology},
  year      = {2009},
  volume    = {48},
  number    = {7},
  pages     = {1464--1482},
  month     = {jul},
  doi       = {10.1175/2009jamc2122.1},
  file      = {:Ensembles\\The Role of Monthly Updated Climate Forecasts in Improving Intraseasonal Water Allocation.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1175/2009JAMC2122.1},
}

@Article{Valeriano2010,
  author    = {Oliver C. Saavedra Valeriano and Toshio Koike and Kun Yang and Tobias Graf and Xin Li and Lei Wang and Xujun Han},
  title     = {Decision support for dam release during floods using a distributed biosphere hydrological model driven by quantitative precipitation forecasts},
  journal   = {Water Resources Research},
  year      = {2010},
  abstract  = {This study proposes a decision support system for real‐time dam operation during heavy
rainfall. It uses an operational mesoscale quantitative precipitation forecast (QPF) to force a
hydrological model and considers the forecast error from the previous time step, which
is introduced as a perturbation range applied to the most recent QPF. A weighting module
accounts for the location, intensity, and extent of the error. Missing precipitation intensities
within contributing areas and information from surrounding areas can both be considered.
Forecast error is defined as the ratio of QPF to the observed precipitation within an
evaluation zone (sub‐basin, basin, buffer, or total domain). An objective function is
established to minimize the flood volume at control points downstream and to maximize
reservoir storage. The decision variables are the dam releases, which are constrained to the
ensemble streamflow’s information. A prototype was applied to one of the most important
river basins in Japan, the Tone reservoir system. The efficiency of the approach was
evident in reduced flood peaks downstream and increased water storage. The results from
three events indicate that the developed decision support system is feasible for real‐life dam
operation.},
  file      = {:Ensembles\\Decision support for dam release during floods using a distributed biosphere hydrological model driven by quantitative precipitation forecasts.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Boucher2012,
  author    = {M.-A. Boucher and D. Tremblay and L. Delorme and L. Perreault and F. Anctil},
  title     = {Hydro-economic assessment of hydrological forecasting systems},
  journal   = {Journal of Hydrology},
  year      = {2012},
  volume    = {416-417},
  pages     = {133--144},
  month     = {jan},
  doi       = {10.1016/j.jhydrol.2011.11.042},
  file      = {:Ensembles\\Hydro-economic assessment of hydrological forecasting systems.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2011.11.042},
}

@Article{Franz2003,
  author    = {Kristie J. Franz and Holly C. Hartmann and Soroosh Sorooshian and Roger Bales},
  title     = {Verification of National Weather Service Ensemble Streamflow Predictions for Water Supply Forecasting in the Colorado River Basin},
  journal   = {Journal of Hydrometeorology},
  year      = {2003},
  volume    = {4},
  abstract  = {The Ensemble Streamflow Prediction (ESP) system, developed by the National Weather Service (NWS), uses
conceptual hydrologic models and historical data to generate a set, or ensemble, of possible streamflow scenarios
conditioned on the initial states of a given basin. Using this approach, simulated historical probabilistic forecasts
were generated for 14 forecast points in the Colorado River basin, and the statistical properties of the ensembles
were evaluated. The median forecast traces were analyzed using ‘‘traditional’’ verification measures; these
forecasts represented ‘‘deterministic ESP forecasts.’’ The minimum-error and historical traces were examined
to evaluate the median forecasts and the forecast system. Distribution-oriented verification measures were used
to analyze the probabilistic information contained in the entire forecast ensemble. Using a single-trace prediction,
for example, the median, resulted in a loss of valuable uncertainty information about predicted seasonal volumes
that is provided by the entire ensemble. The minimum-error and historical traces revealed that there are errors
in the data, calibration, and models, which are part of the uncertainty provided by the probabilistic forecasts,
but are not considered in the median forecast. The simulated ESP forecasts more accurately predicted future
streamflow than climatology forecasts and, on average, provided useful information about the likelihood of
future streamflow magnitude with a lead time of up to 7 months. Overall, the forecast provided stronger probability
statements and became more reliable at shorter lead times. The distribution-oriented verification approach was
shown to be applicable to ESP outlooks and appropriate for extracting detailed performance information, although
interpretation of the results is complicated by inadequate sample sizes.},
  file      = {:Ensembles\\Verification of National Weather Service Ensemble Streamflow Predictions for Water Supply Forecasting in the Colorado River Basin.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Kim1997,
  author        = {Young-Oh Kim and Richard N. Palmer},
  title         = {Value of Seasonal Flow Forecasts in Bayesian Stochastic Programming},
  journal       = {Journal of Water Resources Planning and Management},
  year          = {1997},
  volume        = {123},
  number        = {6},
  pages         = {327--335},
  __markedentry = {[quebbs:1]},
  abstract      = {This paper presents a Bayesian Stochastic Dynamic Programming (BSDP) model to investigate
the value of seasonal flow forecasts in hydropower generation. The proposed BSDP framework generates
monthly operating policies for the Skagit Hydropower System (SHS), which supplies energy to the Seattle
metropolitan area. The objective function maximizes the total benefits resulting from energy produced by the
SHS and its interchange with the Bonneville Power Administration. The BSDP-derived operating policies for
the SHS are simulated using historical monthly inflows, as well as seasonal flow forecasts during 60 years from
January 1929 through December 1988. Performance of the BSDP model is compared with alternative stochastic
dynamic programming models. To illustrate the potential advantage of using the seasonal flow forecasts and
other hydrologic information, the sensitivity of SHS operation is evaluated by varying (1) the reservoir capacity;
(2) the energy demand; and (3) the energy price. The simulation results demonstrate that including the seasonal
forecasts is beneficial to SHS operation.},
  file          = {:Ensembles\\Value of Seasonal Flow Forecasts in Bayesian Stochastic Programming.pdf:PDF},
  timestamp     = {2016-10-25},
}

@Article{Zhao2011a,
  author    = {Tongtiegang Zhao and Ximing Cai and Dawen Yang},
  title     = {Effect of streamflow forecast uncertainty on real-time reservoir operation},
  journal   = {Advances in Water Resources},
  year      = {2011},
  volume    = {34},
  number    = {4},
  pages     = {495--504},
  month     = {apr},
  doi       = {10.1016/j.advwatres.2011.01.004},
  file      = {:Ensembles\\Effect of streamflow forecast uncertainty on real-time reservoir operation.pdf:PDF},
  keywords  = {Martingale Model of Forecasting Evolution (MMFE)},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-22},
  url       = {http://dx.doi.org/10.1016/j.advwatres.2011.01.004},
}

@Article{Fundel2013,
  author    = {F. Fundel and S. Jörg-Hess and M. Zappa},
  title     = {Monthly hydrometeorological ensemble prediction of streamflow droughts and corresponding drought indices},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2013},
  volume    = {17},
  number    = {1},
  pages     = {395--407},
  month     = {jan},
  abstract  = {Streamflow droughts, characterized by low runoff
as consequence of a drought event, affect numerous aspects
of life. Economic sectors that are impacted by low streamflow are, e.g., power production, agriculture, tourism, water
quality management and shipping. Those sectors could potentially benefit from forecasts of streamflow drought events,
even of short events on the monthly time scales or below. Numerical hydrometeorological models have increasingly been
used to forecast low streamflow and have become the focus
of recent research. Here, we consider daily ensemble runoff
forecasts for the river Thur, which has its source in the Swiss
Alps. We focus on the evaluation of low streamflow and
of the derived indices as duration, severity and magnitude,
characterizing streamflow droughts up to a lead time of one
month.
The ECMWF VarEPS 5-member ensemble reforecast,
which covers 18 yr, is used as forcing for the hydrological model PREVAH. A thorough verification reveals that,
compared to probabilistic peak-flow forecasts, which show
skill up to a lead time of two weeks, forecasts of streamflow droughts are skilful over the entire forecast range of one
month. For forecasts at the lower end of the runoff regime,
the quality of the initial state seems to be crucial to achieve a
good forecast quality in the longer range. It is shown that the
states used in this study to initialize forecasts satisfy this requirement. The produced forecasts of streamflow drought indices, derived from the ensemble forecasts, could be beneficially included in a decision-making process. This is valid for
probabilistic forecasts of streamflow drought events falling
below a daily varying threshold, based on a quantile derived
from a runoff climatology. Although the forecasts have a tendency to overpredict streamflow droughts, it is shown that the
relative economic value of the ensemble forecasts reaches up
to 60 %, in case a forecast user is able to take preventive action based on the forecast.},
  doi       = {10.5194/hess-17-395-2013},
  file      = {:Ensembles\\Monthly hydrometeorological ensemble prediction of streamflow droughts and corresponding drought indices.pdf:PDF},
  publisher = {Copernicus {GmbH}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.5194/hess-17-395-2013},
}

@Article{Demargne2014,
  author    = {Julie Demargne and Limin Wu and Satish K. Regonda and James D. Brown and Haksu Lee and Minxue He and Dong-jun Seo and Robert Hartman and Henry D. Herr and Mark Fresch and John Schaake and Yuejian Zhu},
  title     = {The Science of NOAA’s Operational Hydrologic Ensemble Forecast Service},
  journal   = {Bulletin of the American Meteorological Society},
  year      = {2014},
  pages     = {79--98},
  month     = {January},
  file      = {:Ensembles\\The Science of NOAA's Operational Hydrologic Ensemble Forecast Service.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Georgakakos2004,
  author    = {Konstantine P Georgakakos and Dong-Jun Seo and Hoshin Gupta and John Schaake and Michael B Butts},
  title     = {Towards the characterization of streamflow simulation uncertainty through multimodel ensembles},
  journal   = {Journal of Hydrology},
  year      = {2004},
  volume    = {298},
  number    = {1-4},
  pages     = {222--241},
  month     = {oct},
  abstract  = {Distributed hydrologic modeling holds significant promise for improved estimates of streamflow with high spatial resolution.
However, uncertainty in model structure and parameters, which are distributed in space, and in operational weather radar
rainfall estimates, which comprise the main input to the models, contributes to significant uncertainty in distributed model
streamflow simulations over a wide range of space and time scales. Using the simulations produced for the Distributed Model
Intercomparison Project (DMIP), this paper develops and applies sample-path methods to characterize streamflow simulation
uncertainty by diverse distributed hydrologic models. The emphasis in this paper is on the model parameter and structure
uncertainty given radar rainfall forcing. Multimodel ensembles are analyzed for six application catchments in the Central US to
characterize model structure uncertainty within the sample of models (both calibrated and uncalibrated) participating in DMIP.
Ensembles from single distributed and lumped models are also used for one of the catchments to provide a basis to characterize
the impact of parametric uncertainty versus model structure uncertainty in flow simulation statistics. Two main science
questions are addressed: (a) what is the value of multimodel streamflow ensembles in terms of the probabilistic characterization
of simulation uncertainty? And (b) how do probabilistic skill measures of multimodel versus single-model ensembles compare?
Discussed also are implications for the operational use of streamflow ensembles generated by distributed hydrologic models.
The results support the serious consideration of ensemble simulations and predictions created by diverse models in real time
flow prediction.},
  doi       = {10.1016/j.jhydrol.2004.03.037},
  file      = {:Ensembles\\Towards the characterization of streamflow simulation uncertainty through multimodel ensembles.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2004.03.037},
}

@Article{Wu2011,
  author    = {Limin Wu and Dong-Jun Seo and Julie Demargne and James D. Brown and Shuzheng Cong and John Schaake},
  title     = {Generation of ensemble precipitation forecast from single-valued quantitative precipitation forecast for hydrologic ensemble prediction},
  journal   = {Journal of Hydrology},
  year      = {2011},
  volume    = {399},
  number    = {3-4},
  pages     = {281--298},
  month     = {mar},
  abstract  = {Reliable and skillful precipitation ensemble forecasts are necessary to produce reliable and skilful hydrologic ensemble forecasts. It is well known that, in general, raw precipitation ensemble forecasts from the
numerical weather prediction (NWP) models are not very reliable and that, for short-range prediction,
human forecasters add significant skill to the NWP-generated single-valued quantitative precipitation
forecasts (QPF). In this paper, we describe and evaluate a statistical procedure for producing precipitation
ensemble forecasts from single-valued QPFs. The procedure is based on the bivariate probability distribution between the observed precipitation and the single-valued QPF. The distribution is modeled as a
mixed-type in which the relationship between the positive observed precipitation and positive forecast
precipitation is assumed to be bivariate meta-Gaussian. We also describe and comparatively evaluate a
generalized meta-Gaussian model in which the model parameter is optimized by minimizing the mean
Continuous Ranked Probability Score. The performance of these procedures is assessed through dependent and cross validation using data for selected river basins in the service areas of the Arkansas-Red
Basin, California-Nevada and Middle-Atlantic River Forecast Centers of the National Weather Service.
The validation results show that, overall, the precipitation ensembles generated by the proposed procedures are reliable and capture the skill in the conditioning single-valued forecasts very well.},
  doi       = {10.1016/j.jhydrol.2011.01.013},
  file      = {:Ensembles\\Generation of ensemble precipitation forecast from single-valued quantitative precipitation forecast for hydrologic ensemble prediction.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2011.01.013},
}

@Article{Regonda2013,
  author    = {Satish Kumar Regonda and Dong-Jun Seo and Bill Lawrence and James D. Brown and Julie Demargne},
  title     = {Short-term ensemble streamflow forecasting using operationally-produced single-valued streamflow forecasts {\textendash} A Hydrologic Model Output Statistics ({HMOS}) approach},
  journal   = {Journal of Hydrology},
  year      = {2013},
  volume    = {497},
  pages     = {80--96},
  month     = {aug},
  abstract  = {We present a statistical procedure for generating short-term ensemble streamflow forecasts from singlevalued, or deterministic, streamflow forecasts produced operationally by the U.S. National Weather Service (NWS) River Forecast Centers (RFCs). The resulting ensemble streamflow forecast provides an estimate of the predictive uncertainty associated with the single-valued forecast to support risk-based
decision making by the forecasters and by the users of the forecast products, such as emergency managers. Forced by single-valued quantitative precipitation and temperature forecasts (QPF, QTF), the singlevalued streamflow forecasts are produced at a 6-h time step nominally out to 5 days into the future. The
single-valued streamflow forecasts reflect various run-time modifications, or ‘‘manual data assimilation’’,
applied by the human forecasters in an attempt to reduce error from various sources in the end-to-end
forecast process. The proposed procedure generates ensemble traces of streamflow from a parsimonious
approximation of the conditional multivariate probability distribution of future streamflow given the single-valued streamflow forecast, QPF, and the most recent streamflow observation. For parameter estimation and evaluation, we used a multiyear archive of the single-valued river stage forecast produced
operationally by the NWS Arkansas-Red River Basin River Forecast Center (ABRFC) in Tulsa, Oklahoma.
As a by-product of parameter estimation, the procedure provides a categorical assessment of the effective
lead time of the operational hydrologic forecasts for different QPF and forecast flow conditions. To evaluate the procedure, we carried out hindcasting experiments in dependent and cross-validation modes.
The results indicate that the short-term streamflow ensemble hindcasts generated from the procedure
are generally reliable within the effective lead time of the single-valued forecasts and well capture the
skill of the single-valued forecasts. For smaller basins, however, the effective lead time is significantly
reduced by short basin memory and reduced skill in the single-valued QPF.},
  doi       = {10.1016/j.jhydrol.2013.05.028},
  file      = {:Ensembles\\Short-term ensemble streamflow forecasting using operationally-produced single-valued streamflow forecasts – A Hydrologic Model Output Statistics (HMOS) approach.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2013.05.028},
}

@Article{Renner2009,
  author    = {M. Renner and M.G.F. Werner and S. Rademacher and E. Sprokkereef},
  title     = {Verification of ensemble flow forecasts for the River Rhine},
  journal   = {Journal of Hydrology},
  year      = {2009},
  volume    = {376},
  number    = {3-4},
  pages     = {463--475},
  month     = {oct},
  abstract  = {Ensemble stream flow predictions obtained by forcing rainfall–runoff models with probabilistic weather
forecasting products are becoming more commonly used in operational flood forecasting applications. In
this paper the performance of ensemble flow forecasts at various stations in the Rhine basin are studied
by the means of probabilistic verification statistics. When compared to climatology positive skill scores
are found at all river gauges for lead times of up to 9 days, thus proving the medium-range flow forecasts
to be useful. A preliminary comparison between the low resolution ECMWF-EPS forecast and the highresolution COSMO-LEPS forecast products shows that downscaling of global meteorological forecast
products is recommended before use in forcing rainfall–runoff models in flow forecasting.},
  doi       = {10.1016/j.jhydrol.2009.07.059},
  file      = {:Ensembles\\Verification of ensemble flow forecasts for the River Rhine.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2009.07.059},
}

@Article{Cloke2009,
  author    = {H.L. Cloke and F. Pappenberger},
  title     = {Ensemble flood forecasting: A review},
  journal   = {Journal of Hydrology},
  year      = {2009},
  volume    = {375},
  number    = {3-4},
  pages     = {613--626},
  month     = {sep},
  abstract  = {Operational medium range flood forecasting systems are increasingly moving towards the adoption of
ensembles of numerical weather predictions (NWP), known as ensemble prediction systems (EPS), to
drive their predictions. We review the scientific drivers of this shift towards such ‘ensemble flood forecasting’ and discuss several of the questions surrounding best practice in using EPS in flood forecasting
systems. We also review the literature evidence of the ‘added value’ of flood forecasts based on EPS
and point to remaining key challenges in using EPS successfully.},
  doi       = {10.1016/j.jhydrol.2009.06.005},
  file      = {:Ensembles\\Ensemble flood forecasting- A review.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2009.06.005},
}

@Article{Verkade2013,
  author    = {J.S. Verkade and J.D. Brown and P. Reggiani and A.H. Weerts},
  title     = {Post-processing ECMWF precipitation and temperature ensemble reforecasts for operational hydrologic forecasting at various spatial scales},
  journal   = {Journal of Hydrology},
  year      = {2013},
  volume    = {501},
  pages     = {73--91},
  abstract  = {The ECMWF temperature and precipitation ensemble reforecasts are evaluated for biases in the mean,
spread and forecast probabilities, and how these biases propagate to streamflow ensemble forecasts.
The forcing ensembles are subsequently post-processed to reduce bias and increase skill, and to investigate whether this leads to improved streamflow ensemble forecasts. Multiple post-processing techniques
are used: quantile-to-quantile transform, linear regression with an assumption of bivariate normality and
logistic regression. Both the raw and post-processed ensembles are run through a hydrologic model of the
river Rhine to create streamflow ensembles. The results are compared using multiple verification metrics
and skill scores: relative mean error, Brier skill score and its decompositions, mean continuous ranked
probability skill score and its decomposition, and the ROC score. Verification of the streamflow ensembles
is performed at multiple spatial scales: relatively small headwater basins, large tributaries and the Rhine
outlet at Lobith. The streamflow ensembles are verified against simulated streamflow, in order to isolate
the effects of biases in the forcing ensembles and any improvements therein. The results indicate that the
forcing ensembles contain significant biases, and that these cascade to the streamflow ensembles. Some
of the bias in the forcing ensembles is unconditional in nature; this was resolved by a simple quantile-toquantile transform. Improvements in conditional bias and skill of the forcing ensembles vary with forecast lead time, amount, and spatial scale, but are generally moderate. The translation to streamflow forecast skill is further muted, and several explanations are considered, including limitations in the modelling
of the space–time covariability of the forcing ensembles and the presence of storages.},
  file      = {:Ensembles\\Post-processing ECMWF precipitation and temperature ensemble forecasts for operational hydrologic forecasting at various spatial scales.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Hamlet2002,
  author        = {Alan F. Hamlet and Daniel Huppert and Dennis P. Lettenmaier},
  title         = {Economic Value of Long-Lead Streamflow Forecasts for Columbia River Hydropower},
  journal       = {Journal of Water Resources Planning and Management},
  year          = {2002},
  volume        = {128},
  number        = {2},
  pages         = {91--101},
  __markedentry = {[quebbs:1]},
  abstract      = {Recent advances in long-lead climate forecasting have made it possible to produce useful streamflow forecasts for the
Columbia River basin roughly six months earlier than current forecasts that rely on snowpack measurements. The resulting increase in
forecast lead time facilitates considerable improvements in system operating performance, especially in years of expected above average
flows. In the current reservoir operating system, the so called ‘‘critical’’ and ‘‘assured refill’’ rule curves that restrict releases for
hydropower generation in the period from August to December are based on the critical ~most severe low flow! and third lowest flow
sequences of record, respectively. These rule curves provide appropriate protection of energy capacity and reservoir refill in extreme low
flow conditions, but are restrictive in normal and high flow years until midwinter when operational streamflow forecasts based on
observed snowpack become available, and the climatological constraints are relaxed to account for expected summer streamflows. The use
of long lead time streamflow forecasts allows current operating constraints to be relaxed in years when there is a high likelihood of ample
streamflow. In these years, more spot market energy sales can be made in the late summer and fall/early winter because of increased
available water for releases, and spill from reservoirs in wet years is also reduced. Reservoir model simulations using alternative reservoir
rule curves based upon retrospective long-lead streamflow forecasts from water years 1931 to 1987 show that the proposed alternative
operating system based on climate forecasts can increase nonfirm energy production from the major Columbia River hydropower dams by
as much as 5.5 million MW/h/year, resulting in an average increase in annual revenue of approximately $153 million per year in
comparison with the status quo. Other uses of the Columbia River are largely unaffected by the proposed changes in the operating system.
In particular, firm energy, the reliability of storage reservoir refill, and the frequency of meeting of streamflow targets for salmon
protection would be essentially unchanged in comparison with the status quo. The increased hydropower revenue is therefore directly
attributed to use of long-lead forecast information and does not represent a trade-off among other management objectives.},
  file          = {:Ensembles\\Economic Value of Long-Lead Streamflow Forecasts for Columbia River Hydropower.pdf:PDF},
  timestamp     = {2016-10-25},
}

@Article{Wood2008,
  author    = {Andrew W. Wood and John C. Schaake},
  title     = {Correcting Errors in Streamflow Forecast Ensemble Mean and Spread},
  journal   = {J. Hydrometeor},
  year      = {2008},
  volume    = {9},
  number    = {1},
  pages     = {132--148},
  month     = {feb},
  abstract  = {When hydrological models are used for probabilistic streamflow forecasting in the Ensemble Streamflow
Prediction (ESP) framework, the deterministic components of the approach can lead to errors in the
estimation of forecast uncertainty, as represented by the spread of the forecast ensemble. One avenue for
correcting the resulting forecast reliability errors is to calibrate the streamflow forecast ensemble to match
observed error characteristics. This paper outlines and evaluates a method for forecast calibration as applied
to seasonal streamflow prediction. The approach uses the correlation of forecast ensemble means with
observations to generate a conditional forecast mean and spread that lie between the climatological mean
and spread (when the forecast has no skill) and the raw forecast mean with zero spread (when the forecast
is perfect). Retrospective forecasts of summer period runoff in the Feather River basin, California, are used
to demonstrate that the approach improves upon the performance of traditional ESP forecasts by reducing
errors in forecast mean and improving spread estimates, thereby increasing forecast reliability and skill.},
  doi       = {10.1175/2007jhm862.1},
  file      = {:Ensembles\\Correcting Errors in Streamflow Forecast Ensemble Mean and Spread.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1175/2007JHM862.1},
}

@Article{Duan2007,
  author    = {Qingyun Duan and Newsha K. Ajami and Xiaogang Gao and Soroosh Sorooshian},
  title     = {Multi-model ensemble hydrologic prediction using Bayesian model averaging},
  journal   = {Advances in Water Resources},
  year      = {2007},
  volume    = {30},
  number    = {5},
  pages     = {1371--1386},
  month     = {may},
  abstract  = {Multi-model ensemble strategy is a means to exploit the diversity of skillful predictions from different models. This paper studies
the use of Bayesian model averaging (BMA) scheme to develop more skillful and reliable probabilistic hydrologic predictions from
multiple competing predictions made by several hydrologic models. BMA is a statistical procedure that infers consensus predictions
by weighing individual predictions based on their probabilistic likelihood measures, with the better performing predictions receiving
higher weights than the worse performing ones. Furthermore, BMA provides a more reliable description of the total predictive uncertainty than the original ensemble, leading to a sharper and better calibrated probability density function (PDF) for the probabilistic
predictions. In this study, a nine-member ensemble of hydrologic predictions was used to test and evaluate the BMA scheme. This
ensemble was generated by calibrating three different hydrologic models using three distinct objective functions. These objective functions were chosen in a way that forces the models to capture certain aspects of the hydrograph well (e.g., peaks, mid-flows and low
flows). Two sets of numerical experiments were carried out on three test basins in the US to explore the best way of using the BMA
scheme. In the first set, a single set of BMA weights was computed to obtain BMA predictions, while the second set employed multiple sets of weights, with distinct sets corresponding to different flow intervals. In both sets, the streamflow values were transformed
using Box–Cox transformation to ensure that the probability distribution of the prediction errors is approximately Gaussian. A split
sample approach was used to obtain and validate the BMA predictions. The test results showed that BMA scheme has the advantage
of generating more skillful and equally reliable probabilistic predictions than original ensemble. The performance of the expected
BMA predictions in terms of daily root mean square error (DRMS) and daily absolute mean error (DABS) is generally superior
to that of the best individual predictions. Furthermore, the BMA predictions employing multiple sets of weights are generally better
than those using single set of weights.},
  doi       = {10.1016/j.advwatres.2006.11.014},
  file      = {:Ensembles\\Multi-model ensemble hydrologic prediction using Bayesian model averaging.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.advwatres.2006.11.014},
}

@Article{Brown2012b,
  author    = {James D. Brown and Dong-Jun Seo and Jun Du},
  title     = {Verification of Precipitation Forecasts from {NCEP}'s Short-Range Ensemble Forecast ({SREF}) System with Reference to Ensemble Streamflow Prediction Using Lumped Hydrologic Models},
  journal   = {Journal of Hydrometeorology},
  year      = {2012},
  volume    = {13},
  number    = {3},
  pages     = {808--836},
  month     = {jun},
  abstract  = {Precipitation forecasts from the Short-Range Ensemble Forecast (SREF) system of the National Centers for
Environmental Prediction (NCEP) are verified for the period April 2006–August 2010. Verification is conducted
for 10–20 hydrologic basins in each of the following: the middle Atlantic, the southern plains, the windward slopes
of the Sierra Nevada, and the foothills of the Cascade Range in the Pacific Northwest. Mean areal precipitation is
verified conditionally upon forecast lead time, amount of precipitation, season, forecast valid time, and accumulation period. The stationary block bootstrap is used to quantify the sampling uncertainties of the verification
metrics. In general, the forecasts are more skillful for moderate precipitation amounts than either light or heavy
precipitation. This originates from a threshold-dependent conditional bias in the ensemble mean forecast. Specifically, the forecasts overestimate low observed precipitation and underestimate high precipitation (a type-II
conditional bias). Also, the forecast probabilities are generally overconfident (a type-I conditional bias), except
for basins in the southern plains, where forecasts of moderate to high precipitation are reliable. Depending on
location, different types of bias correction may be needed. Overall, the northwest basins show the greatest potential for statistical postprocessing, particularly during the cool season, when the type-I conditional bias and
correlations are both high. The basins of the middle Atlantic and southern plains show less potential for statistical
postprocessing, as the type-II conditional bias is larger and the correlations are weaker. In the Sierra Nevada, the
greatest benefits of statistical postprocessing should be expected for light precipitation, specifically during the
warm season, when the type-I conditional bias is large and the correlations are strong.},
  doi       = {10.1175/jhm-d-11-036.1},
  file      = {:Ensembles\\Verification of Precipitation Forecasts from NCEP’s Short-Range Ensemble Forecast (SREF) System with Reference to Ensemble Streamflow Prediction Using Lumped Hydrologic Models.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1175/JHM-D-11-036.1},
}

@Article{Reggiani2009,
  author    = {P. Reggiani and M. Renner and A. H. Weerts and P. A. H. J. M. van Gelder},
  title     = {Uncertainty assessment via Bayesian revision of ensemble streamflow predictions in the operational river Rhine forecasting system},
  journal   = {Water Resources Research},
  year      = {2009},
  volume    = {45},
  abstract  = {Ensemble streamflow forecasts obtained by using hydrological models with ensemble
weather products are becoming more frequent in operational flow forecasting. The
uncertainty of the ensemble forecast needs to be assessed for these products to become
useful in forecasting operations. A comprehensive framework for Bayesian revision has
been recently developed and applied to operational flood forecasting with deterministic
weather forecasts. The Bayesian revision yields a posterior density, conditional on all
information available to the forecaster at the onset of a forecast run. This conditional
density objectively quantifies the uncertainty. Here the Bayesian approach is generalized
for use with ensemble weather predictions. An end-to-end application of a Bayesian
postprocessor for ensemble streamflow forecasts in the river Rhine forecasting system is
presented. A verification of the postprocessor shows good performance when compared
in terms of the ranked probability skill score to non-Bayesian uncertainty assessment, such
as ranking threshold exceedance probabilities for members of a streamflow ensemble
prediction. In this context it is also addressed how the proposed Bayesian processor can
serve in supporting rational decision making for flood warning under conditions of
uncertainty.},
  file      = {:Ensembles\\Uncertainty assessment via Bayesian revision of ensemble streamflow predictions in the operational river Rhine forecasting system.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Regonda2006,
  author    = {Satish Kumar Regonda and Balaji Rajagopalan and Martyn Clark and Edith Zagona},
  title     = {A multimodel ensemble forecast framework: Application to spring seasonal flows in the Gunnison River Basin},
  journal   = {Water Resources Research},
  year      = {2006},
  volume    = {42},
  abstract  = {We propose a multimodel ensemble forecast framework for streamflow forecasts at
multiple locations that incorporates large-scale climate information. It has four broad
steps: (1) Principal component analysis is performed on the spatial streamflows to identify
the dominant modes of variability. (2) Potential predictors of the dominant streamflow
modes are identified from several large-scale climate features and snow water equivalent
information. (3) Objective criterion is used to select a suite of candidate nonlinear
regression models each with different predictors. (4) Ensemble forecasts of the dominant
streamflow modes are generated from the candidate models and are combined objectively
to produce a multimodel ensemble, which are then back transformed to produce spatially
coherent streamflow forecasts at all the locations. The utility of the framework is
demonstrated in the skillful forecast of spring seasonal streamflows at six locations in the
Gunnison River Basin at several lead times. The generated ensemble streamflow forecast
provides valuable and useful information for optimal management and planning of water
resources in the basin.},
  file      = {:Ensembles\\A multimodel ensemble forecast framework- Application to spring seasonal flows in the Gunnison River Basin.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Bracken2010,
  author    = {Cameron Bracken and Balaji Rajagopalan and James Prairie},
  title     = {A multisite seasonal ensemble streamflow forecasting technique},
  journal   = {Water Resources Research},
  year      = {2010},
  volume    = {46},
  abstract  = {We present a technique for providing seasonal ensemble streamflow forecasts at
several locations simultaneously on a river network. The framework is an integration of
two recent approaches: the nonparametric multimodel ensemble forecast technique and the
nonparametric space‐time disaggregation technique. The four main components of the
proposed framework are as follows: (1) an index gauge streamflow is constructed as the
sum of flows at all the desired spatial locations; (2) potential predictors of the spring
season (April–July) streamflow at this index gauge are identified from the large‐scale
ocean‐atmosphere‐land system, including snow water equivalent; (3) the multimodel
ensemble forecast approach is used to generate the ensemble flow forecast at the index
gauge; and (4) the ensembles are disaggregated using a nonparametric space‐time
disaggregation technique resulting in forecast ensembles at the desired locations and for all
the months within the season. We demonstrate the utility of this technique in skillful
forecast of spring seasonal streamflows at four locations in the Upper Colorado River
Basin at different lead times. Where applicable, we compare the forecasts to the Colorado
Basin River Forecast Center’s Ensemble Streamflow Prediction (ESP) and the National
Resource Conservation Service “coordinated” forecast, which is a combination of the ESP,
Statistical Water Supply, a principal component regression technique, and modeler
knowledge. We find that overall, the proposed method is equally skillful to existing
operational models while tending to better predict wet years. The forecasts from this
approach can be a valuable input for efficient planning and management of water resources
in the basin.},
  file      = {:Ensembles\\A multisite seasonal ensemble streamflow forecasting technique.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Hashino2006,
  author    = {T. Hashino and A. A. Bradley and S. S. Schwartz},
  title     = {Evaluation of bias-correction methods for ensemble},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2006},
  volume    = {3},
  pages     = {561-594},
  abstract  = {Ensemble prediction systems are used operationally to make probabilistic streamflow
forecasts for seasonal time scales. However, hydrological models used for ensemble streamflow prediction often have simulation biases that degrade forecast quality
5 and limit the operational usefulness of the forecasts. This study evaluates three biascorrection methods for ensemble streamflow volume forecasts. All three adjust the
ensemble traces using a transformation derived with simulated and observed flows
from a historical simulation. The quality of probabilistic forecasts issued when using
the three bias-correction methods is evaluated using a distributions-oriented verifica-
10 tion approach. Comparisons are made of retrospective forecasts of monthly flow volumes for the Des Moines River, issued sequentially for each month over a 48-year
record. The results show that all three bias-correction methods significantly improve
forecast quality by eliminating unconditional biases and enhancing the potential skill.
Still, subtle differences in the attributes of the bias-corrected forecasts have important
15 implications for their use in operational decision-making. Diagnostic verification distinguishes these attributes in a context meaningful for decision-making, providing criteria
to choose among bias-correction methods with comparable skill.},
  file      = {:Ensembles\\Evaluation of bias-correction methods for ensemble streamflow volume forecasts.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Vrugt2006,
  author    = {Jasper A. Vrugt and Hoshin V. Gupta and Breanndán Ó Nualláin and Willem Bouten},
  title     = {Real-Time Data and Assimilation for Operational and Ensemble Streamflow and Forecasting},
  journal   = {Journal of Hydrometeorology},
  year      = {2006},
  volume    = {7},
  abstract  = {Operational flood forecasting requires that accurate estimates of the uncertainty associated with modelgenerated streamflow forecasts be provided along with the probable flow levels. This paper demonstrates
a stochastic ensemble implementation of the Sacramento model used routinely by the National Weather
Service for deterministic streamflow forecasting. The approach, the simultaneous optimization and data
assimilation method (SODA), uses an ensemble Kalman filter (EnKF) for recursive state estimation allowing for treatment of streamflow data error, model structural error, and parameter uncertainty, while
enabling implementation of the Sacramento model without major modification to its current structural
form. Model parameters are estimated in batch using the shuffled complex evolution metropolis stochasticensemble optimization approach (SCEM-UA). The SODA approach was implemented using parallel computing to handle the increased computational requirements. Studies using data from the Leaf River, Mississippi, indicate that forecast performance improvements on the order of 30% to 50% can be realized even
with a suboptimal implementation of the filter. Further, the SODA parameter estimates appear to be less
biased, which may increase the prospects for finding useful regionalization relationships.},
  file      = {:Ensembles\\Real-Time Data Assimilation for Operational Ensemble Streamflow Forecasting.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Day1985,
  author    = {Gerald N . Day},
  title     = {Extended Streamflow Forecasting Using NWSRFS},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {1985},
  volume    = {111},
  number    = {2},
  pages     = {157-170},
  abstract  = {Extended forecasting using the National Weather Service River
Forecast System (NWSRFS) is done with the NWS Extended Streamflow Pre-
diction (ESP) program. This paper examines the theory, capabilities, and po-
tential applications of the ESP procedure. ESP uses conceptual hydrologic/hy-
draulic models to forecast future streamflow using. the current snow, soil 
moisture, river, and reservoir conditions with historical meteorological data. 
The ESP procedure assumes that meteorological events that occurred in the 
past are representative of events that may occur in the future. Each year of 
historical meteorological data is assumed to be a possible representation of the 
future and is used to simulate a streamflow trace. The simulated streamflow 
traces can be scanned for maximum flow, minimum flow, volume of flow, res-
ervoir stage, etc., for any period in the future. ESP produces a probabilistic 
forecast for each streamflow variable and period of interest. The procedure was 
originally developed for water supply forecasting in snowmelt areas, but it can 
also be used to produce spring flood outlooks, forecasts for navigation, inflow 
hydrographs for reservoir operation, and time series needed for risk analysis 
during droughts.},
  file      = {:Ensembles\\Extended Streamflow Forecasting Using NWSRFS.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Smith1992,
  author    = {J. A. Smith and G. N. Day and M. D. Kane},
  title     = {Nonparametric Framework for Long-range Streamflow Forecasting},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {1992},
  volume    = {118},
  number    = {1},
  pages     = {82--92},
  abstract  = {The extended streamflow prediction (ESP) procedure of the National
Weather Service River Forecast System (NWSRFS) produces long-range forecasts 
of streamflow through the use of hydrologic models and historical hydrologic data. 
An important element of the ESP procedure is converting hydrologic-model output 
to estimates of a forecast random variable. In this paper, nonparametric statistical 
procedures are developed for combining hydrologic models and historical hydro-
logic data into long-range streamflow forecasts. Although these procedures are 
developed for use within the ESP system, they should be broadly applicable to 
problems of long-range streamflow forecasting. Two notable features of the pro-
cedures developed in this paper are: (1) Climate information is easily incorporated; 
and (2) hydrologic-model errors can be accommodated. Results are presented for 
a test implementation of ESP for a basin in the southeastern United States during 
the severe drought period of 1988. The relative importance of climate information 
and soil moisture information for long-range streamflow forecasting is compared 
and contrasted.},
  file      = {:Ensembles\\Nonparametric Framework for Long‐range Streamflow Forecasting.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{You2008,
  author        = {Jiing-Yun You and Ximing Cai},
  title         = {Determining forecast and decision horizons for reservoir operations under hedging policies},
  journal       = {Water Resources Research},
  year          = {2008},
  volume        = {44},
  __markedentry = {[quebbs:1]},
  abstract      = {Hedging policies for reservoir operations makes a small deficit in current supply to
reduce the probability of a severe water shortage in the future. One of the critical
questions for hedging research is how long the forecast period should be so that reliable
inflow forecast in the period can be used for decision making under hedging. Decision
makers always hope to look further into the future; however, the longer the forecast
period, the more uncertain and less reliable the involved information, which will have a
diminishing influence on decision making. For dynamic reservoir operation optimization
models, the decision horizon (DH) may be defined as the initial periods in which
decisions are not affected by forecast data beyond a certain period, defined as the
forecast horizon (FH). This paper determines FH with given DH for dynamic reservoir
operation problems through both theoretical and numerical analysis. We use order of
magnitude analysis and numerical modeling to identify the impact of various factors
such as water stress level (the deficit between water availability and demand), reservoir
size, inflow uncertainty, evaporation rate, and discount rate. Three types of inflow time
series are used: stationary, nonstationary with seasonality, and random walk. Results
show that inflow characteristics and reservoir capacity have major impacts on FH when
water stress is modest; larger reservoir capacity and the deterministic component of
inflow such as seasonality require a longer FH. Economic factors have strong impacts
when water stress levels are high.},
  file          = {:Ensembles\\Determining forecast and decision horizons for reservoir operations under hedging policies.pdf:PDF},
  timestamp     = {2016-10-25},
}

@Article{Ding2015,
  author    = {Wei Ding and Chi Zhang and Yong Peng and Ruijie Zeng and Huicheng Zhou and Ximing Cai},
  title     = {An analytical framework for flood water conservation considering forecast uncertainty and acceptable risk},
  journal   = {Water Resources Research},
  year      = {2015},
  volume    = {51},
  number    = {6},
  pages     = {4702--4726},
  month     = {jun},
  abstract  = {This paper addresses how much flood water can be conserved for use after the flood season
through the operation of reservoir by taking into account the residual flood control capacity (the difference
between flood conveyance capacity and the expected inflow in a lead time). A two-stage model for
dynamic control of the flood-limited water level (the maximum allowed water level during the flood season,
DC-FLWL) is established considering forecast uncertainty and acceptable flood risk. It is found that DC-FLWL
is applicable when the reservoir inflow ranges from small to medium levels of the historical records, while
both forecast uncertainty and acceptable risk in the downstream affect the feasible space of DC-FLWL. As
forecast uncertainty increases (under a given risk level) or as acceptable risk level decreases (under a given
forecast uncertainty level), the minimum required safety margin for flood control increases, and the chance
for DC-FLWL decreases. The derived hedging rules from the modeling framework illustrate either the dominant role of water conservation or flood control or the trade-off between the two objectives under different
levels of forecast uncertainty and acceptable risk. These rules may provide useful guidelines for conserving
water from flood, especially in the area with heavy water stress. The analysis is illustrated via a case study
with a real-world reservoir in northeastern China.},
  doi       = {10.1002/2015wr017127},
  file      = {:Ensembles\\An analytical framework for flood water conservation considering forecast uncertainty and acceptable risk.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1002/2015WR017127},
}

@Article{Zhao2012a,
  author        = {Tongtiegang Zhao and Dawen Yang and Ximing Cai and Jianshi Zhao and Hao Wang},
  title         = {Identifying effective forecast horizon for real-time reservoir operation under a limited inflow forecast},
  journal       = {Water Resources Research},
  year          = {2012},
  volume        = {48},
  __markedentry = {[quebbs:1]},
  abstract      = {The use of a streamflow forecast for real-time reservoir operation is constrained by
forecast uncertainty (FU) and limited forecast horizon (FH). The effects of the two factors
are complicating since increasing the FH usually provides more information for decision
making in a longer time framework but with increasing uncertainty, which offsets the
information gain from a longer FH. This paper illustrates the existence of an effective FH
(EFH) with a given forecast, which balances the effects of the FH and FU and provides the
maximum information for reservoir operation decision making. With the assumption of a
concave objective function, a monotonic relationship between current operation decision
and ending storage is derived. Metrics representing the error resulting from a limited
forecast relative to a perfect forecast are defined to evaluate reservoir performance.
Procedures to analyze the complicating effect of FU and FH and to identify EFH are
proposed. Results show that: (1) when FH is short, FH is the dominating factor for
determining reservoir operation, and reservoir performance exhibits a quick improvement as
FH increases; (2) when FH is long, the inflow information may be too uncertain to guide
reservoir operation decisions and FU becomes the dominating factor; and (3) at a medium
FH, reservoir performance depends on the complicating effects of FU and FH and EFH
locates with a certain balanced level of FU and FH. The statistical characteristics of EFH
are illustrated with case studies with deterministic forecast and ensemble forecast.
Moreover, the impacts of temporal correlation of FU, inflow variability, evaporation loss,
and reservoir capacity on EFH are explored.},
  file          = {:Ensembles\\Identifying effective forecast horizon for real-time reservoir operation under a limited inflow forecast.pdf:PDF},
  timestamp     = {2016-11-01},
}

@Article{Anghileri2016,
  author        = {D. Anghileri and N. Voisin and A. Castelletti and F. Pianosi and B. Nijssen and D. P. Lettenmaier},
  title         = {Value of long-term streamflow forecasts to reservoir operations for water supply in snow-dominated river catchments},
  journal       = {Water Resources Research},
  year          = {2016},
  volume        = {52},
  number        = {6},
  pages         = {4209--4225},
  month         = {jun},
  __markedentry = {[quebbs:1]},
  abstract      = {We present a forecast-based adaptive management framework for water supply reservoirs and
evaluate the contribution of long-term inflow forecasts to reservoir operations. Our framework is developed
for snow-dominated river basins that demonstrate large gaps in forecast skill between seasonal and
inter-annual time horizons. We quantify and bound the contribution of seasonal and inter-annual forecast
components to optimal, adaptive reservoir operation. The framework uses an Ensemble Streamflow
Prediction (ESP) approach to generate retrospective, one-year-long streamflow forecasts based on the Variable Infiltration Capacity (VIC) hydrology model. We determine the optimal sequence of daily release decisions using the Model Predictive Control (MPC) optimization scheme. We then assess the forecast value by
comparing system performance based on the ESP forecasts with the performances based on climatology
and perfect forecasts. We distinguish among the relative contributions of the seasonal component of the
forecast versus the inter-annual component by evaluating system performance based on hybrid forecasts,
which are designed to isolate the two contributions. As an illustration, we first apply the forecast-based
adaptive management framework to a specific case study, i.e., Oroville Reservoir in California, and we then
modify the characteristics of the reservoir and the demand to demonstrate the transferability of the findings
to other reservoir systems. Results from numerical experiments show that, on average, the overall ESP value
in informing reservoir operation is 35% less than the perfect forecast value and the inter-annual component
of the ESP forecast contributes 20–60% of the total forecast value.},
  doi           = {10.1002/2015wr017864},
  file          = {:Ensembles/Value of long-term streamflow forecasts to reservoir operations for water supply in snow-dominated river catchments.pdf:PDF;:Programs\\MODSIM\\Integration of hydrologic and water allocation models in basinscale water resources management considering crop pattern and climate change- Karkheh River Basin in Iran.pdf:PDF},
  publisher     = {Wiley-Blackwell},
  timestamp     = {2016-10-25},
  url           = {http://dx.doi.org/10.1002/2015WR017864},
}

@Article{You2013,
  author        = {Gene Jiing-Yun You and Cheng-Wei Yu},
  title         = {Theoretical error convergence of limited forecast horizon in optimal reservoir operating decisions},
  journal       = {Water Resources Research},
  year          = {2013},
  volume        = {49},
  __markedentry = {[quebbs:1]},
  abstract      = {This study proposes a method of analyzing the error bound of optimal reservoir
operation based on an inflow forecast with a limited horizon. This is a practical approach to
real-world applications because current weather forecasts and climate predictions cannot
necessarily achieve the ‘‘perfect forecast’’ required for optimal solutions. This study
proposes a method to measure the error and error bound according to terminal stage
boundary conditions, for which a theoretical convergence rate is derived. Our results
suggest that convergence can be attained at a rate faster than the inverse of the extension of
the study horizon. This demonstrates that the application of rolling horizons can improve
the quality of decision making by exploiting available forecasts/information. When a
perfect forecast is unavailable, the rolling decision procedure with regularly updated
forecast information could help to avoid serious losses due to shortsighted policies.},
  file          = {:Ensembles\\Theoretical error convergence of limited forecast horizon in optimal reservoir operating decisions.pdf:PDF},
  timestamp     = {2016-10-25},
}

@Article{Eum2010,
  author    = {Hyung-Il Eum and Young-Oh Kim},
  title     = {The value of updating ensemble streamflow prediction in reservoir operations},
  journal   = {Hydrological Processes},
  year      = {2010},
  volume    = {24},
  number    = {20},
  pages     = {2888--2899},
  month     = {sep},
  abstract  = {This study proposes a new monthly ensemble streamflow prediction (ESP) forecasting system that can update the ESP in
the middle of a month to reflect the meteorological and hydrological variations during that month. The reservoir operating
policies derived from a sampling stochastic dynamic programming model using ESP scenarios updated three times a month
were applied to the Geum River basin to measure the value of updated ESP for 21 years with 100 initial storage combinations.
The results clearly demonstrate that updating the ESP scenario improves the accuracy of the forecasts and consequently their
operational benefit. This study also proves that the accuracy of the ESP scenario, particularly when high flows occur, has a
considerable effect on the reservoir operations.},
  doi       = {10.1002/hyp.7702},
  file      = {:Ensembles\\The value of updating ensemble streamflow prediction in reservoir operations.pdf:PDF},
  keywords  = {ensemble streamflow prediction; sampling stochastic dynamic programming; forecast accuracy; reservoir operations},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1002/hyp.7702},
}

@Article{Alemu2011,
  author    = {Eset T. Alemu and Richard N. Palmer and Austin Polebitski and Bruce Meaker},
  title     = {Decision Support System for Optimizing Reservoir Operations Using Ensemble Streamflow Predictions},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2011},
  volume    = {137},
  number    = {1},
  pages     = {72-82},
  abstract  = {This paper investigates the value of ensemble streamflow predictions and energy price forecasts as aid to decision makers in
scheduling the quantity and timing of reservoir releases for daily, weekly, and seasonal operations while meeting regulatory constraints.
A decision support system DSS is described as it incorporates two integrated models of system operation: a simulation model that
replicates general operating rules for the hydropower system and an optimization model that refines operations based upon forecasts of
state variables. The DSS provides a series of recommendations for the quantity and timing of reservoir releases to optimize the economic
value of the electrical energy produced, while balancing requirements and concerns related to flood control, environmental flows, and
water supply. The DSS generates a range of optimal reservoir releases using an ensemble streamflow forecast and identifies robust
operational solutions. The results indicate the value of the forecasts in improving system operation.},
  file      = {:Ensembles\\Decision Support System for Optimizing Reservoir Operations Using Ensemble Streamflow Predictions.pdf:PDF},
  keywords  = {Decision support systems; Hydropower; Reservoir operation; Simulation; Optimization; Forecasts},
  timestamp = {2016-10-25},
}

@Article{Cote2016,
  author    = {Pascal Côté and Robert Leconte},
  title     = {Comparison of Stochastic Optimization Algorithms for Hydropower Reservoir Operation with Ensemble Streamflow Prediction},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2016},
  volume    = {142},
  number    = {2},
  abstract  = {Stochastic optimization methods have been developed over the last few decades to help water managers who are regularly
confronted with making complex decisions about reservoir releases in the context of streamflow uncertainties. However, a comparative
evaluation of the performance of the methods in an operational context is not an easy task, which makes it difficult to select the approach
that offers the best performance. This paper presents a comparison between four optimization algorithms in a test bed in which ensemble
streamflow predictions (ESPs) are updated each time a decision is taken. The comparison was performed on the Rio Tinto Alcan (RTA)
hydropower system in Québec, Canada, which consists of six generating stations in series and three major reservoirs. The tested optimization
algorithms are the deterministic optimization approach currently used by RTA and three explicit stochastic optimization approaches,
i.e., stochastic dynamic programming, sampling stochastic dynamic programming, and a scenario tree approach. The results showed that
methods on the basis of scenarios prove superior to methods on the basis of probability distributions. Moreover, using an anticipative
deterministic approach to calculate the release decisions for the first period was found to be an inadequate strategy. Artificially introducing
underdispersion in ESPs was also found to affect the quality of the results, and the optimization methods were affected differently. Given that
hydrological dispersion will likely differ in the future as a consequence of climate change, further evaluation of optimization techniques
should be carried out before selecting approaches that best meet managers’ needs in a climate change context.},
  file      = {:Ensembles\\Comparison of Stochastic Optimization Algorithms for Hydropower Reservoir Operation with Ensemble Streamflow Prediction.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Tao2014,
  author    = {Yumeng Tao and Qingyun Duan and Aizhong Ye and Wei Gong and Zhenhua Di and Mu Xiao and Kuolin Hsu},
  title     = {An evaluation of post-processed {TIGGE} multimodel ensemble precipitation forecast in the Huai river basin},
  journal   = {Journal of Hydrology},
  year      = {2014},
  volume    = {519},
  pages     = {2890--2905},
  month     = {nov},
  abstract  = {This paper evaluates how post-processing can enhance raw precipitation forecasts made by different
numerical weather prediction (NWP) models archived in TIGGE (THORPEX Interactive Grand Global
Ensemble) database. Ensemble Pre-Processor (EPP), developed at U.S. National Weather Service, is used
to post-process raw precipitation forecasts. EPP involves several major steps: (1) deriving the joint distributions of raw forecasts and observations corresponding to different canonical events; (2) obtaining
the probability distributions of observations given the raw forecasts; and (3) constructing ensemble forecasts from the conditional probability distributions given the raw forecasts. Raw precipitation forecasts
from five NWP models (CMA, ECMWF, JMA, NCEP and UKMO) during the summer-fall period (rainy season) from 2007 to 2011 were evaluated over the Huai river basin in China. The lead time for the precipitation forecasts is set to 9 days, which are divided into 11 canonical events (defined as daily precipitation
events or aggregate precipitation events over a period of several consecutive days). Our experiments
show that post-processed precipitation forecasts shows substantial improvement over the raw forecasts.
Post-processing reduces both the biases and the root mean squared error of the raw forecasts significantly. In terms of ensemble spread, both the Brier skill scores and continuous ranked probability skill
score are improved appreciably after post-processing. Reliability diagrams and rank histograms also confirm that post-processed ensemble forecasts possess better ensemble spread property compared to the
raw forecasts. Among the five NWP models, ECMWF and JMA have the best overall performance in both
raw and post-processed forecasts. The raw and post-processed UKMO and NCEP forecasts outperform
other models in certain events. Post-processing can improve the CMA raw forecasts substantially, but still
its performance is consistently worse than that of the other models.},
  doi       = {10.1016/j.jhydrol.2014.04.040},
  file      = {:Ensembles\\An evaluation of post-processed TIGGE multimodel ensemble precipitation forecast in the Huai river basin.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2014.04.040},
}

@Article{Alfieri2012,
  author    = {Lorenzo Alfieri and Peter Salamon and Florian Pappenberger and Fredrik Wetterhall and Jutta Thielen},
  title     = {Operational early warning systems for water-related hazards in {Europe}},
  journal   = {Environmental Science {\&} Policy},
  year      = {2012},
  volume    = {21},
  pages     = {35--49},
  month     = {aug},
  abstract  = {Preparedness towards natural hazards is a key factor in the reduction of their impact on the
society. Recent international initiatives are fostering the development of a culture of risk
prevention and the promotion of early warning systems. Numerical weather predictions
have become the basis of several flood-related warning systems, enabling the detection of
hazardous events with sufficient lead-time to prepare effective emergency and response
plans. The objective of this paper is to review current European operational warning
systems for water-related hazards induced by severe weather conditions. In details, it
includes systems for detecting surface water flooding, flash floods, debris flows, mud flows,
rainfall-induced landslides, river floods and coastal floods. Technical features and capabilities of different systems are described, together with some noteworthy examples. The main
strengths of each system type are highlighted and suggestions are provided for developing
and further improving their overall skills in hazard detection and the mutual coordination.},
  doi       = {10.1016/j.envsci.2012.01.008},
  file      = {:Ensembles\\Operational early warning systems for water-related hazards in Europe.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.envsci.2012.01.008},
}

@Article{Dong2006,
  author    = {X. Dong and C. M. Dohmen-Janssen and M. Booij and S. Hulscher},
  title     = {Effect of flow forecasting quality on benefits of reservoir operation – a case study for the Geheyan reservoir (China)},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2006},
  volume    = {3},
  pages     = {3771--3814},
  abstract  = {This paper presents a methodology to determine the effect of flow forecasting quality on the benefits of reservoir operation. The benefits are calculated in terms of the
electricity generated, and the quality of the flow forecasting is defined in terms of lead
5 time and accuracy of the forecasts. In order to determine such an effect, an optimization model for reservoir operation was developed which consists of two sub-models: a
long-term (monthly) and a short-term (daily) optimization sub-model. A methodology
was developed to couple these two sub-models, so that both short-term benefits (time
span in the order of the flow forecasting lead time) and long-term benefits (one year)
10 were considered and balanced. Both sub-models use Discretized Dynamic Programming (DDP) as their optimization algorithms. The Geheyan reservoir on the Qingjiang
River in China was taken as case study. Observed (from the 1997 hydrological year)
and forecasted flow series were used to calculate the benefits. Forecasted flow series were created by adding noises to the observed series. Different magnitudes of
15 noise reflected different levels of forecasting accuracies. The results reveal, first of all,
a threshold lead time of 33 days, beyond which further extension of the forecasting
lead time will not lead to a significant increase in benefits. Secondly, for lead times
shorter than 33 days, a longer lead time will generally lead to a higher benefit. Thirdly,
a perfect inflow forecasting with a lead time of 4 days will realize 87% of the theoreti-
20 cal maximum electricity generated in one year. Fourthly, for a certain lead time, more
accurate forecasting leads to higher benefits. For inflow forecasting with a fixed lead
time of 4 days and different forecasting accuracies, the benefits can increase by 5 to
9% compared to the actual operation results. It is concluded that the definition of the
appropriate lead time will depend mainly on the physical conditions of the basin and on
25 the characteristics of the reservoir. The derived threshold lead time (33 days) gives a
theoretical upper limit for the extension of forecasting lead time. Criteria for the appropriate forecasting accuracy for a specific feasible lead-time should be defined from the
benefit-accuracy relationship, starting from setting a preferred benefit level, in terms
3772
HESSD
3, 3771–3814, 2006
Effect of flow
forecasting quality
on benefits of
reservoir operation
X. Dong et al.
Title Page
Abstract Introduction
Conclusions References
Tables Figures
◭ ◮
◭ ◮
Back Close
Full Screen / Esc
Printer-friendly Version
Interactive Discussion
EGU
of percentage of the theoretical maximum. Inflow forecasting with a higher accuracy
does not always increase the benefits, because these also depend on the operation
strategies of the reservoir.},
  file      = {:Ensembles\\Effect of flow forecasting quality on benefits of reservoir operation - a case study for the Geheyan reservoir (China).pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Seo2006,
  author    = {D.-J. Seo and H. D. Herr and J. C. Schaake},
  title     = {A statistical post-processor for accounting of hydrologic uncertainty in short-range ensemble streamflow prediction},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2006},
  volume    = {3},
  pages     = {1987--2035},
  abstract  = {In addition to the uncertainty in future boundary conditions of precipitation and temper
ature (i.e. the meteorological uncertainty), parametric and structural uncertainties in
the hydrologic models and uncertainty in the model initial conditions (i.e. the hydrologic
5 uncertainties) constitute a major source of error in hydrologic prediction. As such, ac
curate accounting of both meteorological and hydrologic uncertainties is critical to pro
ducing reliable probabilistic hydrologic prediction. In this paper, we describe and eval
uate a statistical procedure that accounts for hydrologic uncertainty in short-range (1
to 5 days ahead) ensemble streamflow prediction (ESP). Referred to as the ESP post-
0 processor, the procedure operates on ensemble traces of model-predicted streamflow
that reflect only the meteorological uncertainty and produces post-processed ensemble
traces that reflect both the meteorological and hydrologic uncertainties. A combination
of probability matching and regression, the procedure is simple, parsimonious and ro
bust. For a critical evaluation of the procedure, independent validation is carried out for
5 five basins of the Juniata River in Pennsylvania, USA, under a very stringent setting.
The results indicate that the post-processor is fully capable of producing ensemble
traces that are unbiased in the mean and in the probabilistic sense. Due primarily
to the uncertainties in the cumulative probability distributions (CDF) of observed and
simulated flows, however, the unbiasedness may be compromised to a varying degree
0 in real world situations. It is also shown, however, that the uncertainties in the CDF’s
do not significantly diminish the value of post-processed ensemble traces for decision
making, and that probabilistic prediction based on post-processed ensemble traces
significantly improves the value of single-value prediction at all ranges of flow.},
  file      = {:Ensembles\\A statistical post-processor for accounting of hydrologic uncertainty in short-range ensemble streamflow prediciton.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Najafi2012,
  author    = {Mohammad Reza Najafi and Hamid Moradkhani and Thomas C. Piechota},
  title     = {Ensemble Streamflow Prediction: Climate signal weighting methods vs. Climate Forecast System Reanalysis},
  journal   = {Journal of Hydrology},
  year      = {2012},
  volume    = {442-443},
  pages     = {105--116},
  month     = {jun},
  abstract  = {Ensemble Streamflow Prediction (ESP) provides the means for statistical post-processing of forecasts and
estimating the inherent uncertainties. In addition, large scale climate variables provide valuable information for hydrologic predictions. In this study we develop methods to assign weights to ESP ensemble
members according to climate signals which are selected based on the spearman’s rank correlation coefficients. Analysis was performed over the snow dominated East River basin to improve the spring streamflow
volumetric forecast. Principle Component Analysis (PCA) was found to increase the accuracy of the weighting scheme considerably. We compare five parametric and nonparametric weighting methods including
Fuzzy C-Means clustering, Formal Likelihood, Informal Likelihood and two variants of K-Nearest Neighbors
approaches. The methods are found to be simple and efficient while the results seem promising. The predictions, based on simple average or the median of the ensemble members, combined with the weighted
ensemble forecasts provide improved estimates of probable streamflow ranges and the uncertainty bounds.
Improvement in the weighting approach was obtained by selecting the climate signals, choosing the right
number of principle components and considering several weighting approaches. As an alternative approach
to ESP, an additional climate dataset, the Climate Forecast System Reanalysis (CFSR) provided via the
National Centers for Environmental Prediction (NCEP) in its most recent reanalysis project was tested.},
  doi       = {10.1016/j.jhydrol.2012.04.003},
  file      = {:Ensembles\\Ensemble Streamflow Prediction- Climate signal weighting methods vs. Climate Forecast System Reanalysis.pdf:PDF},
  keywords  = {Ensemble Streamflow Prediction Climate signal PCA CFSR Post-processing},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2012.04.003},
}

@Article{Kang2010,
  author    = {Tae-Ho Kang and Young-Oh Kim and Il-Pyo Hong},
  title     = {Comparison of pre- and post-processors for ensemble streamflow prediction},
  journal   = {Atmospheric Science Letters},
  year      = {2010},
  volume    = {11},
  number    = {2},
  pages     = {153--159},
  month     = {jun},
  doi       = {10.1002/asl.276},
  file      = {:Ensembles\\Comparison of pre- and post-processors for ensemble streamflow prediction.pdf:PDF},
  keywords  = {ensemble streamflow prediction; probabilistic climate forecast; hydrologic model; pre-processor; post-processor; uncertainty},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1002/asl.276},
}

@Article{Ficchi2016,
  author    = {A. Ficchì and L. Raso and D. Dorchies and F. Pianosi and P.-O. Malaterre and P.-J. Van Overloop and M. Jay-Allemand},
  title     = {Optimal Operation of the Multireservoir System in the Seine River Basin Using Deterministic and Ensemble Forecasts},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2016},
  volume    = {142},
  number    = {1},
  abstract  = {This article investigates the improvement of the operation of a four-reservoir system in the Seine River basin, France, by use of
deterministic and ensemble weather forecasts and real-time control. In the current management, each reservoir is operated independently from
the others and following prescribed rule-curves, designed to reduce floods and sustain low flows under the historical hydrological conditions.
However, this management system is inefficient when inflows are significantly different from their seasonal average and may become even
more inadequate to cope with the predicted increase in extreme events induced by climate change. In this work, a centralized real-time control
system is developed to improve reservoirs operation by exploiting numerical weather forecasts that are becoming increasingly available. The
proposed management system implements a well-established optimization technique, model predictive control (MPC), and its recently modified version that can incorporate uncertainties, tree-based model predictive control (TB-MPC), to account for deterministic and ensemble
forecasts respectively. The management system is assessed by simulation over historical events and compared to the no-forecasts strategy
based on rule-curves. Simulation results show that the proposed real-time control system largely outperforms the no-forecasts management
strategy, and that explicitly considering forecast uncertainty through ensembles can compensate for the loss in performance due to forecast
inaccuracy.},
  file      = {:Ensembles\\Optimal Operation of the Multireservoir System in the Seine River Basin Using Deterministic and Ensemble Forecasts.pdf:PDF},
  timestamp = {2016-10-25},
}

@Article{Jeong2005,
  author    = {Dae-Il Jeong and Young-Oh Kim},
  title     = {Rainfall-runoff models using artificial neural networks for ensemble streamflow prediction},
  journal   = {Hydrological Processes},
  year      = {2005},
  volume    = {19},
  number    = {19},
  pages     = {3819--3835},
  abstract  = {Previous ensemble streamflow prediction (ESP) studies in Korea reported that modelling error significantly affects
the accuracy of the ESP probabilistic winter and spring (i.e. dry season) forecasts, and thus suggested that improving
the existing rainfall-runoff model, TANK, would be critical to obtaining more accurate probabilistic forecasts with
ESP. This study used two types of artificial neural network (ANN), namely the single neural network (SNN) and the
ensemble neural network (ENN), to provide better rainfall-runoff simulation capability than TANK, which has been
used with the ESP system for forecasting monthly inflows to the Daecheong multipurpose dam in Korea. Using the
bagging method, the ENN combines the outputs of member networks so that it can control the generalization error
better than an SNN. This study compares the two ANN models with TANK with respect to the relative bias and the
root-mean-square error. The overall results showed that the ENN performed the best among the three rainfall-runoff
models. The ENN also considerably improved the probabilistic forecasting accuracy, measured in terms of average hit
score, half-Brier score and hit rate, of the present ESP system that used TANK. Therefore, this study concludes that
the ENN would be more effective for ESP rainfall-runoff modelling than TANK or an SNN.},
  doi       = {10.1002/hyp.5983},
  file      = {:Ensembles\\Rainfall-runoff models using artificial neural networks for ensemble streamflow prediction.pdf:PDF},
  keywords  = {artificial neural networks; ensemble neural network; ensemble streamflow prediction; probabilistic forecasting; rainfall-runoff model},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1002/hyp.5983},
}

@Article{Alfieri2014,
  author    = {Lorenzo Alfieri and Florian Pappenberger and Fredrik Wetterhall and Thomas Haiden and David Richardson and Peter Salamon},
  title     = {Evaluation of ensemble streamflow predictions in {Europe}},
  journal   = {Journal of Hydrology},
  year      = {2014},
  volume    = {517},
  pages     = {913--922},
  month     = {sep},
  abstract  = {In operational hydrological forecasting systems, improvements are directly related to the continuous
monitoring of the forecast performance. An efficient evaluation framework must be able to spot issues
and limitations and provide feedback to the system developers. In regional systems, the expertise of analysts on duty is a major component of the daily evaluation. On the other hand, large scale systems need to
be complemented with semi-automated tools to evaluate the quality of forecasts equitably in every part
of their domain.
This article presents the current status of the monitoring and evaluation framework of the European
Flood Awareness System (EFAS). For each grid point of the European river network, 10-day ensemble
streamflow predictions are evaluated against a reference simulation which uses observed meteorological
fields as input to a calibrated hydrological model. Performance scores are displayed over different
regions, forecast lead times, basin sizes, as well as in time, considering average scores for moving 12-
month windows of forecasts. Skilful predictions are found in medium to large rivers over the whole
10-day range. On average, performance drops significantly in river basins with upstream area smaller
than 300 km2, partly due to underestimation of the runoff in mountain areas. Model limitations and recommendations to improve the evaluation framework are discussed in the final section.},
  doi       = {10.1016/j.jhydrol.2014.06.035},
  file      = {:Ensembles\\Evaluation of ensemble streamflow predictions in Europe.pdf:PDF},
  keywords  = {Keywords: Flood early warning Ensemble streamflow predictions CRPS Skill scores Distributed hydrological modelling},
  publisher = {Elsevier {BV}},
  timestamp = {2016-10-25},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2014.06.035},
}

@Article{Gobena2010,
  author    = {A.K. Gobena and T.Y. Gan},
  title     = {Incorporation of seasonal climate forecasts in the ensemble streamflow prediction system},
  journal   = {Journal of Hydrology},
  year      = {2010},
  volume    = {385},
  number    = {1-4},
  pages     = {336--352},
  month     = {may},
  abstract  = {A technique for incorporating 0–3 months lead temperature and precipitation forecasts from two Canadian numerical weather prediction (NWP) models into the ensemble streamflow prediction (ESP) system
is presented. The technique involves downscaling monthly NWP forecast outputs to station locations
using the model output statistics (MOS) approach and then temporally disaggregating the monthly forecasts into daily input weather data suitable for driving a hydrologic model. The daily weather sequence
for a desired month is generated by a nearest neighbor re-sampling of one of the years in the historical
record, and then modifying the daily weather data for the same month of the re-sampled year so as to
reproduce the MOS-based monthly forecast value. Streamflow forecasts from the MOS-based scheme
are compared to pre-ESP and post-ESP re-sampling schemes without seasonal climate forecast guidance.
In the pre-ESP scheme, daily weather inputs for the hydrologic model were conditionally re-sampled
from historical records. In the post-ESP scheme, streamflow traces produced by the climatic ESP system
were conditionally re-sampled. The three schemes were applied to the Bow and Castle rivers, both
located in the headwaters of the South Saskatchewan River basin in the province of Alberta, Canada. Correlations between the MOS-based median forecast and observed flow for the Castle River were consistently higher than those based on the pre-ESP and post-ESP schemes. Other skill measures showed
mixed results, with the MOS-based forecasts being more skillful in some cases and less skillful in others.
All three schemes exhibited better skill for above-normal flow categories than for below-normal categories. It is also shown that considerable improvement in the ESP forecast skill could be achieved through
more accurate simulation of streamflow, particularly for forecast issue dates late in the water year.},
  doi       = {10.1016/j.jhydrol.2010.03.002},
  file      = {:Ensembles\\Incorporation of seasonal climate forecasts in the ensemble streamflow prediction system.pdf:PDF},
  keywords  = {Streamflow forecasting Ensemble streamflow prediction Model output statistics K-nearest neighbors re-sampling Canada South Saskatchewan River basin},
  publisher = {Elsevier {BV}},
  timestamp = {2017-02-02},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2010.03.002},
}

@Article{Faber2001,
  author    = {B.A. Faber and J.R. Stedinger},
  title     = {Reservoir optimization using sampling SDP with ensemble streamflow prediction (ESP) forecasts},
  journal   = {Journal of Hydrology},
  year      = {2001},
  volume    = {249},
  pages     = {113-133},
  file      = {:Ensembles\\Reservoir optimization using sampling SDP with ensemble streamflow prediction (ESP) forecasts.pdf:PDF},
  keywords  = {dynamic programming, streamflow forecasting, reservoir operation, stochastic optimization},
  timestamp = {2016-10-25},
}

@Article{Rajagopalan2002,
  author    = {Balaji Rajagopalan and Upmanu Lall and Stephen E. Zebiak},
  title     = {Categorical Climate and Forecasts through Regularization and Optimal Combination and of and Multiple GCM and Ensembles},
  journal   = {Monthly Weather Review},
  year      = {2002},
  volume    = {130},
  pages     = {1792--1811},
  abstract  = {A Bayesian methodology is used to assess the information content of categorical, probabilistic forecasts of
specific variables derived from a general circulation model (GCM) forecast ensemble, and to combine a ‘‘prior’’
forecast (climatological probabilities of each category) with a categorical probabilistic forecast derived from a
GCM ensemble to develop posterior, or ‘‘regularized’’ categorical probabilities. The combination algorithm
assigns a weight to a particular model forecast and to climatology. The ratio of the sample likelihood of the
model based on the posterior categorical probabilities, to that based on climatological probabilities, computed
over the period of record of historical forecasts, provides a measure of the skill or information content of a
candidate model. The weight given to a GCM forecast serves as a secondary indicator of its information content.
Model weights are determined by maximizing the likelihood ratio. Results using the so-called ranked probability
skill score as an objective function are also obtained, and are found to be very similar to the likelihood-based
results.
The procedure is extended to the optimal combination of forecasts from multiple GCMs. An application of
the method is presented for global, seasonal precipitation and temperature forecasts in two different seasons,
based on 41 yr of observational and model simulation data. The multimodel combination skill is significantly
better than climatology skill in only a few regions of the globe, but is generally an improvement over individual
models, and over a simple average of forecasts from different models. Limitations and possible improvements
of the methodology are discussed.},
  file      = {:Ensembles\\Categorical Climate Forecasts through Regularization and Optimal Combination of Multiple GCM Ensembles.pdf:PDF},
  timestamp = {2016-10-26},
}

@Article{Wood2002,
  author    = {Andrew W. Wood and Edwin P. Maurer and Arun Kumar and Dennis P. Lettenmaier},
  title     = {Long-range experimental hydrologic forecasting for the eastern United States},
  journal   = {Journal of Geophysical Research},
  year      = {2002},
  volume    = {107},
  number    = {D20},
  abstract  = {We explore a strategy for long-range hydrologic forecasting that uses ensemble
climate model forecasts as input to a macroscale hydrologic model to produce runoff and
streamflow forecasts at spatial and temporal scales appropriate for water management.
Monthly ensemble climate model forecasts produced by the National Centers for
Environmental Prediction/Climate Prediction Center global spectral model (GSM) are bias
corrected, downscaled to 1/8 horizontal resolution, and disaggregated to a daily time
step for input to the Variable Infiltration Capacity hydrologic model. Bias correction is
effected by evaluating the GSM ensemble forecast variables as percentiles relative to the
GSM model climatology and then extracting the percentiles’ associated variable values
instead from the observed climatology. The monthly meteorological forecasts are then
interpolated to the finer hydrologic model scale, at which a daily signal that preserves the
forecast anomaly is imposed through resampling of the historic record. With the resulting
monthly runoff and streamflow forecasts for the East Coast and Ohio River basin, we
evaluate the bias correction and resampling approaches during the southeastern United
States drought from May to August 2000 and also for the El Nin ˜o conditions of December
1997 to February 1998. For the summer 2000 study period, persistence in anomalous
initial hydrologic states predominates in determining the hydrologic forecasts. In contrast,
the El Nin ˜o-condition hydrologic forecasts derive direction both from the climate model
forecast signal and the antecedent land surface state. From a qualitative standpoint the
hydrologic forecasting strategy appears successful in translating climate forecast signals to
hydrologic variables of interest for water management.},
  doi       = {10.1029/2001JD000659},
  file      = {:Ensembles\\Long-range experimental hydrologic forecasting for the eastern United States.pdf:PDF},
  timestamp = {2016-11-01},
}

@Article{Huisman2009,
  author    = {J.A. Huisman and L. Breuer and H. Bormann and A. Bronstert and B.F.W. Croke and H.-G. Frede and T. Gräff and L. Hubrechts and A.J. Jakeman and G. Kite and J. Lanini and G. Leavesley and D.P. Lettenmaier and G. Lindström and J. Seibert and M. Sivapalan and N.R. Viney and P. Willems},
  title     = {Assessing the impact of land use change on hydrology by ensemble modeling ({LUCHEM}) {III}: Scenario analysis},
  journal   = {Advances in Water Resources},
  year      = {2009},
  volume    = {32},
  number    = {2},
  pages     = {159--170},
  month     = {feb},
  doi       = {10.1016/j.advwatres.2008.06.009},
  file      = {:Ensembles\\Assessing-the-impact-of-land-use-change-on-hydrology-by-ensemble-modeling-LUCHEM-III-Scenario-analysis_2009_Advances-in-Water-Resources.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-08},
  url       = {http://dx.doi.org/10.1016/j.advwatres.2008.06.009},
}

@Article{Breuer2009,
  author    = {L. Breuer and J.A. Huisman and P. Willems and H. Bormann and A. Bronstert and B.F.W. Croke and H.-G. Frede and T. Gräff and L. Hubrechts and A.J. Jakeman and G. Kite and J. Lanini and G. Leavesley and D.P. Lettenmaier and G. Lindström and J. Seibert and M. Sivapalan and N.R. Viney},
  title     = {Assessing the impact of land use change on hydrology by ensemble modeling ({LUCHEM}). I: Model intercomparison with current land use},
  journal   = {Advances in Water Resources},
  year      = {2009},
  volume    = {32},
  number    = {2},
  pages     = {129--146},
  month     = {feb},
  doi       = {10.1016/j.advwatres.2008.10.003},
  file      = {:Ensembles\\Assessing the impact of land use change on hydrology by ensemble modeling (LUCHEM). I- Model intercomparison with current land use.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-08},
  url       = {http://dx.doi.org/10.1016/j.advwatres.2008.10.003},
}

@Article{Viney2009,
  author    = {Neil R. Viney and H. Bormann and L. Breuer and A. Bronstert and B.F.W. Croke and H. Frede and T. Gräff and L. Hubrechts and J.A. Huisman and A.J. Jakeman and G.W. Kite and J. Lanini and G. Leavesley and D.P. Lettenmaier and G. Lindström and J. Seibert and M. Sivapalan and P. Willems},
  title     = {Assessing the impact of land use change on hydrology by ensemble modelling ({LUCHEM}) {II}: Ensemble combinations and predictions},
  journal   = {Advances in Water Resources},
  year      = {2009},
  volume    = {32},
  number    = {2},
  pages     = {147--158},
  month     = {feb},
  doi       = {10.1016/j.advwatres.2008.05.006},
  file      = {:Ensembles\\Assessing-the-impact-of-land-use-change-on-hydrology-by-ensemble-modelling-LUCHEM-II-Ensemble-combinations-and-predictions_2009_Advances-in-Water-Reso.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-08},
  url       = {http://dx.doi.org/10.1016/j.advwatres.2008.05.006},
}

@Article{Bormann2009,
  author    = {H. Bormann and L. Breuer and T. Gräff and J.A. Huisman and B. Croke},
  title     = {Assessing the impact of land use change on hydrology by ensemble modelling ({LUCHEM}) {IV}: Model sensitivity to data aggregation and spatial (re-)distribution},
  journal   = {Advances in Water Resources},
  year      = {2009},
  volume    = {32},
  number    = {2},
  pages     = {171--192},
  month     = {feb},
  doi       = {10.1016/j.advwatres.2008.01.002},
  file      = {:Ensembles\\Assessing-the-impact-of-land-use-change-on-hydrology-by-ensemble-modelling-LUCHEM-IV-Model-sensitivity-to-data-aggregation-and-spatial-re-distribution.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-08},
  url       = {http://dx.doi.org/10.1016/j.advwatres.2008.01.002},
}

@Article{Seguin2016,
  author    = {Sara Seguin and Pascal Cote and Charles Audet},
  title     = {Self-Scheduling Short-Term Unit Commitment and Loading Problem},
  journal   = {{IEEE} Transactions on Power Systems},
  year      = {2016},
  volume    = {31},
  number    = {1},
  pages     = {133--142},
  month     = {jan},
  doi       = {10.1109/tpwrs.2014.2383911},
  file      = {:Optimization\\Self-Scheduling Short-Term Unit Commitment and Loading Problem.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp = {2016-11-08},
  url       = {http://dx.doi.org/10.1109/TPWRS.2014.2383911},
}

@Article{Arsenault2014,
  author    = {Richard Arsenault and Annie Poulin and Pascal Côté and and François Brissette},
  title     = {Comparison of Stochastic Optimization Algorithms in Hydrological Model Calibration},
  journal   = {Journal of Hydrologic Engineering},
  year      = {2014},
  volume    = {19},
  number    = {7},
  pages     = {1374--1384},
  abstract  = {Ten stochastic optimization methods—adaptive simulated annealing (ASA), covariance matrix adaptation evolution strategy
(CMAES), cuckoo search (CS), dynamically dimensioned search (DDS), differential evolution (DE), genetic algorithm (GA), harmony
search (HS), pattern search (PS), particle swarm optimization (PSO), and shuffled complex evolution–University of Arizona (SCE–UA)—
were used to calibrate parameter sets for three hydrological models on 10 different basins. Optimization algorithm performance was compared
for each of the available basin-model combinations. For each model-basin pair, 40 calibrations were run with the 10 algorithms. Results were
tested for statistical significance using a multicomparison procedure based on Friedman and Kruskal-Wallis tests. A dispersion metric was
used to evaluate the fitness landscape underlying the structure on each test case. The trials revealed that the dimensionality and general fitness
landscape characteristics of the model calibration problem are important when considering the use of an automatic optimization method. The
ASA, CMAES, and DDS algorithms were either as good as or better than the other methods for finding the lowest minimum, with ASA being
consistently among the best. The SCE–UA method performs better when the model complexity is reduced, whereas the opposite is true for
DDS. Convergence speed was also studied, and the same three methods (CMAES, DDS, and ASA) were shown to converge faster than the
other methods. The SCE–UA method converged nearly as fast as the best methods when the model with the smallest parameter space was
used but was not as worthy in the higher-dimension parameter space of the other models. Convergence speed has little impact on algorithm
efficiency. The methods offering the worst performance were DE, CS, GA, HS, and PSO, although they did manage to find good local minima
in some trials. However, the other available methods generally outperformed these algorithms.},
  file      = {:Optimization\\Comparison of Stochastic Optimization Algorithms in Hydrological Model Calibration.pdf:PDF},
  keywords  = {Hydrology; Model calibration; Stochastic optimization; Parameter search; Model complexity; Algorithm performance},
  timestamp = {2016-11-08},
}

@Article{Haguma2015,
  author    = {Didier Haguma and Robert Leconte and Stéphane Krau and Pascal Côté and François Brissette},
  title     = {Water Resources Optimization Method in the Context of Climate Change},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2015},
  volume    = {141},
  number    = {2},
  abstract  = {This paper describes a method for water resources optimization in the context of climate change. The method takes into account
the midterm variability or seasonality of inflows as well as the uncertainty in the climate change and resulting flows. The objective of the
optimization algorithm is to find a compromise between the long-term planning of water resources systems and the midterm operations for
optimum hydropower production. The proposed algorithm consists of the midterm dynamic programming formulation coupled with the use
of the expected value of the cost-to-go function between two consecutive long-term periods. Future climate projections and transition probabilities between projections represent the stochastic nature of inflows and the nonstationarity of climate. The performance of the method was
evaluated through the simulation of inflow projections for the Manicouagan River basin in Quebec, Canada. The results showed that the
algorithm was able to adapt the operating policy to the climate seasonality and climate change uncertainties in the optimization problem.},
  file      = {:Climate\\Water Resources Optimization Method in the Context of Climate Change.pdf:PDF},
  keywords  = {Climate change; Water resources system; Hydrologic regime; Operating policy},
  timestamp = {2016-11-08},
}

@TechReport{Seguin2016a,
  author      = {Sara Seguin and Charles Audet and Pascal Cote},
  title       = {Scenario tree modeling for stochastic and short-term hydropower operations planning},
  institution = {Rio Tinto},
  year        = {2016},
  abstract    = {The authors investigate the complexity needed in the structure of the scenario trees to maximize
energy production in a rolling-horizon framework. Three comparisons, applied to the stochastic short-term
unit commitment and loading problem are conducted. The first one involves generating a set of scenario
trees built from inflow forecast data over a rolling-horizon. The second replaces the entire set of scenario
trees by the median scenario. The third replaces the set of trees by scenario fans. The method used to build
scenario trees, based on minimization of the nested distance, requires three parameters: number of stages,
number of child nodes at each stage, and aggregation of the period covered by each stage. The authors
formulate the question of finding the best values of these parameters as a blackbox optimization problem
that maximizes the energy production over the rolling-horizon. Numerical experiments on three hydropower
plants in series suggest that using a set of scenario trees is preferable to using the median scenario, but using
a fan of scenarios yields a comparable solution with less computational effort},
  file        = {:Optimization\\Scenario tree modeling for stochastic short-term hydropower operations planning.pdf:PDF},
  keywords    = {Blackbox optimization, stochastic programming, short-term hydropower optimization, rollinghorizon, hydro unit commitment and loading problem},
  timestamp   = {2016-11-08},
}

@InProceedings{Anghileri2014,
  author    = {Anghileri, Daniela and Voisin, Nathalie and Castelletti, Andrea and Pianosi, Francesca and Nijssen, Bart and Lettenmaier, Dennis},
  title     = {Value of seasonal flow forecast to reservoir operation for water supply in snow-dominated catchments},
  booktitle = {EGU General Assembly Conference Abstracts},
  year      = {2014},
  volume    = {16},
  pages     = {14106},
  timestamp = {2016-11-10},
}

@Article{Cote2011,
  author    = {C{\^o}t{\'e}, Pascal and Haguma, Didier and Leconte, Robert and Krau, Stephane},
  title     = {Stochastic optimisation of Hydro-Quebec hydropower installations: a statistical comparison between SDP and SSDP methods},
  journal   = {Canadian Journal of Civil Engineering},
  year      = {2011},
  volume    = {38},
  number    = {12},
  pages     = {1427--1434},
  publisher = {NRC Research Press},
  timestamp = {2016-11-10},
}

@Article{Collischonn2007,
  author    = {Collischonn, Walter and Tucci, Carlos Eduardo Morelli and Clarke, Robin Thomas and Chou, Sin Chan and Guilhon, Luiz Guilherme and Cataldi, M{\'a}rcio and Allasia, Daniel},
  title     = {Medium-range reservoir inflow predictions based on quantitative precipitation forecasts},
  journal   = {Journal of hydrology},
  year      = {2007},
  volume    = {344},
  number    = {1},
  pages     = {112--122},
  publisher = {Elsevier},
  timestamp = {2016-11-10},
}

@Article{Fan2014,
  author    = {Fan, Fernando Mainardi and Collischonn, Walter and Meller, Adalberto and Botelho, Luiz C{\'e}sar Mendes},
  title     = {Ensemble streamflow forecasting experiments in a tropical basin: The S{\~a}o Francisco river case study},
  journal   = {Journal of Hydrology},
  year      = {2014},
  volume    = {519},
  pages     = {2906--2919},
  publisher = {Elsevier},
  timestamp = {2016-11-10},
}

@Article{Hirsch1981,
  author    = {Hirsch, Robert M},
  title     = {Stochastic hydrologic model for drought management},
  journal   = {Journal of the Water Resources Planning and Management Division},
  year      = {1981},
  volume    = {107},
  number    = {2},
  pages     = {303--313},
  publisher = {ASCE},
  timestamp = {2016-11-10},
}

@Article{Hirsch1978,
  author    = {Hirsch, Robert M},
  title     = {Risk analyses for a water supply system: Occoquan Reservoir, Fairfax and Prince William Counties, Virginia, USA/Des analyses al{\'e}atoires d'un syst{\`e}me d'approvisionnement en eau: Occoquan Reservoir, Fairfax et Prince William Counties, Virginia, USA},
  journal   = {Hydrological Sciences Journal},
  year      = {1978},
  volume    = {23},
  number    = {4},
  pages     = {475--505},
  file      = {:Statistics\\Risk analyses for a water supply system- Occoquan Reservoir, Fairfax and Prince William Counties, Virginia, USA.pdf:PDF},
  publisher = {Taylor \& Francis},
  timestamp = {2016-11-10},
}

@Article{Lima2010,
  author    = {Lima, Carlos HR and Lall, Upmanu},
  title     = {Climate informed monthly streamflow forecasts for the Brazilian hydropower network using a periodic ridge regression model},
  journal   = {Journal of hydrology},
  year      = {2010},
  volume    = {380},
  number    = {3},
  pages     = {438--449},
  publisher = {Elsevier},
  timestamp = {2016-11-10},
}

@Article{Mediero2007,
  author    = {Mediero, L and Garrote, L and Martin-Carrasco, F},
  title     = {A probabilistic model to support reservoir operation decisions during flash floods},
  journal   = {Hydrological sciences journal},
  year      = {2007},
  volume    = {52},
  number    = {3},
  pages     = {523--537},
  publisher = {Taylor \& Francis},
  timestamp = {2016-11-10},
}

@Article{Mishra2005,
  author    = {Mishra, A. K. and Desai, V. R.},
  title     = {Drought forecasting using stochastic models},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2005},
  volume    = {19},
  number    = {5},
  pages     = {326--339},
  abstract  = {Drought is a global phenomenon that occurs virtually in all landscapes causing significant damage both in natural environment and in human lives. Due to the random nature of contributing factors, occurrence and severity of droughts can be treated as stochastic in nature. Early indication of possible drought can help to set out drought mitigation strategies and measures in advance. Therefore drought forecasting plays an important role in the planning and management of water resource systems. In this study, linear stochastic models known as ARIMA and multiplicative Seasonal Autoregressive Integrated Moving Average (SARIMA) models were used to forecast droughts based on the procedure of model development. The models were applied to forecast droughts using standardized precipitation index (SPI) series in the Kansabati river basin in India, which lies in the Purulia district of West Bengal state in eastern India. The predicted results using the best models were compared with the observed data. The predicted results show reasonably good agreement with the actual data, 1--2 months ahead. The predicted value decreases with increase in lead-time. So the models can be used to forecast droughts up to 2 months of lead-time with reasonably accuracy.},
  doi       = {10.1007/s00477-005-0238-4},
  file      = {:Hydrology\\Drought forecasting using stochastic models.pdf:PDF},
  issn      = {1436-3259},
  timestamp = {2016-11-15},
  url       = {http://dx.doi.org/10.1007/s00477-005-0238-4},
}

@Article{Stedinger2014,
  author    = {Stedinger, Jery R and Tan, Sue Nee and Shoemaker, Christine A and Lamontagne, Jonathan R and Barton, Steven B},
  title     = {Short-Term Optimization Model With ESP Forecasts For Columbia Hydropower System With Optimized Multi-Turbine Powerhouses},
  year      = {2014},
  timestamp = {2016-11-10},
}

@Article{Hadka2013,
  author    = {David Hadka and Patrick Reed},
  title     = {Borg: An Auto-Adaptive Many-Objective Evolutionary Computing Framework},
  journal   = {Evolutionary Computation},
  year      = {2013},
  volume    = {21},
  number    = {2},
  note      = {This is the algorithm used in ExplorerDV https://www.decisionvis.com/explorerdv/},
  abstract  = {This study introduces the Borg multi-objective evolutionary algorithm (MOEA) for many-objective, multimodal optimization. The Borg MOEA combines -dominance, a measure of convergence speed named -progress, randomized restarts, and auto-adaptive multioperator recombination into a unified optimization framework. A comparative study on 33 instances of 18 test problems from the DTLZ, WFG, and CEC 2009 test suites demonstrates Borg meets or exceeds six state of the art MOEAs on the majority of the tested problems. The performance for each test problem is evaluated using a 1,000 point Latin hypercube sampling of each algorithm's feasible parameteri- zation space. The statistical performance of every sampled MOEA parameterization is evaluated using 50 replicate random seed trials. The Borg MOEA is not a single algorithm; instead it represents a class of algorithms whose operators are adaptively selected based on the problem. The adaptive discovery of key operators is of particular importance for benchmarking how variation operators enhance search for complex many-objective problems.},
  file      = {:Optimization\\Borg- An Auto-Adaptive Many-Objective Evolutionary Computing Framework.pdf:PDF},
  keywords  = {Evolutionary algorithm, multiobjective optimization, many-objective optimization, multimodal problems, epsilon-dominance},
  timestamp = {2016-11-15},
}

@Article{Hadka2015,
  author    = {David Hadka and Jonathan Herman and Patrick Reed and Klaus Keller},
  title     = {An open source framework for many-objective robust decision making},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2015},
  volume    = {74},
  pages     = {114--129},
  month     = {dec},
  note      = {Borg MOEA},
  abstract  = {This study introduces a new open source software framework to support bottom-up environmental systems planning under deep uncertainty with a focus on many-objective robust decision making (MORDM), called OpenMORDM. OpenMORDM contains two complementary components: (1) a software application programming interface (API) for connecting planning models to computational exploration tools for many-objective optimization and sensitivity-based discovery of critical deeply uncertain factors; and (2) a web-based visualization toolkit for exploring high-dimensional datasets to better understand system trade-offs, vulnerabilities, and dependencies. We demonstrate the OpenMORDM framework on a challenging environmental management test case termed the “lake problem”. The lake problem has been used extensively in the prior environmental decision science literature and, in this study, captures the challenges posed by conflicting economic and environmental objectives, a water quality “tipping point” beyond which the lake may become irreversibly polluted, and multiple deeply uncertain factors that may undermine the robustness of pollution management policies. The OpenMORDM software framework enables decision makers to identify policy-relevant scenarios, quantify the trade-offs between alternative strategies in different scenarios, flexibly explore alternative definitions of robustness, and identify key system factors that should be monitored as triggers for future actions or additional planning. The web-based OpenMORDM visualization toolkit allows decision makers to easily share and visualize their datasets, with the option for analysts to extend the framework with customized scripts in the R programming language. OpenMORDM provides a platform for constructive decision support, allowing analysts and decision makers to interactively discover promising alternatives and potential vulnerabilities while balancing conflicting objectives.},
  doi       = {10.1016/j.envsoft.2015.07.014},
  file      = {:Optimization\\An open source framework for many-objective robust decision making.pdf:PDF},
  keywords  = {Robust decision making; Deep uncertainty; Threshold; Scenario discovery; Risk assessment; Robustness},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-15},
  url       = {http://dx.doi.org/10.1016/j.envsoft.2015.07.014},
}

@Book{Verkade2015,
  title     = {Estimating Real-time and Predictive Hydrological and Uncertainty},
  publisher = {Jan Verkade},
  year      = {2015},
  author    = {Jan Verkade},
  booktitle = {Estimating Real-time and Predictive Hydrological and Uncertainty},
  file      = {:Ensembles\\Estimating Real-Time Predictive Hydrological Uncertainty.pdf:PDF},
  keywords  = {hydrology, forecasting, predictive uncertainty},
  timestamp = {2016-11-15},
}

@TechReport{Pena2011,
  author      = {Malaquias Peña},
  title       = {Ensemble Forecasts and their Verification},
  institution = {IMSG at EMC/NCEP/NOAA},
  year        = {2011},
  file        = {:Ensembles\\Ensemble Forecasts and their Verification.pdf:PDF},
  keywords    = {Brier, CRPS, BSS, Reliability, Skill, Resolution, ROC},
  timestamp   = {2016-11-15},
}

@Article{Vannitsem2009,
  author    = {S. Vannitsem},
  title     = {A unified linear Model Output Statistics scheme for both deterministic and ensemble forecasts},
  journal   = {Quarterly Journal of the Royal Meteorological Society},
  year      = {2009},
  volume    = {135},
  number    = {644},
  pages     = {1801--1815},
  month     = {oct},
  abstract  = {An extension of the classical linear Model Output Statistics (MOS) technique is proposed allowing for
the post-processing of ensemble forecasts. In this new approach, the cost function on which the least square parameter
estimation is based takes into account the presence of errors in both observations and model observables (referred to as
Error-in-Variables MOS, EVMOS), unlike the classical linear MOS cost function whose implicit assumption is the absence
of errors in the model observables. It allows for the maintenance of an appropriate variability for the corrected forecasts,
even for long lead times and for providing a framework in which both deterministic and probabilistic forecasts can be
corrected. The scheme is successfully tested for ensemble correction in the context of an idealized low-order chaotic
system, the Lorenz atmospheric model, in the presence of model errors, and compared with a classical technique, known
as the non-homogeneous Gaussian regression (NGR) method. The potential use of this approach is also briefly discussed.},
  doi       = {10.1002/qj.491},
  file      = {:Ensembles\\A unified linear Model Output Statistics scheme for both deterministic and ensemble forecasts.pdf:PDF},
  keywords  = {EVMOS; NGR; post-processing},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-11-15},
  url       = {http://dx.doi.org/10.1002/qj.491},
}

@Article{Buizza1999,
  author    = {R. Buizza and A. Hollingsworth and F. Lalaurette and A. Ghelli},
  title     = {Probabilistic predictions of precipitation using the ECMWF ensemble prediction system},
  journal   = {Weather and Forecasting},
  year      = {1999},
  volume    = {14},
  pages     = {168--189},
  abstract  = {The forecast skill of the European Centre for Medium-Range Weather Forecasts Ensemble Prediction System
(EPS) in predicting precipitation probabilities is discussed. Four seasons are analyzed in detail using signal
detection theory and reliability diagrams to define objective measure of predictive skill.
First, the EPS performance during summer 1997 is discussed. Attention is focused on Europe and two European
local regions, one centered around the Alps and the other around Ireland. Results indicate that for Europe the
EPS can give skillful prediction of low precipitation amounts [i.e., lower than 2 mm (12 h)21] up to forecast
day 6, and of high precipitation amounts [i.e., between 2 and 10 mm (12 h)21] up to day 4. Lower levels of
skill are achieved for smaller local areas.
Then, the EPS performance during summer 1996 (i.e., prior to the enhancement introduced on 10 December
1996 from 33 to 51 members and to resolution increase from T63 L19 to T
L159 L31) and summer 1997 are
compared. Results show that the EPS has been remarkably more skillful during summer 1997 than summer
1996, with the gain in predictability up to 3 days for the highest [5 and 10 mm (12 h)21] amounts of precipitation.
Finally, the EPS performance during wintertime is analyzed. Two issues are investigated: the seasonal variability of the forecast skill of the new EPS, and the impact of the system upgrade on the wintertime performance.
The comparison of the performance of the new EPS system during winter 1996/97 and during summer 1997
indicates that the EPS is more skillful during winter than during summer, with differences in predictive skill
around 3 days for precipitation amounts larger than 2 mm (12 h)21. The comparison of the EPS performance
before and after the system upgrade on 10 December 1996 during winter confirms the summer conclusion that
the upgraded system is more skillful than the old one.},
  file      = {:Ensembles\\Probabilistic predictions of precipitation using the ECMWF ensemble prediction system.pdf:PDF},
  timestamp = {2016-11-15},
}

@Article{Juras2000,
  author    = {Josip Juras},
  title     = {Comments on ‘‘Probabilistic and Predictions of Precipitation and Using the and ECMWF Ensemble and Prediction System"},
  journal   = {Weather and Forecasting},
  year      = {2000},
  volume    = {15},
  pages     = {365--366},
  file      = {:Ensembles\\Comments on- Probabilistic Predictions of Precipitation Using the ECMWF Ensemble Prediction System.pdf:PDF},
  timestamp = {2016-11-15},
}

@Article{Anscombe1973,
  author    = {F. J. Anscombe},
  title     = {Graphs in Statistical Analysis},
  journal   = {The American Statistician},
  year      = {1973},
  volume    = {27},
  number    = {1},
  pages     = {17-21},
  note      = {Anscombe's quartet},
  file      = {:Statistics\\Graphs in Statistical Analysis.pdf:PDF},
  timestamp = {2016-11-15},
}

@Article{Weigel2011,
  author    = {Andreas P. Weigel and Simon J. Mason},
  title     = {The Generalized Discrimination Score for Ensemble Forecasts},
  journal   = {Monthly Weather Review},
  year      = {2011},
  volume    = {139},
  number    = {9},
  pages     = {3069--3074},
  month     = {sep},
  abstract  = {This article refers to the study of Mason and Weigel, where the generalized discrimination score D has been
introduced. This score quantifies whether a set of observed outcomes can be correctly discriminated by the
corresponding forecasts (i.e., it is a measure of the skill attribute of discrimination). Because of its generic
definition, D can be adapted to essentially all relevant verification contexts, ranging from simple yes–no
forecasts of binary outcomes to probabilistic forecasts of continuous variables. For most of these cases, Mason
and Weigel have derived expressions for D, many of which have turned out to be equivalent to scores that are
already known under different names. However, no guidance was provided on how to calculate D for ensemble forecasts. This gap is aggravated by the fact that there are currently very few measures of forecast
quality that could be directly applied to ensemble forecasts without requiring that probabilities be derived
from the ensemble members prior to verification. This study seeks to close this gap. A definition is proposed
of how ensemble forecasts can be ranked; the ranks of the ensemble forecasts can then be used as a basis for
attempting to discriminate between corresponding observations. Given this definition, formulations of D are
derived that are directly applicable to ensemble forecasts.},
  doi       = {10.1175/mwr-d-10-05069.1},
  file      = {:Ensembles\\The Generalized Discrimination Score for Ensemble Forecasts.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-11-15},
  url       = {http://dx.doi.org/10.1175/MWR-D-10-05069.1},
}

@Article{Murphy1992,
  author    = {Allan H. Murphy and Robert L. Winkler},
  title     = {Diagnostic verification of probability forecasts},
  journal   = {International Journal of Forecasting},
  year      = {1992},
  volume    = {7},
  pages     = {435--455},
  abstract  = {Verification of probability forecasts traditionally consists largely of the computation of a few overall performance measures. This paper outlines a diagnostic approach to the evaluation of probability forecasts. The basic elements of this approach are the joint distribution of forecasts and observations and the conditional and marginal distributions associated with factorizations of the joint distribution. These distributions and their summary measures, together with selected performance measures and their decompositions, provide potentially insightful and useful information concerning the fundamental characteristics of the forecasts of interest, the corresponding observations, and their relationship.
This approach and the associated methodology are illustrated by presenting some results of an analysis of U.S. National Weather Service probability of precipitation (PoP) forecasts. The diagnostic analysis of PoP forecasts consists of graphical displays and quantitative measures describing various aspects (or attributes) of forecast quality, including calibration (or reliability), refinement, resolution, discrimination, accuracy, bias, and skill. In general, the samples of PoP forecasts examined here are relatively well-calibrated, unbiased, and skillful, but lacking to some degree in accuracy, refinement, resolution, and discrimination. Some differences in these characteristics as a function of forecast type (modelbased/subjective), season (cool/warm), and lead time are noted. Diagnostic verification of probability forecasts has obvious benefits to modelers and forecasters in terms of providing detailed feedback and suggesting ways in which forecasts might be improved.},
  file      = {:Ensembles\\Diagnostic verification of probability forecasts.pdf:PDF},
  keywords  = {Forecast verification, Diagnostic verification of forecasts, Aspects of forecast quality, Probability forecasts, Weather forecasts},
  timestamp = {2016-11-15},
}

@Article{Mason2009,
  author    = {Simon J. Mason and Andreas P. Weigel},
  title     = {A Generic Forecast Verification Framework for Administrative Purposes},
  journal   = {Monthly Weather Review},
  year      = {2009},
  volume    = {137},
  number    = {1},
  pages     = {331--349},
  month     = {jan},
  abstract  = {There are numerous reasons for calculating forecast verification scores, and considerable attention has been given to designing and analyzing the properties of scores that can be used for scientific purposes. Much less attention has been given to scores that may be useful for administrative reasons, such as communicating changes in forecast quality to bureaucrats and providing indications of forecast quality to the general public. The two-alternative forced choice (2AFC) test is proposed as a scoring procedure that is sufficiently generic to be usable on forecasts ranging from simple yes–no forecasts of dichotomous outcomes to forecasts of continuous variables, and can be used with deterministic or probabilistic forecasts without seriously reducing the more complex information when available. Although, as with any single verification score, the proposed test has limitations, it does have broad intuitive appeal in that the expected score of an unskilled set of forecasts (random guessing or perpetually identical forecasts) is 50%, and is interpretable as an indication of how often the forecasts are correct, even when the forecasts are expressed probabilistically and/or the observations are not discrete.},
  doi       = {10.1175/2008mwr2553.1},
  file      = {:Ensembles\\A generic forecast verification framework for administrative purposes.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-11-15},
  url       = {http://dx.doi.org/10.1175/2008MWR2553.1},
}

@Article{Verkade2011,
  author    = {J. S. Verkade and M. G. F. Werner},
  title     = {Estimating the benefits of single value and probability forecasting for flood warning},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2011},
  volume    = {15},
  number    = {12},
  pages     = {3751--3765},
  month     = {dec},
  abstract  = {Flood risk can be reduced by means of flood forecasting, warning and response systems (FFWRS). These systems include a forecasting sub-system which is imperfect, meaning that inherent uncertainties in hydrological forecasts may result in false alarms and missed events. This forecasting uncertainty decreases the potential reduction of flood risk, but is seldom accounted for in estimates of the benefits of FFWRSs. In the present paper, a method to estimate the benefits of (imperfect) FFWRSs in reducing flood risk is presented. The method is based on a hydro-economic model of expected annual damage (EAD) due to flooding, combined with the concept of Relative Economic Value (REV). The estimated benefits include not only the reduction of flood losses due to a warning response, but also consider the costs of the warning response itself, as well as the costs associated with forecasting uncertainty. The method allows for estimation of the benefits of FFWRSs that use either deterministic or probabilistic forecasts. Through application to a case study, it is shown that FFWRSs using a probabilistic forecast have the potential to realise higher benefits at all lead-times. However, it is also shown that provision of warning at increasing lead-time does not necessarily lead to an increasing reduction of flood risk, but rather that an optimal lead-time at which warnings are provided can be established as a function of forecast uncertainty and the cost-loss ratio of the user receiving and responding to the warning.},
  doi       = {10.5194/hess-15-3751-2011},
  file      = {:Ensembles\\Estimating the benefits of single value and probability forecasting for flood warning.pdf:PDF},
  publisher = {Copernicus {GmbH}},
  timestamp = {2016-11-17},
  url       = {http://dx.doi.org/10.5194/hess-15-3751-2011},
}

@Article{Reggiani2008,
  author    = {P. Reggiani and A.H. Weerts},
  title     = {A Bayesian approach to decision-making under uncertainty: An application to real-time forecasting in the river Rhine},
  journal   = {Journal of Hydrology},
  year      = {2008},
  volume    = {356},
  pages     = {56--69},
  abstract  = {Enhanced ability to forecast peak discharges remains the most relevant nonstructural measure for flood protection. Extended forecasting lead times are desirable
as they facilitate mitigating action and response in case of extreme discharges. Forecasts
remain however affected by uncertainty as an exact prognosis of water levels is inherently
impossible. Here, we implement a dedicated uncertainty processor, that can be used
within operational flood forecasting systems.
The processor is designed to support decision-making under conditions of uncertainty.
The scientific approach at the basis of the uncertainty processor is general and independent of the deterministic models used. It is based on Bayesian revision of prior knowledge
on the basis of past evidence on model performance against observations. The revision of
the prior distributions on water levels and/or flow rates leads to posterior probability
distributions that are translated into an effective decision support under uncertainty.
The processor is validated on the operational real-time river Rhine flood forecasting
system.},
  file      = {:Ensembles\\A Bayesian approach to decision-making under uncertainty- An application to real-time forecasting in the river Rhine.pdf:PDF},
  keywords  = {Uncertainty; Decision support; Operational flood forecasting; Bayesian revision; River Rhine},
  timestamp = {2016-11-17},
}

@Article{Hamill2006,
  author    = {Thomas M. Hamill and Jeffrey S. Whitaker and Steven L. Mullen},
  title     = {Reforecasts: An Important Dataset for Improving Weather Predictions},
  journal   = {Bulletin of the American Meteorological Society},
  year      = {2006},
  volume    = {87},
  number    = {1},
  pages     = {33--46},
  month     = {jan},
  abstract  = {Reanalyses such as the National Centers for Environmental Prediction (NCEP)–National R Center for Atmospheric Research (NCAR) reanalysis (Kalnay et al. 1996) and the European Centre
for Medium-Range Weather Forecasts (ECMWF)
40-year reanalysis (ERA-40; Uppala et al. 2005) have
become heavily used products for geophysical science
research. These reanalyses run a practical, consistent
data assimilation and short-range forecast system
over a long period of time. While the observation
type and quality may change somewhat, the forecast
model and assimilation system are typically fixed.
This facilitates the generation of a reanalysis dataset
that is fairly consistent in quality over time. These
reanalysis datasets have facilitated a wide range of
research; for example, the Kalnay et al. (1996) article
above has been cited more than 3200 times.},
  doi       = {10.1175/bams-87-1-33},
  file      = {:Ensembles\\Reforecasts- An Important Dataset for Improving Weather Predictions.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-11-17},
  url       = {http://dx.doi.org/10.1175/BAMS-87-1-33},
}

@Article{Ramos2013,
  author    = {M. H. Ramos and S. J. van Andel and F. Pappenberger},
  title     = {Do probabilistic forecasts lead to better decisions?},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2013},
  volume    = {17},
  number    = {6},
  pages     = {2219--2232},
  month     = {jun},
  abstract  = {The last decade has seen growing research in producing probabilistic hydro-meteorological forecasts and increasing their reliability. This followed the promise that, supplied with information about uncertainty, people would take better risk-based decisions. In recent years, therefore, research and operational developments have also started focusing attention on ways of communicating the probabilistic forecasts to decision-makers. Communicating probabilistic forecasts includes preparing tools and products for visualisation, but also requires understanding how decision-makers perceive and use uncertainty information in real time. At the
EGU General Assembly 2012, we conducted a laboratorystyle experiment in which several cases of flood forecasts and a choice of actions to take were presented as part of a game to participants, who acted as decision-makers. Answers were collected and analysed. In this paper, we present the results of this exercise and discuss if we indeed make better decisions on the basis of probabilistic forecasts.},
  doi       = {10.5194/hess-17-2219-2013},
  file      = {:Ensembles\\Do probabilistic forecasts lead to better decisions.pdf:PDF},
  publisher = {Copernicus {GmbH}},
  timestamp = {2016-11-17},
  url       = {http://dx.doi.org/10.5194/hess-17-2219-2013},
}

@Article{Demeritt2010,
  author        = {David Demeritt and S{\'{e}}bastien Nobert and Hannah Cloke and Florian Pappenberger},
  title         = {Challenges in communicating and using ensembles in operational flood forecasting},
  journal       = {Meteorological Applications},
  year          = {2010},
  volume        = {17},
  number        = {2},
  pages         = {209--222},
  month         = {may},
  __markedentry = {[quebbs:1]},
  abstract      = {Following trends in operational weather forecasting, where ensemble prediction systems (EPS) are now
increasingly the norm, flood forecasters are beginning to experiment with using similar ensemble methods. Most of the
effort to date has focused on the substantial technical challenges of developing coupled rainfall-runoff systems to represent
the full cascade of uncertainties involved in predicting future flooding. As a consequence much less attention has been given
to the communication and eventual use of EPS flood forecasts. Drawing on interviews and other research with operational
flood forecasters from across Europe, this paper highlights a number of challenges to communicating and using ensemble
flood forecasts operationally. It is shown that operational flood forecasters understand the skill, operational limitations, and
informational value of EPS products in a variety of different and sometimes contradictory ways. Despite the efforts of
forecasting agencies to design effective ways to communicate EPS forecasts to non-experts, operational flood forecasters
were often skeptical about the ability of forecast recipients to understand or use them appropriately. It is argued that better
training and closer contacts between operational flood forecasters and EPS system designers can help ensure the uncertainty
represented by EPS forecasts is represented in ways that are most appropriate and meaningful for their intended consumers,
but some fundamental political and institutional challenges to using ensembles, such as differing attitudes to false alarms
and to responsibility for management of blame in the event of poor or mistaken forecasts are also highlighted.},
  doi           = {10.1002/met.194},
  file          = {:Ensembles\\Challenges in communicating and using ensembles in operational flood forecasting.pdf:PDF},
  keywords      = {risk communication; flood risk management; uncertainty; civil protection; EFAS; Europe},
  publisher     = {Wiley-Blackwell},
  timestamp     = {2016-11-17},
  url           = {http://dx.doi.org/10.1002/met.194},
}

@Article{Krzysztofowic1999,
  author    = {Roman Krzysztofowicz},
  title     = {Bayesian Forecasting via Deterministic Model},
  journal   = {Risk Analysis},
  year      = {1999},
  volume    = {19},
  number    = {4},
  pages     = {739--749},
  abstract  = {Rational decision making requires that the total uncertainty about a variate of interest (a
predictand) be quantified in terms of a probability distribution, conditional on all available
information and knowledge. Suppose the state-of-knowledge is embodied in a deterministic
model, which is imperfect and outputs only an estimate of the predictand. Fundamentals are
presented of two Bayesian methods for producing a probabilistic forecast via any deterministic
model. The Bayesian Processor of Forecast (BPF) quantifies the total uncertainty in terms
of a posterior distribution, conditional on model output. The Bayesian Forecasting System
(BFS) decomposes the total uncertainty into input uncertainty and model uncertainty, which
are characterized independently and then integrated into a predictive distribution. The BFS
is compared with Monte Carlo simulation and “ensemble forecasting” technique, none of
which can alone produce a probabilistic forecast that quantifies the total uncertainty, but
each can serve as a component of the BFS.},
  file      = {:Ensembles\\Bayesian Forecasting via Deterministic Model.pdf:PDF},
  keywords  = {Probabilistic forecasting; uncertainty quantification; Bayesian method; Monte-Carlo simulation; decision making},
  timestamp = {2016-11-17},
}

@Article{Wilks2014,
  author    = {Daniel S. Wilks},
  title     = {Multivariate ensemble Model Output Statistics using empirical copulas},
  journal   = {Quarterly Journal of the Royal Meteorological Society},
  year      = {2014},
  volume    = {141},
  number    = {688},
  pages     = {945--952},
  month     = {aug},
  abstract  = {Statistical post-processing of ensemble forecasts usually is carried out independently for
individual, scalar predictands. However, in some applications multivariate joint forecast
distributions, which capture both the univariate marginal distributions of their constituent
scalar predictands as well as the dependence structure among them, may be required.
Copulas are functions that link multivariate distribution functions to their constituent
univariate marginal distributions. Empirical copulas are non-parametric copula functions
that are easy to implement. This article compares recently proposed variants of empirical
copula coupling (ECC-Q and ECC-R), which take their dependence structures from raw
forecast ensembles, and the Schaake shuffle, which is based on unconditional random
samples from the historical climatology, in a four-dimensional multivariate ensemble
post-processing setting. These alternatives were compared for probability forecasts of
multi-day ‘heat waves’, based on the 11-member National Oceanic and Atmospheric
Administration (NOAA) reforecast ensembles. Best forecast accuracy was achieved using
the unconditional climatological dependence structures sampled by the Schaake shuffle,
implying that any forecast improvements due to flow-specific dependencies that might
be captured by the ensemble-based copulas are not sufficient to overcome errors in the
ensemble’s representation of those dependencies.},
  doi       = {10.1002/qj.2414},
  file      = {:Ensembles\\Multivariate ensemble Model Output Statistics using empirical copulas.pdf:PDF},
  keywords  = {ensemble forecasting; ensemble post-processing; non-homogeneous Gaussian regression; empirical copula; Schaake shuffle},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-11-17},
  url       = {http://dx.doi.org/10.1002/qj.2414},
}

@Article{Roulin2012,
  author    = {Emmanuel Roulin and St{\'{e}}phane Vannitsem},
  title     = {Postprocessing of Ensemble Precipitation Predictions with Extended Logistic Regression Based on Hindcasts},
  journal   = {Monthly Weather Review},
  year      = {2012},
  volume    = {140},
  number    = {3},
  pages     = {874--888},
  month     = {mar},
  abstract  = {Extended logistic regression is used to calibrate areal precipitation forecasts over two small catchments in Belgium computed with the European Centre for Medium-Range Weather Forecasts (ECMWF) Ensemble Prediction System (EPS) between 2006 and 2010. The parameters of the postprocessing are estimated from the hindcast database, characterized by a much lower number of members (5) than the EPS (51). Therefore, the parameters have to be corrected for predictor uncertainties. They have been fitted on the 51-member EPS ensembles, on 5-member subensembles drawn from the same EPS, and on the 5-member hindcasts. For small ensembles, a simple “regression calibration” method by which the uncertain predictors are corrected has been applied. The different parameter sets have been compared, and the corresponding extended logistic regressions have been applied to the 51-member EPS. The forecast probabilities have then been validated using rain gauge data and compared with the raw EPS. In addition, the calibrated distributions are also used to modify the ensembles of precipitation traces.

The postprocessing with the extended logistic regression is shown to improve the continuous ranked probability skill score relative to the raw ensemble, and the regression calibration to remove a large portion of the bias in parameter estimation with small ensembles. With a training phase limited to a 5-week moving window, the benefit lasts for the first 2 forecast days in winter and the first 5 or 6 days in summer. In general, substantial improvements of the mean error and of the continuous ranked probability score have been shown.},
  doi       = {10.1175/mwr-d-11-00062.1},
  file      = {:Ensembles\\Postprocessing of Ensemble Precipitation Predictions with Extended Logistic Regression Based on Hindcasts.pdf:PDF},
  keywords  = {Ensembles; Forecast verification; Hindcasts},
  publisher = {American Meteorological Society},
  timestamp = {2016-11-17},
  url       = {http://dx.doi.org/10.1175/MWR-D-11-00062.1},
}

@Article{Robertson2013,
  author    = {D. E. Robertson and D. L. Shrestha and Q. J. Wang},
  title     = {Post-processing rainfall forecasts from numerical weather prediction models for short-term streamflow forecasting},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2013},
  volume    = {17},
  number    = {9},
  pages     = {3587--3603},
  month     = {sep},
  note      = {log sinh transformation},
  abstract  = {Sub-daily ensemble rainfall forecasts that are bias
free and reliably quantify forecast uncertainty are critical for
flood and short-term ensemble streamflow forecasting. Postprocessing of rainfall predictions from numerical weather
prediction models is typically required to provide rainfall
forecasts with these properties. In this paper, a new approach
to generate ensemble rainfall forecasts by post-processing
raw numerical weather prediction (NWP) rainfall predictions
is introduced. The approach uses a simplified version of the
Bayesian joint probability modelling approach to produce
forecast probability distributions for individual locations and
forecast lead times. Ensemble forecasts with appropriate spatial and temporal correlations are then generated by linking
samples from the forecast probability distributions using the
Schaake shuffle.
The new approach is evaluated by applying it to postprocess predictions from the ACCESS-R numerical weather
prediction model at rain gauge locations in the Ovens catchment in southern Australia. The joint distribution of NWP
predicted and observed rainfall is shown to be well described
by the assumed log-sinh transformed bivariate normal distribution. Ensemble forecasts produced using the approach
are shown to be more skilful than the raw NWP predictions
both for individual forecast lead times and for cumulative totals throughout all forecast lead times. Skill increases result
from the correction of not only the mean bias, but also biases
conditional on the magnitude of the NWP rainfall prediction.
The post-processed forecast ensembles are demonstrated to
successfully discriminate between events and non-events for
both small and large rainfall occurrences, and reliably quantify the forecast uncertainty.
Future work will assess the efficacy of the post-processing
method for a wider range of climatic conditions and also
investigate the benefits of using post-processed rainfall forecasts for flood and short-term streamflow forecasting.},
  doi       = {10.5194/hess-17-3587-2013},
  file      = {:Ensembles\\Post-processing rainfall forecasts from numerical weather prediction models for short-term streamflow forecasting.pdf:PDF},
  keywords  = {Bayesian joint probability, ROC, CRPS, Reliability Diagram},
  publisher = {Copernicus {GmbH}},
  timestamp = {2016-11-17},
  url       = {http://dx.doi.org/10.5194/hess-17-3587-2013},
}

@Article{Raftery2005,
  author    = {Adrian E. Raftery and Tilmann Gneiting and Fadoua Balabdaoui and Michael Polakowski},
  title     = {Using Bayesian Model Averaging to Calibrate Forecast Ensembles},
  journal   = {Monthly Weather Review},
  year      = {2005},
  volume    = {133},
  pages     = {1155--1174},
  abstract  = {Ensembles used for probabilistic weather forecasting often exhibit a spread-error correlation, but they
tend to be underdispersive. This paper proposes a statistical method for postprocessing ensembles based on
Bayesian model averaging (BMA), which is a standard method for combining predictive distributions from
different sources. The BMA predictive probability density function (PDF) of any quantity of interest is a
weighted average of PDFs centered on the individual bias-corrected forecasts, where the weights are equal
to posterior probabilities of the models generating the forecasts and reflect the models’ relative contributions to predictive skill over the training period. The BMA weights can be used to assess the usefulness of
ensemble members, and this can be used as a basis for selecting ensemble members; this can be useful given
the cost of running large ensembles. The BMA PDF can be represented as an unweighted ensemble of any
desired size, by simulating from the BMA predictive distribution.
The BMA predictive variance can be decomposed into two components, one corresponding to the
between-forecast variability, and the second to the within-forecast variability. Predictive PDFs or intervals
based solely on the ensemble spread incorporate the first component but not the second. Thus BMA
provides a theoretical explanation of the tendency of ensembles to exhibit a spread-error correlation but yet
be underdispersive.
The method was applied to 48-h forecasts of surface temperature in the Pacific Northwest in January–
June 2000 using the University of Washington fifth-generation Pennsylvania State University–NCAR Mesoscale Model (MM5) ensemble. The predictive PDFs were much better calibrated than the raw ensemble,
and the BMA forecasts were sharp in that 90% BMA prediction intervals were 66% shorter on average than
those produced by sample climatology. As a by-product, BMA yields a deterministic point forecast, and this
had root-mean-square errors 7% lower than the best of the ensemble members and 8% lower than the
ensemble mean. Similar results were obtained for forecasts of sea level pressure. Simulation experiments
show that BMA performs reasonably well when the underlying ensemble is calibrated, or even overdispersed.},
  file      = {:Ensembles\\Using Bayesian Model Averaging to Calibrate Forecast Ensembles.pdf:PDF},
  timestamp = {2016-11-17},
}

@Article{Hoeting1999,
  author    = {Jennifer A. Hoeting and David Madigan and Adrian E. Raftery and Chris T. Volinsky},
  title     = {Bayesian Model and Averaging: A Tutorial},
  journal   = {Statistical Science},
  year      = {1999},
  volume    = {14},
  number    = {4},
  pages     = {382--417},
  abstract  = {Standard statistical practice ignores model uncertainty. Data
analysts typically select a model from some class of models and then
proceed as if the selected model had generated the data. This approach
ignores the uncertainty in model selection, leading to over-conﬁdent in-
ferences and decisions that are more risky than one thinks they are.
Bayesian model averaging (BMA) provides a coherent mechanism for ac-
counting for this model uncertainty. Several methods for implementing
BMA have recently emerged. We discuss these methods and present a
number of examples. In these examples, BMA provides improved out-of-
sample predictive performance. We also provide a catalogue of currently
available BMA software.},
  file      = {:Statistics\\Bayesian Model Averaging- A Tutorial.pdf:PDF},
  keywords  = {Bayesian model averaging, Bayesian graphical models, learning; model uncertainty, Markov chain Monte Carlo},
  timestamp = {2016-11-17},
}

@Article{Hamill2004,
  author    = {Thomas M. Hamill and Jeffrey S. Whitaker and Xue Wei},
  title     = {Ensemble reforecasting: improving medium-range forecast skill using retrospective forecasts},
  journal   = {Monthly Weather Review},
  year      = {2004},
  volume    = {132},
  pages     = {1434--1447},
  file      = {:Ensembles\\Ensemble reforecasting- improving medium-range forecast skill using retrospective forecasts.pdf:PDF},
  timestamp = {2016-11-17},
}

@Article{Krzysztofowicz1997,
  author    = {Roman Krzysztofowicz},
  title     = {Transformation and normalization of variates with specified distributions},
  journal   = {Journal of Hydrology},
  year      = {1997},
  volume    = {197},
  pages     = {286--292},
  abstract  = {Given two continuous random variables X and Y, with specified strictly increasing cumulative distribution functions F and G, respectively, the one-to-one transform t which maps one variate into another, say Y=t(X), has an analytic form, t(X)=G−1(F(X)) or t(X)=G−1(1−F(X)), depending upon whether t is increasing or decreasing. This fact of probability theory is reviewed and compared with another method for finding t that was recently proposed. Applications to system identification, normalization of a variate, and normalization of a sample are briefly discussed.},
  file      = {:Statistics\\Transformation and normalization of variates with specified distributions.pdf:PDF},
  keywords  = {normal quantile transform (NQT)},
  timestamp = {2016-11-18},
}

@Article{Zhu2002,
  author    = {Yuejian Zhu and Zoltan Toth Abd Richard Wobus and David Richardson and Kenneth Mylne},
  title     = {The Economic Value Of Ensemble-Based Weather Forecasts},
  journal   = {Bulletin of the American Meteorological Society},
  year      = {2002},
  volume    = {83},
  pages     = {73--83},
  abstract  = {Quantifying forecast uncertainty with an ensemble approach can improve the users’ bottom line},
  file      = {:Ensembles\\The Economic Value Of Ensemble-Based Weather Forecasts.pdf:PDF},
  timestamp = {2016-11-18},
}

@Article{Murphy1985,
  author        = {Allan H. Murphy},
  title         = {Decision Making and the Value of Forecasts in a Generalized Model of the Cost-Loss Ratio Situation},
  journal       = {Monthly Weather Review},
  year          = {1985},
  volume        = {113},
  pages         = {362--369},
  __markedentry = {[quebbs:1]},
  abstract      = {Meteorologists have devoted considerable attention to studies of the use and value of forecasts in a simple two-action, two-event decision-making problem generally referred to as the cost-loss ratio situation, An N-action, N-event generalization of the standard cost-loss ratio situation is described here, and the expected value of different types of forecasts in this situation is investigated. Specifically, expressions are developed for the expected expenses associated with the use of climatological, imperfect, and perfect information, and these expressions are employed to derive formulas for the expected value of imperfect and perfect forecasts. The three-action, three-event situation is used to illustrate the generalized model and the value-information results, by considering examples based on specific numerical values of the relevant parameters. Some possible extensions of this model are briefly discussed.},
  file          = {:Ensembles\\Decision Making and the Value of Forecasts in a Generalized Model of the Cost-Loss Ratio Situation.pdf:PDF},
  timestamp     = {2016-11-18},
}

@Article{Hamill1997,
  author    = {Thomas M. Hamill},
  title     = {Reliability Diagrams for Multicategory Probabilistic Forecasts},
  journal   = {Weather and Forecasting},
  year      = {1997},
  volume    = {12},
  pages     = {736--741},
  abstract  = {The most common method of verifying multicategory probabilistic forecasts such as are used in probabilistic
quantitative precipitation forecasting is through the use of the ranked probability score. This single number
description of forecast accuracy can never capture the multidimensional nature of forecast quality and does not
inform the forecaster about the sources of forecast deficiencies. A new type of reliability diagram is developed
here and applied to probabilistic quantitative precipitation forecasts from a university contest. This diagram is
shown to potentially be useful in helping the forecaster to correct some errors in assigning the categorical
probabilities.},
  doi       = {ng},
  file      = {:Ensembles\\Reliability Diagrams for Multicategory Probabilistic Forecasts.pdf:PDF},
  timestamp = {2016-11-20},
}

@Article{Weerts2011,
  author    = {A. H. Weerts and H. C. Winsemius and J. S. Verkade},
  title     = {Estimation of predictive hydrological uncertainty using quantile regression: examples from the National Flood Forecasting System (England and Wales)},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2011},
  volume    = {15},
  number    = {1},
  pages     = {255--265},
  month     = {jan},
  abstract  = {In this paper, a technique is presented for assessing the predictive uncertainty of rainfall-runoff and hydraulic forecasts. The technique conditions forecast uncertainty on the forecasted value itself, based on retrospective Quantile Regression of hindcasted water level forecasts and forecast errors. To test the robustness of the method, a number of retrospective forecasts for different catchments across England and Wales having different size and hydrological characteristics have been used to derive in a probabilistic sense the relation between simulated values of water levels and matching errors. From this study, we can conclude that using Quantile Regression for estimating forecast errors conditional on the forecasted water levels provides a relatively simple, efficient and robust means for estimation of predictive uncertainty.},
  doi       = {10.5194/hess-15-255-2011},
  file      = {:Ensembles\\Estimation of predictive hydrological uncertainty using quantile regression- examples from the National Flood Forecasting System (England and Wales).pdf:PDF},
  publisher = {Copernicus {GmbH}},
  timestamp = {2016-11-21},
  url       = {http://dx.doi.org/10.5194/hess-15-255-2011},
}

@Article{Doblas-reyes2005,
  author    = {Francisco J. Doblas-reyes and Renate Hagedorn and T. N. Palmer},
  title     = {The rationale behind the success of multi-model ensembles in seasonal forecasting – II. Calibration},
  journal   = {Tellus},
  year      = {2005},
  volume    = {57A},
  pages     = {234--252},
  abstract  = {The DEMETER multi-model ensemble system is used to investigate the enhancement in seasonal predictability that can
be achieved by calibrating single-model ensembles and combining them to issue multi-model predictions. The forecast
quality of both deterministic and probabilistic predictions is assessed and compared to the skill of a simple multi-model
ensemble where all the single models are equally weighted. Both calibration and combination are carried out using cross-
validation. Single-model seasonal ensembles are calibrated using canonical correlation analysis for model adjustment
and variance inflation for reliability enhancement. Results indicate that both model adjustment and inflation increase the
skill of tropical predictions for single-model ensembles, provided that the training time series are long enough. Some
improvements are also found for extratropical areas, although mostly due to an increase of reliability associated with the
inflation. The beneficial impact of calibration is smaller for the simple multi-model than for the single-model ensembles
due to the relatively high reliability of the former. The raw single-model predictions are also linearly combined using
grid-point multiple linear regression to create an optimized multi-model system. Results indicate that the forecast quality
of the simple multi-model ensemble is generally difficult to improve using multiple linear regression due to the lack
of robustness of the regression coefficients. As in the case of the calibration, longer time series would be preferred to
achieve a significant forecast quality improvement. Over the tropics, a multiple linear regression, that uses the principal
components of the model anomalies for the target area as predictors indicates a substantial gain in skill even with the
available sample size. The implications of these results in an operational context are discussed.},
  file      = {:Ensembles\\The rationale behind the success of multi-model ensembles in seasonal forecasting – II. Calibration and combination.pdf:PDF},
  publisher = {Tellus (2005), 57A, 234–252 Copyright ©C Blackwell Munksgaard, 2005 Printed in UK. All rights reserved T E L L U S},
  timestamp = {2016-11-21},
}

@Article{Ziehmann2000,
  author    = {Christine Ziehmann},
  title     = {Comparison of a single-model EPS and with a multi-model and ensemble consisting of a few operational models},
  journal   = {Tellus},
  year      = {2000},
  volume    = {52A},
  pages     = {280--299},
  abstract  = {Since the introduction of operational ensemble forecasts in Numerical Weather Prediction
(NWP) more than 5 years ago, the dispute on how to best determine the initial perturbations
has largely dominated the direction of research in the field of ensemble prediction. While it is
important to consider uncertainties in the initial condition, errors due to model physics or the
model numerics and truncation provide another source of forecast errors and might also be
considered in ensemble prediction. In this study, we compare the performance of 2 fundamentally
different ensemble schemes. First, the ensemble prediction system (EPS) of the European Centre
for Medium Range Forecasts is taken as a representative of the single-model approach based
on the perfect model assumption and thus taking only the uncertainty in the observations into
account. Second, a virtual ensemble comprised of the operational forecasts of 4 NWP centers
as a ‘‘gratis’’ candidate of the multi-model approach which, in addition, takes model errors into
account. The comparison is based on forecasts of 500 hPa fields over Europe for a summer and
a winter period in 1997 and on diagnostics ranging from various measures for the performance
of the ensemble means to the statistical consistency and discrimination properties of the
ensembles. The different sizes of both ensembles poses the main difficulty for the interpretation
of the results. If the ensemble size is not considered as a criterion for the evaluation, the results
lead to controversial conclusions; but when penalizing for an overly large and inefficient
ensemble the results are for the most part consistent, and one has to conclude that the multimodel ensemble performs better in most forecast aspects.},
  file      = {:Ensembles\\COMPARISON OF A SINGLE-MODEL EPS WITH A MULTI-MODEL ENSEMBLE CONSISTING OF A FEW OPERATIONAL MODELS.pdf:PDF},
  publisher = {T ellus (2000), 52A, 280–299 Copyright © Munksgaard, 2000 Printed in UK. All rights reserved TELLUS},
  timestamp = {2016-11-21},
}

@TechReport{Clark2015,
  author      = {Martyn P. Clark and Bart Nijssen and Jessica D. Lundquist and Dmitri Kavetski and David E. Rupp and Ross A. Woods and Jim E. Freer and Ethan D. Gutmann and Andy W. Wood and Levi D. Brekke and Jeffrey R. Arnold and David J. Gochis and Roy M. Rasmussen and David G. Tarboton and Vinod Mahat and Gerald N. Flerchinger and Danny G. Marks},
  title       = {The structure for unifying multiple modeling alternatives (SUMMA), Version 1.0: Technical Description},
  institution = {NCAR},
  year        = {2015},
  number      = {NCAR/TN-514},
  abstract    = {This note describes the conservation equations and flux parameterizations used in the Structure for
Unifying Multiple Modeling Alternatives (SUMMA). The processes considered here include radiation
transfer through the vegetation canopy, within- and below-canopy turbulence, canopy interception,
canopy transpiration, snow accumulation and ablation, and runoff generation.},
  doi         = {10.5065/D6WQ01TD},
  file        = {:Hydrology\\The structure for unifying multiple modeling alternatives (SUMMA), Version 1.0- Technical Description.pdf:PDF},
  keywords    = {SUMMA},
  timestamp   = {2016-11-21},
}

@Article{Clark2015a,
  author    = {Martyn P. Clark and Bart Nijssen and Jessica D. Lundquist and Dmitri Kavetski and David E. Rupp and Ross A. Woods and Jim E. Freer and Ethan D. Gutmann and Andrew W. Wood and Levi D. Brekke and Jeffrey R. Arnold and David J. Gochis and Roy M. Rasmussen},
  title     = {A unified approach for process-based hydrologic modeling: 1. Modeling concept},
  journal   = {Water Resources Research},
  year      = {2015},
  volume    = {51},
  number    = {4},
  pages     = {2498--2514},
  month     = {apr},
  abstract  = {This work advances a unified approach to process-based hydrologic modeling to enable controlled and systematic evaluation of multiple model representations (hypotheses) of hydrologic processes
and scaling behavior. Our approach, which we term the Structure for Unifying Multiple Modeling Alternatives (SUMMA), formulates a general set of conservation equations, providing the flexibility to experiment
with different spatial representations, different flux parameterizations, different model parameter values,
and different time stepping schemes. In this paper, we introduce the general approach used in SUMMA,
detailing the spatial organization and model simplifications, and how different representations of multiple
physical processes can be combined within a single modeling framework. We discuss how SUMMA can be
used to systematically pursue the method of multiple working hypotheses in hydrology. In particular, we
discuss how SUMMA can help tackle major hydrologic modeling challenges, including defining the appropriate complexity of a model, selecting among competing flux parameterizations, representing spatial variability across a hierarchy of scales, identifying potential improvements in computational efficiency and
numerical accuracy as part of the numerical solver, and improving understanding of the various sources of
model uncertainty.},
  doi       = {10.1002/2015wr017198},
  file      = {:Hydrology\\A unified approach for process-based hydrologic modeling- 1. Modeling concept.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-11-21},
  url       = {http://dx.doi.org/10.1002/2015WR017198},
}

@Article{Clark2015b,
  author    = {Martyn P. Clark and Bart Nijssen and Jessica D. Lundquist and Dmitri Kavetski and David E. Rupp and Ross A. Woods and Jim E. Freer and Ethan D. Gutmann and Andrew W. Wood and David J. Gochis and Roy M. Rasmussen and David G. Tarboton and Vinod Mahat and Gerald N. Flerchinger and Danny G. Marks},
  title     = {A unified approach for process-based hydrologic modeling: 2. Model implementation and case studies},
  journal   = {Water Resources Research},
  year      = {2015},
  volume    = {51},
  number    = {4},
  pages     = {2515--2542},
  month     = {apr},
  abstract  = {This work advances a unified approach to process-based hydrologic modeling, which we term
the ‘‘Structure for Unifying Multiple Modeling Alternatives (SUMMA).’’ The modeling framework, introduced
in the companion paper, uses a general set of conservation equations with flexibility in the choice of process parameterizations (closure relationships) and spatial architecture. This second paper specifies the
model equations and their spatial approximations, describes the hydrologic and biophysical process parameterizations currently supported within the framework, and illustrates how the framework can be used in
conjunction with multivariate observations to identify model improvements and future research and data
needs. The case studies illustrate the use of SUMMA to select among competing modeling approaches
based on both observed data and theoretical considerations. Specific examples of preferable modeling
approaches include the use of physiological methods to estimate stomatal resistance, careful specification
of the shape of the within-canopy and below-canopy wind profile, explicitly accounting for dust concentrations within the snowpack, and explicitly representing distributed lateral flow processes. Results also demonstrate that changes in parameter values can make as much or more difference to the model predictions
than changes in the process representation. This emphasizes that improvements in model fidelity require a
sagacious choice of both process parameterizations and model parameters. In conclusion, we envisage that
SUMMA can facilitate ongoing model development efforts, the diagnosis and correction of model structural
errors, and improved characterization of model uncertainty.},
  doi       = {10.1002/2015wr017200},
  file      = {:Hydrology\\A unified approach for process-based hydrologic modeling- 2. Model implementation and case studies.pdf:PDF},
  keywords  = {SUMMA},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-11-21},
  url       = {http://dx.doi.org/10.1002/2015WR017200},
}

@MastersThesis{Sadeghi2015,
  author    = {Hossein Sadeghi},
  title     = {Medium-range Ensemble Precipitation and Streamflow Forecasting for the Upper Trinity River Basin in Texas Via the Nws Hydrologic Ensemble Forecast Service},
  school    = {The University of Texas at Arlington},
  year      = {2015},
  month     = {Dec},
  abstract  = {Compared to forecasts of short-term precipitation accumulations (daily or shorter)
at lead times larger than a few days, those of longer-term accumulations (3-daily or
longer) are significantly more skillful owing to the larger temporal scale of aggregation. If
one can utilize this skill present in medium-range precipitation forecast in hydrologic
prediction, it is very likely that the lead time of hydrologic forecasts, in particular, of
streamflow and soil moisture may be extended. Though forecasts of longer-term
accumulations of precipitation are more skillful than those of shorter-term accumulations,
precipitation forecasts in general are too uncertain to be used as deterministic, or singlevalued,
input.
The main goal of this study is to increase forecast lead time of streamflow
forecasts by using medium range ensemble precipitation forecasts. A premise for this
study is that, in the ensemble paradigm, forecasting of precipitation and streamflow
provides extending forecast lead time with improved forecast skill. To utilize forecast skill
in medium range precipitation forecasts in the ensemble paradigm, this study uses
Hydrologic Ensemble Forecast Service (HEFS).

In the HEFS, the Meteorological Ensemble Forecast Processor (MEFP) was
used to generate ensemble precipitation hindcasts using the Global Ensemble Forecast 
System (GEFS) reforecast data. Raw streamflow hindcasts were generated via the
Community Hydrologic Prediction System (CHPS) using the Sacramento Soil Moisture
Accounting model (SAC-SMA) and unit hydrograph. To reduce biases and uncertainties
in the hydrologic model results, raw streamflow ensembles were post-processed by the
Ensemble Postprocessor (EnsPost). The precipitation, raw and post-processed
streamflow ensembles were verified using the Ensemble Verification System (EVS) to
assess the quality of hindcasts. Ensemble hindcasts of precipitation and streamflow were
generated using the HEFS for a 26-year period between 1986 and 2011. The study area
consisted of five headwater basins located upstream of the Dallas-Fort Worth (DFW)
metropolitan area in the Upper Trinity River Basin in Texas.

The main findings of this study include: (1) adjusting modulation canonical events is a
very effective way to improve predictive skill in ensemble forecasts of precipitation, raw,
and post-processed streamflow forecasts: (2) GEFS-forced medium-range precipitation
hindcasts for the study area have valuable skill in 1-, 3-, 5-daily, weekly, and biweekly aggregated
hindcasts; (3) in the ensemble paradigm, forecast skill in medium-range
precipitation forecasts can be effectively utilized to improve the quality of streamflow
forecasts in extended forecast lead time via HEFS.

This study used the HEFS successfully, demonstrating the HEFS’s portability in the
Unix/Linux environment outside of National Weather Service (NWS). This study also
showed that the HEFS is an effective tool for generating skillful forecasts of precipitation
and streamflow ensembles. This study would provide water resources managers with
improved streamflow forecasts for the extended forecast lead time to effectively manage
water resources and to mitigate water-related hazards.},
  file      = {:Ensembles\\Medium-range Ensemble Precipitation and Streamflow Forecasting for the Upper Trinity River Basin in Texas Via the Nws Hydrologic Ensemble Forecast Service.pdf:PDF},
  timestamp = {2016-11-21},
}

@TechReport{Brown2014,
  author      = {James Brown},
  title       = {Verification of temperature, precipitation and streamflow forecasts from the Hydrologic Ensemble Forecast Service (HEFS) of the U.S. National Weather Service: an evaluation of the medium-range forecasts with forcing inputs from NCEP’s Global Ensemble Forecast System (GEFS) and a comparison to the frozen version of NCEP’s Global Forecast System (GFS)},
  institution = {United States National Weather Service},
  year        = {2014},
  number      = {2013-09},
  abstract    = {Retrospective forecasts of temperature, precipitation, and streamflow were generated with the Hydrologic Ensemble
Forecast Service (HEFS) of the U.S. National Weather Service (NWS) for selected river basins in four NWS River
Forecast Centers (RFCs), namely the Arkansas-Red Basin RFC (ABRFC), the Colorado Basin RFC (CBRFC), the
California-Nevada RFC (CNRFC) and the Middle Atlantic RFC (MARFC). The meteorological hindcasts were produced
with the HEFS Meteorological Ensemble Forecast Processor (MEFP). The MEFP was calibrated with forcing inputs
from the Global Ensemble Forecast System (GEFS) of the National Centers for Environmental Prediction (NCEP). The
streamflow hindcasts cover a ~15 year period from 1985-1999 with a forecast horizon of 1-14 days. Retrospective
forecasts were also produced with the frozen (circa 1997) version of NCEP’s Global Forecast System (GFS).The
hindcasts were verified conditionally upon forecast lead time, magnitude of the observed and forecast variables, and
season. Verification results are presented for the temperature and precipitation forecasts from the MEFP and for the
streamflow forecasts before and after bias-correction with the HEFS Ensemble Postprocessor (EnsPost). This report
presents the verification results, describes the expected performance and limitations of the HEFS for short- to mediumrange
forecasting with the GEFS, identifies the benefits of the GEFS when compared to the frozen GFS, and provides
recommendations on future research and additional evaluation of the HEFS.},
  file        = {:Ensembles\\Verification of temperature, precipitation and streamflow forecasts from the Hydrologic Ensemble Forecast Service (HEFS).pdf:PDF},
  timestamp   = {2016-11-21},
}

@Article{Hamill2013,
  author    = {Thomas M. Hamill and Gary T. Bates and Jeffrey S. Whitaker and Donald R. Murray and Michael Fiorino and Thomas J. Galarneau Jr. and Yuejian Zhu and William Lapenta},
  title     = {NOAA’s Second-Generation Global Medium-Range Ensemble Reforecast Dataset},
  journal   = {Bulletin of the American Meteorological Society},
  year      = {2013},
  pages     = {1553-1565},
  month     = {Oct},
  abstract  = {A multidecadal ensemble reforecast database is now available that is approximately consistent with the operational 0000 UTC cycle of the 2012 NOAA Global Ensemble Forecast System (GEFS). The reforecast dataset consists of an 11-member ensemble run once each day from 0000 UTC initial conditions. Reforecasts are run to +16 days. As with the operational 2012 GEFS, the reforecast is run at T254L42 resolution (approximately 1/2° grid spacing, 42 levels) for week +1 forecasts and T190L42 (approximately 3/4° grid spacing) for the week +2 forecasts. Reforecasts were initialized with Climate Forecast System Reanalysis initial conditions, and perturbations were generated using the ensemble transform with rescaling technique. Reforecast data are available from 1985 to present.

Reforecast datasets were previously demonstrated to be very valuable for detecting and correcting systematic errors in forecasts, especially forecasts of relatively rare events and longer-lead forecasts. What is novel about this reforecast dataset relative to the first-generation NOAA reforecast is that (i) a modern, currently operational version of the forecast model is used (the previous reforecast used a model version from 1998); (ii) a much larger set of output data has been saved, including variables relevant for precipitation, hydrologic, wind energy, solar energy, severe weather, and tropical cyclone forecasting; and (iii) the archived data are at much higher resolution.

The article describes more about the reforecast configuration and provides a few examples of how this second-generation reforecast data may be used for research and a variety of weather forecast applications.},
  file      = {:Ensembles\\NOAA’s Second-Generation Global Medium-Range Ensemble Reforecast Dataset.pdf:PDF},
  timestamp = {2016-11-21},
}

@Article{Maraun2013,
  author    = {Douglas Maraun},
  title     = {Bias Correction, Quantile Mapping, and Downscaling: Revisiting the Inflation Issue},
  journal   = {Journal of Climate},
  year      = {2013},
  volume    = {26},
  number    = {6},
  pages     = {2137--2143},
  month     = {mar},
  abstract  = {Quantile mapping is routinely applied to correct biases of regional climate model simulations compared to
observational data. If the observations are of similar resolution as the regional climate model, quantile
mapping is a feasible approach. However, if the observations are of much higher resolution, quantile mapping
also attempts to bridge this scale mismatch. Here, it is shown for daily precipitation that such quantile
mapping–based downscaling is not feasible but introduces similar problems as inflation of perfect prognosis
(‘‘prog’’) downscaling: the spatial and temporal structure of the corrected time series is misrepresented, the
drizzle effect for area means is overcorrected, area-mean extremes are overestimated, and trends are affected.
To overcome these problems, stochastic bias correction is required.},
  doi       = {10.1175/jcli-d-12-00821.1},
  file      = {:Ensembles\\Bias Correction, Quantile Mapping, and Downscaling- Revisiting the Inflation Issue.pdf:PDF},
  publisher = {American Meteorological Society},
  timestamp = {2016-11-22},
  url       = {http://dx.doi.org/10.1175/JCLI-D-12-00821.1},
}

@Article{Pappenberger2015,
  author     = {Pappenberger, F. and Ramos, M. H. and Cloke, H. L. and Wetterhall, F. and Alfieri, L. and Bogner, K. and Mueller, A. and Salamon, P.},
  title      = {How do {I} know if my forecasts are better? {Using} benchmarks in hydrological ensemble prediction},
  journal    = {Journal of Hydrology},
  year       = {2015},
  volume     = {522},
  pages      = {697--713},
  month      = mar,
  abstract   = {Summary
The skill of a forecast can be assessed by comparing the relative proximity of both the forecast and a benchmark to the observations. Example benchmarks include climatology or a naïve forecast. Hydrological ensemble prediction systems (HEPS) are currently transforming the hydrological forecasting environment but in this new field there is little information to guide researchers and operational forecasters on how benchmarks can be best used to evaluate their probabilistic forecasts. In this study, it is identified that the forecast skill calculated can vary depending on the benchmark selected and that the selection of a benchmark for determining forecasting system skill is sensitive to a number of hydrological and system factors. A benchmark intercomparison experiment is then undertaken using the continuous ranked probability score (CRPS), a reference forecasting system and a suite of 23 different methods to derive benchmarks. The benchmarks are assessed within the operational set-up of the European Flood Awareness System (EFAS) to determine those that are ‘toughest to beat’ and so give the most robust discrimination of forecast skill, particularly for the spatial average fields that EFAS relies upon.

Evaluating against an observed discharge proxy the benchmark that has most utility for EFAS and avoids the most naïve skill across different hydrological situations is found to be meteorological persistency. This benchmark uses the latest meteorological observations of precipitation and temperature to drive the hydrological model. Hydrological long term average benchmarks, which are currently used in EFAS, are very easily beaten by the forecasting system and the use of these produces much naïve skill. When decomposed into seasons, the advanced meteorological benchmarks, which make use of meteorological observations from the past 20 years at the same calendar date, have the most skill discrimination. They are also good at discriminating skill in low flows and for all catchment sizes. Simpler meteorological benchmarks are particularly useful for high flows. Recommendations for EFAS are to move to routine use of meteorological persistency, an advanced meteorological benchmark and a simple meteorological benchmark in order to provide a robust evaluation of forecast skill. This work provides the first comprehensive evidence on how benchmarks can be used in evaluation of skill in probabilistic hydrological forecasts and which benchmarks are most useful for skill discrimination and avoidance of naïve skill in a large scale HEPS. It is recommended that all HEPS use the evidence and methodology provided here to evaluate which benchmarks to employ; so forecasters can have trust in their skill evaluation and will have confidence that their forecasts are indeed better.},
  doi        = {10.1016/j.jhydrol.2015.01.024},
  file       = {:Ensembles\\How do I know if my forecasts are better- Using benchmarks in hydrological ensemble prediction.pdf:PDF},
  issn       = {0022-1694},
  keywords   = {Benchmark, Evaluation, Forecast performance, Hydrological ensemble prediction, Probabilistic forecasts, Verification},
  shorttitle = {How do {I} know if my forecasts are better?},
  timestamp  = {2016-11-22},
  url        = {http://www.sciencedirect.com/science/article/pii/S0022169415000414},
  urldate    = {2016-10-22},
}

@MastersThesis{Lerch2012,
  author    = {Sebastian Lerch},
  title     = {Verification of probabilistic forecasts for rare and extreme events},
  school    = {Ruprecht-Karls-Universit¨at Heidelberg},
  year      = {2012},
  month     = {jul},
  abstract  = {Accurate predictions of extreme events are of critical importance for avoiding human
losses and economic damages. Over the last decades, the conviction that
forecasts should be probabilistic in nature has gained ground. To assess forecast
quality, theoretically justifiable evaluation procedures for the verification of probabilistic
forecasts for extreme events thus have to be developed. Despite the large
variety of verification methods for general probabilistic forecasts, there is a notable
lack of evaluation procedures tailored to extreme events. In many contexts,
particularly in the public and media, forecast evaluation takes place by restricting
the standard evaluation procedures to subsets of extreme events. However, we
demonstrate that conditioning the observation on being an extreme event leads
to the use of improper verification procedures that may discredit even the most
skillful forecasters. Recently, two novel approaches to the forecast verification
for extreme events have been proposed in the economic literature using weighted
scoring rules that emphasize specific regions of interest. We develop a general
framework for forecast evaluation and analyze these approaches within this framework
using a simulation study and a data example. Furthermore, a new approach
to forecast evaluation conditional on extreme ensemble predictions and a simple
regime-switching forecasting procedure for wind speed are proposed.},
  file      = {:Ensembles\\Verification of probabilistic forecasts for rare and extreme events.pdf:PDF},
  timestamp = {2016-11-22},
}

@Article{Ouarda2001,
  author    = {T. B. M. J. Ouarda and J. W. Labadie},
  title     = {Chance-constrained optimal control for multireservoir system optimization and risk analysis},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2001},
  volume    = {15},
  number    = {technical},
  pages     = {185-204},
  abstract  = {A vast array of techniques have been developed and applied to optimal
operation of large-scale multireservoir systems. Researchers continue to be 
challenged by the highly complex, stochastic, nonlinear, and high dimensional 
nature of this dynamic optimization problem. An optimal control model is 
presented which incorporates chance-constraints on system state variables that 
assure satisfaction of operational restrictions under specifed levels of reliability. 
The chance-constrained optimal control (CCOC) model is tested on a four-
reservoir case study, and its performance assessed based on various quantitative 
and qualitative criteria, including maintenance of acceptable levels of risk and 
provision of risk-beneft trade-off information. The concepts of reliability, 
resiliency and vulnerability are utilized to characterize operating policies 
generated by the algorithm. CCOC is recommended for operational guidance of 
large-scale multireservoir systems due to its robustness, fexibility, modest 
computational requirements, and ability to include risk considerations directly 
impacting the choice of operational schemes.},
  file      = {:Optimization\\Chance-constrained optimal control for multireservoir system optimization and risk analysis.pdf:PDF},
  timestamp = {2016-11-22},
}

@Article{Raso2012,
  author    = {L. Raso and N. van de Giesen and P. Stive and D. Schwanenberg and P. J. van Overloop},
  title     = {Tree structure generation from ensemble forecasts for real time control},
  journal   = {Hydrological Processes},
  year      = {2012},
  volume    = {27},
  number    = {1},
  pages     = {75--82},
  month     = {sep},
  abstract  = {This paper presents a new methodology to generate a tree from an ensemble. The reason to generate a tree is to use the ensemble
in multistage stochastic programming. A correct tree structure is of critical importance because it strongly affects the performance
of the optimization. A tree, in contrast to an ensemble, specifies when its trajectories diverge from each other.
A tree can be generated from the ensemble data by aggregating trajectories over time until the difference between them becomes
such that they can no longer be assumed to be similar, at such a point, the tree branches.
The proposed method models the information flow: it takes into account which observations will become available, at which
moment, and their level of uncertainty, i.e. their probability distributions (pdf). No conditions are imposed on those distributions.
The method is well suited to trajectories that are close to each other at the beginning of the forecasting horizon and spread out
going on in time, as ensemble forecasts typically are.},
  doi       = {10.1002/hyp.9473},
  file      = {:Ensembles\\Tree structure generation from ensemble forecasts for real time control.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-11-22},
  url       = {http://dx.doi.org/10.1002/hyp.9473},
}

@Article{Nolde2008,
  author    = {Kristian Nolde and Markus Uhr and Manfred Morari},
  title     = {Medium term scheduling of a hydro-thermal system using stochastic model predictive control},
  journal   = {Automatica},
  year      = {2008},
  volume    = {44},
  number    = {6},
  pages     = {1585--1594},
  month     = {jun},
  abstract  = {A multistage stochastic programming formulation is presented for monthly production planning of a hydro-thermal system. Stochasticity from
variations in water reservoir inflows and fluctuations in demand of electric energy are considered explicitly. The problem can be solved efficiently
via Nested Benders Decomposition. The solution is implemented in a model predictive control setup and performance of this control technique is
demonstrated in simulations. Tuning parameters, such as prediction horizon and shape of the stochastic programming tree are identified and their
effects are analyzed.},
  doi       = {10.1016/j.automatica.2008.03.002},
  file      = {:Optimization\\Medium term scheduling of a hydro-thermal system using stochastic model predictive control.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-22},
  url       = {http://dx.doi.org/10.1016/j.automatica.2008.03.002},
}

@Article{Castelletti2008,
  author    = {Andrea Castelletti and Francesca Pianosi and Rodolfo Soncini-Sessa},
  title     = {Water reservoir control under economic, social and environmental constraints},
  journal   = {Automatica},
  year      = {2008},
  volume    = {44},
  number    = {6},
  pages     = {1595--1607},
  month     = {jun},
  abstract  = {Although great progress has been made in the last 40 years, efficient operation of water reservoir systems still remains a very active research
area. The combination of multiple water uses, non-linearities in the model and in the objectives, strong uncertainties in inputs and high dimensional
state make the problem challenging and intriguing. The purpose of this paper is to review, in a strict Control Theory perspective, recent and
significant advances in designing management policies for water reservoir networks, under economic, social and environmental constraints. A
general and thorough problem formulation is provided, along with a description of traditional solution techniques, their limitations and possible
alternative approaches.},
  doi       = {10.1016/j.automatica.2008.03.003},
  file      = {:Reservoirs\\Water reservoir control under economic, social and environmental constraints.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-22},
  url       = {http://dx.doi.org/10.1016/j.automatica.2008.03.003},
}

@Article{Overloop2008,
  author    = {Peter-Jules van Overloop and Steven Weijs and Sjoerd Dijkstra},
  title     = {Multiple Model Predictive Control on a drainage canal system},
  journal   = {Control Engineering Practice},
  year      = {2008},
  volume    = {16},
  pages     = {531--540},
  abstract  = {Model Predictive Control has been implemented on a large drainage canal system in the Netherlands. This water system can be
represented as a reservoir with uncertain inflow due to rainfall runoff and a water level that has to be kept within a certain range by a
control flow that is limited in capacity. Tests demonstrate that Model Predictive Control outperforms feedback and feedforward
controls. To deal with uncertainty in the expected inflow, Multiple Model Predictive Control (MMPC) is proposed. This controller
minimizes an objective function in which the risk of damage is used by applying different scenarios to multiple identical models.},
  file      = {:Optimization\\Multiple Model Predictive Control on a drainage canal system.pdf:PDF},
  keywords  = {Model predictive control; Multiple model optimisation; Multi-objective optimisations; Uncertainty; Open water systems; Risk},
  timestamp = {2016-11-22},
}

@Article{Toriello2016,
  author        = {Toriello, Alejandro and Uhan, Nelson A.},
  title         = {Dynamic linear programming games with risk-averse players},
  journal       = {Mathematical Programming},
  year          = {2016},
  month         = jul,
  issn          = {0025-5610, 1436-4646},
  __markedentry = {[quebbs:1]},
  abstract      = {Motivated by situations in which independent agents wish to cooperate in
some uncertain endeavor over time, we study dynamic linear programming games,
which generalize classical linear production games to multi-period settings under
uncertainty. We specifically consider that players may have risk-averse attitudes
towards uncertainty, and model this risk aversion using coherent conditional risk measures. For this setting, we study the strong sequential core, a natural extension of
the core to dynamic settings. We characterize the strong sequential core as the set of
allocations that satisfy a particular finite set of inequalities that depend on an auxiliary
optimization model, and then leverage this characterization to establish sufficient conditions for emptiness and non-emptiness. Qualitatively, whereas the strong sequential
core is always non-empty when players are risk-neutral, our results indicate that cooperation in the presence of risk aversion is much more difficult. We illustrate this with
an application to cooperative newsvendor games, where we find that cooperation is
possible when it least benefits players, and may be impossible when it offers more
benefit.},
  doi           = {10.1007/s10107-016-1054-y},
  file          = {:Optimization\\Dynamic linear programming games with risk-averse players.pdf:PDF},
  keywords      = {Cooperative game · Stochastic linear program · Risk measure},
  language      = {en},
  timestamp     = {2016-11-22},
  url           = {http://link.springer.com/10.1007/s10107-016-1054-y},
  urldate       = {2016-11-11},
}

@InCollection{Densing2013,
  author        = {Densing, Martin},
  title         = {Price-driven hydropower dispatch under uncertainty},
  booktitle     = {Handbook of {Risk} {Management} in {Energy} {Production} and {Trading}},
  publisher     = {Springer},
  year          = {2013},
  pages         = {73--104},
  __markedentry = {[quebbs:1]},
  abstract      = {After a review of hydropower optimization models, we focus on pricedriven hydropower dispatch models under uncertainty of the electricity price. We
present two modeling approaches for pumped-storage plants. In the first model, the
water level is constrained in expectation. We discuss the marginal price of water,
which is obtained analytically, and influences of price variances. The second model
is a multistage stochastic linear program on a scenario tree. Financial risk is constrained by a time-consistent extension of CVaR (conditional-value-at-risk). The
model has two time scales: The short-term dispatch decision is separated from the
long-term planning by aggregating electricity prices into occupation times at price
levels. The risk constraint is tested in a case study.},
  file          = {:Optimization\\Price-Driven Hydropower Dispatch Under Uncertainty.pdf:PDF},
  timestamp     = {2016-11-22},
  url           = {http://link.springer.com/chapter/10.1007/978-1-4614-9035-7_4},
  urldate       = {2016-11-11},
}

@Article{Gneiting2005,
  author    = {Tilmann Gneiting and Adrian E. Raftery},
  title     = {Weather forecasting with ensemble methods},
  journal   = {Science},
  year      = {2005},
  volume    = {310},
  number    = {5746},
  pages     = {247--248},
  month     = {oct},
  abstract  = {Aradical change has occurred in the
practice of numerical weather prediction
over the past decade. Until
the early 1990s, atmospheric scientists
viewed weather forecasting as an intrinsically
deterministic endeavor: For a given
set of “best” input data, one “best” weather
prediction is generated. Armed with sophisticated
computing resources (including
supercomputers), weather centers ran carefully
designed numerical weather prediction
models to produce deterministic forecasts
of future atmospheric states. Although
this is still the case today, weather prediction
has been transformed through the
implementation of ensemble forecasts. An
ensemble forecast comprises multiple (typically
between 5 and 100) runs of numerical
weather prediction models, which differ in
the initial conditions and/or the numerical
representation of the atmosphere, thereby
addressing the two major sources of forecast
uncertainty.},
  doi       = {10.1126/science.1120154},
  file      = {:Ensembles\\Weather forecasting with ensemble methods.pdf:PDF},
  publisher = {American Association for the Advancement of Science ({AAAS})},
  timestamp = {2016-11-22},
  url       = {http://dx.doi.org/10.1126/science.1120154},
}

@Article{Abaza2014,
  author    = {Mabrouk Abaza and Fran{\c{c}}ois Anctil and Vincent Fortin and Richard Turcotte},
  title     = {Sequential streamflow assimilation for short-term hydrological ensemble forecasting},
  journal   = {Journal of Hydrology},
  year      = {2014},
  volume    = {519},
  pages     = {2692--2706},
  month     = {nov},
  abstract  = {This paper evaluates the application of the Ensemble Kalman Filter (EnKF) for streamflow assimilation
within an ensemble prediction system designed for short-term hydrological forecasting at the outlet of
the au Saumon watershed. The EnKF updates three state variables of a distributed hydrological model
(soil moisture in the intermediate layer, soil moisture in the deep layer, and land routing) to improve
the initial conditions of the forecasts. A systematic method for the identification of the perturbation factors (ensemble generation) and for the selection of the ensemble size is discussed. EnKF results show a
substantial improvement in performance and reliability over the open-loop estimates. Manual assimilation was also assessed and led to a performance similar to the EnKF; however, the EnKF forecasts are substantially more reliable. While an ensemble size of 1000 members was required to fully sample the
hydrological and meteorological uncertainty, similar results are obtained in terms of skill when limiting
the ensemble size to 50.},
  doi       = {10.1016/j.jhydrol.2014.08.038},
  file      = {:Ensembles\\Sequential streamflow assimilation for short-term hydrological ensemble forecasting.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-11-22},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2014.08.038},
}

@TechReport{Twedt1977,
  author      = {T.M. Twedt and J.C. Schaake and E.L. Peck},
  title       = {Extended Streamflow Prediction},
  institution = {National Weather Service},
  year        = {1977},
  file        = {:Ensembles\\Extended Streamflow Prediction.pdf:PDF},
  timestamp   = {2016-12-05},
}

@TechReport{Laurine1993,
  author      = {Donald P. Laurine and Cara S. McCarthy},
  title       = {Extended Streamflow Prediction, Analysis, and Display Program (ESPADP)},
  institution = {NOAA/National Weather Service},
  year        = {1993},
  month       = {mar},
  file        = {:Ensembles\\Extended Streamflow Prediction, Analysis, and Display Program.pdf:PDF},
  timestamp   = {2016-12-05},
}

@TechReport{Balsamo2015,
  author      = {Gianpaolo Balsamo},
  title       = {Global Earth Observation for integrated water resource assessment},
  institution = {eartH2Observe},
  year        = {2015},
  abstract    = {This report describes the first water resources reanalysis (WRR-tier1) produced by 8 project partners
and 2 external partners. The report contains a description of the modelling protocol, the modelling
systems and the data access and quality control performed. The modelling systems include four land
surface models, 5 global hydrological models and a simple water balance model. This first version of
the WRR is based on the current modelling systems of each partner forced with a state-of-the-art
atmospheric reanalysis. The 9 modelling systems simulations are available in the data server, and the
meta-data and overall quality of the dataset and accessibility has been verified to a general standard.
This first release is meant to set a benchmark dataset for future testing of the enhanced reanalysis in
tier 2 and to enable the WP3-WP4-WP6 interactions. This report only provides a descriptive document
to serve and enable the work of the remaining project work packages and is associated with the
milestone MS6 (WRR tier 1 available for other work packages). 

The forcing dataset is freely available at both 3 hourly and daily frequencies in the data server at:
https://wci.earth2observe.eu/thredds/catalog/ecmwf/met_forcing_v0/catalog.html
The files are organized in folders for each month containing separate files for each variable and can be
accessed via direct HTTP download or OPENDAP:
Using HTTP:
http://wci.earth2observe.eu/thredds/fileServer/ecmwf/met_forcing_v0/[YEAR]/[VAR]_E2OBS_[YEAR][MONTH].nc
e.g
http://wci.earth2observe.eu/thredds/fileServer/ecmwf/met_forcing_v0/1992/LWdown_E2OBS_199202.nc},
  file        = {:Climate\\Global Earth Observation for integrated water resource assessment.pdf:PDF},
  timestamp   = {2016-12-21},
}

@Article{Weedon2014,
  author    = {Graham P. Weedon and Gianpaolo Balsamo and Nicolas Bellouin and Sandra Gomes and Martin J. Best and Pedro Viterbo},
  title     = {The {WFDEI} meteorological forcing data set: {WATCH} Forcing Data methodology applied to {ERA}-Interim reanalysis data},
  journal   = {Water Resources Research},
  year      = {2014},
  volume    = {50},
  number    = {9},
  pages     = {7505--7514},
  month     = {sep},
  note      = {See associated README file ftp://rfdata:forceDATA@ftp.iiasa.ac.at a},
  abstract  = {The WFDEI meteorological forcing data set has been generated using the same methodology
as the widely used WATCH Forcing Data (WFD) by making use of the ERA-Interim reanalysis data. We discuss
the specifics of how changes in the reanalysis and processing have led to improvement over the WFD. We
attribute improvements in precipitation and wind speed to the latest reanalysis basis data and improved
downward shortwave fluxes to the changes in the aerosol corrections. Covering 1979–2012, the WFDEI will
allow more thorough comparisons of hydrological and Earth System model outputs with hydrologically and
phenologically relevant satellite products than using the WFD.

ftp://rfdata:forceDATA@ftp.iiasa.ac.at a},
  doi       = {10.1002/2014wr015638},
  file      = {:Climate\\The WFDEI meteorological forcing data set- WATCH Forcing Data methodology applied to ERO-Interim reanalysis data.pdf:PDF;:Climate\\The WFDEI meteorological forcing data set- WATCH Forcing Data methodology applied to ERO-Interim reanalysis data_README.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-12-21},
  url       = {http://dx.doi.org/10.1002/2014WR015638},
}

@Article{Gaborit2016,
  author    = {Étienne Gaborit and Vincent Fortin and Xiaoyong Xu and Frank Seglenieks and Bryan Tolson and Lauren M. Fry and Tim Hunter and François Anctil and Andrew D. Gronewold},
  title     = {A Hydrological Prediction System Based on the SVS Land-Surface Scheme: Implementation and Evaluation of the GEM-Hydro platform on the watershed of Lake Ontario},
  journal   = {Hydrol. Earth Syst. Sci.},
  year      = {2016},
  abstract  = {This work describes the implementation of the distributed GEM-Hydro runoff modeling platform, developed at
Environment and Climate Change Canada (ECCC) over the last decade. The latest version of GEM-Hydro combines the
SVS (Soil, Vegetation and Snow) land-surface scheme and the WATROUTE routing scheme in order to provide streamflow
predictions on a gridded river network. SVS is designed to be two-way coupled to the GEM (Global Environmental Multiscale) atmospheric model exploited by ECCC for operational weather and environmental forecasting. Although SVS has
20 been shown to accurately track soil moisture during the warm season, it has never been evaluated before for hydrological
prediction. This paper presents a first evaluation of its ability to simulate streamflow for all major rivers flowing into Lake
Ontario. The skill level of GEM-Hydro is assessed by comparing the quality of simulated flows to that of two established
hydrological models, MESH and WATFLOOD, which share the same routing scheme (WATROUTE) but rely on different
land-surface schemes. All models are calibrated using the same meteorological forcings, objective function, calibration
25 algorithm, and watershed delineation. Results show that GEM-Hydro performs well and is competitive with MESH and
WATFLOOD. A computationally efficient strategy is proposed to calibrate the land-surface model of GEM-Hydro: a simple
unit hydrograph is used for routing instead of its standard distributed routing component. The distributed routing part of the
model can then be run in a second step to estimate streamflow everywhere inside the domain. Global and local calibration
strategies are compared in order to estimate runoff for ungauged portions of the Lake Ontario watershed. Overall,
30 streamflow predictions obtained using a global calibration strategy, in which a single parameter set is identified for the
whole watershed of Lake Ontario, show skills comparable to the predictions based on local calibration. Hence, global
calibration provides spatially consistent parameter values, robust performance at gauged locations, and reduces the
complexity and computational burden of the calibration procedure. This work contributes to the Great Lakes Runoff Intercomparison Project for Lake Ontario (GRIP-O) which aims at improving Lake Ontario basin runoff simulations by
comparing different models using the same input forcings.},
  doi       = {10.5194/hess-2016-508},
  file      = {:Hydrology\\A Hydrological Prediction System Based on the SVS Land-Surface Scheme- Implementation and Evaluation of the GEM-Hydro platform on the watershed of Lake Ontario.pdf:PDF},
  keywords  = {Distributed models, GEM-Hydro, Local and global calibrations, Ungauged catchments, Unit hydrograph.},
  timestamp = {2016-12-22},
}

@Article{Beven1979,
  author    = {K. J. Beven and M. J. Kirkby},
  title     = {A physically based, variable contributing area model of basin hydrology / Un mod{\`{e}}le {\`{a}} base physique de zone d{\textquotesingle}appel variable de l{\textquotesingle}hydrologie du bassin versant},
  journal   = {Hydrological Sciences Bulletin},
  year      = {1979},
  volume    = {24},
  number    = {1},
  pages     = {43--69},
  month     = {mar},
  abstract  = {A hydrological forecasting model is presented that attempts to combine the important
distributed effects of channel network topology and dynamic contributing areas with the advantages
of simple lumped parameter basin models. Quick response flow is predicted from a storage/contributing area relationship derived analytically from the topographic structure of a unit within a
basin. Average soil water response is represented by a constant leakage infiltration store and an
exponential subsurface water store. A simple non-linear routing procedure related to the link
frequency distribution of the channel network completes the model and allows distinct basin
sub-units, such as headwater and sideslope areas to be modelled separately. The model parameters
are physically based in the sense that they may be determined directly by measurement and the
model may be used at ungauged sites. Procedures for applying the model and tests with data from
the Crimple Beck basin are described. Using only measured and estimated parameter values, without optimization, the model makes satisfactory predictions of basin response. The modular form of
the model structure should allow application over a range of small and medium sized basins while
retaining the possibility of including more complex model components when suitable data are
available.},
  doi       = {10.1080/02626667909491834},
  file      = {:Hydrology\\A physically based variable contributing area model of basin hydrology.pdf:PDF},
  keywords  = {HSPF},
  publisher = {Informa {UK} Limited},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1080/02626667909491834},
}

@Article{Viviroli2009,
  author    = {D. Viviroli and M. Zappa and J. Gurtz and R. Weingartner},
  title     = {An introduction to the hydrological modelling system {PREVAH} and its pre- and post-processing-tools},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2009},
  volume    = {24},
  number    = {10},
  pages     = {1209--1222},
  month     = {oct},
  abstract  = {Spatially distributed modelling is an important instrument for studying the hydrological cycle, both
concerning its present state as well as possible future changes in climate and land use. Results of such
simulations are particularly relevant for the fields of water resources, natural hazards and hydropower.
The semi-distributed hydrological modelling system PREVAH (PREecipitation-Runoff-EVApotranspiration HRU Model) implements a conceptual process-oriented approach and has been developed especially
to suit conditions in mountainous environments with their highly variable environmental and climatic
conditions.
This article presents an overview of the actual model core of PREVAH and introduces the various tools
which have been developed for obtaining a comprehensive, user-friendly modelling system: DATAWIZARD for importing and managing hydrometeorological data, WINMET for pre-processing meteorological data, GRIDMATH for carrying out elementary raster data operations, FAOSOIL for processing FAO
World Soil Map information, WINHRU for pre-processing spatial data and aggregating hydrological
response units (HRU), WINPREVAH for operating the model, HYDROGRAPH for visualising hydrograph
data and VIEWOPTIM for visualising the calibration procedure. The PREVAH components introduced here
support a modelling task from pre-processing the data over the actual model calibration and validation
to visualising and interpreting the results (post-processing). A brief overview of current PREVAH
applications demonstrates the flexibility of the modelling system with examples that range from water
balance modelling over flood estimation and flood forecasting to drought analysis in Switzerland,
Austria, China, Russia and Sweden.},
  doi       = {10.1016/j.envsoft.2009.04.001},
  file      = {:Hydrology\\An introduction to the hydrological modelling system PREVAH and its pre- and post-processing tools.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1016/j.envsoft.2009.04.001},
}

@Article{Bell2007,
  author    = {Bell, V. A. and Kay, A. L. and Jones, R. G. and Moore, R. J.},
  title     = {Development of a high resolution grid-based river flow model for use with regional climate model output},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2007},
  volume    = {11},
  number    = {1},
  pages     = {532--549},
  doi       = {10.5194/hess-11-532-2007},
  timestamp = {2016-12-22},
  url       = {http://www.hydrol-earth-syst-sci.net/11/532/2007/},
}

@Article{Kerkhoven2011,
  author    = {E. Kerkhoven and T.Y. Gan},
  title     = {Unconditional uncertainties of historical and simulated river flows subjected to climate change},
  journal   = {Journal of Hydrology},
  year      = {2011},
  volume    = {396},
  number    = {1-2},
  pages     = {113--127},
  month     = {jan},
  abstract  = {The objective of this study was to estimate the unconditional sample uncertainty of observed streamflows and streamflows simulated from a hydrologic model (MISBA) for the Fraser River Basin (FRB)
and the Athabasca River Basin (ARB) of Canada under historic conditions and under future conditions
simulated by General Circulation Models (GCMs). For each basin, the multifractal properties of 54 simulated hydrographs based on the predictions of seven GCMs and four climate scenarios over three 30-year
periods of the 21st century were evaluated and used to generate extended artificial time series by the
randomized generalized multifractal cascade model. Uncertainty estimates derived from this multifractal
approach were compared with classical statistics, Hurst exponent, and autocorrelation methods. The
multifractal approach resulted in greater departures from statistical independence, higher skewness,
and a wider range of flows over a 30-year time scale than the other methods. Under climate change,
the multifractal strength of streamflows of FRB increased with temperature as the snow fed character
of the basin weakened, but in the colder ARB, a decrease in multifractal strength resulted under rising
temperatures because of declined snow packs. The estimated unconditional sample uncertainty was
compared with uncertainty associated with model and emissions scenario selection. Among four major
sources of uncertainty, uncertainty associated with two different hydrologic models (MISBA and SACSMA) and global emission patterns in the 21st century were relatively small (20% or less) even though
for the latter, the range of SRES climate scenarios may not be representative of future economy and
the seven GCMs may not accurately represent actual physical processes. The uncertainties associated
with multifractal variation were the largest, on the order of ±50%},
  doi       = {10.1016/j.jhydrol.2010.10.042},
  file      = {:Hydrology\\Unconditional uncertainties of historical and simulated river flows subjected to climate change.pdf:PDF},
  keywords  = {Athabasca and Fraser River Basins Hydrologic model structure Unconditional uncertainties Multifractal detrended fluctuation analysis Generalized multifractal cascade model SRES climate scenarios},
  publisher = {Elsevier {BV}},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2010.10.042},
}

@Article{Kasprzyk2013,
  author    = {Joseph R. Kasprzyk and Shanthi Nataraj and Patrick M. Reed and Robert J. Lempert},
  title     = {Many objective robust decision making for complex environmental systems undergoing change},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2013},
  volume    = {42},
  pages     = {55--71},
  month     = {apr},
  abstract  = {This paper introduces many objective robust decision making (MORDM). MORDM combines concepts
and methods from many objective evolutionary optimization and robust decision making (RDM), along
with extensive use of interactive visual analytics, to facilitate the management of complex environmental
systems. Many objective evolutionary search is used to generate alternatives for complex planning
problems, enabling the discovery of the key tradeoffs among planning objectives. RDM then determines
the robustness of planning alternatives to deeply uncertain future conditions and facilitates decision
makers’ selection of promising candidate solutions. MORDM tests each solution under the ensemble of
future extreme states of the world (SOW). Interactive visual analytics are used to explore whether solutions of interest are robust to a wide range of plausible future conditions (i.e., assessment of their
Pareto satisficing behavior in alternative SOW). Scenario discovery methods that use statistical data
mining algorithms are then used to identify what assumptions and system conditions strongly influence
the cost-effectiveness, efficiency, and reliability of the robust alternatives. The framework is demonstrated using a case study that examines a single city’s water supply in the Lower Rio Grande Valley
(LRGV) in Texas, USA. Results suggest that including robustness as a decision criterion can dramatically
change the formulation of complex environmental management problems as well as the negotiated
selection of candidate alternatives to implement. MORDM also allows decision makers to characterize
the most important vulnerabilities for their systems, which should be the focus of ex post monitoring
and identification of triggers for adaptive management.},
  doi       = {10.1016/j.envsoft.2012.12.007},
  file      = {:MCDA\\Many objective robust decision making for complex environmental systems undergoing change.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1016/j.envsoft.2012.12.007},
}

@Article{Herman2015,
  author    = {Jonathan D. Herman and Patrick M. Reed and Harrison B. Zeff and Gregory W. Characklis},
  title     = {How Should Robustness Be Defined for Water Systems Planning under Change?},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2015},
  volume    = {141},
  number    = {10},
  abstract  = {Water systems planners have long recognized the need for robust solutions capable of withstanding deviations from the conditions
for which they were designed. Robustness analyses have shifted from expected utility to exploratory bottom-up approaches which identify
vulnerable scenarios prior to assigning likelihoods. Examples include Robust Decision Making (RDM), Decision Scaling, Info-Gap, and
Many-Objective Robust Decision Making (MORDM). We propose a taxonomy of robustness frameworks to compare and contrast these
approaches based on their methods of (1) alternative generation, (2) sampling of states of the world, (3) quantification of robustness measures,
and (4) sensitivity analysis to identify important uncertainties. Building from the proposed taxonomy, we use a regional urban water supply
case study in the Research Triangle region of North Carolina to illustrate the decision-relevant consequences that emerge from each of these
choices. Results indicate that the methodological choices in the taxonomy lead to the selection of substantially different planning alternatives,
underscoring the importance of an informed definition of robustness. Moreover, the results show that some commonly employed methodological choices and definitions of robustness can have undesired consequences when ranking decision alternatives. For the demonstrated
test case, recommendations for overcoming these issues include: (1) decision alternatives should be searched rather than prespecified,
(2) dominant uncertainties should be discovered through sensitivity analysis rather than assumed, and (3) a carefully elicited multivariate
satisficing measure of robustness allows stakeholders to achieve their problem-specific performance requirements. This work emphasizes
the importance of an informed problem formulation for systems facing challenging performance tradeoffs and provides a common vocabulary
to link the robustness frameworks widely used in the field of water systems planning},
  doi       = {10.1061/(ASCE)WR.1943-5452.0000509},
  file      = {:MCDA\\How Should Robustness Be Defined for Water Systems Planning under Change.pdf:PDF},
  timestamp = {2016-12-22},
}

@Article{Herman2014,
  author    = {Jonathan D. Herman and Harrison B. Zeff and Patrick M. Reed and Gregory W. Characklis},
  title     = {Beyond optimality: Multistakeholder robustness tradeoffs for regional water portfolio planning under deep uncertainty},
  journal   = {Water Resources Research},
  year      = {2014},
  volume    = {50},
  number    = {10},
  pages     = {7692--7713},
  month     = {oct},
  abstract  = {While optimality is a foundational mathematical concept in water resources planning and management, ‘‘optimal’’ solutions may be vulnerable to failure if deeply uncertain future conditions deviate
from those assumed during optimization. These vulnerabilities may produce severely asymmetric impacts
across a region, making it vital to evaluate the robustness of management strategies as well as their impacts
for regional stakeholders. In this study, we contribute a multistakeholder many-objective robust decision
making (MORDM) framework that blends many-objective search and uncertainty analysis tools to discover
key tradeoffs between water supply alternatives and their robustness to deep uncertainties (e.g., population
pressures, climate change, and financial risks). The proposed framework is demonstrated for four interconnected water utilities representing major stakeholders in the ‘‘Research Triangle’’ region of North Carolina,
U.S. The utilities supply well over one million customers and have the ability to collectively manage drought
via transfer agreements and shared infrastructure. We show that water portfolios for this region that compose optimal tradeoffs (i.e., Pareto-approximate solutions) under expected future conditions may suffer significantly degraded performance with only modest changes in deeply uncertain hydrologic and economic
factors. We then use the Patient Rule Induction Method (PRIM) to identify which uncertain factors drive the
individual and collective vulnerabilities for the four cooperating utilities. Our framework identifies key stakeholder dependencies and robustness tradeoffs associated with cooperative regional planning, which are
critical to understanding the tensions between individual versus regional water supply goals. Cooperative
demand management was found to be the key factor controlling the robustness of regional water supply
planning, dominating other hydroclimatic and economic uncertainties through the 2025 planning horizon.
Results suggest that a modest reduction in the projected rate of demand growth (from approximately 3%
per year to 2.4%) will substantially improve the utilities’ robustness to future uncertainty and reduce the
potential for regional tensions. The proposed multistakeholder MORDM framework offers critical insights
into the risks and challenges posed by rising water demands and hydrological uncertainties, providing a
planning template for regions now forced to confront rapidly evolving water scarcity risks.},
  doi       = {10.1002/2014wr015338},
  file      = {:MCDA\\Beyond optimality- Multistakeholder robustness tradeoffs for regional water portfolio planning under deep uncertainty.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1002/2014WR015338},
}

@Article{Haasnoot2013,
  author    = {Marjolijn Haasnoot and Jan H. Kwakkel and Warren E. Walker and Judith ter Maat},
  title     = {Dynamic adaptive policy pathways: A method for crafting robust decisions for a deeply uncertain world},
  journal   = {Global Environmental Change},
  year      = {2013},
  volume    = {23},
  number    = {2},
  pages     = {485--498},
  month     = {apr},
  doi       = {10.1016/j.gloenvcha.2012.12.006},
  file      = {:MCDA\\Dynamic adaptive policy pathways- A method for crafting robust decisions for a deeply uncertain world.pdf:PDF},
  keywords  = {Uncertainty Policymaking Adaptation pathways Adaptive policies Water management Rhine delta},
  publisher = {Elsevier {BV}},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1016/j.gloenvcha.2012.12.006},
}

@Article{Matrosov2013,
  author    = {Evgenii S. Matrosov and Ashley M. Woods and Julien J. Harou},
  title     = {Robust Decision Making and Info-Gap Decision Theory for water resource system planning},
  journal   = {Journal of Hydrology},
  year      = {2013},
  volume    = {494},
  pages     = {43--58},
  month     = {jun},
  abstract  = {Stationarity assumptions of linked human–water systems are frequently invalid given the difficult-topredict changes affecting such systems. In this case water planning occurs under conditions of deep or
severe uncertainty, where the statistical distributions of future conditions and events are poorly known.
In such situations predictive system simulation models are typically run under different scenarios to
evaluate the performance of future plans under different conditions. Given that there are many possible
plans and many possible futures, which simulations will lead to the best designs? Robust Decision Making (RDM) and Info-Gap Decision Theory (IGDT) provide a structured approach to planning complex systems under such uncertainty. Both RDM and IGDT make repeated use of trusted simulation models to
evaluate different plans under different future conditions. Both methods seek to identify robust rather
than optimal decisions, where a robust decision works satisfactorily over a broad range of possible
futures. IGDT efficiently charts system performance with robustness and opportuneness plots summarising system performance for different plans under the most dire and favourable sets of future conditions.
RDM samples a wider range of dire, benign and opportune futures and offers a holistic assessment of the
performance of different options. RDM also identifies through ‘scenario discovery’ which combinations of
uncertain future stresses lead to system vulnerabilities. In our study we apply both frameworks to a
water resource system planning problem: London’s water supply system expansion in the Thames basin,
UK. The methods help identify which out of 20 proposed water supply infrastructure portfolios is the
most robust given severely uncertain future hydrological inflows, water demands and energy prices. Multiple criteria of system performance are considered: service reliability, storage susceptibility, capital and
operating cost, energy use and environmental flows. Initially the two decision frameworks lead to different recommendations. We show the methods are complementary and can be beneficially used together
to better understand results and reveal how the particulars of each method can skew results towards particular future plans.},
  doi       = {10.1016/j.jhydrol.2013.03.006},
  file      = {:MCDA\\Robust Decision Making and Info-Gap Decision Theory for water resource system planning.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1016/j.jhydrol.2013.03.006},
}

@Article{Brown2010,
  author    = {Casey Brown},
  title     = {Decision-scaling for Robust Planning and Policy under Climate Uncertainty},
  journal   = {World Resources Report Uncertainty Series, Washington, DC},
  year      = {2010},
  file      = {:MCDA\\Decision-scaling for Robust Planning and Policy under Climate Uncertainty.pdf:PDF},
  timestamp = {2016-12-23},
  url       = {http://www.worldresourcesreport.org/},
}

@Article{Chaney2016,
  author    = {Nathaniel W. Chaney and Eric F. Wood and Alexander B. McBratney and Jonathan W. Hempel and Travis W. Nauman and Colby W. Brungard and Nathan P. Odgers},
  title     = {{POLARIS}: A 30-meter probabilistic soil series map of the contiguous United States},
  journal   = {Geoderma},
  year      = {2016},
  volume    = {274},
  pages     = {54--67},
  month     = {jul},
  abstract  = {A new complete map of soil series probabilities has been produced for the contiguous United States at a 30 m spatial resolution. This innovative database, named POLARIS, is constructed using available high-resolution
geospatial environmental data and a state-of-the-art machine learning algorithm (DSMART-HPC) to remap the
Soil Survey Geographic (SSURGO) database. This 9 billion grid cell database is possible using available high performance computing resources. POLARIS provides a spatially continuous, internally consistent, quantitative prediction of soil series. It offers potential solutions to the primary weaknesses in SSURGO: 1) unmapped areas are
gap-filled using survey data from the surrounding regions, 2) the artificial discontinuities at political boundaries
are removed, and 3) the use of high resolution environmental covariate data leads to a spatial disaggregation of
the coarse polygons. The geospatial environmental covariates that have the largest role in assembling POLARIS
over the contiguous United States (CONUS) are fine-scale (30 m) elevation data and coarse-scale (~2 km) estimates of the geographic distribution of uranium, thorium, and potassium. A preliminary validation of POLARIS
using the NRCS National Soil Information System (NASIS) database shows variable performance over CONUS.
In general, the best performance is obtained at grid cells where DSMART-HPC is most able to reduce the chance
of misclassification. The important role of environmental covariates in limiting prediction uncertainty suggests
including additional covariates is pivotal to improving POLARIS' accuracy. This database has the potential to improve the modeling of biogeochemical, water, and energy cycles in environmental models; enhance availability
of data for precision agriculture; and assist hydrologic monitoring and forecasting to ensure food and water
security.},
  doi       = {10.1016/j.geoderma.2016.03.025},
  file      = {:Hydrology\\POLARIS- A 30-meter probabilistic soil series map of the contiguous United States.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2016-12-22},
  url       = {http://dx.doi.org/10.1016/j.geoderma.2016.03.025},
}

@Article{Ghile2014,
  author    = {Y. B. Ghile and M. Ü. Taner and C. Brown and J. G. Grijsen and Amal Talbi},
  title     = {Bottom-up climate risk assessment of infrastructure investment in the Niger River Basin},
  journal   = {Climatic Change},
  year      = {2013},
  volume    = {122},
  number    = {1-2},
  pages     = {97--110},
  month     = {nov},
  abstract  = {The Niger River is the third largest river in the African continent. Nine riparian
countries share its basin, which rank all among the world’s thirty poorest. Existing challenges
in West Africa, including endemic poverty, inadequate infrastructure and weak adaptive
capacity to climate variability, make the region vulnerable to climate change. In this study, a
risk-based methodology is introduced and demonstrated for the analysis of climate change
impacts on planned infrastructure investments in water resources systems in the Upper and
Middle Niger River Basin. The methodology focuses on identifying the vulnerability of the
Basin’s socio-economic system to climate change, and subsequently assessing the likelihood
of climate risks by using climate information from a multi-run, multi-GCM ensemble of
climate projections. System vulnerabilities are analyzed in terms of performance metrics of
hydroelectricity production, navigation, dry and rainy season irrigated agriculture, flooding in
the Inner Delta of the Niger and the sustenance of environmental flows. The study reveals low
to moderate risks in terms of stakeholder-defined threshold levels for most metrics in the 21st
Century. The highest risk levels were observed for environmental flow targets. The findings
indicate that the range of projected changes in an ensemble of CMIP3 GCM projections imply
only relatively low risks of unacceptable climate change impacts on the present large-scale
infrastructure investment plan for the Basin.},
  doi       = {10.1007/s10584-013-1008-9},
  file      = {:MCDA\\Bottom-up climate risk assessment of infrastructure investment in the Niger River Basin.pdf:PDF},
  keywords  = {hydroeconomic, decision-scaling},
  publisher = {Springer Nature},
  timestamp = {2016-12-23},
  url       = {http://dx.doi.org/10.1007/s10584-013-1008-9},
}

@InProceedings{Spring2014,
  author = {Spring},
  title  = {University of Massachusetts - Amherst ScholarWorks@UMass Amherst Environmental \& Water Resources Engineering Masters Projects Civil and Environmental Engineering},
  year   = {2014},
  file   = {:MCDA\\Quantifying the Impacts of Future Uncertainties on the Apalachicola-Chattahoochee-Flint Basin.pdf:PDF},
}

@MastersThesis{Lownsbery2014,
  author    = {Katherine E. Lownsbery},
  title     = {Quantifying the Impacts of Future Uncertainties on the Apalachicola-Chattahoochee-Flint Basin},
  school    = {University of Massachusetts - Amherst},
  year      = {2014},
  type      = {mathesis},
  abstract  = {Water resources systems are increasingly stressed by both climate and changing water demands. The
uncertainty associated with these stressors greatly complicates risk assessments, especially because the
relative and combined impacts of each stressor on water resources systems is often unknown. This study
applies a bottom-up ex post scenario analysis approach (termed decision-scaling) to explore the
spatiotemporal distribution of impacts from multiple stressors on a multi-objective transboundary river
basin – the Apalachicola-Chattahoochee-Flint basin. The response of this large water resources system to
variability and change in climate (specifically precipitation and temperature), as well as change in water
demand (specifically municipal, industrial, and agriculture water demand), is examined using a novel
“stress test” approach that simultaneously explores the relative and joint impacts of each stressor. The
resulting system response is used to frame available projections of climate and water demand change in
terms of risk to system performance. Additionally, an analysis of variance was conducted on the resulting
ex post scenarios to attribute uncertainty in system response to uncertainty in projections of the various
stressors. The findings of this analysis indicate that projected changes in mean precipitation are the
dominant source of projected stress in the basin, while the impacts from temperature and demand vary in
importance spatially. Early in the 55 year planning period, internal climate variability is the greatest
source of uncertainty in system response, while by the end of the planning period uncertainty in
projections of trends in precipitation dominates. Uncertainty in projections for other stressors also
contributes to uncertainty in system response depending on spatial location. This study demonstrates the
application of the decision-scaling methodology to a large, complicated, multi-objective basin with
multiple stressors and yields important insights into water resources risk assessments for planning.},
  file      = {:MCDA\\Quantifying the Impacts of Future Uncertainties on the Apalachicola-Chattahoochee-Flint Basin.pdf:PDF},
  keywords  = {hydroeconomic},
  timestamp = {2016-12-23},
}

@Article{Zhang2015,
  author    = {Hongzhou Zhang},
  title     = {Sino-Indian water disputes: the coming water wars?},
  journal   = {Wiley Interdisciplinary Reviews: Water},
  year      = {2015},
  volume    = {3},
  number    = {2},
  pages     = {155--166},
  month     = {nov},
  abstract  = {As water scarcity in both China and India worsens, the competition over shared
water resources in their transboundary rivers, particularly the Brahmaputra
River, is set to intensify. Without an effective working mechanism between the
two countries, water conflicts could potentially become a serious challenge to
Sino-Indian relations. Nonetheless, the water wars narrative, which is gaining
steam in India, is being overstated. This article argues that the major supporting
arguments of the water wars narrative are very weak. To begin with, China
has no plan to divert waters from Brahmaputra River. Second, even if China
could successfully divert water from the Brahmaputra River, its impacts on
the downstream countries will be rather limited. Third, China is not a water
hegemon. Rather, it is becoming more willing to cooperate with neighboring
countries regarding transboundary rivers.},
  doi       = {10.1002/wat2.1123},
  file      = {:WaterResources\\Sino-Indian water disputes- the coming water wars.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2017-01-02},
  url       = {http://dx.doi.org/10.1002/wat2.1123},
}

@Article{Yang2016,
  author    = {Y.C. Ethan Yang and Sungwook Wi and Patrick A. Ray and Casey M. Brown and Abedalrazq F. Khalil},
  title     = {The future nexus of the Brahmaputra River Basin: Climate, water, energy and food trajectories},
  journal   = {Global Environmental Change},
  year      = {2016},
  volume    = {37},
  pages     = {16--30},
  month     = {mar},
  abstract  = {Advance knowledge of conflicting trajectories of water–energy–food (WEF) nexus is highly relevant for
water policy and planning, especially for basins that cross national boundaries. The Brahmaputra River
Basin in South Asia, home for 130 million people, is such a basin. Development of new hydropower
projects, upstream water diversions and possible climate changes introduce concerns among riparian
countries about future water supply for energy and food production in the basin. This study presents a
new hydro-economic water system model of the basin coupled with ex post scenario analysis under the
“nexus thinking” concept to identify and illustrate where development paths are in conflict. Results
indicate that the ability of future development to remain free of conflict hinges mostly on the amount of
precipitation falling in the basin in the future. Uncertain future precipitation along with uncertain future
temperature and the unknown amount of upstream water diversion combine to strongly influence future
water, energy and food production in the basin. Specifically, decreases in precipitation coupled with large
upstream diversions (e.g., diversion in the territory of China) would leave one or more riparian countries
unable to secure enough water to produce their desired energy and food. Future climate projected by
General Circulation Models suggest a warmer and wetter climate condition in the region, which is
associated with an increase in streamflow and easing of conflicts at the WEF nexus in the basin. The
methodology presented here is expected to be generally useful for diagnosing the conditions that may
cause water resources development goals to not be achieved due to either changes in climate or water use
among competing users.},
  doi       = {10.1016/j.gloenvcha.2016.01.002},
  file      = {:WaterResources\\The future nexus of the Brahmaputra River Basin Climate, water, energy and food trajectories.pdf:PDF},
  keywords  = {BRAhmaputra HydroEconomic MOdel (BRAHEMO)},
  publisher = {Elsevier {BV}},
  timestamp = {2017-01-21},
  url       = {http://dx.doi.org/10.1016/j.gloenvcha.2016.01.002},
}

@Article{Ray2015,
  author    = {Patrick A. Ray and Yi-Chen E. Yang and Sungwook Wi and Abedalrazq Khalil and Vansa Chatikavanij and Casey Brown},
  title     = {Room for improvement: Hydroclimatic challenges to poverty-reducing development of the Brahmaputra River basin},
  journal   = {Environmental Science {\&} Policy},
  year      = {2015},
  volume    = {54},
  pages     = {64--80},
  month     = {dec},
  abstract  = {The Brahmaputra river is the largest (by annual discharge) of the three in the Ganges-BrahmaputraMeghna (GBM) system, and by itself carries more flow than all but 4 rivers in the world. It is the primary
water source for over 130 million people, many of whom are mired in chronic poverty. The potential in
the Brahmaputra River basin for poverty-reducing development of agriculture and hydropower is great.
However, progress in these sectors and others has been hindered by significant natural and
anthropogenic challenges. As they attempt to develop their water resources in a manner that reduces
water-related vulnerabilities, the people of the Tibet Autonomous Region of China, Bhutan, Northeast
India, and Bangladesh face a number of challenges, including: endemic poverty; floods; droughts;
groundwater over-abstraction; political unrest; and the broader development ambitions of the member
nations (leading to net import or export of resources from the basin). To those challenges have recently
been added climate change and difficult decisions regarding hydropower development. A critical
compounding factor in the Brahmaputra basin is the lack of an authoritative, reliable, and
comprehensive network of basin-wide information on climate, streamflow, natural hazards, and
economic factors, such as agricultural production, prices, and trade. Anthropocentric development in the
Brahmaputra basin must balance the goal of immediate poverty reduction with the preservation of the
vulnerable, rich natural heritage of the basin, in the interest both of intergenerational human equity, and
biocentric egalitarianism. In the space allotted here, we provide a snapshot of the demographic and
hydroclimatic characteristics of the basin of greatest concern to water system planners aiming at poverty
reduction through sustainable development. We propose that the basin’s hydro-climatological,
economic, and political complexities are such that a basin-wide water system knowledge platform is
needed to organize quantitative thinking on potential water-related investments in the basin.},
  doi       = {10.1016/j.envsci.2015.06.015},
  file      = {:WaterResources\\Room for improvement_Hydroclimatic challenges to poverty-reducing development of the Brahmaputra River basin.pdf:PDF},
  keywords  = {Brahmaputra river Water resources Hydro-economic modeling Climate change Risk assessment River basin planning Tibet Northeast India Bhutan Bangladesh Hydropower Irrigation},
  publisher = {Elsevier {BV}},
  timestamp = {2017-01-02},
  url       = {http://dx.doi.org/10.1016/j.envsci.2015.06.015},
}

@Article{Yang2014,
  author    = {Y. C. Ethan Yang and Patrick A. Ray and Casey M. Brown and Abedalrazq F. Khalil and Winston H. Yu},
  title     = {Estimation of flood damage functions for river basin planning: a case study in Bangladesh},
  journal   = {Natural Hazards},
  year      = {2014},
  volume    = {75},
  number    = {3},
  pages     = {2773--2791},
  month     = {oct},
  abstract  = {Located at the low-lying deltaic floodplain of Ganges–Brahmaputra–Meghna
river basin, Bangladesh suffers damages from flooding with regularity. From the perspective of long-term planning and management, a reliable flood damage function is a
critical component in the estimation of flood-induced economic loss. Such functions are,
however, notoriously difficult to develop. This study utilizes in-stream water level and
flood-affected area (FAA) data from Flood Forecasting and Warning Center and Bangladesh Water Development Board to evaluate the best form and data input characteristics of
flood damage functions for Bangladesh. The performance of various function configurations (geographic data, water level data, and function form) was tested. The Nash–Sutcliffe
efficiency and residual error analysis results suggest that, in general, the logistic function
performs better than the other two function forms, and the maximum of daily-maximal
water level is the best suited to estimate (FAA). As expected, when information is available
from all basins (the Ganges, the Brahmaputra, and the Meghna), the resulting flood damage
functions provide the most accurate estimations of FAA. Furthermore, the comparison
between single- and multivariable flood damage functions does not demonstrate a clear
advantage of using multivariate function in our study area. When flood damage functions
with finer spatial and temporal resolution can be constructed using remote sensing technology or hydrodynamic modeling, the intra-year and district-level changes to FAA can be
evaluated. These findings provide a better flood management plan for Bangladesh and have
potential to be generalized to other similarly flood-affected nations.},
  doi       = {10.1007/s11069-014-1459-y},
  file      = {:WaterResources\\Estimation of flood damage functions for river basin planning – A case study in Bangladesh.pdf:PDF},
  publisher = {Springer Nature},
  timestamp = {2017-01-02},
  url       = {http://dx.doi.org/10.1007/s11069-014-1459-y},
}

@Book{Jackson2016,
  title     = {Eating, Drinking: Surviving},
  publisher = {Springer},
  year      = {2016},
  editor    = {Peter Jackson and Walter E.L. Spiess and Farhana Sultana},
  series    = {Springer Briefs in Global Understanding},
  doi       = {10.1007/978-3-319-42468-2},
  file      = {:WaterResources\\Eating, Drinking- Surviving.pdf:PDF},
  keywords  = {food security, nutrition, climate change},
  timestamp = {2017-01-02},
}

@TechReport{ORNL2012,
  title       = {Performance Assessment Manual},
  institution = {Hydro Performance Processes, Inc. and Oak Ridge National Laboratory (ORNL)},
  year        = {2012},
  number      = {1.1},
  month       = dec,
  note        = {Hydropower Advancement Project},
  abstract    = {The Hydropower Advancement Project (HAP) was initiated by the Wind and Water Power
Program within the Department of Energy's Office of Energy Efficiency and Renewable Energy
(DOE-EERE) as a systematic approach to best practices implementation for improving the
efficiency, capability, and water utilization of existing U.S. hydropower plants.
The HAP considers three performance levels for hydropower facilities: (1) the Installed
Performance Level (IPL); (2) the Current Performance Level (CPL); and (3) the Potential
Performance Level (PPL). The Installed Performance Level is that achievable by the facility
under design conditions immediately after commissioning (typically, the installed name-plate
capacity performance). The Current Performance Level is often lower than the IPL due to wear
and tear and/or due to changes in the constraints placed on a facility that prevent it from
operating as originally designed. However, the CPL can be higher than the IPL if the facility has
undergone some degree of modernization or has utilized advanced maintenance practices such
as cavitation welding to best-blade contours [Spicher, 2004]. The Potential Performance Level
is that which could be achieved under current operating constraints through installation of best
available technology and implementation of best practices for operations and maintenance.},
  file        = {:Reservoirs\\PerformanceAssessManualCompRev1_1.pdf:PDF},
  timestamp   = {2017-01-20},
}

@Article{McNider2015,
  author    = {R.T. McNider and C. Handyside and K. Doty and W.L. Ellenburg and J.F. Cruise and J.R. Christy and D. Moss and V. Sharda and G. Hoogenboom and Peter Caldwell},
  title     = {An integrated crop and hydrologic modeling system to estimate hydrologic impacts of crop irrigation demands},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2015},
  volume    = {72},
  pages     = {341--355},
  month     = {oct},
  abstract  = {The present paper discusses a coupled gridded crop modeling and hydrologic modeling system that can
examine the benefits of irrigation and costs of irrigation and the coincident impact of the irrigation water
withdrawals on surface water hydrology. The system is applied to the Southeastern U.S. The system tools
to be discussed include a gridded version (GriDSSAT) of the crop modeling system DSSAT. The irrigation
demand from GriDSSAT is coupled to a regional hydrologic model (WaSSI). GriDSSAT and WaSSI are
coupled through the USDA NASS CropScape data to provide crop acreages in each watershed. The crop
model provides the dynamic irrigation demand which is a function of the weather. The hydrologic model
responds to the weather and includes all other anthropogenic competing uses of water. Examples of the
system include an analysis of the hydrologic impact of future expansion of irrigation and the real-time
impact of short-term drought.},
  doi       = {10.1016/j.envsoft.2014.10.009},
  file      = {:WaterResources\\An integrated crop and hydrologic modeling system to estimate hydrologic impacts of crop irrigation demands.pdf:PDF},
  keywords  = {Agriculture Hydrology Drought Crop modeling Hydrology modeling},
  publisher = {Elsevier {BV}},
  timestamp = {2017-01-21},
  url       = {https://doi.org/10.1016%2Fj.envsoft.2014.10.009},
}

@TechReport{Sutton2013,
  author      = {William R. Sutton and Jitendra P. Srivastava and James E. Neumann},
  title       = {Looking Beyond the Horizon: How Climate Change Impacts and Adaptation Responses Will Reshape Agriculture in Eastern Europe and Central Asia},
  institution = {World Bank},
  year        = {2013},
  abstract    = {Agriculture and climate change are inextricably linked, as agriculture is one of the most climate-sensitive of all sectors. In many countries, such as the four that are examined in this work, the risks of climate change for the agricultural sector are a particularly immediate and important problem because the majority of the rural population depends either directly or indirectly on agriculture for their livelihoods. The risks of climate change cannot be effectively dealt with, and the opportunities cannot be effectively exploited, without a clear plan for aligning agricultural policies with climate change, for developing key agricultural institution capabilities, and for making needed infrastructure and on-farm investments. Developing such a plan ideally involves a combination of high-quality quantitative analysis and consultation with key stakeholders, particularly farmers, as well as local agricultural experts. The most effective plans for adapting the sector to climate change will involve both human and physical capital enhancements, but many of these investments can also enhance agricultural productivity right now, under current climate conditions. The experiences of Albania, FYR Macedonia, Moldova, and Uzbekistan, highlighted in this work, show that it is possible to develop a plan to meet these objectives; one that is comprehensive, empirically-driven, and yet consultative and quick to develop. This plan also relies heavily on rigorous modeling that recognizes the importance of temperature, precipitation, and general water availability in forecasting changes to farm output and that considers multiple crop types and also livestock. This work draws on the experience of applying this approach to these four nations in Europe and Central Asia with the ultimate goal to help each country mainstream climate change adaptation into agricultural policies, programs, and investments. It also highlights the projected impacts of climate change on agriculture in these countries through forecast variations in temperature and rainfall patterns so crucial to farming, and as a result, offers a map for navigating the risks and realizing the opportunities.},
  doi         = {10.1596/978-0-8213-9768-8},
  keywords    = {CLIMATE CHANGE, AGRICULTURE, ADAPTATION, MITIGATION, CLIMATE SMART AGRICULTURE, DISASTER MANAGEMENT, RISK MANAGEMENT, WATER RESOURCES, IRRIGATION, CROP MODELING, IMPACT ASSESSMENT, REDUCING VULNERABILITY, RESILIENCE, FARMING, METHODOLOGY, CAPACITY BUILDING, PARTICIPATORY, AWARENESS RAISING, CLIMATE SMART, GREEN GROWTH, MAINSTREAMING CLIMATE CHANGE, WORLD BANK, ENVIRONMENT, ECONOMIC ANALYSIS, BENEFIT-COST, RURAL DEVELOPMENT, CROPS, LIVESTOCK},
  timestamp   = {2017-01-21},
  url         = {http://elibrary.worldbank.org/doi/abs/10.1596/978-0-8213-9768-8},
}

@Article{Foster2017,
  author    = {T. Foster and N. Brozovi{\'{c}} and A.P. Butler and C.M.U. Neale and D. Raes and P. Steduto and E. Fereres and T.C. Hsiao},
  title     = {{AquaCrop}-{OS}: An open source version of {FAO}{\textquotesingle}s crop water productivity model},
  journal   = {Agricultural Water Management},
  year      = {2017},
  volume    = {181},
  pages     = {18--22},
  month     = {feb},
  abstract  = {Crop simulation models are valuable tools for quantifying crop yield response to water, and for devising
strategies to improve agricultural water management. However, applicability of the majority of crop models is limited greatly by a failure to provide open-access to model source code. In this study, we present an
open-source version of the FAO AquaCrop model, which simulates efficiently water-limited crop production across diverse environmental and agronomic conditions. Our model, called AquaCrop-OpenSource
(AquaCrop-OS), can be run in multiple programming languages and operating systems. Support for
parallel execution reduces significantly simulation times when applying the model in large geospatial
frameworks, for long-run policy analysis, or for uncertainty assessment. Furthermore, AquaCrop-OS is
compliant with the Open Modelling Interface standard facilitating linkage to other disciplinary models,
for example to guide integrated water resources planning.},
  doi       = {10.1016/j.agwat.2016.11.015},
  file      = {:WaterResources\\AquaCrop-OS- An open source version of FAO’s crop water.pdf:PDF},
  keywords  = {AquaCrop Crop model Agriculture Water Open source Policy},
  publisher = {Elsevier {BV}},
  timestamp = {2017-01-21},
  url       = {https://doi.org/10.1016%2Fj.agwat.2016.11.015
www.aquacropos.com},
}

@Article{Levina2016,
  author    = {Levina and Waluyo Hatmoko and Wulan Seizarwati and Ronald Vernimmen},
  title     = {Comparison of {TRMM} Satellite Rainfall and {APHRODITE} for Drought Analysis in the Pemali-comal River Basin},
  journal   = {Procedia Environmental Sciences},
  year      = {2016},
  volume    = {33},
  pages     = {187--195},
  abstract  = {Drought analysis needs continuous long time-series of monthly rainfall. Standardized Precipitation Index (SPI) and Standardized
Runoff Index (SRI) which determine meteorological and hydrological drought index respectively are computed with the input data
from TRMM 3B42RT and APHRODITE. The results are compared to the ground station data, in order to determine which data
has good performance to describe drought condition in Pemali-Comal river basin. The meteorological drought index computed
from TRMM gives better result than APHRODITE for SPI of 3 to 12 months, except for SPI 1 month. Nevertheless, the
hydrological drought index from TRMM generally has better result than APHRODITE.},
  doi       = {10.1016/j.proenv.2016.03.069},
  file      = {:Hydrology\\Precipitation\\Comparison of TRMM Satellite Rainfall and APHRODITE for Drought Analysis in the Pemali-comal River Basin.pdf:PDF},
  keywords  = {meteorological drought; hydrological drought; standardized precipitation index; standardized runoff index},
  publisher = {Elsevier {BV}},
  timestamp = {2017-01-22},
  url       = {https://doi.org/10.1016%2Fj.proenv.2016.03.069},
}

@Article{Zhao2015,
  author    = {Chuancheng Zhao and Shuxia Yao and Shiqiang Zhang and Haidong Han and Qiudong Zhao and Shuhua Yi},
  title     = {Validation of the Accuracy of Different Precipitation Datasets over Tianshan Mountainous Area},
  journal   = {Advances in Meteorology},
  year      = {2015},
  volume    = {2015},
  pages     = {1--10},
  abstract  = {Precipitation is one of the important water supplies in the arid and semiarid regions of northwestern China, playing a vital role
in maintaining the fragile ecosystem. In remote mountainous area, it is difficult to obtain an accurate and reliable spatialization of
the precipitation amount at the regional scale due to the inaccessibility, the sparsity of observation stations, and the complexity of
relationships between precipitation and topography. Furthermore, accurate precipitation is important driven data for hydrological
models to assess the water balance and water resource for hydrologists. Therefore, the use of satellite remote sensing becomes an
important means over mountainous area. Precipitation datasets based on station data or pure satellite data have been increasingly
available in spite of several weaknesses. This paper evaluates the usefulness of three precipitation datasets including TRMM
3B43 V6, 3B43 V7, and Asian Precipitation Highly Resolved Observational Data Integration Towards Evaluation with rain gauge
data over Tianshan mountainous area where precipitation data is scarce. The results suggest that precipitation measurements only
provided accurate information on a small scale, while the satellite remote sensing of precipitation had obvious advantages in basin
scale or large scale especially over remote mountainous area.},
  doi       = {10.1155/2015/617382},
  file      = {:Hydrology\\Precipitation\\Validation of the Accuracy of Different Precipitation Datasets over Tianshan Mountainous Area.pdf:PDF},
  keywords  = {APHRODITE, TRMM},
  publisher = {Hindawi Publishing Corporation},
  timestamp = {2017-01-22},
  url       = {https://doi.org/10.1155%2F2015%2F617382},
}

@Article{Ewert2015,
  author    = {F. Ewert and R.P. Rötter and M. Bindi and H. Webber and M. Trnka and K.C. Kersebaum and J.E. Olesen and M.K. van Ittersum and S. Janssen and M. Rivington and M.A. Semenov and D. Wallach and J.R. Porter and D. Stewart and J. Verhagen and T. Gaiser and T. Palosuo and F. Tao and C. Nendel and P.P. Roggero and L. Barto{\v{s}}ov{\'{a}} and S. Asseng},
  title     = {Crop modelling for integrated assessment of risk to food production from climate change},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2015},
  volume    = {72},
  pages     = {287--303},
  month     = {oct},
  abstract  = {The complexity of risks posed by climate change and possible adaptations for crop production has called
for integrated assessment and modelling (IAM) approaches linking biophysical and economic models.
This paper attempts to provide an overview of the present state of crop modelling to assess climate
change risks to food production and to which extent crop models comply with IAM demands. Considerable progress has been made in modelling effects of climate variables, where crop models best satisfy
IAM demands. Demands are partly satisfied for simulating commonly required assessment variables.
However, progress on the number of simulated crops, uncertainty propagation related to model parameters and structure, adaptations and scaling are less advanced and lagging behind IAM demands. The
limitations are considered substantial and apply to a different extent to all crop models. Overcoming
these limitations will require joint efforts, and consideration of novel modelling approaches.},
  doi       = {10.1016/j.envsoft.2014.12.003},
  file      = {:WaterResources\\Crop modelling for integrated assessment of risk to food production from climate change.pdf:PDF},
  keywords  = {Uncertainty Scaling Integrated assessment Risk assessment Adaptation Crop models},
  publisher = {Elsevier {BV}},
  timestamp = {2017-01-22},
  url       = {https://doi.org/10.1016%2Fj.envsoft.2014.12.003},
}

@Article{Steduto2009,
  author    = {Pasquale Steduto and Theodore C. Hsiao and Dirk Raes and Elias Fereres},
  title     = {{AquaCrop} - The {FAO} Crop Model to Simulate Yield Response to Water: I. Concepts and Underlying Principles},
  journal   = {Agronomy Journal},
  year      = {2009},
  volume    = {101},
  number    = {3},
  pages     = {426},
  abstract  = {This article introduces the FAO crop model AquaCrop. It simulates attainable yields of major herbaceous crops as a function
of water consumption under rainfed, supplemental, deficit, and full irrigation conditions. The growth engine of AquaCrop is
water-driven, in that transpiration is calculated first and translated into biomass using a conservative, crop-specific parameter:
the biomass water productivity, normalized for atmospheric evaporative demand and air CO2 concentration. The normalization
is to make AquaCrop applicable to diverse locations and seasons. Simulations are performed on thermal time, but can be on
calendar time, in daily time-steps. The model uses canopy ground cover instead of leaf area index (LAI) as the basis to calculate
transpiration and to separate out soil evaporation from transpiration. Crop yield is calculated as the product of biomass and
harvest index (HI). At the start of yield formation period, HI increases linearly with time after a lag phase, until near physiological maturity. Other than for the yield, there is no biomass partitioning into the various organs. Crop responses to water deficits
are simulated with four modifiers that are functions of fractional available soil water modulated by evaporative demand, based
on the differential sensitivity to water stress of four key plant processes: canopy expansion, stomatal control of transpiration,
canopy senescence, and HI. The HI can be modified negatively or positively, depending on stress level, timing, and canopy duration. AquaCrop uses a relatively small number of parameters (explicit and mostly intuitive) and attempts to balance simplicity,
accuracy, and robustness. The model is aimed mainly at practitioner-type end-users such as those working for extension services,
consulting engineers, governmental agencies, nongovernmental organizations, and various kinds of farmers associations. It is
also designed to fit the need of economists and policy specialists who use simple models for planning and scenario analysis.},
  doi       = {10.2134/agronj2008.0139s},
  file      = {:WaterResources\\AquaCrop—The FAO Crop Model to Simulate Yield Response to Water I. Concepts and Underlying Principles.pdf:PDF},
  publisher = {American Society of Agronomy},
  timestamp = {2017-02-03},
  url       = {https://doi.org/10.2134%2Fagronj2008.0139s},
}

@Article{Farahani2009,
  author    = {Hamid J. Farahani and Gabriella Izzi and Theib Y. Oweis},
  title     = {Parameterization and Evaluation of the {AquaCrop} Model for Full and Deficit Irrigated Cotton},
  journal   = {Agronomy Journal},
  year      = {2009},
  volume    = {101},
  number    = {3},
  pages     = {469},
  abstract  = {Predicting yield is increasingly important to optimize irrigation under limited available water for enhanced sustainability and
profitable production. Food and Agriculture Organization (FAO) of the United Nations addresses this need by providing a yield
response to water simulation model (AquaCrop) with limited sophistication. In this study, AquaCrop was parameterized and
tested for cotton (Gossypium hirsutum L.) under full (100%) and deficit (40, 60, and 80% of full) irrigation regimes in the hot,
dry, and windy Mediterranean environment of northern Syria. Model parameterization used the 2006 data and was straightforward within the designed user-interface, owing to the limited number of key parameters. Accurate simulation of canopy cover
was central to sound prediction of evapotranspiration and biomass accumulation. Key user-input parameters for this purpose
were identified as the coefficients defining canopy development and the threshold soil water depletion levels for the water stress
indices. The parameterized model was tested using data from the 2004 and 2005 seasons, resulting in accurate prediction of
evapotranspiration (<13% error). The predicted yield values were within 10% of measurements, except in the 60 and 80% irrigation regimes in 2004, with errors up to 32%. The model closely predicted the trend in total soil water, but deviation existed for
individual soil layers. This study provides first estimate values for cotton parameters useful for future model testing and use.
Model parameterization is site-specific, and thus the applicability of key calibrated parameters must to be tested under different
climate, soil, variety, irrigation methods, and field management.},
  doi       = {10.2134/agronj2008.0182s},
  file      = {:WaterResources\\Parameterization and Evaluation of the AquaCrop Model for Full and Deficit Irrigated Cotton.pdf:PDF},
  publisher = {American Society of Agronomy},
  timestamp = {2017-01-22},
  url       = {https://doi.org/10.2134%2Fagronj2008.0182s},
}

@Article{Evett2009,
  author    = {Steven R. Evett and Judy A. Tolk},
  title     = {Introduction: Can Water Use Efficiency Be Modeled Well Enough to Impact Crop Management?},
  journal   = {Agronomy Journal},
  year      = {2009},
  volume    = {101},
  number    = {3},
  pages     = {423},
  abstract  = {Crop water use efficiency (WUE, yield per unit of water use) is key for agricultural production with limited water resources.
Policymakers and water resource managers working at all scales need to address the multitudinous scenarios in which cropping
systems and amounts, timing and methods of irrigation, and fertilizer applications may be changed to improve WUE while
meeting yield and harvest quality goals. Experimentation cannot address all scenarios, but accurate simulation models may fill
in the gaps. The nine papers in this special section explore how four simulation models were used to simulate yield, water use, and
WUE of cotton (Gossypium hirsutum L.), maize (Zea mays L.), quinoa (Chenopodium quinoa Willd.), and sunflower (Helianthus
annuus L.) in North and South America, Europe, and the Middle East. All the models simulated WUE adequately under wellwatered conditions, but tended to misestimate WUE under conditions of water stress, which limits their use for exploration of
deficit irrigation scenarios or rain-fed or dryland situations with expected soil water deficits. None of the experimental conditions reported involved separate measurements of evaporation (E) and transpiration (T); so there was no opportunity to test the
separation of E and T simulated in the newest of the models, AquaCrop. The lack of separate E measurements also limited the
authors in exploring reasons why WUE was not simulated well under water stress conditions. Future studies exploring WUE
simulation should include E or T measurements so that effects of management methods that reduce E can be studied.},
  doi       = {10.2134/agronj2009.0038xs},
  file      = {:WaterResources\\Introduction Can Water Use Efficiency Be Modeled Well Enough to Impact Crop Management.pdf:PDF},
  publisher = {American Society of Agronomy},
  timestamp = {2017-01-22},
  url       = {https://doi.org/10.2134%2Fagronj2009.0038xs},
}

@Article{Hsiao2009,
  author    = {Theodore C. Hsiao and Lee Heng and Pasquale Steduto and Basilio Rojas-Lara and Dirk Raes and Elias Fereres},
  title     = {{AquaCrop} - The {FAO} Crop Model to Simulate Yield Response to Water: {III}. Parameterization and Testing for Maize},
  journal   = {Agronomy Journal},
  year      = {2009},
  volume    = {101},
  number    = {3},
  pages     = {448},
  abstract  = {The first crop chosen to parameterize and test the new FAO AquaCrop model is maize (Zea mays L.). Working mainly with data
sets from 6 yr of maize field experiments at Davis, CA, plus another 4 yr of Davis maize canopy data, a set of conservative (nearly
constant) parameters of AquaCrop, presumably applicable to widely different conditions and not specific to a given crop cultivar,
was evaluated by test simulations, and used to simulate the 6 yr of Davis data. The treatment variable was irrigation—withholding
water after planting continuously, only up to tasseling, from tasseling onward, or intermittently, and with full irrigation (FI) as the
control. From year to year, plant density (7–11.9 plants m−2), planting date (14 May–15 June), cultivar (a total of four), and atmospheric evaporative demand varied. The conservative parameters included: canopy growth and canopy decline coefficient (CDC);
crop coefficient for transpiration (Tr) at full canopy; normalized water productivity for biomass (WP*); soil water depletion thresholds for the inhibition leaf growth and of stomatal conductance, and for the acceleration of canopy senescence; reference harvest
index (HI
o
); and coefficients for adjusting harvest index (HI) in relation to inhibition of leaf growth and of stomatal conductance.
With all 19 parameters held constant, AquaCrop simulated the final aboveground biomass within 10% of the measured value for at
least 8 of the 13 treatments (6 yr of experiments) and also the grain yield for at least five of the cases. In at least four of the cases, the
simulated results were within 5% of the measured for biomass as well as for grain yield. The largest deviation between the simulated
and measured values was 22% for biomass, and 24% for grain yield. Importantly, the simulated pattern of canopy progression and
biomass accumulation over time were close to those measured, with Willmott’s index of agreement (d) for 11 of the 13 cases being
≥0.98 for canopy cover (CC), and ≥0.97 for biomass. Accelerated senescence of canopy due to water stress, however, proved to be difficult to simulate accurately; of the six cases, the index of agreement for the worst one was 0.957 for canopy and 0.915 for biomass.
Possible reasons for the discrepancies between the simulated and measured results include simplifications in the model and inaccuracies in measurements. The usefulness of AquaCrop with well-calibrated conservative parameters in assessing water use efficiency
(WUE) of a crops under different conditions and in devising strategies to improve WUE is discussed.},
  doi       = {10.2134/agronj2008.0218s},
  file      = {:WaterResources\\AquaCrop—The FAO Crop Model to Simulate Yield Response to Water III. Parameterization and Testing for Maize.pdf:PDF},
  publisher = {American Society of Agronomy},
  timestamp = {2017-02-03},
  url       = {https://doi.org/10.2134%2Fagronj2008.0218s},
}

@Article{Raes2009,
  author    = {Dirk Raes and Pasquale Steduto and Theodore C. Hsiao and Elias Fereres},
  title     = {{AquaCropThe} {FAO} Crop Model to Simulate Yield Response to Water: {II}. Main Algorithms and Software Description},
  journal   = {Agronomy Journal},
  year      = {2009},
  volume    = {101},
  number    = {3},
  pages     = {438},
  abstract  = {The AquaCrop model was developed to replace the former FAO I&D Paper 33 procedures for the estimation of crop productivity
in relation to water supply and agronomic management in a framework based on current plant physiological and soil water budgeting concepts. This paper presents the software of AquaCrop for which the concepts and underlying principles are described
in the companion paper (Steduto et al., 2009). Input consists of weather data, crop characteristics, and soil and management
characteristics that define the environment in which the crop will develop. Algorithms and calculation procedures modeling the
infiltration of water, the drainage out of the root zone, the canopy and root zone development, the evaporation and transpiration rate, the biomass production, and the yield formation are presented. The mechanisms of crop response to cope with water
shortage are described by only a few parameters, making the underlying processes more transparent to the user. AquaCrop is a
menu-driven program with a well-developed user interface. With the help of graphs which are updated each time step (1 d) during the simulation run, the user can track changes in soil water content, and the corresponding changes in crop development, soil
evaporation and transpiration rate, biomass production, and yield development. One can halt the simulation at each time step,
to study the effect of changes in water related inputs, making the model particularly suitable for developing deficit irrigation
strategies and scenario analysis.},
  doi       = {10.2134/agronj2008.0140s},
  file      = {:WaterResources\\AquaCrop—The FAO Crop Model to Simulate Yield Response to Water II. Main Algorithms and Software Description.pdf:PDF},
  publisher = {American Society of Agronomy},
  timestamp = {2017-01-22},
  url       = {https://doi.org/10.2134%2Fagronj2008.0140s},
}

@Article{Rosenzweig2013,
  author      = {Cynthia Rosenzweig and J. W. Jones and J. L. Hatfield and A. C. Ruane and K. J. Boote},
  title       = {The Agricultural Model Intercomparison and Improvement Project (AgMIP): Protocols and pilot studies},
  journal     = {Agricultural and Forest Meteorology},
  year        = {2013},
  volume      = {170},
  pages       = {166--182},
  abstract    = {The Agricultural Model Intercomparison and Improvement Project (AgMIP) is a major international effort linking the climate, crop, and economic modeling communities with cutting-edge information technology to produce improved crop and economic models and the next generation of climate impact projections for the agricultural sector. The goals of AgMIP are to improve substantially the characterization of world food security due to climate change and to enhance adaptation capacity in both developing and developed countries. Analyses of the agricultural impacts of climate variability and change require a transdisciplinary effort to consistently link state-of-the-art climate scenarios to crop and economic models. Crop model outputs are aggregated as inputs to regional and global economic models to determine regional vulnerabilities, changes in comparative advantage, price effects, and potential adaptation strategies in the agricultural sector. Climate, Crop Modeling, Economics, and Information Technology Team Protocols are presented to guide coordinated climate, crop modeling, economics, and information technology research activities around the world, along with AgMIP Cross-Cutting Themes that address uncertainty, aggregation and scaling, and the development of Representative Agricultural Pathways (RAPs) to enable testing of climate change adaptations in the context of other regional and global trends. The organization of research activities by geographic region and specific crops is described, along with project milestones.

Pilot results demonstrate AgMIP's role in assessing climate impacts with explicit representation of uncertainties in climate scenarios and simulations using crop and economic models. An intercomparison of wheat model simulations near Obregón, Mexico reveals inter-model differences in yield sensitivity to [CO2] with model uncertainty holding approximately steady as concentrations rise, while uncertainty related to choice of crop model increases with rising temperatures. Wheat model simulations with mid-century climate scenarios project a slight decline in absolute yields that is more sensitive to selection of crop model than to global climate model, emissions scenario, or climate scenario downscaling method. A comparison of regional and national-scale economic simulations finds a large sensitivity of projected yield changes to the simulations’ resolved scales. Finally, a global economic model intercomparison example demonstrates that improvements in the understanding of agriculture futures arise from integration of the range of uncertainty in crop, climate, and economic modeling results in multi-model assessments.},
  file        = {:WaterResources\\The Agricultural Model Intercomparison and Improvement project (AgMIP)- protocols and pilot studies.pdf:PDF},
  institution = {University of Nebraska},
  keywords    = {Agriculture; Food security; Climate change; Crop models; Economic models; Intercomparison; Uncertainty; Risk; Adaptation},
  timestamp   = {2017-01-22},
}

@Article{Wada2010,
  author    = {Wada, Yoshihide and van Beek, Ludovicus P. H. and van Kempen, Cheryl M. and Reckman, Josef W. T. M. and Vasak, Slavek and Bierkens, Marc F. P.},
  title     = {Global depletion of groundwater resources},
  journal   = {Geophysical Research Letters},
  year      = {2010},
  volume    = {37},
  number    = {20},
  pages     = {n/a--n/a},
  note      = {L20402},
  abstract  = {In regions with frequent water stress and large aquifer systems groundwater is often used as an additional water source. If groundwater abstraction exceeds the natural groundwater recharge for extensive areas and long times, overexploitation or persistent groundwater depletion occurs. Here we provide a global overview of groundwater depletion (here defined as abstraction in excess of recharge) by assessing groundwater recharge with a global hydrological model and subtracting estimates of groundwater abstraction. Restricting our analysis to sub-humid to arid areas we estimate the total global groundwater depletion to have increased from 126 (±32) km3 a−1 in 1960 to 283 (±40) km3 a−1 in 2000. The latter equals 39 (±10)% of the global yearly groundwater abstraction, 2 (±0.6)% of the global yearly groundwater recharge, 0.8 (±0.1)% of the global yearly continental runoff and 0.4 (±0.06)% of the global yearly evaporation, contributing a considerable amount of 0.8 (±0.1) mm a−1 to current sea-level rise.},
  doi       = {10.1029/2010GL044571},
  file      = {:Hydrology\\Global depletion of groundwater resources.pdf:PDF},
  issn      = {1944-8007},
  keywords  = {Water cycles, Groundwater hydrology, Anthropogenic effects, Hydrological cycles and budgets, Sea level: variations and mean, groundwater depletion, global hydrology, water stress, sea level rise, PCR-GLOBWB},
  timestamp = {2017-02-02},
  url       = {http://dx.doi.org/10.1029/2010GL044571},
}

@Article{Bierkens2009,
  author    = {M. F. P. Bierkens and L. P. H. van Beek},
  title     = {Seasonal Predictability of European Discharge: {NAO} and Hydrological Response Time},
  journal   = {Journal of Hydrometeorology},
  year      = {2009},
  volume    = {10},
  number    = {4},
  pages     = {953--968},
  month     = {aug},
  abstract  = {In this paper the skill of seasonal prediction of river discharge and how this skill varies between the branches of European rivers across Europe is assessed. A prediction system of seasonal (winter and summer) discharge is evaluated using 1) predictions of the average North Atlantic Oscillation (NAO) index for the coming winter based on May SST anomalies of the North Atlantic; 2) a global-scale hydrological model; and 3) 40-yr European Centre for Medium-Range Weather Forecasts Re-Analysis (ERA-40) data. The skill of seasonal discharge predictions is investigated with a numerical experiment. Also Europe-wide patterns of predictive skill are related to the use of NAO-based seasonal weather prediction, the hydrological properties of the river basin, and a correct assessment of initial hydrological states. These patterns, which are also corroborated by observations, show that in many parts of Europe the skill of predicting winter discharge can, in theory, be quite large. However, this achieved skill mainly comes from knowing the correct initial conditions of the hydrological system (i.e., groundwater, surface water, soil water storage of the basin) rather than from the use of NAO-based seasonal weather prediction. These factors are equally important for predicting subsequent summer discharge.},
  doi       = {10.1175/2009jhm1034.1},
  file      = {:Hydrology\\Seasonal Predictability of European Discharge- NAO and Hydrological Response Time.pdf:PDF},
  keywords  = {Rivers; Seasonal forecasting; North Atlantic Oscillation; Hindcasts; Europe, PCR-GLOBWB},
  publisher = {American Meteorological Society},
  timestamp = {2017-02-02},
  url       = {https://doi.org/10.1175%2F2009jhm1034.1},
}

@Manual{vanBeek2009,
  title        = {The Global Hydrological Model PCR-GLOBWB: Conceptualization, Parameterization and Verification},
  author       = {L.P.H. Rens van Beek and Marc F.P. Bierkens},
  organization = {Utrecht University},
  year         = {2009},
  abstract     = {Models describing hydrological processes at a global scale are now frequently being used
to assess the effect of global change on the world’s water resources. Examples are the
assessment of global water stress [Vörösmarty et al., 2000; Alcamo et al, 2000; Oki et al,
2001], continental runoff [Nijssen et al., 2001; Fekete et al., 2002], projected change in
continental runoff [Milly, et al., 2005], soil moisture fields and global drought [Sheffield
and Wood, 2007] and total continental water storage [Güntner et al., 2007].
Available models can be largely divided into hydrological models that are used off-line
and land surface models forming the land component of general circulation models
(GCMs). Intercomparisons of terrestrial water fluxes from a suite of GCM land surface
models can be found in Dirmeyer et al. [1999, 2006]. Although global hydrological
models (GHMs) are similar in nature to the GCM land surface models, they usually
operate at longer temporal but smaller spatial scales, while terrestrial hydrological
processes are represented in more detail. Known GHMs from the literature are VIC
[Liang et al., 1994] applied at the global scale [Nijssen et al., 2001], LaD [Milly and
Schmakin, 2002], WMB [Fekete et al., 2002], WGHM [Döll et al., 2003] and
WASMOD-M [Widén-Nilsson, 2007]. WBM, WGHM and WASMOD-M are purely
water-balance type models, while VIC and LaD also resolve the surface energy balance.
In this paper we describe a recently developed global hydrological model called PCRGLOBWB,
which is derived from PCRaster GLOBal Water Balance model. PCRaster
[Wesseling et al., 1999] is the dynamic scripting language in which the model is coded.
Although our model is similar to existing GHMs in many ways and uses quite some data
sets in common, we also developed a number of new concepts that are worth presenting
to the hydrological community. In particular we developed new and advanced schemes
for subgrid parameterization of surface runoff, interflow and baseflow and added explicit
routing of surface water flow using the kinematic wave approximation, dynamic
inundation of floodplains and a reservoir scheme. Also, we added a routine for lateral
water transport of latent heat from which we can calculate water temperature and river ice
thickness. This makes the model suitable for runoff analyses at time-scales smaller than a
month, as well as tailored to low flow analyses and nutrient transport..
The remainder of this paper starts with a global description of the model, followed by a
more in depth description of the features that are specific to our model when compared to
existing GHMs. Next, we describe the verification of the model using runoff data.
Continental runoff as calculated from our model is compared to that from earlier studies.},
  file         = {:Programs\\PCR-GLOBWB.pdf:PDF},
  timestamp    = {2017-02-02},
}

@TechReport{Markstrom2005,
  author      = {Steven L. Markstrom and Richard G. Niswonger and R. Steven Regan and David E. Prudic and Paul M. Barlow},
  title       = {GSFLOW—Coupled Ground-Water and Surface-Water Flow Model Based on the Integration of the Precipitation-Runoff Modeling System (PRMS) and the Modular Ground-Water Flow Model (MODFLOW-2005)},
  institution = {United States Geologic Survey},
  year        = {2005},
  file        = {:Programs\\GSFLOW—Coupled Ground-Water and Surface-Water Flow Model Based on the Integration of the Precipitation-Runoff Modeling System (PRMS) and the Modular Ground-Water Flow Model (MODFLOW-2005).pdf:PDF},
  timestamp   = {2017-02-02},
}

@Article{Sutanudjaja2014,
  author    = {Sutanudjaja, E. H. and van Beek, L. P. H. and de Jong, S. M. and van Geer, F. C. and Bierkens, M. F. P.},
  title     = {Calibrating a large-extent high-resolution coupled groundwater-land surface model using soil moisture and discharge data},
  journal   = {Water Resources Research},
  year      = {2014},
  volume    = {50},
  number    = {1},
  pages     = {687--705},
  issn      = {1944-7973},
  abstract  = {We explore the possibility of using remotely sensed soil moisture data and in situ discharge observations to calibrate a large-extent hydrological model. The model used is PCR-GLOBWB-MOD, which is a physically based and fully coupled groundwater-land surface model operating at a daily basis and having a resolution of 30 arc sec (about 1 km at the equator). As a test bed, we use the combined Rhine-Meuse basin (total area: about 200,000 km2), where there are 4250 point-scale observed groundwater head time series that are used to verify the model results. Calibration is performed by simulating 3045 model runs with varying parameter values affecting groundwater head dynamics. The simulation results of all runs are evaluated against the remotely sensed soil moisture time series of SWI (Soil Water Index) and field discharge data. The former is derived from European Remote Sensing scatterometers and provides estimates of the first meter profile soil moisture content at 30 arc min resolution (50 km at the equator). From the evaluation of these runs, we then introduce a stepwise calibration approach that considers stream discharge first, then soil moisture, and finally verify the resulting simulation to groundwater head observations. Our results indicate that the remotely sensed soil moisture data can be used for the calibration of upper soil hydraulic conductivities determining simulated groundwater recharge of the model. However, discharge data should be included to obtain full calibration of the coupled model, specifically to constrain aquifer transmissivities and runoff-infiltration partitioning processes. The stepwise approach introduced in this study, using both discharge and soil moisture data, can calibrate both discharge and soil moisture, as well as predicting groundwater head dynamics with acceptable accuracy. As our approach to parameterize and calibrate the model uses globally available data sets only, it opens up the possibility to set up large-extent coupled groundwater-land surface models in other basins or even globally.},
  comment   = {coupled PCR-GLOBWB with MODFLOW},
  doi       = {10.1002/2013WR013807},
  file      = {:Hydrology\\Calibrating a large-extent high-resolution coupled groundwater-land surface model using soil moisture and discharge data.pdf:PDF},
  keywords  = {Model calibration, Groundwater hydrology, Remote sensing, Modeling, groundwater model, calibration, Rhine-Meuse basin, Soil Water Index (SWI), PCR-GLOBWB},
  timestamp = {2017-02-02},
  url       = {http://dx.doi.org/10.1002/2013WR013807},
}

@Article{Wada2014,
  author    = {Y. Wada and D. Wisser and M. F. P. Bierkens},
  title     = {Global modeling of withdrawal, allocation and consumptive use of surface water and groundwater resources},
  journal   = {Earth System Dynamics},
  year      = {2014},
  volume    = {5},
  number    = {1},
  pages     = {15--40},
  month     = {jan},
  abstract  = {To sustain growing food demand and increasing
standard of living, global water withdrawal and consumptive
water use have been increasing rapidly. To analyze the
human perturbation on water resources consistently over
large scales, a number of macro-scale hydrological models
(MHMs) have been developed in recent decades. However,
few models consider the interaction between terrestrial water
fluxes, and human activities and associated water use,
and even fewer models distinguish water use from surface
water and groundwater resources. Here, we couple a global
water demand model with a global hydrological model and
dynamically simulate daily water withdrawal and consumptive
water use over the period 1979–2010, using two reanalysis
products: ERA-Interim and MERRA. We explicitly
take into account the mutual feedback between supply
and demand, and implement a newly developed water allocation
scheme to distinguish surface water and groundwater
use. Moreover, we include a new irrigation scheme, which
works dynamically with a daily surface and soil water balance,
and incorporate the newly available extensive Global
Reservoir and Dams data set (GRanD). Simulated surface
water and groundwater withdrawals generally show good
agreement with reported national and subnational statistics.
The results show a consistent increase in both surface water
and groundwater use worldwide, with a more rapid increase
in groundwater use since the 1990s. Human impacts on terrestrial
water storage (TWS) signals are evident, altering the
seasonal and interannual variability. This alteration is particularly
large over heavily regulated basins such as the Colorado
and the Columbia, and over the major irrigated basins
such as the Mississippi, the Indus, and the Ganges. Including
human water use and associated reservoir operations generally
improves the correlation of simulated TWS anomalies
with those of the GRACE observations.},
  doi       = {10.5194/esd-5-15-2014},
  file      = {:Hydrology\\Global modeling of withdrawal, allocation and consumptive use of surface water and groundwater resources.pdf:PDF},
  keywords  = {PCR-GLOBWB},
  publisher = {Copernicus {GmbH}},
  timestamp = {2017-02-02},
  url       = {https://doi.org/10.5194%2Fesd-5-15-2014},
}

@Article{Winsemius2015,
  author    = {Hessel C. Winsemius and Jeroen~C.~J.~H. Aerts and Ludovicus~P.~H. van Beek and Marc~F.~P. Bierkens and Arno Bouwman and Brenden Jongman and Jaap~C.~J. Kwadijk and Willem Ligtvoet and Paul~L. Lucas and Detlef~P. van~Vuuren and Philip~J. Ward},
  title     = {Global drivers of future river flood risk},
  journal   = {Nature Climate Change},
  year      = {2015},
  volume    = {6},
  number    = {4},
  pages     = {381--385},
  month     = {dec},
  abstract  = {Understanding global future river flood risk is a prerequisite
for the quantification of climate change impacts and planning effective adaptation strategies1. Existing global flood
risk projections fail to integrate the combined dynamics of
expected socio-economic development and climate change. We
present the first global future river flood risk projections that
separate the impacts of climate change and socio-economic
development. The projections are based on an ensemble of
climate model outputs2, socio-economic scenarios3, and a
state-of-the-art hydrologic river flood model combined with
socio-economic impact models4,5. Globally, absolute damage
may increase by up to a factor of 20 by the end of the century
without action. Countries in Southeast Asia face a severe
increase in flood risk. Although climate change contributes
significantly to the increase in risk in Southeast Asia6, we show
that it is dwarfed by the eect of socio-economic growth, even
after normalization for gross domestic product (GDP) growth.
African countries face a strong increase in risk mainly due to
socio-economic change. However, when normalized to GDP,
climate change becomes by far the strongest driver. Both highand low-income countries may benefit greatly from investing in
adaptation measures, for which our analysis provides a basis.},
  doi       = {10.1038/nclimate2893},
  file      = {:Hydrology\\Global drivers of future river flood risk.pdf:PDF},
  publisher = {Springer Nature},
  timestamp = {2017-02-02},
  url       = {https://doi.org/10.1038%2Fnclimate2893},
}

@Article{Dile2016,
  author    = {Yihun T. Dile and Prasad Daggupati and Chris George and Raghavan Srinivasan and Jeff Arnold},
  title     = {Introducing a new open source {GIS} user interface for the {SWAT} model},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2016},
  volume    = {85},
  pages     = {129--138},
  month     = {nov},
  abstract  = {The Soil and Water Assessment Tool (SWAT) model is a robust watershed modeling tool. It typically uses the ArcSWAT interface to create its inputs. ArcSWAT is public domain software which works in the licensed ArcGIS environment. The aim of this paper was to develop an open source user interface for the SWAT model. The interface, QSWAT, is written in the Python programming language and uses various functionalities of the open source geographic information system, QGIS. The current interface performs similar functions to ArcSWAT, but with additional enhanced features such as merging small subbasins and static and dynamic visualization of outputs. The interface is demonstrated through a case study in the Gumera watershed in the Lake Tana basin of Ethiopia, where it showed a successful performance. QSWAT will be a valuable tool for the SWAT scientific community, with improved availability and functionality compared with other options for creating SWAT models.},
  doi       = {10.1016/j.envsoft.2016.08.004},
  file      = {:Programs\\Introducing a new open source GIS user interface for the SWAT model.pdf:PDF},
  keywords  = {Open source software; QGIS; QSWAT; SWAT; Gumera watershed; Ethiopia},
  publisher = {Elsevier {BV}},
  timestamp = {2017-02-03},
  url       = {https://doi.org/10.1016%2Fj.envsoft.2016.08.004},
}

@Article{Whateley2015,
  author    = {Sarah Whateley and Richard N. Palmer and Casey Brown},
  title     = {Seasonal Hydroclimatic Forecasts as Innovations and the Challenges of Adoption by Water Managers},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2015},
  volume    = {141},
  number    = {5},
  abstract  = {Technological advances in forecasting the Earth’s climate offer a potentially useful tool to support planning and management
decisions in water resources. Previous research has found that the implementation of new ideas and practices are impeded by many challenges
such as low forecast skill, institutional obstacles, and political disincentives to innovation. To better understand barriers to forecast use at
seasonal-to-interannual, decadal, or longer time scales, this paper evaluates a diffusion of innovations (DoI) framework to assess the adoption
of hydroclimatic forecasts by water managers in the Northeast United States. Specifically, this paper seeks to understand how five innovation
characteristics, relative advantage, compatibility, complexity, trialability, and observability, influence the rate of adoption. Methods used for
this analysis include the distribution of a survey, interviews, and a literature review. Results indicated that while much attention has focused
on institutional obstacles, in the Connecticut River Basin obstacles were related to characteristics of the forecasts themselves. Evaluation of
the DoI makes clear that the challenges to forecast use are common to all innovations.},
  doi       = {10.1061/(ASCE)WR.1943-5452.0000466},
  file      = {:Ensembles\\Seasonal Hydroclimatic Forecasts as Innovations and the Challenges of Adoption by Water Managers.pdf:PDF},
  keywords  = {Forecasting; Decision support systems; Management; Climate change; Innovation},
  timestamp = {2017-02-03},
}

@Article{Wilks2009,
  author    = {Daniel S. Wilks},
  title     = {A gridded multisite weather generator and synchronization to observed weather data},
  journal   = {Water Resources Research},
  year      = {2009},
  volume    = {45},
  number    = {W10419},
  doi       = {10.1029/2009WR007902},
  file      = {:Hydrology\\Precipitation\\A gridded multisite weather generator and synchronization to observed weather data.pdf:PDF},
  timestamp = {2017-02-04},
}

@TechReport{Dorigo2009,
  author      = {Marco Dorigo and Thomas Stutzle},
  title       = {Ant Colony Optimization: Overview and Recent Advances},
  institution = {Université Libre de Bruxelles Institut de Recherches Interdisciplinaires et de Développements en Intelligence Artificielle},
  year        = {2009},
  number      = {TR/IRIDIA/2009-013},
  month       = {may},
  abstract    = {Ant Colony Optimization (ACO) [57, 59, 66] is a metaheuristic for solving hard combinatorial
optimization problems. The inspiring source of ACO is the pheromone trail laying and following
behavior of real ants, which use pheromones as a communication medium. In analogy to the
biological example, ACO is based on indirect communication within a colony of simple agents,
called (artificial) ants, mediated by (artificial) pheromone trails. The pheromone trails in ACO
serve as a distributed, numerical information, which the ants use to probabilistically construct
solutions to the problem being solved and which the ants adapt during the algorithm’s execution
to reflect their search experience.},
  file        = {:Optimization\\Ant Colony Optimization- Overview and Recent Advances.pdf:PDF},
  timestamp   = {2017-02-04},
}

@Article{Tapley2004,
  author    = {Byron D. Tapley and Srinivas Bettadpur and John C. Ries and Paul F. Thompson and Michael M. Watkins},
  title     = {GRACE Measurements of Mass Variability in the Earth System},
  journal   = {Science},
  year      = {2004},
  volume    = {305},
  pages     = {503 -- 505},
  month     = {jul},
  abstract  = {Monthly gravity field estimates made by the twin Gravity Recovery and Climate
Experiment (GRACE) satellites have a geoid height accuracy of 2to 3 millimeters at a spatial resolution as small as 400 kilometers. The annual cycle in
the geoid variations, up to 10 millimeters in some regions, peaked predominantly in the spring and fall seasons. Geoid variations observed over South
America that can be largely attributed to surface water and groundwater
changes show a clear separation between the large Amazon watershed and the
smaller watersheds to the north. Such observations will help hydrologists to
connect processes at traditional length scales (tens of kilometers or less) to
those at regional and global scales.},
  file      = {:Hydrology\\GRACE Measurements of Mass Variability in the Earth System.pdf:PDF},
  timestamp = {2017-02-04},
}

@Article{Wagner1999,
  author    = {Wolfgang Wagner and Guido Lemoine and Helmut Rott},
  title     = {A Method for Estimating Soil Moisture from ERS Scatterometer and Soil Data},
  journal   = {Remote Sensing of Environment},
  year      = {1999},
  volume    = {70},
  pages     = {191--207},
  comment   = {The potential of using ERS Scatterometer data for soil moisture monitoring over the Ukraine is investigated. The ERS Scatterometer is a C-band radar with a spatial resolution of 50 km and a high temporal sampling rate. An algorithm for estimating the surface soil moisture content is applied to 6 years of data. A qualitative comparison with meteorological observations and auxiliary information indicates that good-quality surface wetness values can be determined. A simple method is developed to relate the surface estimates with the profile soil moisture content. This model requires as input the remotely sensed radar data and soil data encompassing wilting level, field capacity, and porosity. The method was validated with an extensive data set of gravimetric soil moisture measurements in the 0–20 cm and 0–100 cm layers from the agrometeorological network in the Ukraine. It is found that the ERS Scatterometer data can be used to distinguish about five soil moisture levels with good confidence.},
  file      = {:Hydrology\\A Method for Estimating Soil Moisture from ERS Scatterometer and Soil Data.pdf:PDF},
  timestamp = {2017-02-04},
}

@Article{Scipal2008,
  author    = {K. Scipal and M. Drusch and W. Wagner},
  title     = {Assimilation of a {ERS} scatterometer derived soil moisture index in the {ECMWF} numerical weather prediction system},
  journal   = {Advances in Water Resources},
  year      = {2008},
  volume    = {31},
  number    = {8},
  pages     = {1101--1112},
  month     = {aug},
  abstract  = {The European Centre for Medium-Range Weather Forecasts (ECMWF) currently prepares the assimilation
of soil moisture data derived from advanced scatterometer (ASCAT) measurements. ASCAT is part of the
MetOp satellite payload launched in November 2006 and will ensure the operational provision of soil
moisture information until at least 2020. Several studies showed that soil moisture derived from scatterometer data contain skillful information. Based on data from its predecessor instruments, the ERS-1/
2 scatterometers we examine the potential of future ASCAT soil moisture data for numerical weather prediction (NWP). In a first step, we compare nine years of the ERS scatterometer derived surface soil moisture index (HS) against soil moisture from the ECMWF re-analysis (ERA40) data set (HE) to (i) identify
systematic differences and (ii) derive a transfer function which minimises these differences and transforms HS into model equivalent volumetric soil moisture H S. We then use a nudging scheme to assimilate
H
S in the soil moisture analysis of the ECMWF numerical weather prediction model. In this scheme the
difference between H
S and the model first guess HFG, calculated at 1200 UTC, is added in 1/4 fractions
throughout a 24 h window to the model resulting in analysed soil moisture HNDG. We compare results
from this experiment against those from a control experiment where soil moisture evolved freely and
against those from the operational ECMWF forecast system, which uses an optimum interpolation
scheme to analyse soil moisture. Validation against field observations from the Oklahoma Mesonet,
shows that the assimilation of H
S increases the correlation from 0.39 to 0.66 and decreases the RMSE
from 0.055 m3 m3 to 0.041 m3 m3 compared against the control experiment. The corresponding forecasts for low level temperature and humidity improve only marginally compared to the control experiment and deteriorate compared to the operational system. In addition, the results suggest that an
advanced data assimilation system, like the Extended Kalman Filter, could use the satellite observations
more effectively.},
  doi       = {10.1016/j.advwatres.2008.04.013},
  file      = {:Hydrology\\Assimilation of a ERS scatterometer derived soil moisture index in the ECMWF numerical weather prediction system.pdf:PDF},
  keywords  = {Soil moisture Scatterometer Data assimilation Numerical weather prediction},
  publisher = {Elsevier {BV}},
  timestamp = {2017-02-04},
  url       = {https://doi.org/10.1016%2Fj.advwatres.2008.04.013},
}

@Article{Wagner1999a,
  author    = {Wolfgang Wagner and Guido Lemoine and Maurice Borgeaud and Helmut Rott},
  title     = {A Study of Vegetation Cover Effects on ERS Scatterometer Data},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  year      = {1999},
  volume    = {37},
  number    = {2},
  pages     = {938--948},
  abstract  = {The scatterometer flown onboard the European
remote-sensing satellites ERS-1 and ERS-2 is a vertically polarized radar operating at 5.3 GHz (C-band) and has a spatial
resolution of 50 km. In a number of studies, the sensitivity of
the ERS scatterometer to vegetation has been demonstrated, but
it is not yet clear which vegetation parameters are of primary
importance to explain the ERS scatterometer signal. In this paper,
the effects of land cover and seasonal vegetation development
are investigated by comparing ERS scatterometer data with
land cover information, normalized difference vegetation index
(NDVI) data sets, and meteorological observations. As a study
area, the Iberian Peninsula was chosen. The Iberian Peninsula
is characterized by the Mediterranean climate that has a wet
winter and a dry summer. This allows us to better differentiate
the effects of the annual vegetation and precipitation cycle on
the temporal evolution of the backscattering coefficient 0. It is
shown that the ERS scatterometer has only limited capabilities
for monitoring the vegetation development within a given year
because most of the temporal variability of 0 is due to soil
moisture changes. On the other hand, it might be of merit for
vegetation discrimination on large scales (regional to global)
because the percentage area of forests, bushes, and shrubs within
one ERS scatterometer pixel is found to explain a significant part
of the spatial variability of the signal.},
  file      = {:Hydrology\\A Study of Vegetation Cover Effects on ERS Scatterometer Data.pdf:PDF},
  publisher = {IEEE},
  timestamp = {2017-02-04},
}

@Article{Loon2015,
  author    = {Anne F. Van Loon},
  title     = {Hydrological drought explained},
  journal   = {Wiley Interdisciplinary Reviews: Water},
  year      = {2015},
  volume    = {2},
  number    = {4},
  pages     = {359--392},
  month     = {apr},
  abstract  = {Drought is a complex natural hazard that impacts ecosystems and society in many
ways. Many of these impacts are associated with hydrological drought (drought
in rivers, lakes, and groundwater). It is, therefore, crucial to understand the
development and recovery of hydrological drought. In this review an overview
is given of the current state of scientific knowledge of definitions, processes, and
quantification of hydrological drought. Special attention is given to the influence
of climate and terrestrial properties (geology, land use) on hydrological drought
characteristics and the role of storage. Furthermore, the current debate about
the use and usefulness of different drought indicators is highlighted and recent
advances in drought monitoring and prediction are mentioned. Research on
projections of hydrological drought for the future is summarized. This review also
briefly touches upon the link of hydrological drought characteristics with impacts
and the issues related to drought management. Finally, four challenges for future
research on hydrological drought are defined that relate international initiatives
such as the Intergovernmental Panel on Climate Change (IPCC) and the ‘Panta
Rhei’ decade of the International Association of Hydrological Sciences (IAHS).},
  doi       = {10.1002/wat2.1085},
  file      = {:Hydrology\\Hydrological drought explained.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2017-02-04},
  url       = {https://doi.org/10.1002%2Fwat2.1085},
}

@Article{Schmitz2009,
  author    = {O. Schmitz and D. Karssenberg and W.P.A. van Deursen and C.G. Wesseling},
  title     = {Linking external components to a spatio-temporal modelling framework: Coupling {MODFLOW} and {PCRaster}},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2009},
  volume    = {24},
  number    = {9},
  pages     = {1088--1099},
  month     = {sep},
  abstract  = {An important step in the procedure of building an environmental model is the transformation of
a conceptual model into a numerical simulation. To simplify model construction a framework is required
that relieves the model developer from software engineering concerns. In addition, as the demand for
a holistic understanding of environmental systems increases, access to external model components is
necessary in order to construct integrated models.
We present a modelling framework that provides two- and three-dimensional building blocks for
construction of spatio-temporal models. Two different modelling languages available in the framework, the
first tailored and the second an enhanced Python scripting language, allow the development and modification of models. We explain for both languages the interfaces allowing to link specialised model components and thus extending the functionality of the framework. We demonstrate the coupling of external
components in order to create multicomponent models by the development of the link to the groundwater
model MODFLOW and provide results of an integrated catchment model. The approach described is
appropriate for constructing integrated models that include a coupling of a small number of components.},
  doi       = {10.1016/j.envsoft.2009.02.018},
  file      = {:Hydrology\\Linking external components to a spatio-temporal modelling framework- Coupling MODFLOW and PCRaster.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2017-02-04},
  url       = {https://doi.org/10.1016%2Fj.envsoft.2009.02.018},
}

@Article{Lehner2008,
  author    = {Lehner, B. and Verdin, K. and Jarvis, A.},
  title     = {New Global Hydrography Derived From Spaceborne Elevation Data},
  journal   = {Eos, Transactions, American Geophysical Union (EOS)},
  year      = {2008},
  volume    = {89},
  number    = {10},
  pages     = {93--104},
  month     = {mar},
  file      = {:Hydrology\\New Global Hydrography Derived From Spaceborne Elevation Data.pdf:PDF},
  timestamp = {2017-02-04},
  type      = {89},
}

@Article{Farr2000,
  author    = {Farr, T. G. and M. Kobrick},
  title     = {Shuttle Radar Topography Mission Produces a Wealth of Data},
  journal   = {Eos, Transactions, American Geophysical Union (EOS)},
  year      = {2000},
  volume    = {81},
  number    = {48},
  pages     = {583-585},
  month     = {nov},
  file      = {:Hydrology\\Shuttle radar topography mission produces a wealth of data.pdf:PDF},
  timestamp = {2017-02-04},
}

@Article{Durr2005,
  author    = {Hans H. Durr and Michel Meybeck},
  title     = {Lithologic composition of the Earth's continental surfaces derived from a new digital map emphasizing riverine material transfer},
  journal   = {Global Biogeochemical Cycles},
  year      = {2005},
  volume    = {19},
  number    = {GB4S10},
  abstract  = {A new digital map of the lithology of the continental surfaces is proposed in vector
mode (n  8300, reaggregated at 0.5  0.5 resolution) for 15 rock types (plus water
and ice) targeted to surficial Earth system analysis (chemical weathering, land
erosion, carbon cycling, sediment formation, riverine fluxes, aquifer typology, coastal
erosion). These types include acid (0.98% at global scale) and basic (5.75%) volcanics,
acid (7.23%) and basic (0.20%) plutonics, Precambrian basement (11.52%) and
metamorphic rocks (4.07%), consolidated siliciclastic rocks (16.28%), mixed
sedimentary (7.75%), carbonates (10.40%), semi- to un-consolidated sedimentary rocks
(10.05%), alluvial deposits (15.48%), loess (2.62%), dunes (1.54%) and evaporites
(0.12%). Where sediments, volcanics and metamorphosed rocks are too intimately
mixed, a complex lithology (5.45%) class is added. Average composition is then
tabulated for continents, ocean drainage basins, relief types (n = 7), 10 latitudinal
bands, geological periods (n = 7), and exorheic versus endorheic domain and
for formerly glaciated regions. Surficial lithology is highly heterogeneous and major
differences are noted in any of these ensembles. Expected findings include the
importance of alluvium and unconsolidated deposits in plains and lowlands, of
Precambrian and metamorphic rocks in mid-mountain areas, the occurrence of loess,
dunes and evaporites in dry regions, and of carbonates in Europe. Less expected are the
large occurrences of volcanics (74% of their outcrops) in highly dissected relief and
the importance of loess in South America. Prevalence of carbonate rocks between
15N and 65N and of Precambrian plus metamorphics in two bands (25S–15N and
north of 55N) is confirmed. Asia and the Atlantic Ocean drainage basin, without
Mediterranean and Black Sea, are the most representative ensembles. In cratons the
influence of ancient geological periods is often masked by young sediments, while
active orogens have a specific composition.},
  doi       = {10.1029/2005GB002515},
  file      = {:Hydrology\\Lithologic composition of the Earth's continental surfaces derived from a new digital map emphasizing riverine material transfer.pdf:PDF},
  timestamp = {2017-02-04},
}

@TechReport{Latham2014,
  author      = {John Latham and Renato Cumani and Ilaria Rosati and Mario Bloise},
  title       = {Global Land and Cover SHARE},
  institution = {FAO},
  year        = {2014},
  number      = {1.0},
  file        = {:WaterResources\\Global Land Cover SHARE.pdf:PDF},
  keywords    = {GLC-SHARE},
  timestamp   = {2017-02-04},
}

@TechReport{Lutz2013,
  author      = {A.F. Lutz and W.W. Immerzeel},
  title       = {Water Availability Analysis for the Upper Indus, Ganges, Brahmaputra, Salween and Mekong River and Basins},
  institution = {International Centre for Integrated Mountain Development (ICIMOD)},
  year        = {2013},
  month       = {sep},
  file        = {:WaterResources\\Water Availability Analysis for the Upper Indus, Ganges, Brahmaputra, Salween and Mekong River Basins.pdf:PDF},
  timestamp   = {2017-02-05},
}

@Conference{Ghosh2011,
  author    = {Shyamal Ghosh and Subashisa Dutta},
  title     = {Impact of Climate and Land Use Changes on the Flood Vulnerability of the Brahmaputra Basin},
  booktitle = {GeoSpatial World Forum},
  year      = {2011},
  month     = {jan},
  note      = {Rice Irrigation System Evaluation (RISE) model (Dutta and Zade, 2003)},
  abstract  = {A physically based macro-scale distributed hydrological model (DHM), which works on the
concept of hydrological similarity classes (HSCs), has been calibrated validated and then
used to assess the possible future changes in the flood characteristics and flood vulnerability
of the Brahmaputra basin, India, due to climate and land use changes. Future projected
meteorological data from a regional climate model (RCM) simulation (PRECIS) and the
‘Best Guess’ land use change scenarios were used to obtain the changes in spatio-temporal
distribution of flood generation and its propagation through the Brahmaputra river and its
tributaries. This spatio-temporal distribution of flood regime changes has been analyzed to
assess the flood vulnerability of the basin.
This study reveals that the projected climate change would affect the flood vulnerability more
significantly than the land use / land cover changes. Alteration of paddy agriculture fields
would significantly change the flood characteristics in the valley. The projected climate
change can increase the peak flow of Brahmaputra by about 28%, the same has been found to
be increased by a maximum of about 9% for land use/ land cover changes. Similarly the other
flood characteristics like flood inundation period, monsoonal yield, time to peak, maximum
lift and number of waves in a season have been found to be more vulnerable to be affected by
the projected climate change scenarios and these changes increase towards the downstream
areas of the basin. Longer duration of waves with higher discharges are expected to inundate
more areas, increasing the flood vulnerable area, in future causing serious socio-economic
and ecological changes in the basin. Hydrological impacts of changing land use/ land cover
have been found to be more dominating in the drier years compared to the wet years.},
  file      = {:WaterResources\\Impact of Climate and Land Use Changes on the Flood Vulnerability of the Brahmaputra Basin.pdf:PDF},
  keywords  = {Climate change, Land use, Flood, Brahmaputra basin},
  timestamp = {2017-02-07},
}

@Article{Futter2015,
  author    = {M. N. Futter and P. G. Whitehead and S. Sarkar and H. Rodda and J. Crossman},
  title     = {Rainfall runoff modelling of the Upper Ganga and Brahmaputra basins using {PERSiST}},
  journal   = {Environmental Science: Processes and Impacts},
  year      = {2015},
  volume    = {17},
  number    = {6},
  pages     = {1070--1081},
  abstract  = {There are ongoing discussions about the appropriate level of complexity and sources of uncertainty in rainfall runoff models. Simulations for operational hydrology, flood forecasting or nutrient transport all warrant different levels of complexity in the modelling approach. More complex model structures are appropriate for simulations of land-cover dependent nutrient transport while more parsimonious model structures may be adequate for runoff simulation. The appropriate level of complexity is also dependent on data availability. Here, we use PERSiST; a simple, semi-distributed dynamic rainfall-runoff modelling toolkit to simulate flows in the Upper Ganges and Brahmaputra rivers. We present two sets of simulations driven by single time series of daily precipitation and temperature using simple (A) and complex (B) model structures based on uniform and hydrochemically relevant land covers respectively. Models were compared based on ensembles of Bayesian Information Criterion (BIC) statistics. Equifinality was observed for parameters but not for model structures. Model performance was better for the more complex (B) structural representations than for parsimonious model structures. The results show that structural uncertainty is more important than parameter uncertainty. The ensembles of BIC statistics suggested that neither structural representation was preferable in a statistical sense. Simulations presented here confirm that relatively simple models with limited data requirements can be used to credibly simulate flows and water balance components needed for nutrient flux modelling in large, data-poor basins.},
  doi       = {10.1039/c4em00613e},
  file      = {:WaterResources\\Rainfall runoff modelling of the Upper Ganga and Brahmaputra basins using PERSiST.pdf:PDF},
  publisher = {Royal Society of Chemistry ({RSC})},
  timestamp = {2017-02-05},
  url       = {https://doi.org/10.1039%2Fc4em00613e},
}

@Article{Masood2015,
  author    = {M. Masood and P. J.-F. Yeh and N. Hanasaki and K. Takeuchi},
  title     = {Model study of the impacts of future climate change on the hydrology of Ganges-Brahmaputra-Meghna basin},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2015},
  volume    = {19},
  number    = {2},
  pages     = {747--770},
  month     = {feb},
  abstract  = {The intensity, duration, and geographic extent of floods in Bangladesh mostly depend on the combined influences of three river systems, the Ganges, Brahmaputra and Meghna (GBM). In addition, climate change is likely to have significant effects on the hydrology and water resources of the GBM basin and may ultimately lead to more serious floods in Bangladesh. However, the assessment of climate change impacts on the basin-scale hydrology by using well-calibrated hydrologic modeling has seldom been conducted in the GBM basin due to the lack of observed data for calibration and validation. In this study, a macroscale hydrologic model H08 has been applied over the basin at a relatively fine grid resolution (10 km) by integrating the fine-resolution DEM (digital elevation model) data for accurate river networks delineation. The model has been calibrated via the analysis of model parameter sensitivity and validated based on long-term observed daily streamflow data. The impacts of climate change (considering a high-emissions path) on runoff, evapotranspiration, and soil moisture are assessed by using five CMIP5 (Coupled Model Intercomparison Project Phase 5) GCMs (global circulation models) through three time-slice experiments; the present-day (1979–2003), the near-future (2015–2039), and the far-future (2075–2099) periods. Results show that, by the end of 21st century, (a) the entire GBM basin is projected to be warmed by ~4.3 °C; (b) the changes of mean precipitation (runoff) are projected to be +16.3% (+16.2%), +19.8% (+33.1%), and +29.6% (+39.7%) in the Brahmaputra, Ganges, and Meghna, respectively; and (c) evapotranspiration is projected to increase for the entire GBM (Brahmaputra: +16.4%, Ganges: +13.6%, Meghna: +12.9%) due to increased net radiation as well as warmer temperature. Future changes of hydrologic variables are larger in the dry season (November–April) than in the wet season (May–October). Amongst the three basins, the Meghna shows the highest increase in runoff, indicating higher possibility of flood occurrence. The uncertainty due to the specification of key model parameters in model predictions is found to be low for estimated runoff, evapotranspiration and net radiation. However, the uncertainty in estimated soil moisture is rather large with the coefficient of variation ranging from 14.4 to 31% among the three basins.},
  doi       = {10.5194/hess-19-747-2015},
  file      = {:WaterResources\\Model study of the impacts of future climate change on the hydrology of Ganges–Brahmaputra–Meghna basin.pdf:PDF},
  publisher = {Copernicus {GmbH}},
  timestamp = {2017-02-05},
  url       = {https://doi.org/10.5194%2Fhess-19-747-2015},
}

@Article{Akbor2014,
  author    = {A. H. M. Siddique-E-Akbor and Faisal Hossain and Safat Sikder and C. K. Shum and Steven Tseng and Yuchan Yi and F. J. Turk and Ashutosh Limaye},
  title     = {Satellite Precipitation Data-Driven Hydrological Modeling for Water Resources Management in the Ganges, Brahmaputra, and Meghna Basins},
  journal   = {Earth Interactions},
  year      = {2014},
  volume    = {18},
  number    = {17},
  pages     = {1--25},
  month     = {nov},
  abstract  = {The Ganges–Brahmaputra–Meghna (GBM) river basins exhibit extremes in surface water availability at seasonal to annual time scales. However, because of a lack of basinwide hydrological data from in situ platforms, whether they are real time or historical, water management has been quite challenging for the 630 million inhabitants. Under such circumstances, a large-scale and spatially distributed hydrological model, forced with more widely available satellite meteorological data, can be useful for generating high resolution basinwide hydrological state variable data [streamflow, runoff, and evapotranspiration (ET)] and for decision making on water management. The Variable Infiltration Capacity (VIC) hydrological model was therefore set up for the entire GBM basin at spatial scales ranging from 12.5 to 25 km to generate daily fluxes of surface water availability (runoff and streamflow). Results indicate that, with the selection of representative gridcell size and application of correction factors to evapotranspiration calculation, it is possible to significantly improve streamflow simulation and overcome some of the insufficient sampling and data quality issues in the ungauged basins. Assessment of skill of satellite precipitation forcing datasets revealed that the Tropical Rainfall Measuring Mission (TRMM) Multisatellite Precipitation Analysis (TMPA) product of 3B42RT fared comparatively better than the Climate Prediction Center (CPC) morphing technique (CMORPH) product for simulation of streamflow. The general conclusion that emerges from this study is that spatially distributed hydrologic modeling for water management is feasible for the GBM basins under the scenario of inadequate in situ data availability. Satellite precipitation forcing datasets provide the necessary skill for water balance studies at interannual and interseasonal scales. However, further improvement in skill may be required if these datasets are to be used for flood management at daily to weekly time scales and within a data assimilation framework.},
  doi       = {10.1175/ei-d-14-0017.1},
  file      = {:WaterResources\\Satellite precipitation data–driven hydrological modeling for water resources management in the Ganges, Brahmaputra and Meghna Basins.pdf:PDF},
  keywords  = {Precipitation; Hydrologic models; Land surface model; Model evaluation/performance},
  publisher = {American Meteorological Society},
  timestamp = {2017-02-07},
  url       = {https://doi.org/10.1175%2Fei-d-14-0017.1},
}

@Article{Bailey2016,
  author    = {Ryan T. Bailey and Tyler C. Wible and Mazdak Arabi and Rosemary M. Records and Jeffrey Ditty},
  title     = {Assessing regional-scale spatio-temporal patterns of groundwater-surface water interactions using a coupled {SWAT}-{MODFLOW} model},
  journal   = {Hydrological Processes},
  year      = {2016},
  volume    = {30},
  number    = {23},
  pages     = {4420--4433},
  abstract  = {Interaction between groundwater and surface water in watersheds has significant impacts on water management and water rights, nutrient loading from aquifers to streams, and in-stream flow requirements for aquatic species. Of particular importance are the spatial patterns of these interactions. This study explores the spatio-temporal patterns of groundwater discharge to a river system in a semi-arid region, with methods applied to the Sprague River Watershed (4100 km2) within the Upper Klamath Basin in Oregon, USA. Patterns of groundwater–surface water interaction are explored throughout the watershed during the 1970–2003 time period using a coupled SWAT-MODFLOW model tested against streamflow, groundwater level and field-estimated reach-specific groundwater discharge rates. Daily time steps and coupling are used, with groundwater discharge rates calculated for each model computational point along the stream. Model results also are averaged by month and by year to determine seasonal and decadal trends in groundwater discharge rates. Results show high spatial variability in groundwater discharge, with several locations showing no groundwater/surface water interaction. Average annual groundwater discharge is 20.5 m3/s, with maximum and minimum rates occurring in September–October and March–April, respectively. Annual average rates increase by approximately 0.02 m3/s per year over the 34-year period, negligible compared with the average annual rate, although 70% of the stream network experiences an increase in groundwater discharge rate between 1970 and 2003. Results can assist with water management, identifying potential locations of heavy nutrient mass loading from the aquifer to streams and ecological assessment and planning focused on locations of high groundwater discharge.},
  doi       = {10.1002/hyp.10933},
  file      = {:Programs\\Assessing regional-scale spatio-temporal patterns of groundwater–surface water interactions using a coupled SWAT-MODFLOW model.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2017-02-07},
  url       = {https://doi.org/10.1002%2Fhyp.10933},
}

@Article{Dowlatabadi2015,
  author    = {Sepideh Dowlatabadi and S. M. Ali Zomorodian},
  title     = {Conjunctive simulation of surface water and groundwater using {SWAT} and {MODFLOW} in Firoozabad watershed},
  journal   = {{KSCE} Journal of Civil Engineering},
  year      = {2015},
  volume    = {20},
  number    = {1},
  pages     = {485--496},
  month     = {mar},
  abstract  = {One of the most essential groundwater model components is accurate information about the recharge values within the input data, often introduced to a groundwater model as a percentage of rainfall on aquifers. Recharge values are influenced by many temporal and spatial factors. This paper suggests the use of a SWAT model for surface water simulation and the estimation of recharge rates. In this research, sensitivity analysis, calibration, validation and uncertainty analysis of results were performed by SWAT-CUP software. Due to the semi-distributed features of SWAT and the difficulty of calculating groundwater distributed parameters, recharge values estimated by SWAT were used in a MODFLOW model for groundwater simulation at steady and unsteady states. This method was applied in the Firoozabad basin, which is one of the most suitable agricultural basins for modeling surface water and groundwater in Iran. After MODFLOW model calibration, hydrodynamic coefficients of the aquifer were determined and the sensitivity of the model was checked for hydraulic conductivity and discharge rate of wells. In order to prove confidence, the model was validated. SWAT and MODFLOW models were successfully tested and the results of the combination of the two models were found to be acceptable.},
  doi       = {10.1007/s12205-015-0354-8},
  file      = {:Programs\\Conjunctive simulation of surface water and groundwater using SWAT and MODFLOW in Firoozabad watershed.pdf:PDF},
  publisher = {Springer Nature},
  timestamp = {2017-02-07},
  url       = {https://doi.org/10.1007%2Fs12205-015-0354-8},
}

@PhdThesis{Liang1994,
  author      = {Xu Liang},
  title       = {Two-Layer Variable Infiltration Capacity Land Surface Representation for General Circulation Models},
  school      = {University of Washington},
  year        = {1994},
  month       = {may},
  abstract    = {A simple two-layer variable infiltration capacity (VIC-2L) land surface model suitable for incorporation in general circulation models (GCMs) is described. The model consists of a two-layer characterization of the soil within a GCM grid cell, and uses an aerodynamic representation of latent and sensible heat fluxes at the land surface. The effects of GCM spatial subgrid variability of soil moisture and a hydrologically realistic runoff mechanism are represented in the soil layers. The model was tested using long-term hydrologic and climatalogical data for Kings Creek, Kansas to estimate and validate the hydrological parameters. Surface flux data from three First International Satellite Land Surface Climatology Project Field Experiments (FIFE) intensive field compaigns in the summer and fall of 1987 in central Kansas, and from the Anglo-Brazilian Amazonian Climate Observation Study (ABRACOS) in Brazil were used to validate the mode-simulated surface energy fluxes and surface temperature.},
  file        = {:Programs\\Two-Layer Variable Infiltration Capacity Land Surface Representation for General Circulation Models.pdf:PDF},
  institution = {University of Washington},
  number      = {Service},
  timestamp   = {2017-02-07},
}

@InBook{Markstrom2015,
  chapter   = {Chapter 7 of Section B, Surface Water Book 6, Modeling Techniques},
  title     = {PRMS-IV, the Precipitation-Runoff Modeling System, Version 4},
  publisher = {U.S. Department of the Interior U.S. Geological Survey},
  year      = {2015},
  author    = {Steven L. Markstrom and R. Steven Regan and Lauren E. Hay and Roland J. Viger and Richard M. T. Webb and Robert A. Payn and Jacob H. LaFontaine},
  file      = {:Programs\\Precipitation-Runoff Modeling System, Version 4.pdf:PDF},
  timestamp = {2017-02-07},
}

@Article{Pfeffer2014,
  author    = {Pfeffer, W. Tad and Anthony A. Arendt and Andrew Bliss and Tobias Bolch and J. Graham Cogley and Alex S. Gardner and Jon-ove Hagen and Regine Hock and and Georg Kaser and Christian Kienholz and Evan S. Miles and Geir Moholdt and Nico M{\"O}lg and Frank Paul and Valentina Radic and Philipp Rastner and Bruce H. Raup and Justin Rich and Martin J. Sharp and the Randolph Consortium},
  title     = {The Randolph Glacier Inventory: a globally complete inventory of glaciers},
  journal   = {Journal of Glaciology},
  year      = {2014},
  volume    = {60},
  pages     = {537--552},
  timestamp = {2017-02-11},
}

@TechReport{Hughes2012,
  author      = {Joseph D. Hughes and Christian D. Langevin and Kevin L. Chartier and Jeremy T. White},
  title       = {Documentation of the Surface-Water Routing (SWR1) Process for Modeling Surface-Water Flow with the U.S. Geological Survey Modular Groundwater Model (MODFLOW–2005)},
  institution = {United States Geologic Survey},
  year        = {2012},
  type        = {Book 6, Chapter A40, Version 1.0},
  abstract    = {A flexible Surface-Water Routing (SWR1) Process that solves the continuity equation for one-dimensional and two-dimensional surface-water flow routing has been developed for the U.S. Geological Survey three-dimensional groundwater model, MODFLOW–2005. Simple level- and tilted-pool reservoir routing and a diffusive-wave approximation of the Saint-Venant equations have been implemented. Both methods can be implemented in the same model and the solution method can be simplified to represent constant-stage elements that are functionally equivalent to the standard MODFLOW River or Drain Package boundary conditions.

A generic approach has been used to represent surface-water features (reaches) and allows implementation of a variety of geometric forms. One-dimensional geometric forms include rectangular, trapezoidal, and irregular cross section reaches to simulate one-dimensional surface-water features, such as canals and streams. Two-dimensional geometric forms include reaches defined using specified stage-volume-area-perimeter (SVAP) tables and reaches covering entire finite-difference grid cells to simulate two-dimensional surface-water features, such as wetlands and lakes. Specified SVAP tables can be used to represent reaches that are smaller than the finite-difference grid cell (for example, isolated lakes), or reaches that cannot be represented accurately using the defined top of the model.

Specified lateral flows (which can represent point and distributed flows) and stage-dependent rainfall and evaporation can be applied to each reach. The SWR1 Process can be used with the MODFLOW Unsaturated Zone Flow (UZF1) Package to permit dynamic simulation of runoff from the land surface to specified reaches. Surface-water/groundwater interactions in the SWR1 Process are mathematically defined to be a function of the difference between simulated stages and groundwater levels, and the specific form of the reach conductance equation used in each reach. Conductance can be specified directly or calculated as a function of the simulated wetted perimeter and defined reach bed hydraulic properties, or as a weighted combination of both reach bed hydraulic properties and horizontal hydraulic conductivity. Each reach can be explicitly coupled to a single specific groundwater-model layer or coupled to multiple groundwater-model layers based on the reach geometry and groundwater-model layer elevations in the row and column containing the reach.

Surface-water flow between reservoirs is simulated using control structures. Surface-water flow between reaches, simulated by the diffusive-wave approximation, can also be simulated using control structures. A variety of control structures have been included in the SWR1 Process and include (1) excess-volume structures, (2) uncontrolled-discharge structures, (3) pumps, (4) defined stage-discharge relations, (5) culverts, (6) fixed- or movable-crest weirs, and (7) fixed or operable gated spillways. Multiple control structures can be implemented in individual reaches and are treated as composite flow structures.

Solution of the continuity equation at the reach-group scale (a single reach or a user-defined collection of individual reaches) is achieved using exact Newton methods with direct solution methods or exact and inexact Newton methods with Krylov sub-space methods. Newton methods have been used in the SWR1 Process because of their ability to solve nonlinear problems. Multiple SWR1 time steps can be simulated for each MODFLOW time step, and a simple adaptive time-step algorithm, based on user-specified rainfall, stage, flow, or convergence constraints, has been implemented to better resolve surface-water response. A simple linear- or sigmoid-depth scaling approach also has been implemented to account for increased bed roughness at small surface-water depths and to increase numerical stability. A line-search algorithm also has been included to improve the quality of the Newton-step upgrade vector, if possible.

The SWR1 Process has been benchmarked against one- and two-dimensional numerical solutions from existing one- and two-dimensional numerical codes that solve the dynamic-wave approximation of the Saint-Venant equations. Two-dimensional solutions test the ability of the SWR1 Process to simulate the response of a surface-water system to (1) steady flow conditions for an inclined surface (solution of Manning’s equation), and (2) transient inflow and rainfall for an inclined surface. The one-dimensional solution tests the ability of the SWR1 Process to simulate a looped network with multiple upstream inflows and several control structures. The SWR1 Process also has been compared to a level-pool reservoir solution. A synthetic test problem was developed to evaluate a number of different SWR1 solution options and simulate surface-water/groundwater interaction.

The solution approach used in the SWR1 Process may not be applicable for all surface-water/groundwater problems. The SWR1 Process is best suited for modeling long-term changes (days to years) in surface-water and groundwater flow. Use of the SWR1 Process is not recommended for modeling the transient exchange of water between streams and aquifers when local and convective acceleration and other secondary effects (for example, wind and Coriolis forces) are substantial. Dam break evaluations and two-dimensional evaluations of spatially extensive domains are examples where acceleration terms and secondary effects would be significant, respectively.},
  file        = {:Programs\\Documentation of the Surface-Water Routing (SWR1) Process for Modeling Surface-Water Flow with the U.S. Geological Survey Modular Groundwater Model (MODFLOW–2005).pdf:PDF},
  timestamp   = {2017-02-11},
}

@TechReport{Niswonger2005,
  author      = {Richard G. Niswonger and Sorab Panday and Motomu Ibaraki},
  title       = {MODFLOW-NWT, A Newton Formulation for MODFLOW-2005},
  institution = {United States Department of Interior, United States Geologic Survey},
  year        = {2005},
  type        = {Chapter 37 of Section A, Groundwater Book 6, Modeling Techniques},
  file        = {:Programs\\MODFLOW-NWT, A Newton Formulation for MODFLOW-2005.pdf:PDF},
  timestamp   = {2017-02-12},
}

@TechReport{FAO2009,
  title     = {Harmonized World Soil Database},
  year      = {2009},
  file      = {:Programs\\Harmonized World Soil Database.pdf:PDF},
  timestamp = {2017-02-12},
}

@InBook{Niswonger2006,
  chapter     = {Chapter 19},
  title       = {Documentation of the Unsaturated-Zone Flow (UZF1) Package for modeling unsaturated flow between the land surface and the water table with MODFLOW–2005},
  year        = {2006},
  author      = {Richard G. Niswonger and David E. Prudic and R. Steven Regan},
  volume      = {Section A, Ground Water},
  number      = {Techniques and Methods 6-A19},
  series      = {Book 6, Modeling Techniques},
  file        = {:Programs\\Documentation of the Unsaturated-Zone Flow (UZF1) Package for modeling unsaturated flow between the land surface and the water table with MODFLOW–2005.pdf:PDF},
  institution = {United States Department of the Interior United States Geological Survey},
  timestamp   = {2017-02-14},
}

@TechReport{Hanson2014,
  author      = {R.T. Hanson and Scott E. Boyce and Wolfgang Schmid and Joseph D. Hughes and Steffen M. Mehl and Stanley A. Leake and Thomas Maddock III and Richard G. Niswonger},
  title       = {One-Water Hydrologic Flow Model (MODFLOW-OWHM)},
  institution = {United States Department of the Interior United States Geologic Survey},
  year        = {2014},
  file        = {:Programs\\One-Water Hydrologic Flow Model (MODFLOW-OWHM).pdf:PDF},
  timestamp   = {2017-02-15},
}

@Article{Hanson2010,
  author    = {R. T. Hanson and W. Schmid and C. C. Faunt and B. Lockwood},
  title     = {Simulation and Analysis of Conjunctive Use with {MODFLOW}{\textquotesingle}s Farm Process},
  journal   = {Ground Water},
  year      = {2010},
  volume    = {48},
  number    = {5},
  pages     = {674--689},
  month     = {jun},
  abstract  = {The extension of MODFLOW onto the landscape with the Farm Process (MF-FMP) facilitates fully coupled
simulation of the use and movement of water from precipitation, streamflow and runoff, groundwater flow, and
consumption by natural and agricultural vegetation throughout the hydrologic system at all times. This allows for
more complete analysis of conjunctive use water-resource systems than previously possible with MODFLOW
by combining relevant aspects of the landscape with the groundwater and surface water components. This
analysis is accomplished using distributed cell-by-cell supply-constrained and demand-driven components across
the landscape within “water-balance subregions” comprised of one or more model cells that can represent a
single farm, a group of farms, or other hydrologic or geopolitical entities. Simulation of micro-agriculture in
the Pajaro Valley and macro-agriculture in the Central Valley are used to demonstrate the utility of MF-FMP.
For Pajaro Valley, the simulation of an aquifer storage and recovery system and related coastal water distribution
system to supplant coastal pumpage was analyzed subject to climate variations and additional supplemental
sources such as local runoff. For the Central Valley, analysis of conjunctive use from different hydrologic
settings of northern and southern subregions shows how and when precipitation, surface water, and groundwater
are important to conjunctive use. The examples show that through MF-FMP’s ability to simulate natural and
anthropogenic components of the hydrologic cycle, the distribution and dynamics of supply and demand can be
analyzed, understood, and managed. This analysis of conjunctive use would be difficult without embedding them
in the simulation and are difficult to estimate a priori},
  doi       = {10.1111/j.1745-6584.2010.00730.x},
  file      = {:Hydrology\\Groundwater\\Simulation and analysis of conjunctive use with MODFLOW's Farm Process.pdf:PDF},
  publisher = {Wiley-Blackwell},
  timestamp = {2017-02-15},
  url       = {https://doi.org/10.1111%2Fj.1745-6584.2010.00730.x},
}

@TechReport{Winston2005,
  author      = {Richard B. Winston},
  title       = {ModelMuse—A Graphical User Interface for MODFLOW–2005 and PHAST},
  institution = {USGS},
  year        = {2005},
  file        = {:Programs\\ModelMuse—A Graphical User Interface for MODFLOW-2005 and PHAST.pdf:PDF},
  timestamp   = {2017-02-15},
}

@TechReport{Schmid2006,
  author      = {Wolfgang Schmid and R.T. Hanson and Thomas Maddock III and S.A. Leake},
  title       = {User Guide and for the Farm and Process (FMP1) and for the and U.S. Geological and Survey’s Modular and Three-Dimensional and Finite-Difference Ground-Water Flow Model and MODFLOW},
  institution = {USGS},
  year        = {2006},
  type        = {U.S. Geological Survey Techniques and Methods 6-A17},
  file        = {:Programs\\User guide for the farm process (FMP1) for the U.S. Geological Survey’s modular three-dimensional finite-difference ground-water flow model, MODFLOW-2000.pdf:PDF},
  timestamp   = {2017-02-18},
}

@TechReport{Schmid2009,
  author      = {Schmid, Wolfgang and Hanson R.T.},
  title       = {The Farm and Process Version and 2 (FMP2) and for MODFLOW and Modifications and Upgrades and to FMP1},
  institution = {USGS},
  year        = {2009},
  type        = {Book 6, Chapter A32, 102p},
  file        = {:Programs\\The Farm Process Version 2 (FMP2) for MODFLOW-2005 - Modifications and Upgrades to FMP1.pdf:PDF},
  timestamp   = {2017-02-18},
}

@Article{Hanson2013,
  author    = {Randall T. Hanson and Wolfgang Schmid},
  title     = {Economic Resilience through “One-Water” Management},
  journal   = {USGS},
  year      = {2013},
  abstract  = {Economic Resilience through “One-Water” Management Disruption of water availability leads to food scarcity and loss of economic opportunity. Development of effective water-resource  policies and management strategies could provide resilience to local economies in the face of water disruptions such as drought,  flood, and climate change. To accomplish this, a detailed understanding of human water use and natural water resource availability  is needed. A hydrologic model is a computer software system that simulates the movement and use of water in a geographic area.  It takes into account all components of the water cycle—“One Water”—and helps estimate water budgets for groundwater, surface  water, and landscape features. The U.S. Geological Survey MODFLOW One-Water Integrated Hydrologic Model (MODFLOW- OWHM) software and scientific methods can provide water managers and political leaders with hydrologic information they need  to help ensure water security and economic resilience (fig. 1)},
  file      = {:Programs\\Economic resilience through One-Water management.pdf:PDF},
  timestamp = {2017-02-18},
}

@Article{Schmid2014,
  author    = {Wolfgang Schmid and R.T. Hanson and S.A. Leake and Joseph D. Hughes and Richard G. Niswonger},
  title     = {Feedback of land subsidence on the movement and conjunctive use of water resources},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2014},
  volume    = {62},
  pages     = {253--270},
  month     = {dec},
  abstract  = {The dependency of surface- or groundwater flows and aquifer hydraulic properties on dewateringinduced layer deformation is not available in the USGS's groundwater model MODFLOW. A new integrated hydrologic model, MODFLOW-OWHM, formulates this dependency by coupling mesh deformation with aquifer transmissivity and storage and by linking land subsidence/uplift with deformationdependent flows that also depend on aquifer head and other flow terms. In a test example, flows
most affected were stream seepage and evapotranspiration from groundwater (ETgw). Deformation
feedback also had an indirect effect on conjunctive surface- and groundwater use components: Changed
stream seepage and streamflows influenced surface-water deliveries and returnflows. Changed ETgw
affected irrigation demand, which jointly with altered surface-water supplies resulted in changed supplemental groundwater requirements and pumping and changed return runoff. This modeling feature
will improve the impact assessment of dewatering-induced land subsidence/uplift (following irrigation
pumping or coal-seam gas extraction) on surface receptors, inter-basin transfers, and surfaceinfrastructure integrity.},
  doi       = {10.1016/j.envsoft.2014.08.006},
  file      = {:Hydrology\\Groundwater\\Feedback of land subsidence on the movement and conjunctive use of water resources.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2017-02-18},
  url       = {https://doi.org/10.1016%2Fj.envsoft.2014.08.006},
}

@Article{Perkins1999,
  author    = {Samuel Perkins and Marios Sophocleous},
  title     = {Development of a Comprehensive Watershed Model Applied to Study Stream Yield under Drought Conditions},
  journal   = {Ground Water},
  year      = {1999},
  volume    = {37},
  number    = {3},
  pages     = {418--426},
  abstract  = {We developed a model code to simulate a watershed's hydrology and the hydraulic response of an interconnected stream-aquifer system, and applied the model code to the Lower Republican River Basin in Kansas. The model code links two well-known computer programs: MODFLOW (modular 3-D flow model), which simulates ground water flow and stream-aquifer interaction; and SWAT (soil water assessment tool), a soil water budget simulator for an agricultural watershed. SWAT represents a basin as a collection of subbasins in terms of soil, land use, and weather data, and simulates each subbasin on a daily basis to determine runoff, percolation, evaporation, irrigation, pond seepage, and crop growth. Because SWAT applies a lumped hydrologic model to each sub-basin, spatial heterogeneities with respect to factors such as soil type and land use are not resolved geographically, but can instead be represented statistically. For the Republican River Basin model, each combination of six soil types and three land uses, referred to as a hydrologic response unit (HRU), was simulated with a separate execution of SWAT. A spatially weighted average was then taken over these results for each hydrologic flux and time step by a separate program, SWBAVG. We wrote a package for MODFLOW to associate each subbasin with a subset of aquifer grid cells and stream reaches, and to distribute the hydrologic fluxes given for each subbasin by SWAT and SWBAVG over MODFLOW's stream-aquifer grid to represent tributary flow, surface and ground water diversions, ground water recharge, and evapotranspiration from ground water. The Lower Republican River Basin model was calibrated with respect to measured ground water levels, streamflow, and reported irrigation water use. The model was used to examine the relative contributions of stream yield components and the impact on stream yield and base flow of administrative measures to restrict irrigation water use during droughts. Model results indicate that tributary flow is the dominant component of stream yield and that reduction of irrigation water use produces a corresponding increase in base flow and stream yield. However, the increase in stream yield resulting from reduced water use does not appear to be of sufficient magnitude to restore minimum desirable streamflows.},
  file      = {:Hydrology\\Groundwater\\Development of a Comprehensive Watershed Model Applied to Study Stream Yield under Drought Conditions.pdf:PDF},
  keywords  = {SWAT, MODFLOW},
  timestamp = {2017-02-18},
}

@Article{Razali2011,
  author    = {Nornadiah Mohd Razali and Yap Bee Wah},
  title     = {Power Comparisons of Shapiro-Wilk,Kolmogorov-Smirnov, Lilliefors and Anderson-Darling Tests},
  journal   = {Journal of Statistical Modeling and Analytics},
  year      = {2011},
  volume    = {2},
  number    = {1},
  pages     = {21-33},
  abstract  = {The importance of normal distribution is undeniable since it is an underlying assumption of many statistical
procedures such as t-tests, linear regression analysis, discriminant analysis and Analysis of Variance (ANOVA).
When the normality assumption is violated, interpretation and inferences may not be reliable or valid. The three
common procedures in assessing whether a random sample of independent observations of size n come from a
population with a normal distribution are: graphical methods (histograms, boxplots, Q-Q-plots), numerical methods
(skewness and kurtosis indices) and formal normality tests. This paper* compares the power of four formal tests of
normality: Shapiro-Wilk (SW) test, Kolmogorov-Smirnov (KS) test, Lilliefors (LF) test and Anderson-Darling (AD)
test. Power comparisons of these four tests were obtained via Monte Carlo simulation of sample data generated
from alternative distributions that follow symmetric and asymmetric distributions. Ten thousand samples of various
sample size were generated from each of the given alternative symmetric and asymmetric distributions. The power
of each test was then obtained by comparing the test of normality statistics with the respective critical values.
Results show that Shapiro-Wilk test is the most powerful normality test, followed by Anderson-Darling test,
Lilliefors test and Kolmogorov-Smirnov test. However, the power of all four tests is still low for small sample size.},
  file      = {:Statistics\\Power Comparisons of Shapiro-Wilk,Kolmogorov-Smirnov, Lilliefors and Anderson-Darling Tests.pdf:PDF},
  timestamp = {2017-02-20},
}

@TechReport{Schaefer2016,
  author      = {M.G. Schaefer and G.H. Taylor and T.W. Parzybok},
  title       = {Regional Precipitation-Frequency Analysis using the Climate Region Method for Application in Analyses of Extreme Precipitation and Floods},
  institution = {Extreme Precipitation Group},
  year        = {2016},
  number      = {precipitation-},
  abstract    = {This Technical Memorandum (TM) documents the methodologies that are used in conducting 
L-Moment regional precipitation-frequency analyses by the Extreme Precipitation Group (EPG).
These methodologies were developed over a 30-year period (1985-2016) for the specific purpose
of providing precipitation-frequency information for extreme storms for use in conducting
probabilistic and risk-based analyses of extreme floods for low Annual Exceedance Probabilities
(AEPs). A number of significant improvements have been made over the years to the basic
Climate Region Method (CRM) particularly related to reducing aleatoric and epistemic
uncertainties in quantile estimates for extreme precipitation magnitudes for specific storm types.
These improvements are the result of collaboration by MG Schaefer, JR Wallis and GH Taylor in
conducting numerous regional precipitation-frequency analyses. The current methodology is
termed the Schaefer-Wallis-Taylor (SWT) version of the Climate Region Method and has been
used in regional frequency analyses for precipitation maxima and minima in diverse climates for
large area regional studies in Washington34,43,44, Oregon45, California41,42,51,52, Montana30,
Tennessee and the southeastern US23, British Columbia37,38, Mexico27, Peru27, Chile27, Caribbean
Islands27, and Victoria Australia27.
The SWT version of the Climate Region Method and has been used with the Stochastic Event Flood
Model (SEFM50) for conducting hydrologic risk analyses at over 30 major dams in the United States
and British Columbia for the U.S. Bureau of Reclamation, U.S. Army Corps of Engineers, Tennessee
Valley Authority (TVA), BCHydro and Southern California Edison (SCE). Studies are currently
underway for 49 dams for TVA in the Tennessee Valley, 7 dams for BCHydro on the Upper Columbia
River, and 10 dams for SCE at high elevations in the Sierra Mountains.
The following sections provide documentation and a description of the evolution of the SWT-CRM
methodology as a component of developing watershed precipitation-frequency relationships and
uncertainty bounds for use in watershed modeling of extreme floods.},
  file        = {:Hydrology\\Precipitation\\Regional Precipitation-Frequency Analysis using the Climate Region Method for Application in Analyses of Extreme Precipitation and Floods.pdf:PDF},
  timestamp   = {2017-02-22},
}

@Manual{Terink2015,
  title        = {SPHY v2.0: Spatial Processes in Hydrology},
  author       = {W. Terink and A.F. Lutz and W.W. Immerzeel},
  organization = {FutureWater},
  month        = {October},
  year         = {2015},
  file         = {:Programs\\SPHY_manualV6.pdf:PDF},
  timestamp    = {2017-02-23},
}

@Article{Newman2015,
  author    = {Andrew J. Newman and Martyn P. Clark and Jason Craig and Bart Nijssen and Andrew Wood and Ethan Gutmann and Naoki Mizukami and Levi Brekke and Jeff R. Arnold},
  title     = {Gridded Ensemble Precipitation and Temperature Estimates for the Contiguous United States},
  journal   = {Journal of Hydrometeorology},
  year      = {2015},
  volume    = {16},
  number    = {6},
  pages     = {2481--2500},
  month     = {dec},
  abstract  = {Gridded precipitation and temperature products are inherently uncertain because of myriad factors, including interpolation from a sparse observation network, measurement representativeness, and measurement errors. Generally uncertainty is not explicitly accounted for in gridded products of precipitation or temperature; if it is represented, it is often included in an ad hoc manner. A lack of quantitative uncertainty estimates for hydrometeorological forcing fields limits the application of advanced data assimilation systems and other tools in land surface and hydrologic modeling. This study develops a gridded, observation-based ensemble of precipitation and temperature at a daily increment for the period 1980–2012 for the conterminous United States, northern Mexico, and southern Canada. This allows for the estimation of precipitation and temperature uncertainty in hydrologic modeling and data assimilation through the use of the ensemble variance. Statistical verification of the ensemble indicates that it has generally good reliability and discrimination of events of various magnitudes but has a slight wet bias for high threshold events (>50 mm). The ensemble mean is similar to other widely used hydrometeorological datasets but with some important differences. The ensemble product produces a more realistic occurrence of precipitation statistics (wet day fraction), which impacts the empirical derivation of other fields used in land surface and hydrologic modeling. In terms of applications, skill in simulations of streamflow in 671 headwater basins is similar to other coarse-resolution datasets. This is the first version, and future work will address temporal correlation of precipitation anomalies, inclusion of other data streams, and examination of topographic lapse rate choices.},
  doi       = {10.1175/jhm-d-15-0026.1},
  file      = {:Hydrology\\Precipitation\\Gridded Ensemble Precipitation and Temperature Estimates for the Contiguous United States.pdf:PDF},
  keywords  = {Atm/Ocean Structure/ Phenomena; Precipitation; Physical Meteorology and Climatology; Hydrology; Hydrometeorology; Mathematical and statistical techniques; Interpolation schemes; Statistical techniques; Models and modeling; Ensembles},
  publisher = {American Meteorological Society},
  timestamp = {2017-02-23},
  url       = {https://doi.org/10.1175%2Fjhm-d-15-0026.1},
}

@Book{Nagarajan2013,
  title     = {Bayesian Networks in R},
  publisher = {Springer},
  year      = {2013},
  author    = {Radhakrishnan Nagarajan and Marco Scutari and Sophie Lèbre},
  editor    = {Robert Gentleman and Kurt Hornik and Giovanni Parmigiani},
  file      = {:Statistics\\Bayesian Networks in R.pdf:PDF},
  timestamp = {2017-03-14},
}

@Article{Glahn1972,
  author    = {Harry R. Glahn and Dale A. Lowry},
  title     = {The use of model output statistics (MOS) in objective weather forecasting},
  journal   = {Journal of Applied Meteorology},
  year      = {1972},
  volume    = {11},
  pages     = {1203--1211},
  month     = {dec},
  file      = {:Ensembles\\The Use of Model Output Statistics (MOS) in Objective Weather Forecasting.pdf:PDF},
  timestamp = {2017-03-14},
}

@Manual{R2017,
  title        = {R: A Language and Environment for Statistical Computing},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  year         = {2017},
  timestamp    = {2017-03-16},
  url          = {https://www.R-project.org/},
}

@Article{Basco-Carrera2017,
  author    = {Laura Basco-Carrera and Andrew Warren and Eelco van Beek and Andreja Jonoski and Alessio Giardino},
  title     = {Collaborative modelling or participatory modelling? A framework for water resources management},
  journal   = {Environmental Modelling {\&} Software},
  year      = {2017},
  volume    = {91},
  pages     = {95--110},
  month     = {may},
  abstract  = {Decision Support Systems, and, more recently, participatory and collaborative modelling have emerged
as a response to increased focus on stakeholder participation in modelling activities for certain fields like
water resources management. Researchers and practitioners frequently use ‘buzzwords’ such as
‘participatory modelling’ and ‘collaborative modelling’. In some cases, both terms are used interchangeably, largely due to unclear distinction between them in literature. This article draws the line
between participatory and collaborative modelling by using levels of participation and cooperation as
conditioning dimensions. Based on this methodology, a new generic framework is presented. This
framework can help identify determinant features of both modelling approaches currently used in water
resources management. It permits analysis of these approaches in terms of context, specific use, information handling, stakeholder involvement, modelling team and means. The article concludes with an
application of the framework to a collaborative modelling approach carried out for a groundwater study
in the Netherlands.},
  doi       = {10.1016/j.envsoft.2017.01.014},
  file      = {:WaterResources\\Collaborative Modelling or Participatory Modelling- a framework for water resources management.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2017-03-19},
  url       = {https://doi.org/10.1016%2Fj.envsoft.2017.01.014},
}

@Article{Todini2007,
  author    = {E. Todini},
  title     = {Hydrological catchment modelling: past, present and future},
  journal   = {Hydrologic Earth Systems Science},
  year      = {2007},
  volume    = {11},
  number    = {1},
  pages     = {468--482},
  abstract  = {This paper discusses basic issues in hydrological modelling and flood forecasting, ranging from the roles of physically-based and data-driven rainfall runoff models, to the concepts of predictive uncertainty and equifinality and their implications. The evolution of a wide range of hydrological catchment models employing the physically meaningful and data-driven approaches introduces the need for objective test beds or benchmarks to assess the merits of the different models in reconciling the alternative approaches. In addition, the paper analyses uncertainty in models and predictions by clarifying the meaning of uncertainty, by distinguishing between parameter and predictive uncertainty and by demonstrating how the concept of equifinality must be addressed by appropriate and robust inference approaches. Finally, the importance of predictive uncertainty in the decision making process is highlighted together with possible approaches aimed at overcoming the diffidence of end-users.},
  file      = {:Ensembles\\Hydrological catchment modelling- past, present and future.pdf:PDF},
  timestamp = {2017-03-25},
}

@Book{Hastie2017,
  title     = {The Elements of Statistical Learning - Data Mining, Inference, and Prediction},
  publisher = {Springer},
  year      = {2017},
  editor    = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  file      = {:Statistics\\The Elements of Statistical Learning.pdf:PDF},
  timestamp = {2017-03-27},
}

@Book{Liese2008,
  title     = {Statistical Decision Theory - Estimation, Testing, and Selection},
  publisher = {Springer},
  year      = {2008},
  editor    = {Friedrich Liese and Klaus-J. Miescke},
  file      = {:Statistics\\Statistical Decision Theory.pdf:PDF},
  timestamp = {2017-03-27},
}

@Book{Hyndman2008,
  title     = {Forecasting with Exponential Smoothing - The State Space Approach},
  publisher = {Springer},
  year      = {2008},
  editor    = {Rob J. Hyndman and Anne B. Koehler and J. Keith Ord and Ralph D. Snyder},
  file      = {:Statistics\\Forecasting with Exponential Smoothing - The State-Space Approach.pdf:PDF},
  timestamp = {2017-03-27},
}

@Book{Tille2006,
  title     = {Sampling Algorithms},
  publisher = {Springer},
  year      = {2006},
  editor    = {Yves Tille},
  file      = {:Statistics\\Sampling Algorithms.pdf:PDF},
  timestamp = {2017-03-27},
}

@Book{Gaetan2010,
  title     = {Spatial Statistics and Modeling},
  publisher = {Springer},
  year      = {2010},
  author    = {Carlo Gaetan and Xavier Guyon},
  file      = {:Statistics\\Spatial Statistics and Modeling.pdf:PDF},
  timestamp = {2017-03-27},
}

@Book{Lemieux2010,
  title     = {Monte Carlo and Quasi-Monte Carlo Sampling},
  publisher = {Springer},
  year      = {2010},
  editor    = {Christiane Lemieux},
  file      = {:Statistics\\Monte Carlo and Quasi-Monte Carlo Sampling.pdf:PDF},
  timestamp = {2017-03-27},
}

@Book{Clarke2009,
  title     = {Principles and Theory for Data Mining and Machine Learning},
  publisher = {Springer},
  year      = {2009},
  author    = {Bertrand Clarke and Ernest Fokoue and Hao Helen Zhang},
  file      = {:Statistics\\Principles and Theory for Data Mining and Machine Learning.pdf:PDF},
  timestamp = {2017-03-27},
}

@Book{Severance2013,
  title     = {Python for Informatics},
  publisher = {Open},
  year      = {2013},
  author    = {Charles Severance},
  abstract  = {SQL Databases},
  file      = {:Programs\\Python for Informatics.pdf:PDF},
  timestamp = {2017-03-27},
}

@Article{Schoups2010,
  author    = {Schoups, Gerrit and Vrugt, Jasper A.},
  title     = {A formal likelihood function for parameter and predictive inference of hydrologic models with correlated, heteroscedastic, and non-Gaussian errors},
  journal   = {Water Resources Research},
  year      = {2010},
  volume    = {46},
  number    = {10},
  pages     = {n/a--n/a},
  issn      = {1944-7973},
  note      = {W10531},
  abstract  = {Estimation of parameter and predictive uncertainty of hydrologic models has traditionally relied on several simplifying assumptions. Residual errors are often assumed to be independent and to be adequately described by a Gaussian probability distribution with a mean of zero and a constant variance. Here we investigate to what extent estimates of parameter and predictive uncertainty are affected when these assumptions are relaxed. A formal generalized likelihood function is presented, which extends the applicability of previously used likelihood functions to situations where residual errors are correlated, heteroscedastic, and non-Gaussian with varying degrees of kurtosis and skewness. The approach focuses on a correct statistical description of the data and the total model residuals, without separating out various error sources. Application to Bayesian uncertainty analysis of a conceptual rainfall-runoff model simultaneously identifies the hydrologic model parameters and the appropriate statistical distribution of the residual errors. When applied to daily rainfall-runoff data from a humid basin we find that (1) residual errors are much better described by a heteroscedastic, first-order, auto-correlated error model with a Laplacian distribution function characterized by heavier tails than a Gaussian distribution; and (2) compared to a standard least-squares approach, proper representation of the statistical distribution of residual errors yields tighter predictive uncertainty bands and different parameter uncertainty estimates that are less sensitive to the particular time period used for inference. Application to daily rainfall-runoff data from a semiarid basin with more significant residual errors and systematic underprediction of peak flows shows that (1) multiplicative bias factors can be used to compensate for some of the largest errors and (2) a skewed error distribution yields improved estimates of predictive uncertainty in this semiarid basin with near-zero flows. We conclude that the presented methodology provides improved estimates of parameter and total prediction uncertainty and should be useful for handling complex residual errors in other hydrologic regression models as well.},
  doi       = {10.1029/2009WR008933},
  file      = {:Hydrology\\A formal likelihood function for parameter and predictive inference of hydrologic models with correlated, heteroscedastic, and non-Gaussian errors.pdf:PDF},
  keywords  = {Uncertainty assessment, Model calibration, Estimation and forecasting, Stochastic hydrology, Bayesian inference},
  timestamp = {2017-03-28},
  url       = {http://dx.doi.org/10.1029/2009WR008933},
}

@Article{Graham2010,
  author        = {Nicholas E. Graham and Konstantine P. Georgakakos},
  title         = {Toward Understanding the Value of Climate Information for Multiobjective Reservoir Management under Present and Future Climate and Demand Scenarios},
  journal       = {Journal of Applied Meteorology and Climatology},
  year          = {2010},
  volume        = {49},
  number        = {4},
  pages         = {557--573},
  month         = {apr},
  __markedentry = {[quebbs:1]},
  abstract      = {Numerical simulation techniques and idealized reservoir management models are used to assess the utility of climate information for the effective management of a single multiobjective reservoir. Reservoir management considers meeting release and reservoir volume targets and minimizing wasteful spillage. The influence of reservoir size and inflow variability parameters on the management benefits is examined. The effects of climate and demand (release target) change on the management policies and performance are also quantified for various change scenarios. Inflow forecasts emulate ensembles of dynamical forecasts for a hypothetical climate system with somewhat predictable low-frequency variability. The analysis considers the impacts of forecast skill. The mathematical problem is cast in a dimensionless time and volume framework to allow generalization. The present work complements existing research results for specific applications and expands earlier analytical results for simpler management situations in an effort to draw general conclusions for the present-day reservoir management problem under uncertainty. The findings support the following conclusions: (i) reliable inflow forecasts are beneficial for reservoir management under most situations if adaptive management is employed; (ii) tolerance to forecasts of lower reliability tends to be higher for larger reservoirs; (iii) reliable inflow forecasts are most useful for a midrange of reservoir capacities; (iv) demand changes are more detrimental to reservoir management performance than inflow change effects of similar magnitude; (v) adaptive management is effective for mitigating climatic change effects and may even help to mitigate demand change effects.},
  doi           = {10.1175/2009jamc2135.1},
  file          = {:Reservoirs\\Toward understanding the value of climate information for multiobjective reservoir management under present and future climate and demand scenarios.pdf:PDF},
  keywords      = {Streamflow; Hydrologic models; Climate prediction; Climate change; Seasonal forecasting},
  publisher     = {American Meteorological Society},
  timestamp     = {2017-03-28},
  url           = {https://doi.org/10.1175%2F2009jamc2135.1},
}

@Article{Finley1884,
  author    = {Finley, J.P.},
  title     = {Tornado Prediction},
  journal   = {American Meteorological Journal},
  year      = {1884},
  volume    = {1},
  pages     = {85-88},
  timestamp = {2017-03-31},
}

@Article{Gilbert1884,
  author    = {Gilbert, G.K.},
  title     = {Finley's tornado predictions},
  journal   = {American Meteorological Journal},
  year      = {1884},
  volume    = {1},
  pages     = {166-172},
  timestamp = {2017-03-31},
}

@Article{Leith1974,
  author    = {C.E. Leith},
  title     = {Theoretical Skill of Monte Carlo Forecasts},
  journal   = {Monthly Weather Review},
  year      = {1974},
  volume    = {102},
  number    = {6},
  pages     = {409--418},
  note      = {orginal proposal for ensemble forecasting},
  abstract  = {The theoretical skill of Monte Carlo approximations to the stochastic dynamic forecasting technique proposed by Epstein is examined by means of an extension of earlier atmospheric predictability studies that used the test-field model of two-dimensional turbulence. The fundamental statistical hydrodynamical concept of an ensemble of phase paths evolving in a dynamical phase space is reviewed and used to define the statistical properties of a finite Monte Carlo sample. The application of a linear regression step to arrive at a final best estimate of the state of the atmosphere is also discussed. The resulting forecasts approach the climatological mean at forecast times so late that all skill has been lost.

For an ideal case with an observing resolution, hopefully achievable in the 1980s with satellite-based sensors, it is found that the. Monte Carlo procedure leads to the greatest improvement in mean-square vector wind forecast skill in the 6- to 10-day range. For another case corresponding roughly to present operational resolution the wind forecast skill is improved considerably in the 2- to 5-day range. Much of the improvement in mean-square skill is a consequence of the optimal filtering nature of the procedure which damps erroneous small scale structure in favor of the more predictable large scales.},
  doi       = {10.1175/1520-0493(1974)102<0409:TSOMCF>2.0.CO;2},
  file      = {:Ensembles\\Theoretical Skill of Monte Carlo Forecasts.pdf:PDF},
  timestamp = {2017-03-31},
}

@Article{Wilson1999,
  author    = {Laurence J. Wilson and William R. Burrows and Andreas Lanzinger},
  title     = {A Strategy for Verification of Weather Element Forecasts from an Ensemble Prediction System},
  journal   = {Monthly Weather Review},
  year      = {1999},
  volume    = {127},
  number    = {6},
  pages     = {956-970},
  abstract  = {Abstract Using a Bayesian context, new measures of accuracy and skill are proposed to verify weather element forecasts from ensemble prediction systems (EPSs) with respect to individual observations. The new scores are in the form of probabilities of occurrence of the observation given the EPS distribution and can be applied to individual point forecasts or summarized over a sample of forecasts. It is suggested that theoretical distributions be fit to the ensemble, assuming a shape similar to the shape of the climatological distribution of the forecast weather element. The suggested accuracy score is simply the probability of occurrence of the observation given the fitted distribution, and the skill score follows the standard format for comparison of the accuracy of the ensemble forecast with the accuracy of an unskilled forecast such as climatology. These two scores are sensitive to the location and spread of the ensemble distribution with respect to the verifying observation. The new scores are illustrated using the output of the European Centre for Medium-Range Weather Forecasts EPS. Tests were carried out on 108 ensemble forecasts of 2-m temperature, precipitation amount, and windspeed, interpolated to 23 Canadian stations. Results indicate that the scores are especially sensitive to location of the ensemble distribution with respect to the observation; even relatively modest errors cause a score value significantly below the maximum possible score of 1.0. Nevertheless, forecasts were found that achieved the perfect score. The results of a single application of the scoring system to verification of ensembles of 500-mb heights suggests considerable potential of the score for assessment of the synoptic behavior of upper-air ensemble forecasts. The paper concludes with a discussion of the new scoring method in the more general context of verification of probability distributions.},
  doi       = {10.1175/1520-0493(1999)127<0956:ASFVOW>2.0.CO;2},
  file      = {:Ensembles\\A strategy for verification of Weather Element Forecasts from an Ensemble Prediction System.pdf:PDF},
  timestamp = {2017-03-31},
}

@Article{Murshed2013,
  author    = {Md. Sharwar Murshed and Yun Am Seo and Jeong-Soo Park},
  title     = {{LH}-moment estimation of a four parameter kappa distribution with hydrologic applications},
  journal   = {Stochastic Environmental Research and Risk Assessment},
  year      = {2013},
  volume    = {28},
  number    = {2},
  pages     = {253--262},
  month     = {may},
  abstract  = {The study of distribution tails is a fundamental
research in statistical frequency analysis relevant to many
research fields, such as insurance, hydrological events,
earthquake, etc. Here, we describe and investigate the
effect and feasibility of the high-order L-moment (LHmoment) method for estimating heavy-tail conditions by
fitting a four parameter kappa distribution. Details of
parameter estimation using LH-moments for the four
parameter kappa distribution (K4D) are described and
formulated. Monte-Carlo simulation is performed to illustrate the performance of the LH-moment method in terms
of heavy-tail quantiles over all quantiles using K4D and
non K4D samples, respectively. The result suggests that the
method is either useful (when the method of L-moment
estimation fails to give a feasible solution) or as effective
as the L-moment approach in handling data following
K4D. Applications to the annual maximum flood and sea
level data are presented.},
  doi       = {10.1007/s00477-013-0746-6},
  file      = {:Statistics\\LH-moment estimation of a four parameter kappa distribution with hydrologic applications.pdf:PDF},
  publisher = {Springer Nature},
  timestamp = {2017-04-10},
  url       = {https://doi.org/10.1007%2Fs00477-013-0746-6},
}

@Article{Hosking1987,
  author    = {J. R. M. Hosking and J. R. Wallis},
  title     = {Parameter and Quantile Estimation for the Generalized Pareto Distribution},
  journal   = {Technometrics},
  year      = {1987},
  volume    = {29},
  number    = {3},
  pages     = {339--349},
  abstract  = {The generalized Pareto distribution is a two-parameter distribution that contains uniform,
exponential, and Pareto distributions as special cases. It has applications in a number of fields,
including reliability studies and the analysis of environmental extreme events. Maximum
likelihood estimation of the generalized Pareto distribution has previously been considered in
the literature, but we show, using computer simulation, that, unless the sample size is 500 or
more, estimators derived by the method of moments or the method of probability-weighted
moments are more reliable. We also use computer simulation to assess the accuracy of confidence intervals for the parameters and quantiles of the generalized Pareto distribut},
  file      = {:Statistics\\Parameter and Quantile Estimation for the Generalized Pareto Distribution.pdf:PDF},
  keywords  = {Maximum likelihood; Method of moments; Probability-weighted moments.},
  timestamp = {2017-04-10},
}

@Manual{MGS2011,
  title     = {L-MOMENT STATISTICS L-RAP Users Manual},
  author    = {Mel Schaefer},
  month     = {August},
  year      = {2011},
  file      = {:Statistics\\LMoments_MGS.pdf:PDF},
  keywords  = {L-Cv, L-Skewness, L-Kurtosis},
  timestamp = {2017-04-10},
}

@Conference{Faber2004,
  author    = {Beth A. Faber and Jery R. Stedinger},
  title     = {SSDP Reservoir Models Using Ensemble Streamflow Prediction (ESP) Forecasts},
  booktitle = {World Water Congress},
  year      = {2004},
  abstract  = {The sequential nature of reservoir operating decisions and the variability of streamflow makes
Stochastic Dynamic Programming an attractive optimization procedure for reservoir system
operations. This paper examines the use of Sampling Stochastic Dynamic Programming (SSDP).
SSDP models employing the National Weather Service’s (NWS) Ensemble Streamflow
Prediction (ESP) forecasts are compared to SSDP models based on historical streamflows and
snowmelt volume forecasts. The SSDP optimization algorithm, which is driven by individual
streamflow scenarios rather than a Markov description of streamflow probabilities, allows the
ESP forecast traces to be employed intact, thus taking full advantage of their rich description of
streamflow variability and the temporal and spatial inter-relationships captured within the traces.},
  file      = {:Optimization\\SSDP Reservoir Models using Ensemble Streamflow Prediction (ESP) Forecasts.pdf:PDF;:Optimization\\Faber-Stedinger.EWRI2001.ssdp.doc:Word},
  timestamp = {2017-04-10},
}

@Article{Kuczera1999,
  author    = {George Kuczera},
  title     = {Comprehensive at-site flood frequency analysis using Monte Carlo Bayesian inference},
  journal   = {Water Resources Research},
  year      = {1999},
  volume    = {35},
  number    = {5},
  pages     = {1551--1557},
  abstract  = {In flood frequencya pplicationsw here the designf lood is requiredt o have a
specifiede xceedancpe robability,e xpectedp robabilitys houldb e used.I ts computation, 
however,p resentsf ormidabled ifficultiesT. his studyp resentsa  Monte Carlo Bayesian 
methodf or computingt he expectedp robabilityd istributiona s well as quantilec onfidence 
limits for any flood frequencyd istributionu singd ata on gaugedf lows,p ossiblyc orrupted 
by rating curvee rror, and on censoredfl ows.T his is achievedb y a three-stepp rocess(:1 ) 
Formulatet he likelihoodf unctionf or the givend ata; (2) approximatet he likelihood 
functionu singa  multinormald istribution;a nd (3) integratet he expectedp robability 
integralu singi mportances amplingT. he FLIKE softwaref or performingt his is described, 
and an examplei s given.},
  file      = {:Statistics\\Comprehensive at-site flood frequency analysis using Monte Carlo Bayesian inference.pdf:PDF},
  timestamp = {2017-04-10},
}

@Conference{Stedinger2004,
  author    = {Jery R. Stedinger and Beth A. Faber},
  title     = {Stochastic Dynamic Programming for Hydropower Operations with Ensemble Streamflow Prediction (ESP) Forecasts},
  booktitle = {Symposium Of Specialists in Electric Operational And Expansion Planning},
  year      = {2004},
  abstract  = {Stochastic dynamic programming as a multi-state
stochastic optimization method with ensemble
streamflow forecasts holds great potential for improving
the operation of hydropower systems. Sampling SDP
(SSDP) is a variation of the traditional SDP algorithm
that can directly incorporate into the optimization
algorithm ensemble streamflow forecasts, such as those
now provided by the US National Weather Service.
This paper illustrates the performance of several SSDP
reservoir-operation optimization models for a
hydropower/water-supply system with the snowmeltdominated hydrology typical of the western United
States. Generally a two-stage model that combines
deterministic optimizations with a good one-stage
probabilistic optimization step does as well as the full
multi-stage stochastic optimization. The optimization
algorithms also did as well with a reduced subset of the
original 42 ensemble forecasts, if the subset was
appropriate selected and weighted to represent the
larger set.},
  file      = {:Optimization\\Stochastic Dynamic Programming for Hydropower Operations with Ensemble Streamflow Prediction (ESP) Forecasts.pdf:PDF},
  keywords  = {hydropower, optimization, stochastic dynamic programming; streamflow forecasts, reservoir operations},
  timestamp = {2017-04-10},
}

@Article{Buizza1998,
  author    = {R. Buizza and T. N. Palmer},
  title     = {Impact of Ensemble and Size on Ensemble and Prediction},
  journal   = {Monthly Weather Review},
  year      = {1998},
  volume    = {126},
  pages     = {2503--2518},
  abstract  = {The impact of ensemble size on the performance of the European Centre for Medium-Range Weather Forecasts
ensemble prediction system (EPS) is analyzed. The skill of ensembles generated using 2, 4, 8, 16, and 32
perturbed ensemble members are compared for a period of 45 days—from 1 October to 15 November 1996.
For each ensemble configuration, the skill is compared with the potential skill, measured by randomly choosing
one of the 32 ensemble members as verification (idealized ensemble). Results are based on the analyses of the
prediction of the 500-hPa geopotential height field. Various measures of performance are applied: skill of the
ensemble mean, spread–skill relationship, skill of most accurate ensemble member, Brier score, ranked probability
score, relative operating characteristic, and the outlier statistic.
The relation between ensemble spread and control error is studied using L2, L8, and L` norms to measure
distances between ensemble members and the control forecast or the verification. It is argued that the supremum
norm is a more suitable measure of distance, given the strategy for constructing ensemble perturbations from
rapidly growing singular vectors. Results indicate that, for the supremum norm, any increase of ensemble size
within the range considered in this paper is strongly beneficial. With the smaller ensemble sizes, ensemble spread
does not provide a reliable bound on control error in many cases. By contrast, with 32 members, spread provides
a bound on control error in nearly all cases. It could be anticipated that further improvement could be achieved
with higher ensemble size still. On the other hand, spread–skill relationship was not consistently improved with
higher ensemble size using the L2 norm.
The overall conclusion is that the extent to which an increase of ensemble size (particularly from 8 to 16,
and 16 to 32 members) improves EPS performance, is strongly dependent on the measure used to assess
performance. In addition to the spread–skill relationship, the measures most sensitive to ensemble size are shown
to be the skill of the best ensemble member (particularly when evaluated on a point-wise basis) and the outlier
statistic.},
  file      = {:Ensembles\\Impact of Ensemble Size on Ensemble Prediction.pdf:PDF},
  timestamp = {2017-04-11},
}

@Article{Ferro2007,
  author    = {Christopher A. T. Ferro},
  title     = {Comparing Probabilistic Forecasting Systems with the Brier Score},
  journal   = {Weather and Forecasting},
  year      = {2007},
  volume    = {22},
  number    = {5},
  pages     = {1076--1088},
  month     = {oct},
  abstract  = {This article considers the Brier score for verifying ensemble-based probabilistic forecasts of binary events.
New estimators for the effect of ensemble size on the expected Brier score, and associated confidence
intervals, are proposed. An example with precipitation forecasts illustrates how these estimates support
comparisons of the performances of competing forecasting systems with possibly different ensemble sizes.},
  doi       = {10.1175/waf1034.1},
  file      = {:Ensembles\\Comparing Probabilistic Forecasting Systems with the Brier Score.pdf:PDF},
  keywords  = {bootstrap},
  publisher = {American Meteorological Society},
  timestamp = {2017-04-11},
  url       = {https://doi.org/10.1175%2Fwaf1034.1},
}

@Manual{FERC2017,
  title     = {Hydropower primer: A Handbook of Hydropower Basics},
  author    = {FERC},
  file      = {:Reservoirs\\FERC hydropower-primer.pdf:PDF},
  timestamp = {2017-04-17},
}

@PhdThesis{Faber2001a,
  author   = {Beth Faber},
  title    = {Real-time Reservoir Optimization Using Ensemble Streamflow Forecasts},
  school   = {Cornell University},
  year     = {2001},
  abstract = {The sequential nature of reservoir operating decisions and the variability of streamflow
makes Stochastic Dynamic Programming an attractive optimization procedure for
reservoir system operations. This study examines the use of Sampling Stochastic
Dynamic Programming (SSDP) for single- and multi-reservoir system operation. SSDP
models based on historical streamflows and snowmelt volume forecasts are compared to
SSDP models employing the National Weather Service's (NWS) Ensemble Streamflow
Prediction (ESP) forecasts. The SSDP optimization algorithm, which is driven by
individual streamflow scenarios rather than a Markov description of streamflow
probabilities, allows the ESP forecast traces to be employed intact, thus taking full
advantage of their stochastic and statistical characterization of streamflow. This study
demonstrates that the use of frequently updated ESP forecasts in a real-time SSDP
optimization for a reservoir system can provide more efficient operating decisions than an
SSDP model employing historical time series data and current snowmelt volume
forecasts. Both models were driven by an appropriately weighted and representative
subset of the original forecast and streamflow samples. This study further demonstrates
that a simplification of SSDP which forms a simpler two-stage optimization model
provides operations that are as efficient as those provided by the complete SSDP model.
Both a single reservoir and a multi-reservoir system that provides water supply and
hydropower were evaluated with various SSDP models},
  file     = {:bethfaber_PhD_thesis.pdf:PDF},
}

@Book{Helsel2002,
  title     = {Statistical Methods in Water Resources},
  publisher = {U.S. Department of the Interior},
  year      = {2002},
  author    = {D.R. Helsel and R.M. Hirsch},
  volume    = {Book 4, Hydrologic Analysis and Interpretation},
  series    = {Techniques of Water-Resources Investigations of the United States Geological Survey},
  abstract  = {Chapter 1. Summarizing Data (260KB)
Chapter 2. Graphical Data Analysis (2MB)
Chapter 3. Describing Uncertainty (354KB)
Chapter 4. Hypothesis Tests (290KB)
Chapter 5. Differences between Two Independent Groups (246KB)
Chapter 6. Matched-Pair Tests (229KB)
Chapter 7. Comparing Several Independent Groups (622KB)
Chapter 8. Correlation (181KB)
Chapter 9. Simple Linear Regression (533KB)
Chapter 10. Alternative Methods for Regression (556KB)
Chapter 11. Multiple Linear Regression (431KB)
Chapter 12. Trend Analysis (691KB)
Chapter 13. Methods for Data Below the Reporting Limit (314KB)
Chapter 14. Discrete Relationships (464 KB)
Chapter 15. Regression for Discrete Responses (214KB)
Chapter 16. Presentation Graphics (16a, 1.1MB; 16b, 2.9MB)},
  file      = {:Statistical Methods in Water Resources.pdf:PDF},
}

@MastersThesis{Faber1995,
  author   = {Beth Ann Faber},
  title    = {Use of Optimization in Planning Operations of Surface Water Collection Systems with Uncertain Streamflows},
  school   = {University of Colorado},
  year     = {1995},
  abstract = {The many layers of uncertainty in natural streamflows make ideal operation
of a surface-water collection system difficult. This study explores the uses of linear
programming in aiding operations of the Denver Water system in the face of these
uncertainties. The effects of differing long-term operating policies on the system's
effective reliability, and the tradeoffs between system reliability and secondary
benefits, such as hydropower generation and streamflow enhancement, are also
analyzed.
Two descriptive models developed weigh the tradeoffs between the
conflicting objectives of system reliabiFty and net revenue, analyzing the changes in
effective system reliability caused by operations policies, and the subsequent change
in water available for secondary benefits. A prescriptive model developed suggests
runoff season operations for the range of probable inflow hydrographs. An implicit
stochastic approach is used in two of the models. The first model optimizes
operations over a 30-year period of historical streamflows, analyzing various
carryover storage targets, and the tradeoff between average system hydropower
revenue and overall reservoir fill rate. The second model employing an implicit
stochastic approach uses a variation of the Two-Period Planning Problem to
simultaneously optimize system operations for six probable hydrographs. The six
hydrographs represent the range of possible streamflows, and the influence of each
on the objective function is weighted by its probability of occurring.},
  file     = {:Optimization\\Faber Masters Thesis.pdf:PDF},
}

@Article{Beckers2016,
  author  = {Joost V. L. Beckers and Albrecht H. Weerts and Erik Tijdeman and Edwin Welles},
  title   = {ENSO-conditioned weather resampling method for seasonal ensemble streamflow prediction},
  journal = {Hydrologic Earth Systems Science},
  year    = {2016},
  file    = {:Ensembles\\ENSO-conditioned weather resampling method for seasonal ensemble streamflow prediction.pdf:PDF},
}

@Article{Kozmik2015,
  author   = {Václav Kozmík and David P. Morton},
  title    = {Evaluating policies in risk-averse multi-stage stochastic programming},
  journal  = {Mathematical Programming},
  year     = {2015},
  volume   = {152},
  number   = {1},
  pages    = {275-300},
  month    = {aug},
  abstract = {We consider a risk-averse multi-stage stochastic program using conditional
value atrisk as theriskmeasure. The underlyingrandom process is assumed to be stagewise independent, and a stochastic dual dynamic programming (SDDP) algorithm is
applied. We discuss the poor performance of the standard upper bound estimator in the
risk-averse setting and propose a new approach based on importance sampling, which
yields improved upper bound estimators. Modest additional computational effort is
required to use our new estimators. Our procedures allow for significant improvement
in terms of controlling solution quality in SDDP-style algorithms in the risk-averse
setting. We give computational results for multi-stage asset allocation using a lognormal distribution for the asset returns},
  doi      = {10.1007/s10107-014-0787-8},
  file     = {:Optimization\\Evaluating policies in risk-averse multi-stage stochastic programming.pdf:PDF},
  keywords = {Multi-stage stochastic programming · Stochastic dual dynamic, programming · Importance sampling · Risk-averse optimization},
}

@Article{Gebretsadik2016,
  author    = {Yohannes Gebretsadik and Charles Fant and Kenneth Strzepek and Channing Arndt},
  title     = {Optimized reservoir operation model of regional wind and hydro power integration case study: Zambezi basin and South Africa},
  journal   = {Applied Energy},
  year      = {2016},
  volume    = {161},
  pages     = {574--582},
  month     = {jan},
  abstract  = {The present study develops a reliability assessment method of wind resource using optimum reservoir target power operations that maximizes the firm generation of integrated wind and hydropower. A combination of water resources model for a system of reservoirs that implements a demand–priority based linear programing algorithm and a single node power grid system model is implemented on hourly time step. This model was accompanied by a global genetic algorithm solver to determine optimum operation targets for each storage reservoir aiming at maximizing the 90th percentile power generation produced by the integration of wind and hydro over the entire simulation period.

This model was applied on the reservoir storages and hydropower system in the Zambezi river basin to test if the storage reservoirs could be efficiently be used to offset wind power intermittence in South Africa subjected to the different physical and policy constraints. Based on the optimized target operation and hourly annual real data for the year 2010, the water resources system and power interconnection system were simulated together to assess the maximum firm generation of power as a result of the new wind and hydro combination target for storage hydropower plants.

The result obtained indicates that high regulation of wind and hydro can be achieved as a result of combined operation and showed 45% increase in the level of wind penetration in South Africa’s power system over the reference scenario. The result also indicated a reduced level of coal power utilization and less cycling requirement. This will have a positive outcome in terms contributing to South Africa’s goal toward reducing greenhouse gas emission and the efforts to build green energy supply and resilience to the impacts of climate change.},
  doi       = {10.1016/j.apenergy.2015.09.077},
  file      = {:Optimization\\Optimized reservoir operation model of regional wind and hydro power integration case study- Zambezi basin and South Africa.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Christensen1991,
  author   = {G S Christensen and S A Soliman and A M Atallah},
  title    = {Optimization of the load-following scheduling problem of the B.P.A. hydro-electric system},
  journal  = {Electrical Power \& Energy Systems},
  year     = {1991},
  volume   = {13},
  number   = {1},
  pages    = {38--42},
  month    = {feb},
  abstract = {This paper presents an efficient algorithm usedJbr solving
the load Jollowing scheduling problem, for large scale
hydro-electric power systems, to obtain a maximum and
most uniJorm surplus power, while satLsfving the various
environmental, physical, legal and contractual constraints.
The proposed algorithm is based on the minimum norm
formulation o/functional anal.vsis, and it takes into account
the variations, of tail water elevation andforebay elevation.
The proposed technique is applied to solve the optimal
long-term load following scheduling problem of the
Bonneville Power Administration (B.P.A.) hydro-electric
system which is considered to be one o/ the largest hydro
systems in the world. Numerical results are reported and
compared with results. They show eonsiderahh, promise.},
  file     = {:Optimization\\Optimization of the load-following scheduling problem of the B.P.A. hydro-electric system.pdf:PDF},
  keywords = {hydro electric power systems, optimization, load following scheduling, BPA},
}

@Article{Karimanzira2016,
  author    = {Divas Karimanzira and Dirk Schwanenberg and Christopher Allen and Steven Barton},
  title     = {Short-Term Hydropower Optimization and Assessment of Operational Flexibility},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2016},
  volume    = {142},
  number    = {2},
  pages     = {04015048},
  month     = {feb},
  abstract  = {Hydroelectric power systems are largely characterized by variability and uncertainty in water resource obligations. Market volatility and the growing number of operational obligations for flood control, navigation, environmental obligations, and ancillary services
(including load-balancing requirements for renewable resources) further the need to quantify sources of uncertainty. The variations caused
by these factors require the hydropower system to have enough upward and downward flexibility for control technologies, such as dynamic
optimal control load-following, unit commitment, or automatic generation, to be effective. Therefore, it is increasingly important to identify
measures of operational flexibility to better manage uncertainty and operational obligations. The objective of this paper is to present and
discuss approaches for assessment of operational flexibility as a function of dynamic states and control input and how the available operational flexibility can be used by hydropower producers in a comprehensive optimization reformulation to accommodate business procedures
to drive the system in an efficient, safe, and interpretable way. The authors consider simple metrics such as power capability and its derivatives
as indicators for upward flexibility and effective energy storage capability for downward flexibility. Test results based on the Federal
Columbia River power system (FCRPS), managed by the Bonneville Power Administration, Army Corps of Engineers, and Bureau of
Reclamation, are presented and demonstrate how operational flexibility can be assessed and that role it plays in short-term operations.},
  doi       = {10.1061/(asce)wr.1943-5452.0000577},
  file      = {:Optimization\\Short-Term Hydropower Optimization and Assessment of Operational Flexibility.pdf:PDF},
  keywords  = {Hydropower; Short-term optimization; Reservoir systems; Operational flexibility},
  publisher = {American Society of Civil Engineers ({ASCE})},
  timestamp = {2017-04-22},
}

@Article{Allen1986,
  author    = {R.B. Allen and S.G. Bridgeman},
  title     = {Dynamic Programming in Hydropower Scheduling},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {1986},
  volume    = {112},
  number    = {3},
  pages     = {339--353},
  abstract  = {A dynamic programming optimization technique has been applied
to three case studies involving hydropower scheduling. Each involved the analysis of an operating strategy for a different time perspective, i.e., instantaneous, hourly, and monthly time frames. The case studies included: (1) The
optimal instantaneous scheduling of hydropower units, with different generating characteristics to maximize overall plant efficiency; (2) the optimal hourly
scheduling of hydropower generation between two hydrologically linked power
plants to maximize overall daily/weekly system efficiency; (3) the optimal monthly
scheduling of hydropower generation to minimize the purchase cost of imported power supply subject to a time-of-day rate structure. The case studies
have shown that optimization techniques can be successfully implemented to
gain insight into complex operating strategies.},
  file      = {:Optimization\\Dynamic Programming in Hydropower Scheduling.pdf:PDF},
  keywords  = {dispatch},
  timestamp = {2017-04-25},
}

@Article{Changchit1989,
  author    = {Chaweng Changchit and M. Palmer Terrell},
  title     = {CCGP Model for Multiobjective Reservoir Systems},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {1989},
  volume    = {115},
  number    = {5},
  pages     = {658--670},
  abstract  = {This paper presents an application of chance-constrained goal programming methodology to a system of multipurpose reservoirs. Several objectives
which may be conflicting and noncommensurate such as flood protection, municipal and industrial (M&I) water supply, hydroelectric power generation, recreation,
etc. are considered in the model. The system goals and constraints are expressed
either deterministically or probabilistically depending on whether the random variable term for inflow into a reservoir is present or not. For a constraint, the requirement must be strictly satisfied. For a goal, it is desired to achieve the solution
which is as close as possible to the specified target. Stochastic inflows with one
period correlation in successive periods are explicitly considered with conditional
distribution functions based on normal and lognormal distributions of inflows provided. The application of the methodology to a three-reservoir system in Oklahoma
is reported. The proposed model uses a time period of a month and may be employed for planning rather than real-time applications.},
  file      = {:Optimization\\CCGP Reservoir Operations.pdf:PDF},
  timestamp = {2017-04-25},
}

@Article{Duckstein1989,
  author    = {L. Duckstein and A. Tecle and H.P. Nachnebel and B.F. Hobbs},
  title     = {Multicriterion Analysis of Hydropower Operation},
  journal   = {Journal of Energy Engineering},
  year      = {1989},
  volume    = {115},
  number    = {3},
  abstract  = {Two real-life examples are presented to show how multicriterion decision-making (MCDM) techniques can help hydropower engineers mitigate the
environmental and social effects of hydropower development and operation. A brief
introduction and overview of MCDM is presented, consisting of an 11-step process
that starts with problem definition and ends with implementation. A typology of
MCDM is provided, dividing the techniques into three groups: outranking, distance-based, and value- or utility-based types. The operation of the Upper Isar
River project in Bavaria is analyzed by means of a value technique and an outranking technique called multicriterion Q-analysis. Fourteen criteria are considered
in
that study, including power production, habitat quality for four groups of species, aesthetics, several recreation indices, minimum flows, and phosphorus loadings. The case study of the Erlauf River Division in Austria is evaluated using a
distance-based technique, called composite programming, combined with Monte
Carlo simulation. An outcome of that study is that the facility's owners have increased the minimum instream flow in order to protect ecological values.},
  file      = {:MCDA\\Multicriterion Analysis of Hydropower Operation.pdf:PDF},
  keywords  = {MCDA},
  timestamp = {2017-04-25},
}

@InProceedings{Suen2010,
  author    = {Jian-Ping Suen and Ruei-Hong Wang},
  title     = {Optimal Reservoir Operation Considering Downstream Water Quality and Environmental Flow Needs},
  booktitle = {World Environmental and Water Resources Congress 2010: Challenges of Change},
  year      = {2010},
  abstract  = {This study develops an optimal reservoir management model based on each tenday operation periods for Shihmen Reservoir. The model tries to not only meet the
human water requirement, but also to consider water quality and ecological issues. In
Taiwan, lots of infrastructures have been built in almost every river to effectively use
water resources and provide disaster defense. It results in downstream flow
regulation or violent flow fluctuation that causes impacts on aquatic ecosystem
biodiversity. Decision makers should take flow variability into account in water
resources management policy.
Human demands, water quality, and ecological issues are considered in the optimal
reservoir management model. Human demands objective is based on water rights of
different users and M-5 Rule Curve of Shihmen Reservoir. Ecological objective is
based on consideration of Environmental flow components (Richter et al. 2007).
Water quality model uses an artificial neural network model to simulate downstream
water quality by using streamflow, rainfall, upstream water quality, and measure time
as inputs. Then this model is combined with human demands and environmental flow
components considerations to establish an optimal reservoir management model by
using genetic algorithm. The optimal reservoir operation model considers human
demands, water quality and flow regime to benefit to both human society and aquatic
ecosystems.},
  file      = {:Optimization\\Optimal Reservoir Operation Considering Downstream Water Quality and Environmental Flow Needs.pdf:PDF},
  timestamp = {2017-04-25},
}

@Article{Goor2011,
  author    = {Q. Goor and R. Keman and A. Tilmant},
  title     = {Optimal Multipurpose-Multireservoir operation model with variable productivity of hydropower plants},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2011},
  volume    = {137},
  number    = {3},
  month     = {may},
  abstract  = {Stochastic dual dynamic programming (SDDP) is one of the few methods available to solve multipurpose-multireservoir operation problems in a stochastic environment. This algorithm requires that the one-stage optimization problem be a convex program so that the efficient Benders decomposition scheme can be implemented to handle the large state-space that characterizes multireservoir operation problems. When working with hydropower systems, one usually assumes that the production of hydroelectricity is dominated by the release term and not by the head (storage) term to circumvent the nonlinearity of the hydropower production function. Although this approximation is satisfactory for high head power stations for which the difference between the maximum and the minimum head is small compared to the maximum head, it may no longer be acceptable when a significant portion of the energy originates from low and/or medium head power plants. Recent developments improve the representation of the nonlinear hydropower function through a convex hull approximation of the true hydropower function. A network of hydropower plants and irrigated areas in the Nile Basin is used to illustrate the difference between the two SDDP formulations on the energy generation and the allocation decisions. - See more at: http://ascelibrary.org/doi/full/10.1061/(ASCE)WR.1943-5452.0000117#sthash.3eUtNw9S.dpuf},
  file      = {:Optimization\\Optimal Multipurpose-Multireservoir operation model with variable productivity of hydropower plants.pdf:PDF},
  timestamp = {2017-04-25},
}

@InProceedings{Liu2010,
  author    = {Pan Liu and Ximing Cai},
  title     = {Deriving Near-optimal Solutions to Deterministic Reservoir Operation Problems},
  booktitle = {World Environmental and Water Resources Congress 2010: Challenges of Change},
  year      = {2010},
  abstract  = {For a deterministic reservoir operation problem even with a single
objective function, there should be some near-optimal solutions whose objective value
is greater than or equal to ) E* 1( − ε for a user-specified ε ≤ ε ≤ )10( as E* is the
optima. Near-optimal solutions provide valuable options for decision-making
because in practical reservoir operations, it is often more realistic to choose one
solution from a set of alternatives with similar or even the same objective value
resulting from the same optimization model. Such comparison allows decision
makers to consider some aspects that are difficult to include in the optimization model.
This paper explores such near-optimal solutions and discusses their statistical
characteristics with two steps. (1) Using a dynamic programming (DP) model, the
near-optimal space (hereafter denoted as NSO, the minimum and maximum bounds of
near-optimal solutions) is derived by building feasible conditions during backtracking.
This approach can be incorporated into the discrete differential dynamic programming
(DDDP) framework, reducing the computational burden greatly. (2) Following the
equifinality concept, the statistical characteristics of the optimal solution can be
analyzed by using uncertainty analysis methods with simulation, when the reservoir
decisions and the operation performance are treated as model parameters and
likelihood function, respectively. With case studies of the China’s Three Gorges
Reservoir, it is found that the near-optimal solutions do exist for the deterministic
reservoir operation problem, and there is great potential benefit in evaluating these
solutions and choosing the most realistic one},
  file      = {:Optimization\\Deriving Near-optimal Solutions to Deterministic Reservoir Operation Problems.pdf:PDF},
  keywords  = {reservoir operation, near-optimal solutions, near-optimal space, dynamic programming, Bayesian, MCMC},
  timestamp = {2017-04-25},
}

@Article{Dariane2009,
  author    = {Alireza B. Dariane and Shervin Momtahen},
  title     = {Optimization of Multireservoir Systems Operation using Modified Direct Search Genetic Algorithm},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2009},
  volume    = {135},
  number    = {3},
  pages     = {141--148},
  abstract  = {A direct search method using genetic algorithms DSGA, which seeks to directly find optimal parameters for prescribed
operating policies, is utilized for optimization of multireservoir operational problems and several modifications are presented. The
problems presented consist of 3, 7, and 16 reservoirs, respectively, from the Greater Karoon system in Iran. For the three-reservoir
problem, the DSGA method is used to obtain optimal linear operating policies and has proven to be very effective in both objective
function values and computational time in comparison to the more traditional optimization models based on dynamic programming.
However, the model must be modified to optimize larger problems successfully. The first set of proposed modifications is primarily for
enhancing the efficiency of the genetic algorithm GA used in the model and reducing its sensitivity to GA parameters such as the
probability of mutations and size of generations. The more robust modified DSGA is then applied to the seven-reservoir problem to obtain
optimal linear policies as well as two forms of piecewise linear ones, which achieves better objective values. The other modifications
applied to the model are a Fourier series approximation which defines the seasonal variation of policy parameters and a stepwise GA,
which employs varying lengths of simulations for fitness evaluations in different generations. These modifications reduce the time of
computations significantly. As a final point, the fine-tuned modified DSGA model optimizes the 16-reservoir problem in less than 20 h,
which is a significant time period. Computational time is estimated to increase geometrically second order with the number of reservoirs},
  file      = {:Optimization\\Optimization of Multireservoir Systems Operation using Modified Direct Search Genetic Algorithm.pdf:PDF},
  keywords  = {Water resources; Water management; Optimization models; Computation; Simulation models},
  timestamp = {2017-04-25},
}

@Article{Deka2009,
  author    = {Paresh Chandra Deka and V. Chandramouli},
  title     = {Fuzzy Neural Network Modeling of Reservoir Operation},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2009},
  volume    = {135},
  number    = {1},
  pages     = {5--12},
  abstract  = {The present study aims at the application of the hybrid model, which consists of artificial neural network and fuzzy logic in
the reservoir operating policy during critical periods. The proposed hybrid model fuzzy neural network FNN combines the learning
ability of artificial neural networks and the transparent nature of fuzzy logic. The FNN model is found to be highly adaptive and efficient
in investigating nonlinear relationships among different variables. The FNN model has been developed to study the behavior of optimal
release operating policy on the proposed reservoir in Pagladiya River of the Assam State in India. Here, reservoir operation policies were
formulated through dynamic programming. The optimal release was related to storage, inflow, and demand. The advantages of using the
FNN model in reservoir release are discussed using the case study},
  file      = {:Optimization\\Fuzzy Neural Network Modeling of Reservoir Operation.pdf:PDF},
  keywords  = {Reservoir operation; Artificial intelligence; Neural networks; Optimization models; Fuzzy sets.},
  timestamp = {2017-04-25},
}

@InProceedings{Martin2001,
  author    = {Quentin W. Martin},
  title     = {Development of Reservoir Operating Rules Using a Genetic Algorithm},
  booktitle = {World Water Congress 2001},
  year      = {2001},
  abstract  = {Deterministic linear and nonlinear programming models have been used extensively to
evaluate the most efficient operation of multiple reservoir systems. Unfortunately, one
limitation of these models is their inability to provide long-term operating rules that are
applicable to actual monthly reservoir management. To address this need, a patternrecognition procedure, called the Reservoir Operation Screening (ROS) model, was
developed to translate the time series of optimal reservoir system decisions into monthly
operating rules. ROS uses an embedded genetic algorithm to find the coefficients for
piecewise linear approximations to reservoir storage and release values computed by
optimization models. The model was developed for the Hydrologic Engineering Center
of the U.S. Army Corps of Engineers as a post-processor for their Prescriptive Reservoir
Model (HEC-PRM). The paper presents the successful ROS application to the HECPRM optimal reservoir storage time series generated for the Panama Canal and Missouri
River Reservoir Systems.},
  file      = {:Optimization\\Development of Reservoir Operating Rules using a Genetic Algorithm.pdf:PDF},
  timestamp = {2017-04-25},
}

@Article{Momtahen2007,
  author    = {Sh. Momtahen and A. B. Dariane},
  title     = {Direct Search Approaches using Genetic Algorithms for Optimization of Water Reservoir Operating Policies},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2007},
  volume    = {133},
  number    = {3},
  pages     = {202--209},
  abstract  = {The direct search approach to determine optimal reservoir operating policies is proposed with a real coded genetic algorithm
GA as the optimization method. The parameters of the policies are optimized using the objective values obtained from system simulations. Different reservoir release rules or forms, such as linear, piecewise linear, fuzzy rule base, and neural network, are applied to a
single reservoir system and compared with conventional models such as stochastic dynamic programming and dynamic programming and
regression. The results of historical and artificial time series simulations show that the GA models are generally superior in identifying
better expected system performance. Parsimony of policy parameters is inferred as a principle for selecting the structure of the policy, and
Fourier series can be helpful for reducing the number of parameters by defining the time variations of coefficients. The proposed method
has shown to be flexible and robust in optimizing various types of policies, even in models that include nonlinear, nonseparable objective
functions and constraints.},
  file      = {:Optimization\\Direct Search Approaches using Genetic Algorithms for Optimization of Water Reservoir Operating Policies.pdf:PDF},
  keywords  = {Water resources; Optimization models; Evolutionary computation; Simulation models; Algorithms},
  timestamp = {2017-04-25},
}

@Article{Yang2007,
  author    = {Chao-Chung Yang and Liang-Cheng Chang and Chao-Hsien Yeh and Chang-Shian Chen},
  title     = {Multiobjective Planning of Surface Water Resources by Multiobjective Genetic Algorithm with Constrained Differential Dynamic Programming},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2007},
  volume    = {133},
  number    = {6},
  pages     = {499--508},
  abstract  = {Owing to the conflict encountered between the two objectives of fixed cost in reservoir installation and operating cost in
time-varying water deficit, multiobjective planning of surface water resources is a difficult job. Instead of combining these two objectives
into just one objective using the weighting factor approach, this investigation proposes a novel method by integrating a multiobjective
genetic algorithm MOGA with constrained differential dynamic programming CDDP. A MOGA is employed to generate the various
combinations of reservoir capacity and estimate the noninferior solution set. However, applying this algorithm to solve the dynamics of
the operating cost, the number of variables increasing with time will dramatically increase the use of computational resources. Consequently, the CDDP is herein adopted to distribute optimal releases among reservoirs to satisfy water demand as much as possible. Next,
the effectiveness of the proposed methodology is verified by solving a multiobjective planning problem of surface water in southern
Taiwan. This real application demonstrates that MOGA can be linked with CDDP to resolve a complex water resources problem.
Additionally, the ability of MOGA on addressing multiple objectives simultaneously without converting to a weighted objective function
provides the opportunity for significant advancement in multiobjective optimization. Finally, this investigation also proposes three suitable
strategies of reservoir construction to decision makers with budget concerns through the analysis of all noninferior solutions.},
  file      = {:Optimization\\Multiobjective Planning of Surface Water Resources by Multiobjective Genetic Algorithm with Constrained Differential Dynamic Programming.pdf:PDF},
  keywords  = {Multiple objective analysis; Algorithms; Surface waters; Water resources},
  timestamp = {2017-04-25},
}

@Article{Suen2009,
  author    = {Jian-Ping Suen and J. Wayland Eheart and Edwin E. Herricks and Fi-John Chang},
  title     = {Evaluating the Potential Impact of Reservoir Operation on Fish Communities},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2009},
  volume    = {135},
  number    = {6},
  pages     = {475--483},
  abstract  = {A developing understanding of instream flow needs now supports maintenance of ecological flow regimes rather than a fixed,
time-invariant regulatory minimum flow. This shift is reflected in management of streamflow change created by existing reservoirs and
flow diversion structures. With an emphasis on regime-based approaches a new connectivity is demanded between reservoir operations
and the resulting downstream flow conditions. Complicating this situation is reservoir management that may be legally limited to flood
control and water supply requirements reducing options for supplying downstream needs. This paper proposes an approach to reservoir
operation that is based on ecological flow regime concepts. Reservoir operation is guided by six hydrologic indicators selected both to
meet the specific flow needs of the local indigenous fish community and to satisfy authorized reservoir operational rules. The approach is
based on incorporation of ecology and life history requirements of the fish community in the decision making process to better define and
meet flow needs. Optimization using nondominated sorting genetic algorithms provides a basis for reservoir operational schemes that are
expected to provide benefit to fish communities downstream while also meeting authorized reservoir storage needs},
  file      = {:Reservoirs\\Evaluating the Potential Impact of Reservoir Operation on Fish Communities.pdf:PDF},
  keywords  = {Reservoir operation; Ecology; Taiwan; Fish management; Instream flow.},
  timestamp = {2017-04-25},
}

@Article{Abolpour2007,
  author    = {Behrouz Abolpour and Mahmood Javan},
  title     = {Optimization Model for Allocating Water in a River Basin during a Drought},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2007},
  volume    = {133},
  number    = {6},
  pages     = {559--572},
  abstract  = {Optimization of water use is a complex problem in a large scale river basin. One of the most important approaches in
optimizing water use in a river basin is to find the relationship between water demand and water supply. The parameters that affect
demand, supply, and the methods of evaluation of such elements are discussed in this study. Also, a method is presented for providing
objective and constraint functions from considering these effects. Fuzzy logic theory is used to modify the stochastic dynamic programming SDP method such that an optimization model is developed for allocating water and can be defined as the “stochastic fuzzy dynamic
programming SFDP” method. This method is applied to optimize water use in the Kor and Seevand river basins, located in the
Bakhtegan watershed, Fars, Iran. The primary water resources management consisted of the variability ranges of decision variables such
as release from Doroodzan Dam and reservoir storage and was also used for allocating water in these river basins based on the SDP
method. Therefore, in the present study, these variability ranges are obtained based on historical data, and divided into several record
classes. Optimum class of release, a case of the record classes, was obtained from the optimization model for each month during the past
4 out of 25 years. Although, the SFDP method can be used in optimizing water allocation during each period, the method is structured and
discussed only during the drought periods 4 years. Later, a comparison was made between optimum classes and record classes that were
operated during the primary water resources management. During this period, the SFDP method reduced the difference between the
release from the dam and the total water demand of the river basin. Therefore, approximately a 27% improvement in adaptation between
release and demand could be attained. Finally, if the decision maker makes the decision for the release from the dam that is optimal
according to our objective function, the reliability of reservoir operating can be increased by 51% during future droughts.},
  file      = {:Optimization\\Optimization Model for Allocating Water in a River Basin during a Drought.pdf:PDF},
  keywords  = {Optimization models; Water supply; Water demand; Fuzzy sets; Reservoir operation; Droughts; River basins.},
  timestamp = {2017-04-25},
}

@InProceedings{Chaleeraktrakoon2005,
  author    = {C. Chaleeraktrakoon and A. Kangrang},
  title     = {A Dynamic Programming for Searching Rule Curves},
  booktitle = {EWRI},
  year      = {2005},
  abstract  = {Rule curves are basic guides for operating a reservoir system. This paper thus
formulates a dynamic programming (DP) for searching the optimal rule curves. The
programming technique is appropriate for the searching due to its staged
characteristic. The formulated DP can be applied to a single or multiple reservoir
systems. The DP has been applied to find the optimal rule curves of the Bhumibol
and Sirikit Reservoirs (the Chao Phraya River Basin, Thailand). Results have been
used for assessing the rule curves of accepted simulation practice. It can be
concluded that the simulation approach does not ensure to always yield the optimal
rule curves of the considered systems.},
  file      = {:Optimization\\Dynamic Programming for Searching Rule Curves.pdf:PDF},
  timestamp = {2017-04-25},
}

@Article{Benedito1991,
  author    = {Benedito P. F. Braga Jr. and William W-G. Yeh and Leonard Becker and Mario T. L. Barros},
  title     = {Stochastic Optimization of Multiple Reservoir System Operation},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {1991},
  volume    = {117},
  number    = {4},
  pages     = {471--481},
  abstract  = {A stochastic dynamic programming model for the optimization of hydropower prroduction of a multiple storage-reservoir system with correlated inflows has been developed. Application was made to a subsystem of the Brazilian
hydroelectric system. The model consists of two parts. An off-line, one-time-only,
deterministic dynamic program computes the value of the stored water in all of
the reservoirs as a function of the several reservoir storages and the month of the
year. The calculated values represent potential energy generation and are based on
historical flow data. The on-line program is formulated in terms of a stochastic
dynamic program and conducted in real time for operational use. Each month a
multidimensional search is made for the optimal set of reservoir releases that maximize system benefits. The search uses the probability transition matrices and the
tables of stored-water benefits for the particular month determined by the off-line
program. The optimization requires knowledge of the previous month's inflows
and the starting storages for the current month; but these, of course, are observables and are readily determined. The following month, the on-line search procedure is repeated to find the optimal releases for that month. The off-line program
also can be used to obtain trade-offs between expected energy-generation benefits
and water-management benefits consequent to some other objective, such as flood
control. Model performance was checked against actual operational data for a Brazilian subsystem, and there are indications of superior performance by the model.},
  file      = {:Optimization\\Stochastic Optimization of Multiple Reservoir System Operation.pdf:PDF},
  timestamp = {2017-04-25},
}

@Article{Huang1993,
  author    = {Wen-Cheng Huang and Chian Min Wu},
  title     = {Diagnostic Checking in Stochastic Dynamic Programming},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {1993},
  volume    = {119},
  number    = {4},
  pages     = {490--494},
  abstract  = {A testingprocedure to diagnosewhether the stochasticdynamicprogramming(SDP) modelsfor reservoir operations willconvergeis presented. Theoretically, the stabilityof SDP can be diagnosedby checkingwhether a coefficient
matrix, connected with the existence and uniqueness of solutions of transition
probabilities for the inflows,is linearlyindependent. The steady-stateSDP model
ofreservoiroperationsisguaranteedafter the SDPconvergencehasbeen approved.
If the rank of the coefficientmatrix is the same as the number of inflow states,
there is preciselyone solutionfor the steady-statedistribution of inflowsand SDP
convergencewillbe reached. Otherwise, the SDP model is divergent.},
  file      = {:Optimization\\Diagnostic Checking in Stochastic Dynamic Programming.pdf:PDF},
  timestamp = {2017-04-25},
}

@Article{Tu2003,
  author    = {Ming-Yen Tu and Nien-Sheng Hsu and William W.-G. Yeh, Hon},
  title     = {Optimization of Reservoir Management and Operation with Hedging Rules},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2003},
  volume    = {129},
  number    = {2},
  pages     = {86--97},
  abstract  = {This research develops a mixed integer linear programming ~MILP! model that considers simultaneously both the traditional
reservoir rule curves and the hedging rules to manage and operate a multipurpose, multireservoir system. During normal periods of
operation, when inflows are plentiful, this optimization model efficiently distributes the available stored water from different reservoirs to
meet the planned demands imposed by competing users. However, during periods of drought, or when anticipating a drought, the planned
demands cannot be fully met, and a water shortage occurs. By considering the hedging rules along with the rule curves, guidelines are
provided for reservoir releases. To minimize the impact of drought, the hedging rules effectively reduce the ongoing water supply to
balance with the target storage requirement. The MILP model is applied to a multireservoir system in the southern region of Taiwan,
where the results obtained demonstrate the applicability and utility of the model.},
  file      = {:Optimization\\Optimization of Reservoir Management and Operation with Hedging Rules.pdf:PDF},
  keywords  = {Reservoir operation; Reservoir management; Water distribution; Water resources management; Taiwan; Optimization.},
  timestamp = {2017-04-25},
}

@Article{Mousavi2004,
  author    = {Seyed Jamshid Mousavi and Mohammad Karamouz and Mohammad Bagher Menhadj},
  title     = {Fuzzy-State Stochastic Dynamic Programming for Reservoir Operation},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2004},
  volume    = {130},
  number    = {6},
  pages     = {460--470},
  abstract  = {A new way of incorporating fuzzy logic concepts is introduced in order to better capture and manage some uncertainties in
applying stochastic dynamic programming (SDP) formulations for reservoir operation. A model called fuzzy-state stochastic dynamic
programming (FSDP), which takes into account both uncertainties due to random nature of hydrological variables and imprecision due to
variable discretization is introduced in this study. In this model, fuzzy transition probabilities for stochastic hydrologic state variables are
calculated by defining a fuzzy Markov chain. These fuzzy probabilities are derived based on fuzzy frequency concept considering different
frequencies for different points of a class interval. In order to show how effective the proposed method is, FSDP was applied to the
Zayandeh–Rud river–reservoir system in Isfahan, in the central part of Iran, and was compared with a demand driven stochastic dynamic
programming model. The results show the robustness of the FSDP solutions with respect to the type of discretization scheme used in
calculating the transition probabilities.},
  file      = {:Optimization\\Fuzzy-State Stochastic Dynamic Programming for Reservoir Operation.pdf:PDF},
  keywords  = {Reservoir operation; Dynamic programming; Fuzzy sets; Probability; Stochastic processes},
  timestamp = {2017-04-25},
}

@InBook{Barros2009,
  title     = {Climate Flow Forecast Model for the Brazilian Hydropower System},
  publisher = {Great Rivers},
  year      = {2009},
  author    = {Mario T. L. Barros and João E. G. Lopes and Renato C. Zambon and Alberto L. Francato and Paulo S. F. Barbosa and Fabio R. Zanfelice},
  abstract  = {The Brazilian Hydropower System (SIN) is composed today by 107 hydropower plants with 81,036 MW of installed capacity. The system is completely connected due to the Brazilian heterogeneous hydrology. The flow forecast is a very important tool to operate SIN and to other decisions involved in the Brazilian electrical sector. This paper aims to present a model for SIN flow forecasting done in a climate basis, in a monthly basis considering rainfall forecasts for six months ahead. The rainfall forecasts are done by the Brazilian Center for Weather Forecast and Climate Studies (CPTEC). The CPTEC climate forecasting model covers the South America continent and produces forecasts in two grids, 200 by 200 Km and 40 by 40 Km. The flow forecast is done by two hydrological methods. One is the rainfall-flow model SMAP (Soil Moisture Accounting Procedure) by and the other a stochastic linear model (MEL). The final forecasts are defined by a weigh function considering SMAP and MEL forecasts. The flow forecast model is called GERAVAZ and was design using a decision support system frame in order to be practical to users. GERAVAZ was applied to twenty basins covering the main Brazilian rivers. These twenty forecasts are the reference to produce the inflow forecasts to all SIN reservoirs. Preliminary results are quite promising and have great evidences of the potential application of this modeling tool.},
  booktitle = {World Environmental and Water Resources Congress 2009},
  doi       = {10.1061/41036(342)476},
  eprint    = {http://ascelibrary.org/doi/pdf/10.1061/41036%28342%29476},
  file      = {:Ensembles\\Climate Flow Forecast Model for the Brazilian Hydropower System.pdf:PDF},
  timestamp = {2017-05-01},
  url       = {http://ascelibrary.org/doi/abs/10.1061/41036%28342%29476},
}

@TechReport{Faunt2009,
  author      = {Claudia C. Faunt},
  title       = {Groundwater Availability of the Central Valley Aquifer, California},
  institution = {United States Geological Survey, Department of the Interior},
  year        = {2009},
  type        = {Professional Paper},
  number      = {1766},
  abstract    = {Chapter A
Introduction, Overview of Hydrogeology, and Textural Model of
California’s Central Valley
By Claudia C. Faunt, Randall T. Hanson, and Kenneth Belitz
Chapter B
Groundwater Availability in California’s Central Valley
By Claudia C. Faunt, Kenneth Belitz, and Randall T. Hanson
Chapter C
Numerical Model of the Hydrologic Landscape and Groundwater
Flow in California’s Central Valley
By Claudia C. Faunt, Randall T. Hanson, Kenneth Belitz, Wolfgang Schmid,
Steven P. Predmore, Diane L. Rewis, and Kelly McPherson
Appendix 1
Supplemental Information—Modifications to
Modflow-2000 Packages and Processes},
  file        = {:Hydrology\\Groundwater\\Groundwater Availability of the Central Valley Aquifer, California.pdf:PDF},
  keywords    = {related to OWHM},
  timestamp   = {2017-05-09},
}

@Article{Stedinger1984,
  author    = {Stedinger, Jery R. and Sule, Bola F. and Loucks, Daniel P.},
  title     = {Stochastic dynamic programming models for reservoir operation optimization},
  journal   = {Water Resources Research},
  year      = {1984},
  volume    = {20},
  number    = {11},
  pages     = {1499--1505},
  issn      = {1944-7973},
  abstract  = {Most applications of stochastic dynamic programming have derived stationary policies which use the previous period's inflow as a hydrologic state variable. This paper develops a stochastic dynamic programming model which employs the best forecast of the current period's inflow to define a reservoir release policy and to calculate the expected benefits from future operations. Use of the best inflow forecast as a hydrologic state variable, instead of the preceding period's inflow, resulted in substantial improvements in simulated reservoir operations with derived stationary reservoir operating policies. While these results are for a dam at Aswan in the Nile River Basin, operators of other reservoir systems also have available to them information other than the preceding period's inflow which can be used to develop improved inflow forecasts.},
  doi       = {10.1029/WR020i011p01499},
  file      = {:Optimization\\Stochastic dynamic programming models for reservoir operation optimization.pdf:PDF},
  keywords  = {Instruments and techniques: modeling},
  timestamp = {2017-05-10},
  url       = {http://dx.doi.org/10.1029/WR020i011p01499},
}

@InBook{Wallace2003a,
  chapter   = {Ch. 10},
  pages     = {637--677},
  title     = {Stochastic programming models in energy},
  publisher = {Elsevier},
  year      = {2003},
  author    = {Stein W. Wallace and Stein-Erik Fleten},
  volume    = {10},
  abstract  = {We give the reader a tour of good energy optimization models that explicitly deal with uncertainty. The uncertainty usually stems from unpredictability of demand and/or prices of energy, or from resource availability and prices. Since most energy investments or operations involve irreversible decisions, a stochastic programming approach is meaningful. Many of the models deal with electricity investments and operations, but some oil and gas applications are also presented. We consider both traditional cost minimization models and newer models that reflect industry deregulation processes. The oldest research precedes the development of linear programming, and most models within the market paradigm have not yet found their final form.},
  file      = {:Optimization\\Stochastic Programming Models in Energy.pdf:PDF},
  keywords  = {Stochastic programming; energy; regulated markets; deregulation; uncertainty; electricity; natural gas; oil},
  timestamp = {2017-05-10},
}

@Article{Beraldi2008,
  author    = {Patrizia Beraldi and Domenico Conforti and Antonio Violi},
  title     = {A two-stage stochastic programming model for electric energy producers},
  journal   = {Computers \& Operations Research},
  year      = {2008},
  volume    = {35},
  number    = {10},
  pages     = {3360 - 3370},
  issn      = {0305-0548},
  note      = {Part Special Issue: Search-based Software Engineering},
  abstract  = {The bilateral contract selection and bids definition constitute a strategic issue for electric energy producers that operate in competitive markets, as the liberalized electricity ones. In this paper we propose a two-stage stochastic integer programming model for the integrated optimization of power production and trading which include a specific measure accounting for risk management. We solve the model by means of a novel enumerative solution approach that exploits the particular problem structure. Finally, we report some preliminary computational experiments.},
  doi       = {https://doi.org/10.1016/j.cor.2007.03.008},
  file      = {:Optimization\\A two-stage stochastic programming model for electric energy producers.pdf:PDF},
  keywords  = {Electricity markets, Power optimization, Stochastic integer programming. },
  timestamp = {2017-05-10},
  url       = {http://www.sciencedirect.com/science/article/pii/S030505480700069X},
}

@Article{Fleten2008,
  author    = {Stein-Erik Fleten and Trine Krogh Kristoffersen},
  title     = {Short-term hydropower production planning by stochastic programming},
  journal   = {Computers \& Operations Research},
  year      = {2008},
  volume    = {35},
  number    = {8},
  pages     = {2656 - 2671},
  issn      = {0305-0548},
  note      = {Queues in Practice},
  abstract  = {Within the framework of multi-stage mixed-integer linear stochastic programming we develop a short-term production plan for a price-taking hydropower plant operating under uncertainty. Current production must comply with the day-ahead commitments of the previous day which makes short-term production planning a matter of spatial distribution among the reservoirs of the plant. Day-ahead market prices and reservoir inflows are, however, uncertain beyond the current operation day and water must be allocated among the reservoirs in order to strike a balance between current profits and expected future profits. A demonstration is presented with data from a Norwegian hydropower producer and the Nordic power market at Nord Pool.},
  doi       = {https://doi.org/10.1016/j.cor.2006.12.022},
  file      = {:Optimization\\Short-term hydropower production planning by stochastic programming.pdf:PDF},
  keywords  = {\{OR\} in energy, Hydropower, Stochastic programming, Scenarios },
  timestamp = {2017-05-10},
  url       = {http://www.sciencedirect.com/science/article/pii/S0305054806003224},
}

@Book{Coello2007,
  title     = {Evolutionary Algorithms for Solving Multi-Objective Problems},
  publisher = {Springer},
  year      = {2007},
  author    = {Coello Coello, Carlos and Lamont, Gary B. and van Veldhuizen, David A.},
  series    = {Genetic and Evolutionary Computation},
  abstract  = {This textbook is the second edition of Evolutionary Algorithms for Solving Multi-Objective Problems, significantly augmented with contemporary knowledge and adapted for the classroom. All the various features of multi-objective evolutionary algorithms (MOEAs) are presented in an innovative and student-friendly fashion, incorporating state-of-the-art research results. The diversity of serial and parallel MOEA structures are given, evaluated and compared. The book provides detailed insight into the application of MOEA techniques to an array of practical problems. The assortment of test suites are discussed along with the variety of appropriate metrics and relevant statistical performance techniques.
Distinctive features of the new edition include:
Designed for graduate courses on Evolutionary Multi-Objective Optimization, with exercises and links to a complete set of teaching material including tutorials
Updated and expanded MOEA exercises, discussion questions and research ideas at the end of each chapter
New chapter devoted to coevolutionary and memetic MOEAs with added material on solving constrained multi-objective problems
Additional material on the most recent MOEA test functions and performance measures, as well as on the latest developments on the theoretical foundations of MOEAs
An exhaustive index and bibliography
This self-contained reference is invaluable to students, researchers and in particular to computer scientists, operational research scientists and engineers working in evolutionary computation, genetic algorithms and artificial intelligence.},
  file      = {:Optimization\\Evolutionary Algorithms for Solving Multi-Objective Problems.pdf:PDF},
  timestamp = {2017-05-10},
}

@Book{Brameier2006,
  title     = {Linear Genetic Programming},
  publisher = {Springer},
  year      = {2006},
  author    = {Markus Brameier and Wolfgange Banzhaf},
  editor    = {David E. Goldberg and John R. Koza},
  series    = {Genetic and Evolutionary Computation},
  file      = {:Optimization\\Linear Genetic Programming.pdf:PDF},
  timestamp = {2017-05-10},
}

@Article{Reed2003,
  author   = {Patrick Reed and Barbara S. Minsker and David E. Goldberg},
  title    = {Simplifying multiobjective optimization: An automated design methodology for the nondominated sorted genetic algorithm-II},
  journal  = {Water Resources Research},
  year     = {2003},
  volume   = {39},
  number   = {7},
  abstract = {Many water resources problems require careful balancing of fiscal, technical, and
social objectives. Informed negotiation and balancing of objectives can be greatly aided
through the use of evolutionary multiobjective optimization (EMO) algorithms, which can
evolve entire tradeoff (or Pareto) surfaces within a single run. The primary difficulty in
using these methods lies in the large number of parameters that must be specified to ensure
that these algorithms effectively quantify design tradeoffs. This technical note addresses
this difficulty by introducing a multipopulation design methodology that automates
parameter specification for the nondominated sorted genetic algorithm-II (NSGA-II). The
NSGA-II design methodology is successfully demonstrated on a multiobjective long-term
groundwater monitoring application. Using this methodology, multiobjective optimization
problems can now be solved automatically with only a few simple user inputs.},
  file     = {Simplifying multiobjective optimization- An automated design methodology for the nondominated sorted genetic algorithm-II.pdf:Optimization\\Simplifying multiobjective optimization- An automated design methodology for the nondominated sorted genetic algorithm-II.pdf:PDF},
}

@InProceedings{Devireddy2003,
  author    = {Venkat Devireddy and Patrick Reed},
  title     = {An Efficient Design Methodology for the Nondominated Sorted Genetic Algorithm-II},
  booktitle = {Genetic and Evolutionary Computation Conference},
  year      = {2003},
  abstract  = {Many real world problems require careful balancing of fiscal,
technical, and social objectives.  Informed negotiation and balancing of 
objectives can be greatly aided through the use of evolutionary multiobjective 
optimization (EMO) algorithms, which can evolve entire tradeoff (or Pareto) 
surfaces within a single run.  The primary difficulty in using these methods lies 
in the large number of parameters that must be specified to ensure that these 
algorithms effectively quantify design tradeoffs. This paper addresses this 
difficulty by introducing a multi-population design methodology that automates 
parameter specification for the Nondominated Sorted Genetic Algorithm-II 
(NSGA-II).  The NSGA-II design methodology is successfully demonstrated on 
four test problems. Using this methodology, multiobjective optimization 
problems can now be solved automatically  with only a few simple user inputs.},
  file      = {:Optimization\\An Efficient Design Methodology for the Nondominated Sorted Genetic Algorithm-II.pdf:PDF},
  timestamp = {2017-03-27},
}

@TechReport{Deb2003,
  author      = {K. Deb and M. Mohan and S. Mishra},
  title       = {A fast multi-objective evolutionary algorithm for finding well-spread pareto-optimal solutions},
  institution = {KanGAL},
  year        = {2003},
  number      = {200302},
  file        = {:Optimization\\A fast multi-objective evolutionary algorithm for finding well-spread pareto-optimal solutions.pdf:PDF},
  timestamp   = {2017-05-10},
}

@InBook{Kukkonen2006,
  pages     = {553--562},
  title     = {A Fast and Effective Method for Pruning of Non-dominated Solutions in Many-Objective Problems},
  publisher = {Springer Berlin Heidelberg},
  year      = {2006},
  author    = {Kukkonen, Saku and Deb, Kalyanmoy},
  editor    = {Runarsson, Thomas Philip and Beyer, Hans-Georg and Burke, Edmund and Merelo-Guerv{\'o}s, Juan J. and Whitley, L. Darrell and Yao, Xin},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-38991-0},
  abstract  = {Diversity maintenance of solutions is an essential part in
multi-objective optimization. Existing techniques are suboptimal either
in the sense of obtained distribution or execution time. This paper proposes an effective and relatively fast method for pruning a set of nondominated solutions. The proposed method is based on a crowding estimation technique using nearest neighbors of solutions in Euclidean sense,
and a technique for finding these nearest neighbors quickly. The method
is experimentally evaluated, and results indicate a good trade-off between
the obtained distribution and execution time. Distribution is good also in
many-objective problems, when number of objectives is more than two},
  booktitle = {Parallel Problem Solving from Nature - PPSN IX: 9th International Conference, Reykjavik, Iceland, September 9-13, 2006, Proceedings},
  doi       = {10.1007/11844297_56},
  file      = {:Optimization\\A Fast and Effective Method for Pruning of Nondominated Solutions in Many-Objective Problems.pdf:PDF},
  timestamp = {2017-05-10},
  url       = {http://dx.doi.org/10.1007/11844297_56},
}

@Article{Murphy1984,
  author    = {Allan H. Murphy and Robert L. Winkler},
  title     = {Probability Forecasting in Meterology},
  journal   = {Journal of the American Statistical Association},
  year      = {1984},
  volume    = {39},
  number    = {387},
  pages     = {489--500},
  abstract  = {Efforts to quantify the uncertainty in weather forecasts began more than 75 years ago, and many studies and experiments involving objective and subjective probability forecasting have been conducted in meteorology in the intervening period. Moreover, the U.S. National Weather Service (NWS) initiated a nationwide program in 1965 in which precipitation probability forecasts were formulated on an operational basis and routinely disseminated to the general public. In addition, the NWS now prepares objective probability forecasts for many variables, using statistical procedures. Hence probability forecasting in meteorology is unique in that very large sets of probability forecasts that have been subjected to detailed evaluation are available. This article has four objectives: (a) to review the history of probability forecasting in meteorology to acquaint statisticians with this body of literature; (b) to describe recent methodological, experimental, and operational activities in this field; (c) to examine current issues in probability forecasting; and (d) to discuss briefly the relationship between probability forecasting in meteorology and probability forecasting in other fields. Results of operational and experimental weather forecasting programs are presented, methods of verifying and evaluating probability forecasts in common use in meteorology are discussed, and an extensive list of references is provided.},
  file      = {:Ensembles\\Probability Forecasting in Meterology.pdf:PDF},
  keywords  = {Analytical forecasting, Probability forecasts, Weather forecasting, Weather, Meteorology, Probabilities, Precipitation, Forecasting techniques, Statistical weather forecasting, Statistical models},
  timestamp = {2017-05-11},
}

@TechReport{IHA2017,
  title       = {Better Hydro Compendium of Case Studies 2017},
  institution = {International Hydropower Association},
  year        = {2017},
  file        = {:Reservoirs\\Better Hydro Compendium of Case Studies 2017.pdf:PDF},
  timestamp   = {2017-05-12},
}

@TechReport{WCD2000,
  title       = {Dams and Development : A new framework for decision-making},
  institution = {WORLD COMMISSION ON DAMS},
  year        = {2000},
  file        = {:Reservoirs\\Dams and Development - A new framework for decision-making.pdf:PDF},
  timestamp   = {2017-05-12},
}

@Unpublished{Salvatier2015,
  author    = {John Salvatier and Thomas V. Wiecki and Christopher Fonnesbeck},
  title     = {Probabilistic Programming in Python using PyMC},
  month     = {jul},
  year      = {2015},
  abstract  = {Probabilistic programming (PP) allows flexible specification of Bayesian statistical models in code. PyMC3
is a new, open-source PP framework with an intutive and readable, yet powerful, syntax that is close to the
natural syntax statisticians use to describe models. It features next-generation Markov chain Monte Carlo
(MCMC) sampling algorithms such as the No-U-Turn Sampler (NUTS; Hoffman, 2014), a self-tuning variant
of Hamiltonian Monte Carlo (HMC; Duane, 1987). This class of samplers works well on high dimensional
and complex posterior distributions and allows many complex models to be fit without specialized knowledge
about fitting algorithms. HMC and NUTS take advantage of gradient information from the likelihood to
achieve much faster convergence than traditional sampling methods, especially for larger models. NUTS also
has several self-tuning strategies for adaptively setting the tunable parameters of Hamiltonian Monte Carlo,
whicstatisticalh means you usually don’t need to have specialized knowledge about how the algorithms work.
PyMC3, Stan (Stan Development Team, 2014), and the LaplacesDemon package for R are currently the only
PP packages to offer HMC.
Probabilistic programming in Python confers a number of advantages including multi-platform compatibility,
an expressive yet clean and readable syntax, easy integration with other scientific libraries, and
extensibility via C, C++, Fortran or Cython. These features make it relatively straightforward to write and
use custom statistical distributions, samplers and transformation functions, as required by Bayesian analysis.
While most of PyMC3’s user-facing features are written in pure Python, it leverages Theano (Bergstra
et al., 2010) to transparently transcode models to C and compile them to machine code, thereby boosting
performance. Theano is a library that allows expressions to be defined using generalized vector data
structures called tensors, which are tightly integrated with the popular NumPy ndarray data structure, and
similarly allow for broadcasting and advanced indexing, just as NumPy arrays do. Theano also automatically
optimizes the likelihood’s computational graph for speed and provides simple GPU integration.
Here, we present a primer on the use of PyMC3 for solving general Bayesian statistical inference and
prediction problems. We will first see the basics of how to use PyMC3, motivated by a simple example:
installation, data creation, model definition, model fitting and posterior analysis. Then we will cover two
case studies and use them to show how to define and fit more sophisticated models. Finally we will show
how to extend PyMC3 and discuss other useful features: the Generalized Linear Models subpackage, custom
distributions, custom transformations and alternative storage backends.},
  file      = {:Statistics\\Probabilistic Programming in Python using PyMC.pdf:PDF},
  timestamp = {2017-05-16},
}

@TechReport{Hirsch1977,
  author      = {Rober Hirsch and John Schaake and Daniel Sheer},
  title       = {Assessment of Current Occoquan Water Supply Situation},
  institution = {Potomac River Basin Commission},
  year        = {1977},
  file        = {:Statistics\\Assessment of Current Occoquan Water Supply Situation.pdf:PDF},
  timestamp   = {2017-05-16},
}

@TechReport{Hirsch1981a,
  author      = {Robert Hirsch},
  title       = {Estimating Probabilities of Reservoir Storage for the Upper Delaware River Basin},
  institution = {United States Geologic Survey},
  year        = {1981},
  file        = {:Statistics\\Estimating Probabilities of Reservoir Storage for the Upper Delaware River Basin.pdf:PDF},
  timestamp   = {2017-05-16},
}

@Article{Turner2017,
  author    = {Sean W. D. Turner and James Bennett and David Robertson and Stefano Galelli},
  title     = {Value of seasonal streamflow forecasts in emergency response reservoir management},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2017},
  volume    = {Under Review},
  abstract  = {Considerable research effort has recently been directed at improving ensemble seasonal streamflow forecasts, and transferring these methods into operational services. This paper examines the value of forecasts when applied to a range hypothetical reservoirs. We compare forecast-informed reservoir operations with operations based on more traditional control rules established from historical records. Using synthetic forecasts, we show that forecast-informed operations can improve reservoir operations where forecasts are accurate, but that this benefit is far more likely to occur in reservoirs operated for continually adjusted objectives (e.g., for hydropower generation) than compared with those operated for emergency response objectives (e.g., urban water supply, for which water use restrictions are seldom imposed). We then test whether a modern experimental forecasting system — called Forecast Guided Stochastic Scenarios (FoGSS) — can benefit a wide range of reservoirs operated for emergency response objectives. FoGSS-informed operations improved reservoir operations in a large majority of the reservoirs tested. In the catchments where FoGSS forecasts sometimes failed to improve operations over conventional control rules, we show that this is partly due to less consistently skilful forecasts at the timing during critical decisions are made.},
  file      = {:Ensembles\\Value of seasonal streamflow forecasts in emergency response reservoir management.pdf:PDF},
  timestamp = {2017-05-16},
}

@Article{Maas2017,
  author    = {Alexander Maas and Andre Dozier and Dale T. Manning and Christopher Goemans},
  title     = {Water storage in a changing environment: The impact of allocation institutions on value},
  journal   = {Water Resources Research},
  year      = {2017},
  volume    = {53},
  number    = {1},
  pages     = {672--687},
  abstract  = {As populations increase in arid regions of the world, investment in water infrastructure improves resource management by increasing control over the location and timing of water allocation. Many studies have explored freer trade as a substitute for additional infrastructure investment. We instead quantify how water allocation institutions, reservoir management objectives, and storage capacity influence the value derived from a reservoir system. We develop a stochastic dynamic programming model of a reservoir system that faces within-year variation in weather-dependent water demand as well as stochastic semiannual inflows. We parameterize the model using the Colorado-Big Thompson system, which transports stored water from the West Slope of the Rocky Mountains to the East Slope. We then evaluate the performance of the system under five institutional settings. Our results suggest that rigid allocation mechanisms and inefficient management objectives result in a decrease of up to 13% in the value generated from stored water when compared to a free trade scenario, an impact on par with predicted losses associated with climate-change-induced inflow reductions. We also find that under biased management objectives, increasing storage capacity can decrease the social value obtained from stored water.},
  file      = {:WaterResources\\Water storage in a changing environment- The impact of allocation institutions on value.pdf:PDF},
  timestamp = {2017-05-16},
}

@Article{Dozier2017,
  author    = {Andre Quinton Dozier and Mazdak Arabi and Benjamin Wostoupal and Christopher Goemans and Yao Zhang and Keith Paustian},
  title     = {Declining agricultural production in rapidly urbanizing semi-arid regions: Policy tradeoffs and sustainability indicators},
  journal   = {Environmental Research Letters},
  year      = {2017},
  volume    = {Accepted},
  abstract  = {In rapidly urbanizing semi-arid regions, increasing amounts of historically irrigated cropland lies permanently fallowed due to water court policies as agricultural water rights are voluntarily being sold to growing cities. This study develops an integrative framework for assessing effects of population growth and land use change on agricultural production and evaluating viability of alternative management strategies, including alternative agricultural transfer methods, regional water ownership restrictions, and urban conservation. A partial equilibrium model of a spatially-diverse regional water rights market is built in application of the framework to an exemplary basin. The model represents agricultural producers as profit-maximizing suppliers and municipalities as cost-minimizing consumers of water rights. Results indicate that selling an agricultural water right today is worth up to 2 times more than 40 years of continued production. All alternative policies that sustain agricultural cropland and crop production decrease total agricultural profitability by diminishing water rights sales revenue, but in doing so, they also decrease municipal water acquisition costs. Defining good indicators and incorporating adequate spatial and temporal detail are critical to properly analyzing policy impacts. To best improve agricultural profit from production and sale of crops, short-term solutions include alternative agricultural transfer methods while long-term solutions incorporate urban conservation.},
  file      = {:WaterResources/Declining agricultural production in rapidly urbanizing semi-arid regions- policy tradeoffs and sustainability indicators.pdf:PDF},
  timestamp = {2017-05-16},
}

@TechReport{SAWI2015,
  author      = {SAWI},
  title       = {Programmatic Approach to Impacts of Climate Risks on Water - Hydropower and Dams},
  institution = {SAWI - World Bank},
  year        = {2015},
  file        = {:WaterResources\\Programmatic Approach to Impacts of Climate Risks on Water - Hydropower and Dams.pdf:PDF},
  timestamp   = {2017-05-18},
}

@Article{Price2016,
  author      = {Gareth Price and Sonali Mittra},
  title       = {Water, Ecosystems and Energy in South Asia - Making Cross-Border Collaboration Work},
  year        = {2016},
  note        = {SAWI},
  abstract    = {The countries of South Asia share several hydro-geological features and some of the world’s major
river basins – the Ganga (or Ganges), the Brahmaputra and the Indus. The Indus basin spans China,
Afghanistan, Pakistan and India, while the Brahmaputra and the Ganga and their tributaries flow
through China, Bhutan, India, Nepal and Bangladesh. These countries are also vulnerable to a wide
range of natural disasters including earthquakes, tsunamis, cyclones, droughts and floods, which affect
hundreds of millions of the region’s inhabitants. Floods in particular are a pervasive and perennial
problem, given the concentration of annual rainfall during the monsoon. As well as affecting people
and property, they damage crops, presenting a further threat to livelihoods given that the majority
of people in the region still depend on farming.
South Asia is home to a number of shared ecosystems. Successful ecosystem management requires
cross-border collaboration. While joint management is frequently interpreted as a diminution of
sovereignty, policy alignment has proven to be feasible when supported by dialogue. In addition, there
is scope for shared learning across South Asia. The challenges faced across the region are similar, and
solutions are readily transferable and replicable.
Despite its abundant hydropower potential, South Asia struggles with energy shortages. No
country in the region is able to provide all of its population with guaranteed supplies of electricity.
Cross-border hydropower, among other energy trading possibilities, therefore offers a partial solution
to energy shortages in South Asia. Cooperation could provide economic benefits and allow for more
amicable relationships in the region. It could also facilitate integrated planning for sustainable waterresource
management.
Several categories of cross-border water cooperation have had success in the region, and could
be expanded and developed to improve water-resource policy and resilience:},
  file        = {:WaterResources\\Water, Ecosystems and Energy in South Asia.pdf:PDF},
  institution = {Chatham House - The Royal Institute of International Affairs},
  timestamp   = {2017-05-18},
}

@Article{Grey2013,
  author    = {D. Grey and D. Garrick and D. Blackmore and J. Kelman, M. Muller and C. Sadoff},
  title     = {Water security in one blue planet: twenty-first century policy challenges for science},
  journal   = {Philosophical Transactions of the Royal Society A},
  year      = {2013},
  volume    = {371},
  number    = {2002},
  abstract  = {Water-related risks threaten society at the local, national and global scales in our inter-connected and rapidly changing world. Most of the world's poor are deeply water insecure and face intolerable water-related risks associated with complex hydrology. Most of the world's wealthy face lower water-related risks and less complex hydrology. This inverse relationship between hydrological complexity and wealth contributes to a divided world. This must be addressed if global water security is to be achieved. Using a risk-based framework provides the potential to link the current policy-oriented discourse on water security to a new and rigorous science-based approach to the description, measurement, analysis and management of water security. To provide the basis for this science-based approach, we propose an encompassing definition rooted in risk science: water security is a tolerable level of water-related risk to society. Water security policy questions need to be framed so that science can marshal interdisciplinary data and evidence to identify solutions. We join a growing group of scientists in asserting a bold vision for science leadership, calling for a new and comprehensive understanding of the planet's water system and society's water needs.},
  file      = {:WaterResources\\Water security in one blue planet- twenty-first century policy challenges for science.pdf:PDF},
  timestamp = {2017-05-18},
}

@TechReport{Vaidya2014,
  author      = {Ramesh Ananda Vaidya and Eklabya Sharma},
  title       = {Research Insights on Climate and Water in the Hindu Kush Himalayas},
  institution = {ICIMOD},
  year        = {2014},
  abstract    = {Part I – Synthesis
Research Insights on Climate Change and Water Resources Management
in the Hindu Kush Himalayas 3
Ramesh A Vaidya, Eklabya Sharma, Bhaskar S Karky, Rajan Kotru, Pradeep Mool, Aditi Mukherji,
Neera S Pradhan, Arun B Shrestha, Shariar Wahid, and David Molden
Part II – Research Papers
Estimation of Discharge from Glacierized River Basins: Case Studies from
Langtang Valley, Nepal and Kafni River Basin, India 41
Rijan Bhakta Kayastha, Rajesh Kumar, Damodar Lamsal, Shaktiman Singh, Kundan Lal Shrestha,
Arun Bhakta Shrestha, and Sunil Kumar Pariyar
Vulnerability Assessment of Flash Floods in Poiqu/Bhotekoshi/Sunkoshi Watershed 54
Narendra Raj Khanal, Jin-Ming Hu, Jie Cao, Hridaya L Koirala, Yun-Gang Li, Pashupati Nepal, Jie Li,
Hai-Feng Jia, and Pradeep K Mool
The Impacts of Climate Change on Water Stress Situations in the
Yellow River Basin, China 76
Jianxin Mu, Liu Qunchang, Hamza Farooq Gabriel, Xu Di, Xu Jingdong, Wu Caili, and Ren Hejing
Climate Change and Water Availability in the Ganges-BrahmaputraMeghna
Basin: Impact on Local Crop Production and Policy Directives 97
Ahmadul Hassan, Shahriar Wahid, Madan Lal Shrestha, Mohammad Abdur Rashid, Tanvir Ahmed,
Anushila Mazumder, Motaleb Hossain Sarker, Bhuiya Md. Tamim Al Hossain, Sarazina Mumu, and
Maminul Haque Sarker
Climate Change Impact on Water Availability, and Farmers’
Adaptation Strategies: Case Studies from Pakistan and Nepal 109
Suman Sijapati, Muhammad Tousif Bhatti, and Neera Shrestha Pradhan
People’s Perceptions of and Adaptation Strategies to Climate Change
in the Koshi River Basin, Nepal 129
Xiaoliu Yang, Narendra Raj Khanal, Hriday Lal Koirala, and Pashupati Nepal
Benefit Sharing Mechanisms in Hydropower Projects: Lessons from
Nepal and India 145
Dhruba Pant, Neena Rao, Surya Nath Upadhyaya, and Bhaskar Singh Karky
Research Note: A Preliminary Investigation of Spatial Variability and Stable Isotope
Content of Monsoon Rainfall in the Lesser Himalayas, Northern India:
A Microwatershed Perspective 161},
  file        = {:WaterResources\\Research Insights on Climate and Water in the Hindu Kush Himalayas.pdf:PDF},
  timestamp   = {2017-05-18},
}

@Article{Chowdhury2004,
  author    = {Md. Rashed Chowdhury and Neil Ward},
  title     = {Hydro-Meteorological Variability in the Greater Ganges-Brahmaputra-Meghna Basins},
  journal   = {International Journal of Climatology},
  year      = {2004},
  volume    = {24},
  pages     = {1495--1508},
  abstract  = {The flows of the Ganges, Brahmaputra and Meghna (GBM) are highly seasonal, and heavily influenced by monsoon
rainfall. As a result, these rivers swell to their banks and often overflow during the monsoon months. This is most
pronounced in the downstream regions, particularly in Bangladesh, which is the lowest riparian country. The objective of
this paper is to study this hydro-meteorological variability in the greater GBM regions, including the headwater regions
in India and their role in streamflows in Bangladesh, and explore the large-scale oceanic factors affecting this hydrometeorological
variability. Global precipitation data, Bangladesh rainfall and streamflow records have been analysed
and related to large-scale climate patterns, including upstream rainfall, regional atmospheric circulation and patterns of
sea-surface temperature.
The findings have quantified how the streamflows of these rivers in Bangladesh are highly correlated with the
rainfall in the upper catchments with typically a lag of about 1 month. Therefore, streamflows in Bangladesh could
be reasonably estimated for 1 to 3 months in advance (especially for the Ganges and Brahmaputra rivers) by employing
simple correlation, if rainfall data from countries further up are available on a real-time and continuous basis. In the
absence of rainfall data, streamflow forecasts are still possible from unusually warm or cold sea-surface temperatures in
the tropics. The study concludes that hydro-meteorological information flow between Bangladesh and other neighbouring
countries is essential for developing a knowledge base for evaluating the potential implications of seasonal streamflow
forecast in the GBM basins in Bangladesh},
  file      = {:WaterResources\\Hydro-Meteorological Variability in the Greater Ganges-Brahmaputra-Meghna Basins.pdf:PDF},
  keywords  = {Ganges–Brahmaputra–Meghna (GBM); rainfall; streamflow; sea-surface temperature (SST); India; Bangladesh},
  timestamp = {2017-05-18},
}

@Article{Jian2009,
  author    = {Jun Jian and Peter J. Webster and Carlos D. Hoyos},
  title     = {Large-scale controls on Ganges and Brahmaputra river discharge on intraseasonal and seasonal time-scales},
  journal   = {Quarterly Journal of the Royal Meteorological Society},
  year      = {2009},
  volume    = {135},
  pages     = {353--370},
  abstract  = {Reliable water supply from the Ganges and Brahmaputra is of critical importance to the sustainability of
the agricultural societies of India and Bangladesh. But, the flow in both basins is highly variable on time-scales ranging
from days to years, creating challenges for the optimization of agricultural practices, water resource management and
disaster mitigation. The following questions are addressed. Is intraseasonal monsoon variability related to the subseasonal
variability of river flow? Do variations in the large-scale tropical sea-surface temperature (SST) located both regionally
and remotely promote seasonal and interannual variations of river discharge? And, if these relationships do exist, are they
determinable with sufficient lead-times to allow useful predictions for user communities in South Asia? We examine these
questions using 50 years of daily river discharge data for both rivers calculated at the points where they enter Bangladesh,
and with SST data in the Indo-Pacific region. We also examine the question of determining the impact of man-made dams,
diversions and barrages on the data record, especially that of the Ganges. A comparison of discharge prior to 1974 (the
time of the construction of the largest barrage) shows no statistical difference that cannot be explained by basin-wide
rainfall distributions. Changes that do occur are restricted to the dry-season months.
Subseasonal river discharge is found to be strongly tied to the monsoon intraseasonal cycle resulting in a near-inphase
timing of Ganges and Brahmaputra discharge. A basin isochrone analysis is used to couple stream-flow variability
and intraseasonal precipitation during the different phases of the intraseasonal cycle. On longer time-scales, statistically
significant correlations are found between mean monthly equatorial Pacific SST and the boreal summer Ganges discharge
with lead times of 2–3 months. These relationships are tied to El Nino–Southern Oscillation (ENSO) oscillations in addition ˜
to SST variability in the southwest and northwest Pacific that also seems to be related to ENSO. The Brahmaputra discharge,
on the other hand, shows somewhat weaker relationships with tropical SST. Strong lagged correlation relationships are
found with SST in the Bay of Bengal but these are the result of very warm SSTs and exceptional Brahmaputra discharge
during the summer of 1998. When this year is removed from the time series, relationships with SST anomalies weaken
everywhere except in the northwest Pacific for the June discharge and in areas of the central Pacific straddling the Equator
for the July discharge. In addition, the northwest Pacific relationship changes polarity for June and July discharges. Although
the relationships are weaker than those found for the Ganges, they are persistent from month to month and suggest that
two different and sequential factors influence Brahmaputra river flow},
  file      = {:WaterResources\\Large-scale controls on Ganges and Brahmaputra river discharge on intraseasonal and seasonal time-scales.pdf:PDF},
  keywords  = {predictability; rainfall–discharge–SST relationship},
  timestamp = {2017-05-18},
}

@Article{Yeh1982,
  author    = {William W-G Yeh and Leonard Becker and Robert Zettlemoyer},
  title     = {Worth of Inflow Forecast for Reservoir Operation},
  journal   = {Journal of the Water Resources Planning and Management Division},
  year      = {1982},
  volume    = {108},
  number    = {3},
  pages     = {257--269},
  abstract  = {This study assesses improved benefits that might be gained from the use of long-range streamflow forecasts in the operation of a typical multipurpose reservoir. Long-range is defined as a period of time ranging from one month to one year. The Oroville-Thermalito reservoir system of the California State Water Project (SWP) is selected for study; major benefits to be derived from long-term streamflow prediction for this system are hydropower generation, water conservation for irrigation and/or other beneficial uses, and decreased seepage damage to crops. Flood control benefits are potentially high but those benefits are more amenable to short-term rather than long-term forecasting. Incremental benefits are determined as functions of forecast time and accuracy on the basis of general adherence to current operating rules. The reservoir is theoretically operated over the 1914-73 time period; forecasts and comparisons are based on the historical streamflows. Procedure failure is defined as inability to meet a minimum storage constraint at any time over the 60-year period. To provide an additional evaluation of benefits from forecasting, analyses are also made using the historical means as estimates of future streamflows.},
  timestamp = {2017-05-22},
}

@Article{Stedinger2010,
  author    = {Jery R. Stedinger and Young-Oh Kim},
  title     = {Probabilities for ensemble forecasts reflecting climate information},
  journal   = {Journal of Hydrology},
  year      = {2010},
  volume    = {391},
  pages     = {9--23},
  abstract  = {A simple but general probability adjustment procedure is proposed for creating climate-series/probability sets that reflect historical frequencies adjusted for climate forecast information. Often forecast information is given as the conditional probability of below-normal, normal, and above-normal temperature
or rainfall depths, though forecast information also can be described by the conditional mean and standard deviation of key variables such as seasonal runoff. Probability adjustment methods developed by
Croley and by Wilks assign the same probability to all climate series in selected categories. This results
in a discontinuity at the interval boundaries, and can seriously misrepresent the mean and variance of the
conditional distribution of key variables. The proposed adjustment is based on a frequency model of the
unconditional and conditional distributions of key variables. This framework allows derivation of a consistent and smooth set of probabilities for climate series across the entire range of a key variable reflecting the change in the likelihood of each individual climate series. Examples show the improvements
obtained in the approximation of the moments and the cumulative distribution function. The paper also
considers multivariate adjustments to reflect several forecasts considering different time periods, different regions, or different variables. Examples for normal and non-normal cases illustrate the care needed
to ensure that the cross-correlations among climate variables are correctly represented, otherwise the
joint dependence is easily distorted.},
  file      = {:Ensembles\\Probabilities for ensemble forecasts reflecting climate information.pdf:PDF},
  keywords  = {Bayesian update Climate forecast Ensemble Streamflow Prediction Probability adjustment Scenario Schaake shuffle},
  timestamp = {2017-05-24},
}

@TechReport{IHA2017a,
  author      = {IHA},
  title       = {Hydropower Status Report},
  institution = {International Hydropower Association},
  year        = {2017},
  file        = {:Hydropower\\2017 Hydropower Status Report.pdf:PDF},
  timestamp   = {2017-05-30},
}

@Article{Dozier2016,
  author    = {A.Q. Dozier and O. David and M. Arabi and W. Lloyd and Y. Zhang},
  title     = {A minimally invasive model data passing interface for integrating legacy environmental system models},
  journal   = {Environmental Modelling \& Software},
  year      = {2016},
  volume    = {80},
  pages     = {265--280},
  abstract  = {This paper presents the Model Data Passing Interface (MODPI). The approach provides fine-grained,
multidirectional feedbacks between legacy environmental system models through read and write access to relevant model data during simulation using a bidirectional, event-based, publish-subscribe
system with a message broker. MODPI only requires commented directives in the original code and an
XML linkage file with an optional custom data conversion module. Automated code generation,
compilation, and execution reduce the programming burden on the modeler. Case study results indicated
that MODPI required less code modifications within each model code base both before and after automated code generation, outperforming a baseline subroutine approach. Performance overhead for
MODPI was minimal for the use case, offering speedup in some cases through parallel execution. MODPI
is much less invasive than other techniques, potentially encouraging adoption by the modeling community in addition to maintainability and reusability of integrated model code.},
  keywords  = {Framework invasiveness, Integrated assessment and modeling, Integrated environmental modeling, Inter-process communication},
  publisher = {Elsevier Ltd},
  timestamp = {2017-05-31},
}

@TechReport{DOE2016,
  author      = {DOE},
  title       = {Hydropower Vision: A New Chapter for America’s 1st Renewable Electricity Source},
  institution = {United States Department of Energy},
  year        = {2016},
  file        = {:Hydropower\\Hydropower Vision- A New Chapter for America’s 1st Renewable Electricity Source.pdf:PDF},
  timestamp   = {2017-06-07},
}

@TechReport{COMET2006,
  author      = {COMET},
  title       = {Streamflow Routing - Muskingum and Lag-K Method},
  institution = {COMET},
  year        = {2006},
  file        = {:Hydraulics\\Streamflow Routing - Section Seven_ Muskingum and Lag and K Methods.pdf:PDF},
  timestamp   = {2017-06-09},
  url         = {http://www.meted.ucar.edu/hydro/basic/Routing/print_version/07-muskingum_lagk.htm},
}

@Article{Naeem2015,
  author    = {Naeem, Usman Ali and Habib-ur-Rehman and Hashmi, Hashim Nisar and Shakir, Abdul Sattar and Ghumman, Abdul Razzaq and Shamim, Muhammad Ali},
  title     = {Ranking sensitive calibrating parameters of UBC Watershed Model},
  journal   = {KSCE Journal of Civil Engineering},
  year      = {2015},
  volume    = {19},
  number    = {5},
  pages     = {1538--1547},
  issn      = {1976-3808},
  abstract  = {Almost in all hydrological models, calibrating parameters are tuned to best match the simulated results with the observed. In the present study sensitivity analysis was carried on the fifteen calibrating parameters of University of British Columbia Watershed Model (UBCWM). The study focuses to impart information to the modelers while calibrating UBCWM. To achieve the objectives of the study, UBC Watershed Model was applied on Chitral watershed in Pakistan. UBC Watershed Model is a semi distributed Hydrological model which divides the entire watershed in several elevation bands. The model was calibrated for the year 2006 with the coefficient of efficiency as well as the coefficient of determination equal to 0.94. The numerical values of the calibrating parameters were changed by increasing 20{\%} and then by decreasing 20{\%} of the standard calibrated values one by one. Sensitivity of the model was evaluated by computing the Absolute Sensitivity Index for each parameter. The sensitivity analysis results showed that the P0SREPO as the most sensitive parameter with 3.31525 Absolute Sensitivity Index (ASI) whereas C0IMPA found to be least sensitive giving a value of 0.0452 as Absolute Sensitivity Index (ASI). The logical trends in the results of sensitivity analysis show the robustness of the model.},
  doi       = {10.1007/s12205-015-0515-9},
  file      = {:Hydrology\\Ranking sensitive calibrating parameters of UBC Watershed Model.pdf:PDF},
  timestamp = {2017-06-10},
  url       = {http://dx.doi.org/10.1007/s12205-015-0515-9},
}

@Article{Refsgaard1997,
  author    = {Jens Christian Refsgaard},
  title     = {Parameterization, calibration and validation of distributed hydrologic models},
  journal   = {Journal of Hydrology},
  year      = {1997},
  volume    = {198},
  number    = {1--4},
  pages     = {69--97},
  month     = {nov},
  abstract  = {This paper emphasizes the different requirements for calibration and validation of lumped and distributed models. On the basis of a theoretically founded modelling protocol, the different steps in distributed hydrological modelling are illustrated through a case study based on the MIKE SHE code and the 440 km2 Karup catchment in Denmark. The importance of a rigorous and purposeful parameterisation is emphasized in order to get as few “free” parameters as possible for which assessments through calibration are required. Calibration and validation using a split-sample procedure were carried out for catchment discharge and piezometric heads at seven selected observation wells. The validated model was then used for two further validation tests. Firstly, model simulations were compared with observations from three additional discharge sites and four additional wells located within the catchment. This internal validation showed significantly poorer results compared to the calibration/validation sites. Secondly, the validated model based on a 500 m model grid was used to generate three additional models with 1000 m, 2000 m and 4000 m grids through interpolation of model parameters. The results from the multi-scale validation suggested that a maximum grid size of 1000 m should be used for simulations of discharge and ground-water heads, while the results deteriorated with coarser model grids.},
  file      = {:Hydrology\\Parameterization, calibration and validation of distributed hydrologic models.pdf:PDF},
  timestamp = {2017-06-10},
}

@Article{Senarath2000,
  author    = {Sharika U. S. Senarath and Fred L. Ogden and Charles W. Downer and Hatim O. Sharif},
  title     = {On the calibration and verification of two dimensional, distributed, Hortonian, continuous watershed models},
  journal   = {Water Resources Research},
  year      = {2000},
  volume    = {36},
  number    = {6},
  pages     = {1495--1510},
  month     = {nov},
  abstract  = {Physically based, two-dimensional, distributed parameter Hortonian hydrologic models are sensitive to a number of spatially varied parameters and inputs and are particularly sensitive to the initial soil moisture field. However, soil moisture data are generally unavailable for most catchments. Given an erroneous initial soil moisture field, single-event calibrations are easily achieved using different combinations of model parameters, including physically unrealistic values. Verification of single-event calibrations is very difficult for models of this type because of parameter estimation errors that arise from initial soil moisture field uncertainty. The purpose of this study is to determine if the likelihood of obtaining a verifiable calibration increases when a continuous flow record, consisting of multiple runoff producing events is used for model calibration. The physically based, two-dimensional, distributed, Hortonian hydrologic model CASC2D [Julien et al., 1995] is converted to a continuous formulation that simulates the temporal evolution of soil moisture between rainfall events. Calibration is performed using 6 weeks of record from the 21.3 km 2 Goodwin Creek Experimental Watershed, located in northern Mississippi. Model parameters are assigned based on soil textures, land use/land cover maps, and a combination of both. The sensitivity of the new model formulation to parameter variation is evaluated. Calibration is performed using the shuffled complex evolution method [Duan et al., 1991]. Three different tests are conducted to evaluate model performance based on continuous calibration. Results show that calibration on a continuous basis significantly improves model performance for periods, or subcatchments, not used in calibration and the likelihood of obtaining realistic simulations of spatially varied catchment dynamics. The automated calibration reveals that the parameter assignment methodology used in this study results in overparameterization. Additional research is needed in spatially distributed hydrologic model parameter assignment methodologies for hydrologic forecasting.},
  file      = {:Hydrology\\On the calibration and verification of two dimensional, distributed, Hortonian, continuous watershed models.pdf:PDF},
  timestamp = {2017-06-10},
}

@Manual{UBC1995,
  title        = {UBC Watershed Model Manual},
  organization = {University of British Columbia Mountain Hydrology Group},
  address      = {Department of Civil Engineering CEME 2010 2324 Main Mall Vancouver, B.C., V6T 1Z4},
  edition      = {4.0},
  month        = {feb},
  file         = {:Programs\\UBCHydrologyModelManual.pdf:PDF},
  timestamp    = {2017-06-10},
}

@Article{Micovic1999,
  author    = {Z. Micovic and M.C. Quick},
  title     = {A rainfall and snowmelt runoff modelling approach to flow estimation at ungauged sites in British Columbia},
  journal   = {Journal of Hydrology},
  year      = {1999},
  volume    = {226},
  pages     = {101--120},
  abstract  = {Streamflow was calculated from meteorological data using the UBC Watershed Model for 12 heterogeneous watersheds in
British Columbia. These watersheds varied in drainage area, climate, topography, soil type vegetation and geology, which
indicates that statistical regionalization of streamflow is likely to be unreliable. The model results indicated that an average set
of model parameters could be applied to all the watersheds, provided that representative meteorological data was available and
the impermeable fraction of the watersheds could be determined from independent sources such as natural vegetative cover and
surficial geology. The averaged model parameter set gave Nash–Sutcliffe statistical results only slightly lower than results from
a full calibration. Therefore the method appears to be useful for complete pre-calibration of ungauged watersheds so that flows
can be generated for these ungauged sites. The method has been successfully tested on an independent watershed in British
Columbia and another watershed in the Himalayas.},
  file      = {:Hydrology\\A rainfall and snowmelt runoff modelling approach to flow estimation at ungauged sites in British Columbia.pdf:PDF},
  timestamp = {2017-06-10},
}

@Booklet{IHA2017b,
  title     = {2017 Key Trends in Hydropower},
  year      = {2017},
  file      = {:Hydropower\\2017 Key Trends in Hydropower.pdf:PDF},
  timestamp = {2017-06-11},
}

@Manual{TELEMAC2D2014,
  title     = {TELEMAC-2D Users Manual},
  file      = {:Programs\\telemac-2d_user_manual_en_v7p0.pdf:PDF},
  timestamp = {2017-06-12},
}

@Manual{TELEMAC2D2013,
  title     = {TELEMAC-2D Reference Manual},
  file      = {:Programs\\telemac-2d_reference_manual_en_v6p2.pdf:PDF},
  timestamp = {2017-06-12},
}

@Article{Breinl2015,
  author    = {Korbinian Breinl and Thea Turkington and Markus Stowasser},
  title     = {Simulating daily precipitation and temperature: a weather generation framework for assessing hydrometeorological hazards},
  journal   = {Meteorological Application},
  year      = {2015},
  volume    = {22},
  pages     = {334--347},
  abstract  = {Stochastic weather generators simulate synthetic weather data while maintaining statistical properties of the
observations. A new semi-parametric algorithm for multi-site precipitation has been published recently by Breinl et al.
(2013), who used a univariate Markov process to simulate precipitation occurrence at multiple sites for two small rain gauge
networks. Precipitation amounts were simulated in a two-step process by first resampling observations and then sampling and
reshuffling of parametric precipitation amounts. In the present study, the precipitation model by Breinl et al. (2013, J. Hydrol.
498: 23–35) is implemented in a weather generation framework for daily precipitation and temperature. It is extended to a
considerably larger gauge station network of 19 stations and further improved to reduce the duplication of historical records in
the simulation. Autoregressive-moving-average models (ARMA) are used to simulate mean daily temperature at three sites.
Power transformations reduce the bias of simulated temperature extremes. Precipitation amounts are simulated by means of
hybrid distributions consisting of a Weibull distribution for low precipitation amounts and a generalized Pareto distribution
(GPD) for moderate and extreme precipitation amounts. The proposed weather generator is particularly suitable for assessing
hydrometeorological hazards such as flooding as it reproduces the spatial variability of precipitation very well and can generate
unobserved extremes.},
  file      = {:Hydrology\\Precipitation\\Simulating daily precipitation and temperature- a weather generation framework for assessing hydrometeorological hazards.pdf:PDF},
  keywords  = {multi-site weather generator; Markov chain; bootstrap; ARMA; Modulus transformation; k-means clustering},
  timestamp = {2017-06-12},
}

@Manual{FERC2014,
  title        = {R19 - FERC Engineering Guidelines, Risk-Informed Decision Making, Probabilistic Flood Hazard Analysis},
  organization = {Federal Energy Regulatory Commission},
  edition      = {DRAFT},
  year         = {2014},
  file         = {:Hydropower\\R19 - FERC Engineering Guidelines, Risk-Informed Decision Making, Probabilistic Flood Hazard Analysis.pdf:PDF},
  timestamp    = {2017-06-13},
}

@Article{Clark2016,
  author    = {Clark, Martyn P. and Wilby, Robert L. and Gutmann, Ethan D. and Vano, Julie A. and Gangopadhyay, Subhrendu and Wood, Andrew W. and Fowler, Hayley J. and Prudhomme, Christel and Arnold, Jeffrey R. and Brekke, Levi D.},
  title     = {Characterizing Uncertainty of the Hydrologic Impacts of Climate Change},
  journal   = {Current Climate Change Reports},
  year      = {2016},
  volume    = {2},
  number    = {2},
  pages     = {55--64},
  abstract  = {The high climate sensitivity of hydrologic systems, the importance of those systems to society, and the imprecise nature of future climate projections all motivate interest in characterizing uncertainty in the hydrologic impacts of climate change. We discuss recent research that exposes important sources of uncertainty that are commonly neglected by the water management community, especially, uncertainties associated with internal climate system variability, and hydrologic modeling. We also discuss research exposing several issues with widely used climate downscaling methods. We propose that progress can be made following parallel paths: first, by explicitly characterizing the uncertainties throughout the modeling process (rather than using an ad hoc “ensemble of opportunity”) and second, by reducing uncertainties through developing criteria for excluding poor methods/models, as well as with targeted research to improve modeling capabilities. We argue that such research to reveal, reduce, and represent uncertainties is essential to establish a defensible range of quantitative hydrologic storylines of climate change impacts.},
  file      = {:Climate\\Characterizing Uncertainty of the Hydrologic Impacts of Climate Change.pdf:PDF},
  keywords  = {Climate change Hydrologic impacts Uncertainty},
  timestamp = {2017-06-15},
}

@Article{Mendoza2017,
  author    = {Mendoza, P. A. and Wood, A. W. and Clark, E. and Rothwell, E. and Clark, M. P. and Nijssen, B. and Brekke, L. D. and Arnold, J. R.},
  title     = {An intercomparison of approaches for improving predictability in operational seasonal streamflow forecasting},
  journal   = {Hydrology and Earth System Sciences Discussions},
  year      = {2017},
  volume    = {2017},
  pages     = {1--37},
  doi       = {10.5194/hess-2017-60},
  file      = {:Ensembles\\An intercomparison of approaches for improving predictability in operational seasonal streamflow forecasting.pdf:PDF},
  timestamp = {2017-06-15},
  url       = {http://www.hydrol-earth-syst-sci-discuss.net/hess-2017-60/},
}

@Article{Huang2017,
  author    = {Huang, C. and Newman, A. J. and Clark, M. P. and Wood, A. W. and Zheng, X.},
  title     = {Evaluation of snow data assimilation using the ensemble Kalman filter for seasonal streamflow prediction in the western United States},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2017},
  volume    = {21},
  number    = {1},
  pages     = {635--650},
  abstract  = {In this study, we examine the potential of snow water equivalent data assimilation (DA) using the ensemble Kalman filter (EnKF) to improve seasonal streamflow predictions. There are several goals of this study. First, we aim to examine some empirical aspects of the EnKF, namely the observational uncertainty estimates and the observation transformation operator. Second, we use a newly created ensemble forcing dataset to develop ensemble model states that provide an estimate of model state uncertainty. Third, we examine the impact of varying the observation and model state uncertainty on forecast skill. We use basins from the Pacific Northwest, Rocky Mountains, and California in the western United States with the coupled Snow-17 and Sacramento Soil Moisture Accounting (SAC-SMA) models. We find that most EnKF implementation variations result in improved streamflow prediction, but the methodological choices in the examined components impact predictive performance in a non-uniform way across the basins. Finally, basins with relatively higher calibrated model performance (> 0.80 NSE) without DA generally have lesser improvement with DA, while basins with poorer historical model performance show greater improvements.},
  doi       = {10.5194/hess-21-635-2017},
  file      = {:Hydrology\\Evaluation of snow data assimilation using the Ensemble Kalman Filter for seasonal streamflow prediction in the Western United States.pdf:PDF},
  timestamp = {2017-06-15},
  url       = {http://www.hydrol-earth-syst-sci.net/21/635/2017/},
}

@Article{Reed2004,
  author    = {Seann Reed and Victor Koren and Michael Smith and Ziya Zhang and Fekadu Moreda and Dong-Jun Seo and DMIP Participants},
  title     = {Overall distributed model intercomparison project results},
  journal   = {Journal of Hydrology},
  year      = {2004},
  volume    = {298},
  number    = {1},
  pages     = {27-60},
  month     = {oct},
  abstract  = {This paper summarizes results from the Distributed Model Intercomparison Project (DMIP) study. DMIP simulations from twelve different models are compared with both observed streamflow and lumped model simulations. The lumped model simulations were produced using the same techniques used at National Weather Service River Forecast Centers (NWS-RFCs) for historical calibrations and serve as a useful benchmark for comparison. The differences between uncalibrated and calibrated model performance are also assessed. Overall statistics are used to compare simulated and observed flows during all time steps, flood event statistics are calculated for selected storm events, and improvement statistics are used to measure the gains from distributed models relative to the lumped models and calibrated models relative to uncalibrated models. Although calibration strategies for distributed models are not as well defined as strategies for lumped models, the DMIP results show that some calibration efforts applied to distributed models significantly improve simulation results. Although for the majority of basin-distributed model combinations, the lumped model showed better overall performance than distributed models, some distributed models showed comparable results to lumped models in many basins and clear improvements in one or more basins. Noteworthy improvements in predicting flood peaks were demonstrated in a basin distinguishable from other basins studied in its shape, orientation, and soil characteristics. Greater uncertainties inherent to modeling small basins in general and distinguishable inter-model performance on the smallest basin (65 km2) in the study point to the need for more studies with nested basins of various sizes. This will improve our understanding of the applicability and reliability of distributed models at various scales.},
  file      = {:Hydrology\\Overall distributed model intercomparison project results.pdf:PDF},
  keywords  = {Distributed hydrologic modelingModel intercomparisonRadar precipitationRainfall–runoffHydrologic simulation},
  timestamp = {2017-06-19},
}

@Unpublished{Seo2004,
  author    = {D.-J. Seo and J. Schaake and E. Welles and H. Herr and M. Mullusky and J. Demargne and L. Wu and X. Fan and S. Cong},
  title     = {Ensemble Hydrologic Forecasting},
  note      = {NRC AHPS Science Review National Weather Service Office of Hydrologic Development Hydrology Laboratory},
  month     = {jan},
  year      = {2004},
  timestamp = {2017-06-20},
}

@Article{Barbetta2017,
  author    = {Silvia Barbetta and Gabriele Coccia and Tommaso Moramarco and Luca Brocca and Ezio Todini},
  title     = {The multi temporal/multi-model approach to predictive uncertainty assessment in real-time flood forecasting},
  journal   = {Journal of Hydrology},
  year      = {2017},
  volume    = {Accepted},
  month     = {jun},
  abstract  = {This work extends the multi-temporal approach of the Model Conditional
Processor (MCP-MT) to the multi-model case and to the four Truncated Normal
Distributions (TNDs) approach, demonstrating the improvement on the single-temporal
one. The study is framed in the context of probabilistic Bayesian decision-making that is
appropriate to take rational decisions on uncertain future outcomes. As opposed to the
direct use of deterministic forecasts, the probabilistic forecast identifies a predictive
probability density function that represents a fundamental knowledge on future
occurrences. The added value of MCP-MT is the identification of the probability that a
critical situation will happen within the forecast lead-time and when, more likely, it will
occur.MCP-MT is thoroughly tested for both single-model and multi-model configurations at a
gauged site on the Tiber River, central Italy. The stages forecasted by two operative
deterministic models, STAFOM-RCM and MISDc, are considered for the study. The
dataset used for the analysis consists of hourly data from 34 flood events selected on a time
series of six years.
MCP-MT improves over the original models’ forecasts: the peak overestimation and the
rising limb delayed forecast, characterizing MISDc and STAFOM-RCM respectively, are
significantly mitigated, with a reduced mean error on peak stage from 45 to 5 cm and an
increased coefficient of persistence from 0.53 up to 0.75.
The results show that MCP-MT outperforms the single-temporal approach and is
potentially useful for supporting decision-making because the exceedance probability of
hydrometric thresholds within a forecast horizon and the most probable flooding time can
be estimated.},
  doi       = {http://dx.doi.org/10.1016/j.jhydrol.2017.06.030},
  file      = {:Ensembles\\The multi temporal-multi-model approach to predictive uncertainty assessment in real-time flood forecasting.pdf:PDF},
  keywords  = {predictive uncertainty; multi-model and multi-temporal approach; flooding probability; hydrometric thresholds; early-warning},
  timestamp = {2017-06-23},
}

@Article{Barbetta2016,
  author    = {Silvia Barbetta and Gabriele Coccia and Tommaso Moramarco and Ezio Todini},
  title     = {Case Study A Real-Time Flood Forecasting System with Predictive Uncertainty Estimation for the Godavari River, India},
  journal   = {Water},
  year      = {2016},
  volume    = {8},
  number    = {10},
  pages     = {463},
  abstract  = {This work presents the application of the multi-temporal approach of the Model Conditional Processor (MCP-MT) for predictive uncertainty (PU) estimation in the Godavari River basin, India. MCP-MT is developed for making probabilistic Bayesian decision. It is the most appropriate approach if the uncertainty of future outcomes is to be considered. It yields the best predictive density of future events and allows determining the probability that a critical warning threshold may be exceeded within a given forecast time. In Bayesian decision-making, the predictive density represents the best available knowledge on a future event to address a rational decision-making process. MCP-MT has already been tested for case studies selected in Italian river basins, showing evidence of improvement of the effectiveness of operative real-time flood forecasting systems. The application of MCP-MT for two river reaches selected in the Godavari River basin, India, is here presented and discussed by considering the stage forecasts provided by a deterministic model, STAFOM-RCM, and hourly dataset based on seven monsoon seasons in the period 2001–2010. The results show that the PU estimate is useful for finding the exceedance probability for a given hydrometric threshold as function of the forecast time up to 24 h, demonstrating the potential usefulness for supporting real-time decision-making. Moreover, the expected value provided by MCP-MT yields better results than the deterministic model predictions, with higher Nash–Sutcliffe coefficients and lower error on stage forecasts, both in term of mean error and standard deviation and root mean square error.},
  file      = {:Ensembles\\Case Study A Real-Time Flood Forecasting System with Predictive Uncertainty Estimation for the Godavari River, India.pdf:PDF},
  timestamp = {2017-06-24},
}

@Article{Coccia2011,
  author    = {G. Coccia and E. Todini},
  title     = {Recent developments in predictive uncertainty assessment based on the model conditional processor approach},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2011},
  volume    = {15},
  pages     = {3253--3274},
  abstract  = {The work aims at discussing the role of predictive
uncertainty in flood forecasting and flood emergency management,
its relevance to improve the decision making process
and the techniques to be used for its assessment.
Real time flood forecasting requires taking into account
predictive uncertainty for a number of reasons. Deterministic
hydrological/hydraulic forecasts give useful information
about real future events, but their predictions, as usually done
in practice, cannot be taken and used as real future occurrences
but rather used as pseudo-measurements of future occurrences
in order to reduce the uncertainty of decision makers.
Predictive Uncertainty (PU) is in fact defined as the
probability of occurrence of a future value of a predictand
(such as water level, discharge or water volume) conditional
upon prior observations and knowledge as well as on all the
information we can obtain on that specific future value from
model forecasts. When dealing with commensurable quantities,
as in the case of floods, PU must be quantified in terms
of a probability distribution function which will be used by
the emergency managers in their decision process in order to
improve the quality and reliability of their decisions.
After introducing the concept of PU, the presently available
processors are introduced and discussed in terms of their
benefits and limitations. In this work the Model Conditional
Processor (MCP) has been extended to the possibility of using
two joint Truncated Normal Distributions (TNDs), in
order to improve adaptation to low and high flows.
The paper concludes by showing the results of the application
of the MCP on two case studies, the Po river in Italy
and the Baron Fork river, OK, USA. In the Po river case the
data provided by the Civil Protection of the Emilia Romagna
region have been used to implement an operational example,
where the predicted variable is the observed water level.
In the Baron Fork River example, the data set provided by
the NOAA’s National Weather Service, within the DMIP 2
Project, allowed two physically based models, the TOPKAPI
model and TETIS model, to be calibrated and a data driven
model to be implemented using the Artificial Neural Network.
The three model forecasts have been combined with
the aim of reducing the PU and improving the probabilistic
forecast taking advantage of the different capabilities of each
model approach.},
  comment   = {In the case of flood forecasting, predictive uncertainty can
be defined as the uncertainty that a decision maker has on
the future evolution of a predictand that he uses to make
a specific decision.},
  doi       = {10.5194/hess-15-3253-2011},
  file      = {:Ensembles\\Recent developments in predictive uncertainty assessment based on the model conditional processor approach.pdf:PDF},
  timestamp = {2017-06-25},
  url       = {http://www.hydrol-earth-syst-sci.net/15/3253/2011/},
}

@Article{Madadgar2014,
  author    = {Madadgar, Shahrbanou and Moradkhani, Hamid and Garen, David},
  title     = {Towards improved post-processing of hydrologic forecast ensembles},
  journal   = {Hydrological Processes},
  year      = {2014},
  volume    = {28},
  number    = {1},
  pages     = {104--122},
  issn      = {1099-1085},
  abstract  = {Forecast ensembles of hydrological and hydrometeorologial variables are prone to various uncertainties arising from climatology, model structure and parameters, and initial conditions at the forecast date. Post-processing methods are usually applied to adjust the mean and variance of the ensemble without any knowledge about the uncertainty sources. This study initially addresses the drawbacks of a commonly used statistical technique, quantile mapping (QM), in bias correction of hydrologic forecasts. Then, an auxiliary variable, the failure index (γ), is proposed to estimate the ineffectiveness of the post-processing method based on the agreement of adjusted forecasts with corresponding observations during an analysis period prior to the forecast date. An alternative post-processor based on copula functions is then introduced such that marginal distributions of observations and model simulations are combined to create a multivariate joint distribution. A set of 2500 hypothetical forecast ensembles with parametric marginal distributions of simulated and observed variables are post-processed with both QM and the proposed multivariate post-processor. Deterministic forecast skills show that the proposed copula-based post-processing is more effective than the QM method in improving the forecasts. It is found that the performance of QM is highly correlated with the failure index, unlike the multivariate post-processor. In probabilistic metrics, the proposed multivariate post-processor generally outperforms QM. Further evaluation of techniques is conducted for river flow forecast of Sprague River basin in southern Oregon. Results show that the multivariate post-processor performs better than the QM technique; it reduces the ensemble spread and is a more reliable approach for improving the forecast. Copyright © 2012 John Wiley & Sons, Ltd.},
  doi       = {10.1002/hyp.9562},
  file      = {:Ensembles\\Towards improved post-processing of hydrologic forecast ensembles.pdf:PDF},
  keywords  = {ensemble streamflow prediction, copula, quantile mapping, bias correction},
  timestamp = {2017-07-02},
  url       = {http://dx.doi.org/10.1002/hyp.9562},
}

@Book{Gebremichael2010,
  title     = {Satellite Rainfall Applications for Surface Hydrology},
  publisher = {Springer},
  year      = {2010},
  editor    = {Mekonnen Gebremichael and Faisal Hossain},
  abstract  = {Part I Evolution of High Resolution Precipitation Products
The TRMM Multi-Satellite Precipitation Analysis (TMPA) . . . . . . . 3
George J. Huffman, Robert F. Adler, David T. Bolvin, and
Eric J. Nelkin
CMORPH: A “Morphing” Approach for High Resolution
Precipitation Product Generation . . . . . . . . . . . . . . . . . . . . . 23
Robert J. Joyce, Pingping Xie, Yelena Yarosh, John E. Janowiak
and Phillip A. Arkin
The Self-Calibrating Multivariate Precipitation Retrieval
(SCaMPR) for High-Resolution, Low-Latency Satellite-Based
Rainfall Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
Robert J. Kuligowski
Extreme Precipitation Estimation Using Satellite-Based
PERSIANN-CCS Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 49
Kuo-Lin Hsu, Ali Behrangi, Bisher Imam, and Soroosh Sorooshian
The Combined Passive Microwave-Infrared (PMIR) Algorithm . . . . . 69
Chris Kidd and Catherine Muller
The NRL-Blend High Resolution Precipitation Product and its
Application to Land Surface Hydrology . . . . . . . . . . . . . . . . . . 85
Joseph T. Turk, Georgy V. Mostovoy, and Valentine Anantharaj
Kalman Filtering Applications for Global Satellite Mapping of
Precipitation (GSMaP) . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
Tomoo Ushio and Misako Kachi
Part II Evaluation of High Resolution Precipitation Products
Neighborhood Verification of High Resolution Precipitation Products . 127
Elizabeth E. Ebert
ixx Contents
A Practical Guide to a Space-Time Stochastic Error Model for
Simulation of High Resolution Satellite Rainfall Data . . . . . . . . . . 145
Faisal Hossain, Ling Tang, Emmanouil N. Anagnostou,
and Efthymios I. Nikolopoulos
Regional Evaluation Through Independent Precipitation
Measurements: USA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
Mathew R.P. Sapiano, John E. Janowiak, Wei Shi,
R. Wayne Higgins, and Viviane B.S. Silva
Comparison of CMORPH and TRMM-3B42 over Mountainous
Regions of Africa and South America . . . . . . . . . . . . . . . . . . . 193
Tufa Dinku, Stephen J. Connor, and Pietro Ceccato
Evaluation Through Independent Measurements: Complex
Terrain and Humid Tropical Region in Ethiopia . . . . . . . . . . . . . 205
Menberu M. Bitew and Mekonnen Gebremichael
Error Propagation of Satellite-Rainfall in Flood Prediction
Applications over Complex Terrain: A Case Study in
Northeastern Italy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
Efthymios I. Nikolopoulos, Emmanouil N. Anagnostou, and
Faisal Hossain
Probabilistic Assessment of the Satellite Rainfall Retrieval
Error Translation to Hydrologic Response . . . . . . . . . . . . . . . . 229
Hamid Moradkhani and Tadesse T. Meskele
Part III Real Time Operations for Decision Support Systems
Applications of TRMM-Based Multi-Satellite Precipitation
Estimation for Global Runoff Prediction: Prototyping a Global
Flood Modeling System . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
Yang Hong, Robert F. Adler, George J. Huffman and Harold Pierce
Real-Time Hydrology Operations at USDA for Monitoring
Global Soil Moisture and Auditing National Crop Yield Estimates . . . 267
Curt A. Reynolds
Real-Time Decision Support Systems: The Famine Early
Warning System Network . . . . . . . . . . . . . . . . . . . . . . . . . . 295
Chris Funk and James P. Verdin},
  file      = {:Hydrology\\Precipitation\\Satellite Rainfall Applications for Surface Hydrology.pdf:PDF},
  timestamp = {2017-07-02},
}

@Book{Sorooshian2009,
  title     = {Hydrological Modelling and the Water Cycle: Coupling the Atmosphere and Hydrological Models},
  publisher = {Springer},
  year      = {2009},
  editor    = {Soroosh Sorooshian and Kuo-Lin Hsu and Erika Coppola and Barbara Tomassetti and Marco Verdecchia and Guido Visconti},
  volume    = {63},
  series    = {Water Science and Technology},
  edition   = {2},
  isbn      = {978-3-540-77843-1},
  abstract  = {General Review of Rainfall-Runoff Modeling: Model Calibration, Data
Assimilation, and Uncertainty Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
Hamid Moradkhani and Soroosh Sorooshian
Part 1 Measurement of Hydrologic Variables
Satellite-Based Precipitation Measurement Using PERSIANN System . . . . 27
Kuo-Lin Hsu and Soroosh Sorooshian
Satellite Clouds and Precipitation Observations
for Meteorology and Climate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
Vincenzo Levizzani
Advanced Techniques for Polarimetric Radar Estimation of Rainfall . . . . . 69
Gianfranco Vulpiani and Frank S. Marzano
Measurements of Hydrological Variables from Satellite: Application
to Mediterranean Regions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
Francesca Sini, Giorgio Boni and Dara Entekhabi
Part 2 Data Merging and Dowscaling
Geostatistical Tools for Validation of Satellite and NWP Model
Rainfall Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
David I.F. Grimes
vvi Contents
An Ensemble Approach to Uncertainty Estimation for Satellite-Based
Rainfall Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
David I.F. Grimes
Part 3 Hydrologic Modelling: Short and Long-Time Scale
Cetemps Hydrological Model (CHyM), a Distributed Grid-Based Model
Assimilating Different Rainfall Data Sources . . . . . . . . . . . . . . . . . . . . . . . . . . 165
Marco Verdecchia, Erika Coppola, Barbara Tomassetti and Guido Visconti
Rainfall Thresholds for Flood Warning Systems: A Bayesian
Decision Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
M.L.V. Martina, E. Todini and A. Libralon
Watershed Hydrological Modeling: Toward Physically Meaningful
Processes Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
M.L.V. Martina and E. Todini
Simulating Climate Impacts on Water Resources: Experience
from the Okavango River, Southern Africa . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243
Martin C. Todd, Lotta Andersson, Denis A. Hughes, Dominic Kniveton,
Russell Layberry, Michael Murray-Hudson, Hubert H.G. Savenije,
Julie Wilk and Piotr Wolski
Colour Plate Section . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267},
  file      = {:Hydrology\\Hydrological Modelling and the Water Cycle- Coupling the Atmosphere and Hydrological Models.pdf:PDF},
  timestamp = {2017-07-02},
}

@Article{Grantz2005,
  author    = {Grantz, Katrina and Rajagopalan, Balaji and Clark, Martyn and Zagona, Edith},
  title     = {A technique for incorporating large-scale climate information in basin-scale ensemble streamflow forecasts},
  journal   = {Water Resources Research},
  year      = {2005},
  volume    = {41},
  number    = {10},
  pages     = {n/a--n/a},
  issn      = {1944-7973},
  note      = {W10410},
  abstract  = {Water managers throughout the western United States depend on seasonal forecasts to assist with operations and planning. In this study, we develop a seasonal forecasting model to aid water resources decision making in the Truckee-Carson River System. We analyze large-scale climate information that has a direct impact on our basin of interest to develop predictors to spring runoff. The predictors are snow water equivalent (SWE) and 500 mbar geopotential height and sea surface temperature (SST) “indices” developed in this study. We use local regression methods to provide ensemble (probabilistic) forecasts. Results show that the incorporation of climate information, particularly the 500 mbar geopotential height index, improves the skills of forecasts at longer lead times when compared with forecasts based on snowpack information alone. The technique is general and could be used to incorporate large-scale climate information into ensemble streamflow forecasts for other river basins.},
  doi       = {10.1029/2004WR003467},
  file      = {:Ensembles\\A technique for incorporating large-scale climate information in basin-scale ensemble streamflow forecasts.pdf:PDF},
  keywords  = {Climate variability, Estimation and forecasting, Streamflow, Hydroclimatology, Water management, Carson, climate, forecast, nonlinear, nonparametric, Truckee},
  timestamp = {2017-07-02},
  url       = {http://dx.doi.org/10.1029/2004WR003467},
}

@Article{Weigel2007,
  author    = {Andreas P. Weigel and Mark A. Liniger and Christof Appenzeller},
  title     = {Generalization of the Discrete Brier and Ranked Probability Skill Scores for Weighted Multimodel Ensemble Forecasts},
  journal   = {Monthly Weather Review},
  year      = {2007},
  volume    = {135},
  number    = {7},
  pages     = {2778-2785},
  abstract  = {Abstract This note describes how the widely used Brier and ranked probability skill scores (BSS and RPSS, respectively) can be correctly applied to quantify the potential skill of probabilistic multimodel ensemble forecasts. It builds upon the study of Weigel et al. where a revised RPSS, the so-called discrete ranked probability skill score (RPSSD), was derived, circumventing the known negative bias of the RPSS for small ensemble sizes. Since the BSS is a special case of the RPSS, a debiased discrete Brier skill score (BSSD) could be formulated in the same way. Here, the approach of Weigel et al., which so far was only applicable to single model ensembles, is generalized to weighted multimodel ensemble forecasts. By introducing an “effective ensemble size” characterizing the multimodel, the new generalized RPSSD can be expressed such that its structure becomes equivalent to the single model case. This is of practical importance for multimodel assessment studies, where the consequences of varying effective ensemble size need to be clearly distinguished from the true benefits of multimodel combination. The performance of the new generalized RPSSD formulation is illustrated in examples of weighted multimodel ensemble forecasts, both in a synthetic random forecasting context, and with real seasonal forecasts of operational models. A central conclusion of this study is that, for small ensemble sizes, multimodel assessment studies should not only be carried out on the basis of the classical RPSS, since true changes in predictability may be hidden by bias effects—a deficiency that can be overcome with the new generalized RPSSD.},
  comment   = {Debiased RPSS (i.e. RPSSD which is described in
Appendix A of Najafi2012) proposed by Weigel et al. (2007)},
  doi       = {10.1175/MWR3428.1},
  eprint    = {https://doi.org/10.1175/MWR3428.1},
  timestamp = {2017-07-02},
  url       = { 
        https://doi.org/10.1175/MWR3428.1
    
},
}

@Article{Li2009,
  author    = {Li, Haibin and Luo, Lifeng and Wood, Eric F. and Schaake, John},
  title     = {The role of initial conditions and forcing uncertainties in seasonal hydrologic forecasting},
  journal   = {Journal of Geophysical Research: Atmospheres},
  year      = {2009},
  volume    = {114},
  number    = {D4},
  pages     = {n/a--n/a},
  issn      = {2156-2202},
  note      = {D04114},
  abstract  = {A series of hydrologic forecasts with lead times up to 6 months are conducted to investigate the relative contributions of atmospheric forcing and hydrologic initial conditions (IC) to the overall errors in hydrologic forecasting during cold and warm seasons. These experiments are known as the ensemble streamflow prediction (ESP) and the reverse-ESP (R-ESP). Analysis of these hindcasts suggests that IC uncertainties outweigh forcing uncertainties thus dominating forecast errors in a short lead time up to about 1 month; at longer lead times, forcing uncertainties become a more important contributor. Further investigation shows that forecast errors at short lead times due to uncertain ICs are mainly determined by the prescribed IC variability, while the evolution of forecast errors due to imperfect atmospheric forcings mainly corresponds to the interannual variability of precipitation. With respect to difference in forecasts initialized in winter and summer times, ICs tend to have longer impacts on warm season forecasts than on cold season ones, due mainly to drier initial moisture state in the summer time. As far as the basin size is concerned, we find that the larger the basin, the stronger the impacts from ICs at short lead times. Small basins are more sensitive to forcing fields. Regardless of basin size, forcing uncertainties dominate relative forecast errors for long lead times. In order to see whether statistically downscaled forcing fields from dynamic climate models are more skillful than traditional ESP, we conducted additional ESP-type experiments using the statistically downscaled climate forecast system (CFS) fields to drive the hydrological model. In comparison to traditional ESP, the IC errors show a larger impact on the forecasts when forced by the CFS fields, which suggests that the latter contains more skill than the traditional ESP approach.},
  doi       = {10.1029/2008JD010969},
  file      = {:Ensembles\\The role of initial conditions and forcing uncertainties in seasonal hydrologic forecasting.pdf:PDF},
  keywords  = {Uncertainty assessment, Estimation and forecasting, Monitoring networks, forecast uncertainty, hydrologic forecasting, ESP},
  timestamp = {2017-07-03},
  url       = {http://dx.doi.org/10.1029/2008JD010969},
}

@Article{Clark2004a,
  author    = {Martyn P. Clark and Lauren E. Hay},
  title     = {Use of Medium-Range Numerical Weather Prediction Model Output to Produce Forecasts of Streamflow},
  journal   = {Journal of Hydrometeorology},
  year      = {2004},
  volume    = {5},
  number    = {1},
  pages     = {15-32},
  abstract  = { Abstract This paper examines an archive containing over 40 years of 8-day atmospheric forecasts over the contiguous United States from the NCEP reanalysis project to assess the possibilities for using medium-range numerical weather prediction model output for predictions of streamflow. This analysis shows the biases in the NCEP forecasts to be quite extreme. In many regions, systematic precipitation biases exceed 100\% of the mean, with temperature biases exceeding 3°C. In some locations, biases are even higher. The accuracy of NCEP precipitation and 2-m maximum temperature forecasts is computed by interpolating the NCEP model output for each forecast day to the location of each station in the NWS cooperative network and computing the correlation with station observations. Results show that the accuracy of the NCEP forecasts is rather low in many areas of the country. Most apparent is the generally low skill in precipitation forecasts (particularly in July) and low skill in temperature forecasts in the western United States, the eastern seaboard, and the southern tier of states. These results outline a clear need for additional processing of the NCEP Medium-Range Forecast Model (MRF) output before it is used for hydrologic predictions. Techniques of model output statistics (MOS) are used in this paper to downscale the NCEP forecasts to station locations. Forecasted atmospheric variables (e.g., total column precipitable water, 2-m air temperature) are used as predictors in a forward screening multiple linear regression model to improve forecasts of precipitation and temperature for stations in the National Weather Service cooperative network. This procedure effectively removes all systematic biases in the raw NCEP precipitation and temperature forecasts. MOS guidance also results in substantial improvements in the accuracy of maximum and minimum temperature forecasts throughout the country. For precipitation, forecast improvements were less impressive. MOS guidance increases the accuracy of precipitation forecasts over the northeastern United States, but overall, the accuracy of MOS-based precipitation forecasts is slightly lower than the raw NCEP forecasts. Four basins in the United States were chosen as case studies to evaluate the value of MRF output for predictions of streamflow. Streamflow forecasts using MRF output were generated for one rainfall-dominated basin (Alapaha River at Statenville, Georgia) and three snowmelt-dominated basins (Animas River at Durango, Colorado; East Fork of the Carson River near Gardnerville, Nevada; and Cle Elum River near Roslyn, Washington). Hydrologic model output forced with measured-station data were used as “truth” to focus attention on the hydrologic effects of errors in the MRF forecasts. Eight-day streamflow forecasts produced using the MOS-corrected MRF output as input (MOS) were compared with those produced using the climatic Ensemble Streamflow Prediction (ESP) technique. MOS-based streamflow forecasts showed increased skill in the snowmelt-dominated river basins, where daily variations in streamflow are strongly forced by temperature. In contrast, the skill of MOS forecasts in the rainfall-dominated basin (the Alapaha River) were equivalent to the skill of the ESP forecasts. Further improvements in streamflow forecasts require more accurate local-scale forecasts of precipitation and temperature, more accurate specification of basin initial conditions, and more accurate model simulations of streamflow. },
  doi       = {10.1175/1525-7541(2004)005<0015:UOMNWP>2.0.CO;2},
  eprint    = {https://doi.org/10.1175/1525-7541(2004)005<0015:UOMNWP>2.0.CO;2},
  file      = {:Ensembles\\Use of medium-range numerical weather prediction model output to produce forecasts of streamflow.pdf:PDF},
  timestamp = {2017-07-03},
  url       = { 
        https://doi.org/10.1175/1525-7541(2004)005<0015:UOMNWP>2.0.CO;2
    
},
}

@Article{Schellekens2017,
  author    = {Schellekens, J. and Dutra, E. and Mart\'{\i}nez-de la Torre, A. and Balsamo, G. and van Dijk, A. and Sperna Weiland, F. and Minvielle, M. and Calvet, J.-C. and Decharme, B. and Eisner, S. and Fink, G. and Fl\"orke, M. and Pe{\ss}enteiner, S. and van Beek, R. and Polcher, J. and Beck, H. and Orth, R. and Calton, B. and Burke, S. and Dorigo, W. and Weedon, G. P.},
  title     = {A global water resources ensemble of hydrological models: the eartH2Observe Tier-1 dataset},
  journal   = {Earth System Science Data},
  year      = {2017},
  volume    = {9},
  number    = {2},
  pages     = {389--413},
  abstract  = {The dataset presented here consists of an ensemble of 10 global hydrological and land surface models for the period 1979–2012 using a reanalysis-based meteorological forcing dataset (0.5° resolution). The current dataset serves as a state of the art in current global hydrological modelling and as a benchmark for further improvements in the coming years. A signal-to-noise ratio analysis revealed low inter-model agreement over (i) snow-dominated regions and (ii) tropical rainforest and monsoon areas. The large uncertainty of precipitation in the tropics is not reflected in the ensemble runoff. Verification of the results against benchmark datasets for evapotranspiration, snow cover, snow water equivalent, soil moisture anomaly and total water storage anomaly using the tools from The International Land Model Benchmarking Project (ILAMB) showed overall useful model performance, while the ensemble mean generally outperformed the single model estimates. The results also show that there is currently no single best model for all variables and that model performance is spatially variable. In our unconstrained model runs the ensemble mean of total runoff into the ocean was 46 268 km3 yr−1 (334 kg m−2 yr−1), while the ensemble mean of total evaporation was 537 kg m−2 yr−1. All data are made available openly through a Water Cycle Integrator portal (WCI, wci.earth2observe.eu), and via a direct http and ftp download. The portal follows the protocols of the open geospatial consortium such as OPeNDAP, WCS and WMS.},
  doi       = {10.5194/essd-9-389-2017},
  file      = {:Ensembles\\A global water resources ensemble of hydrological models- the eartH2Observe Tier-1 dataset.pdf:PDF;:Statistics\\Approximate Bayesian Inference with the Weighted Likelihood Bootstrap.pdf:PDF},
  timestamp = {2017-07-10},
  url       = {https://www.earth-syst-sci-data.net/9/389/2017/},
}

@TechReport{Ray2015a,
  author      = {Patrick A. Ray and Casey M. Brown},
  title       = {Confronting Climate Uncertainty in Water Resources Planning and Project Design: The Decision Tree Framework},
  institution = {World Bank},
  year        = {2015},
  abstract    = {No methodology has yet been generally accepted for assessing the significance
of climate risks relative to all other risks to water resources projects. The need
for such a process has recently been elevated in the World Bank. For example,
as of December 2013, all International Development Association (IDA) Country Partnership Frameworks must include climate- and disaster-risk considerations in the analysis of the country’s development priorities, and, when
agreed upon with the country, such considerations must be incorporated into
the content of the development programs.
The goal of this book is to outline a pragmatic process for risk assessment of water resources projects that can serve as a decision support tool
to assist project planning under uncertainty and that would be useful for
the World Bank as well as for other practitioners. The approach adopted
here is a robustness-based, bottom-up alternative to previous top-down
approaches to climate risk assessment, the quality of which has been contingent on the accuracy of future climate projections derived from general
circulation models (GCMs).
Though considerable investment has been made in climate modeling
and the downscaling of GCMs with the aim of benefiting decision makers,
a recent study by the World Bank’s Independent Evaluation Group (IEG)
found that “climate models have been more useful for setting context than
for informing investment and policy choices” (IEG 2012, 61) and “they often have relatively low value added for many of the applications described”
(IEG 2012, 69). The lack of success in the use of climate projections to inform decisions is not due to lack of eﬀort in translating model outputs to
be relevant to decision makers. Instead, two fundamental and unavoidable
issues limit the utility of these approaches.
The first issue could be classified as a risk assessment problem. The uncertainty associated with future climate is largely irreducible in the temporal
and spatial scales that are relevant to water resources projects. As a result,
climate science–led eﬀorts do not typically reduce the uncertainty of future climate and, in fact, are unlikely to describe the limits of the range of
possible climate changes. Perhaps most important, GCMs have the least skill
in generating the variables that are most important for water resources projects, such as local hydrologic extremes like floods and drought. Often, the
results of a climate change analysis present a wide range of possible future
mean climates without providing any insight into climate extremes, and give
the sense that they only show the tip of the iceberg for climate uncertainty.
As a result, the project planner gains little insight into the potential impact of
climate change on the project.
The second issue relates to risk management. If climate-related risks
are quantified in the process of climate change risk assessment, it remains unclear in most cases whether the eﬀects of changes in climate on
a certain water resources project are significant relative to the impacts
of changes in other nonclimate factors (such as demographic, technological, land use, and economic changes). Project planners are therefore
ill-equipped to incorporate uncertain climate information into a broader
(all-uncertainty) assessment of a project’s probability of success, and
thus to make intelligent modifications to the project design to reduce its
vulnerabilities to failure. And if the project planner succeeds in characterizing the relative importance of various risks and system vulnerabilities, the choice remains as to how best to manage those risks to improve
system robustness and flexibility. Though a number of analytical tools
have been developed, engagement with the tools can be complex and
expensive.
In the typical engagement with science, the scientific analysis reduces
uncertainty and identifies a likely future, at which point the planner can select the best options for that future. However, given that climate science is
not in a position to present a likely future of limited and reasonable range, a
diﬀerent approach to project assessment and decision making is needed.
This book puts forth a decision support tool in the form of a “decision tree”
to meet this need (see figure ES.1).
The decision tree provides guidance on the application of proven techniques
for climate change risk assessment and advanced tools for risk management.
Decision scaling, upon which the decision tree’s general structure is based, is a
bottom-up, robustness-based approach to water system planning that uses a
stress test for the identification of system vulnerabilities and simple, direct
techniques for the iterative reduction of system vulnerabilities through targeted design modifications. Decision scaling features prominently in the riskassessment aspects of the decision tree because it is efcient and scientifically},
  file        = {:WaterResources\\Confronting Climate Uncertainty in Water Resources Planning and Project Design - The Decision Tree Framework.pdf:PDF},
  timestamp   = {2017-07-19},
}

@Article{Heck2009,
  author    = {Heck, Petra and Klabbers, Martijn and van Eekelen, Marko},
  title     = {A software product certification model},
  journal   = {Software Quality Journal},
  year      = {2009},
  volume    = {18},
  number    = {1},
  pages     = {37},
  month     = {Jun},
  issn      = {1573-1367},
  note      = {Laboratory for Quality Software (LaQuSo)},
  abstract  = {Certification of software artifacts offers organizations more certainty and confidence about software. Certification of software helps software sales, acquisition, and can be used to certify legislative compliance or to achieve acceptable deliverables in outsourcing. In this article, we present a software product certification model. This model has evolved from a maturity model for product quality to a more general model with which the conformance of software product artifacts to certain properties can be assessed. Such a conformance assessment we call a `software product certificate'. The practical application of the model is demonstrated in concrete software certificates for two software product areas that are on different ends of the software product spectrum (ranging from a requirements definition to an executable). For each certificate, a concrete case study has been performed. We evaluate the use of the model for these certificates. It will be shown that the model can be used satisfactorily for quite different kinds of certificates.},
  day       = {27},
  doi       = {10.1007/s11219-009-9080-0},
  file      = {:Programs\\A software product certification model.pdf:PDF},
  timestamp = {2017-07-23},
  url       = {https://doi.org/10.1007/s11219-009-9080-0},
}

@Article{Fowler2016,
  author    = {K.R. Fowler and E.W. Jenkins and M. Parno and J.C. Chrispell and A.I. Colon and R.T. Hanson},
  title     = {Development and Use of Mathematical Models and Software Frameworks for Integrated Analysis of Agricultural Systems and Associated Water Use Impacts},
  journal   = {AIMS Agriculture and Food},
  year      = {2016},
  volume    = {1},
  number    = {2},
  pages     = {208--226},
  abstract  = {The development of appropriate water management strategies requires, in part, a methodology
for quantifying and evaluating the impact of water policy decisions on regional stakeholders. In
this work, we describe the framework we are developing to enhance the body of resources available
to policy makers, farmers, and other community members in their efforts to understand, quantify, and
assess the often competing objectives water consumers have with respect to usage. The foundation for
the framework is the construction of a simulation-based optimization software tool using two existing
software packages. In particular, we couple a robust optimization software suite (DAKOTA) with
the USGS MF-OWHM water management simulation tool to provide a flexible software environment
that will enable the evaluation of one or multiple (possibly competing) user-defined (or stakeholder)
objectives. We introduce the individual software components and outline the communication strategy
we defined for the coupled development. We present numerical results for case studies related to crop
portfolio management with several defined objectives. The objectives are not optimally satisfied for
any single user class, demonstrating the capability of the software tool to aid in the evaluation of a
variety of competing interests.},
  file      = {:WaterResources\\Development and Use of Mathematical Models and Software Frameworks for Integrated Analysis of Agricultural Systems and Associated Water Use Impacts.pdf:PDF},
  keywords  = {multi-objective optimization; water management; crop planning; code coupling},
  timestamp = {2017-07-23},
}

@Article{Hanson2014a,
  author    = {R.T. Hanson and B. Lockwood and Wolfgang Schmid},
  title     = {Analysis of projected water availability with current basin management plan, Pajaro Valley, California},
  journal   = {Journal of Hydrology},
  year      = {2014},
  volume    = {519},
  pages     = {131--147},
  abstract  = {The projection and analysis of the Pajaro Valley Hydrologic Model (PVHM) 34 years into the future using
MODFLOW with the Farm Process (MF-FMP) facilitates assessment of potential future water availability.
The projection is facilitated by the integrated hydrologic model, MF-FMP that fully couples the simulation
of the use and movement of water from precipitation, streamflow, runoff, groundwater flow, and consumption by natural and agricultural vegetation throughout the hydrologic system at all times. MFFMP allows for more complete analysis of conjunctive-use water-resource systems than previously possible with MODFLOW by combining relevant aspects of the landscape with the groundwater and surfacewater components. This analysis is accomplished using distributed cell-by-cell supply-constrained and
demand-driven components across the landscape within ‘‘water-balance subregions’’ (WBS) comprised
of one or more model cells that can represent a single farm, a group of farms, watersheds, or other hydrologic or geopolitical entities. Analysis of conjunctive use would be difficult without embedding the fully
coupled supply-and-demand into a fully coupled simulation, and are difficult to estimate a priori.
The analysis of projected supply and demand for the Pajaro Valley indicate that the current water supply facilities constructed to provide alternative local sources of supplemental water to replace coastal
groundwater pumpage, but may not completely eliminate additional overdraft. The simulation of the
coastal distribution system (CDS) replicates: 20 miles of conveyance pipeline, managed aquifer recharge
and recovery (MARR) system that captures local runoff, and recycled-water treatment facility (RWF) from
urban wastewater, along with the use of other blend water supplies, provide partial relief and substitution for coastal pumpage (aka in-lieu recharge). The effects of these Basin Management Plan (BMP) projects were analyzed subject to historical climate variations and assumptions of 2009 urban water demand
and land use. Water supplied directly from precipitation, and indirectly from reuse, captured local runoff,
and groundwater is necessary but inadequate to satisfy agricultural demand without coastal and regional
storage depletion that facilitates seawater intrusion. These facilities reduce potential seawater intrusion
by about 45% with groundwater levels in the four regions served by the CDS projected to recover to levels
a few feet above sea level. The projected recoveries are not high enough to prevent additional seawater
intrusion during dry-year periods or in the deeper aquifers where pumpage is greater. While these facilities could reduce coastal pumpage by about 55% of the historical 2000–2009 pumpage for these regions,
and some of the water is delivered in excess of demand, other coastal regions continue to create demands
on coastal pumpage that will need to be replaced to reduce seawater intrusion. In addition, inland urban
and agricultural demands continue to sustain water levels below sea level causing regional landward gradients that also drive seawater intrusion. Seawater intrusion is reduced by about 45% but it supplies
about 55% of the recovery of groundwater levels in the coastal regions served by the CDS. If economically
feasible, water from summer agricultural runoff and tile-drain returnflows could be another potential
local source of water that, if captured and reused, could offset the imbalance between supply and demand
as well as reducing discharge of agricultural runoff into the National Marine Sanctuary of Monterey Bay. A
BMP update (2012) identifies projects and programs that will fund a conservation program and will provide additional, alternative water sources to reduce or replace coastal and inland pumpage, and to replenish the aquifers with managed aquifer recharge in an inland portion of the Pajaro Valley.},
  file      = {:Hydrology\\Groundwater\\Analysis of projected water availability with current basin management plan, Pajaro Valley, California.pdf:PDF},
  keywords  = {Groundwater Climate Management Integrated hydrologic models Water allocation Water recycling},
  timestamp = {2017-07-24},
}

@Article{Gutmann2014,
  author    = {Gutmann, Ethan and Pruitt, Tom and Clark, Martyn P. and Brekke, Levi and Arnold, Jeffrey R. and Raff, David A. and Rasmussen, Roy M.},
  title     = {An intercomparison of statistical downscaling methods used for water resource assessments in the United States},
  journal   = {Water Resources Research},
  year      = {2014},
  volume    = {50},
  number    = {9},
  pages     = {7167--7186},
  issn      = {1944-7973},
  abstract  = {Information relevant for most hydrologic applications cannot be obtained directly from the native-scale outputs of climate models. As a result the climate model output must be downscaled, often using statistical methods. The plethora of statistical downscaling methods requires end-users to make a selection. This work is intended to provide end-users with aid in making an informed selection. We assess four commonly used statistical downscaling methods: daily and monthly disaggregated-to-daily Bias Corrected Spatial Disaggregation (BCSDd, BCSDm), Asynchronous Regression (AR), and Bias Corrected Constructed Analog (BCCA) as applied to a continental-scale domain and a regional domain (BCCAr). These methods are applied to the NCEP/NCAR Reanalysis, as a surrogate for a climate model, to downscale precipitation to a 12 km gridded observation data set. Skill is evaluated by comparing precipitation at daily, monthly, and annual temporal resolutions at individual grid cells and at aggregated scales. BCSDd and the BCCA methods overestimate wet day fraction, and underestimate extreme events. The AR method reproduces extreme events and wet day fraction well at the grid-cell scale, but over (under) estimates extreme events (wet day fraction) at aggregated scales. BCSDm reproduces extreme events and wet day fractions well at all space and time scales, but is limited to rescaling current weather patterns. In addition, we analyze the choice of calibration data set by looking at both a 12 km and a 6 km observational data set; the 6 km observed data set has more wet days and smaller extreme events than the 12 km product, the opposite of expected scaling.},
  doi       = {10.1002/2014WR015559},
  file      = {:Climate\\An intercomparison of statistical downscaling methods used for water resource assessments in the United States.pdf:PDF},
  keywords  = {Climate impacts, Water management, Precipitation, Instruments and techniques, statistical downscaling, Bias Corrected Spatial Disaggregation (BCSD), Bias Corrected Constructed Analog (BCCA), Asynchronous Regression},
  timestamp = {2017-07-30},
  url       = {http://dx.doi.org/10.1002/2014WR015559},
}

@Article{Lee2014,
  author    = {Taesam Lee and Changsam Jeong},
  title     = {Nonparametric statistical temporal downscaling of daily precipitation to hourly precipitation and implications for climate change scenarios},
  journal   = {Journal of Hydrology},
  year      = {2014},
  volume    = {510},
  pages     = {182 - 196},
  issn      = {0022-1694},
  abstract  = {Hydro-meteorological time series on finer temporal scales, such as hourly, are essential for assessing the
hydrological effects of land use or climate change on medium and small watersheds. However, these time
series are, in general, available at no finer than daily time intervals. An alternative method of obtaining
finer time series is temporal downscaling of daily time series to hourly time series. In the current study, a
temporal downscaling model that combines a nonparametric stochastic simulation approach with a
genetic algorithm is proposed. The proposed model was applied to Jinju station in South Korea for a historical
time period to validate the model performance. The results revealed that the proposed model preserves
the key statistics (i.e., the mean, standard deviation, skewness, lag-1 correlation, and maximum) of
the historical hourly precipitation data. In addition, the occurrence and transition probabilities are well
preserved in the downscaled hourly precipitation data. Furthermore, the RCP 4.5 and RCP 8.5 climate scenarios
for the Jinju station were also analyzed, revealing that the mean and the wet-hour probability (P1)
significantly increased and the standard deviation and maximum slightly increased in these scenarios.
The magnitude of the increase was greater in RCP 8.5 than RCP 4.5. Extreme events of different durations
were also tested. The downscaled hourly precipitation adequately reproduced the statistical behavior of
the extremes of the historical hourly precipitation data for all durations considered. However, the
inter-daily relation between the 1st hour of the present day and the last hour of the previous day was
not preserved. Overall, the results demonstrated that the proposed temporal downscaling model is a good
alternative method for downscaling simulated daily precipitation data from weather generators or RCM
outputs.},
  doi       = {http://dx.doi.org/10.1016/j.jhydrol.2013.12.027},
  file      = {:Climate\\Nonparametric statistical temporal downscaling of daily precipitation to hourly precipitation and implications for climate change scenarios.pdf:PDF},
  keywords  = {Climate change, Daily precipitation, Extreme events, Hourly precipitation, RCP, Temporal downscaling},
  timestamp = {2017-07-30},
  url       = {http://www.sciencedirect.com/science/article/pii/S0022169413009244},
}

@Article{Pierce2014,
  author    = {David W. Pierce and Daniel R. Cayan and Bridget L. Thrasher},
  title     = {Statistical Downscaling Using Localized Constructed Analogs (LOCA)},
  journal   = {Journal of Hydrometeorology},
  year      = {2014},
  volume    = {15},
  pages     = {2558--2585},
  month     = {dec},
  abstract  = {A new technique for statistically downscaling climate model simulations of daily temperature and precipitation
is introduced and demonstrated over the western United States. The localized constructed analogs
(LOCA) method produces downscaled estimates suitable for hydrological simulations using a multiscale spatial
matching scheme to pick appropriate analog days from observations. First, a pool of candidate observed analog
days is chosen by matching the model field to be downscaled to observed days over the region that is positively
correlated with the point being downscaled, which leads to a natural independence of the downscaling results to
the extent of the domain being downscaled. Then, the one candidate analog day that best matches in the local
area around the grid cell being downscaled is the single analog day used there. Most grid cells are downscaled
using only the single locally selected analog day, but locations whose neighboring cells identify a different analog
day use a weighted combination of the center and adjacent analog days to reduce edge discontinuities. By
contrast, existing constructed analog methods typically use a weighted average of the same 30 analog days for
the entire domain. By greatly reducing this averaging, LOCA produces better estimates of extreme days,
constructs a more realistic depiction of the spatial coherence of the downscaled field, and reduces the problem
of producing too many light-precipitation days. The LOCA method is more computationally expensive than
existing constructed analog techniques, but it is still practical for downscaling numerous climate model
simulations with limited computational resources.},
  doi       = {10.1175/JHM-D-14-0082.1},
  file      = {:Climate\\Statistical Downscaling Using Localized Constructed Analogs (LOCA).pdf:PDF},
  timestamp = {2017-07-30},
}

@TechReport{Brekke2013,
  author      = {Levi Brekke and Bridget L. Thrasher and Edwin P. Maurer and Tom Pruitt},
  title       = {Downscaled CMIP3 and CMIP5 Climate Projections},
  institution = {Bureau of Reclamation Climate Analytics Group Climate Central Lawrence Livermore National Laboratory Santa Clara University Scripps Institution of Oceanography U.S. Army Corps of Engineers U.S. Geological Survey},
  year        = {2013},
  type        = {techreport},
  note        = {Release of Downscaled CMIP5 Climate Projections, Comparison with Preceding Information, and Summary of User Needs},
  file        = {:Climate\\Downscaled CMIP3 and CMIP5 Climate Projections.pdf:PDF},
  keywords    = {BCCA, BCSD},
  timestamp   = {2017-07-30},
  url         = {http://gdo-dcp.ucllnl.org/downscaled_cmip_projections/techmemo/downscaled_climate.pdf},
}

@Article{Maurer2010,
  author    = {Maurer, E. P. and Hidalgo, H. G. and Das, T. and Dettinger, M. D. and Cayan, D. R.},
  title     = {The utility of daily large-scale climate data in the assessment of climate change impacts on daily streamflow in California},
  journal   = {Hydrology and Earth System Sciences},
  year      = {2010},
  volume    = {14},
  number    = {6},
  pages     = {1125--1138},
  abstract  = {Three statistical downscaling methods were applied to NCEP/NCAR reanalysis (used as a surrogate for the best possible general circulation model), and the downscaled meteorology was used to drive a hydrologic model over California. The historic record was divided into an "observed" period of 1950–1976 to provide the basis for downscaling, and a "projected" period of 1977–1999 for assessing skill. The downscaling methods included a bias-correction/spatial downscaling method (BCSD), which relies solely on monthly large scale meteorology and resamples the historical record to obtain daily sequences, a constructed analogues approach (CA), which uses daily large-scale anomalies, and a hybrid method (BCCA) using a quantile-mapping bias correction on the large-scale data prior to the CA approach. At 11 sites we compared three simulated daily flow statistics: streamflow timing, 3-day peak flow, and 7-day low flow. While all downscaling methods produced reasonable streamflow statistics at most locations, the BCCA method consistently outperformed the other methods, capturing the daily large-scale skill and translating it to simulated streamflows that more skillfully reproduced observationally-driven streamflows.},
  doi       = {10.5194/hess-14-1125-2010},
  file      = {:Climate\\The utility of daily large-scale climate data in the assessment of climate change impacts on daily streamflow in California.pdf:PDF},
  timestamp = {2017-07-30},
  url       = {https://www.hydrol-earth-syst-sci.net/14/1125/2010/},
}

@Article{Maurer2007,
  author    = {E.P. Maurer and L. Brekke and T. Pruitt and P.B. Duffy},
  title     = {Fine-resolution climate projections enhance regional climate change Impact Studies},
  journal   = {Eos, Transactions American Geophysical Union},
  year      = {2007},
  volume    = {88},
  number    = {47},
  pages     = {504},
  month     = {dec},
  file      = {:Climate\\Fine-resolution climate projections enhance regional climate change Impact Studies.pdf:PDF},
  keywords  = {BCSD},
  timestamp = {2017-07-30},
}

@Article{Stoner2013,
  author    = {Stoner, Anne M. K. and Hayhoe, Katharine and Yang, Xiaohui and Wuebbles, Donald J.},
  title     = {An asynchronous regional regression model for statistical downscaling of daily climate variables},
  journal   = {International Journal of Climatology},
  year      = {2013},
  volume    = {33},
  number    = {11},
  pages     = {2473--2494},
  issn      = {1097-0088},
  abstract  = {The asynchronous regional regression model (ARRM) is a flexible and computationally efficient statistical
model that can downscale station-based or gridded daily values of any variable that can be transformed into an approximately
symmetric distribution and for which a large-scale predictor exists. This technique was developed to bridge the gap between
large-scale outputs from atmosphere–ocean general circulation models (AOGCMs) and the fine-scale output required for
local and regional climate impact assessments. ARRM uses piecewise regression to quantify the relationship between
observed and modelled quantiles and then downscale future projections. Here, we evaluate the performance of three
successive versions of the model in downscaling daily minimum and maximum temperature and precipitation for 20
stations in North America from diverse climate zones. Using cross-validation to maximize the independent comparison
period, historical downscaled simulations are evaluated relative to observations in terms of three different quantities: the
probability distributions, giving a visual image of the skill of each model; root-mean-square errors; and bias in nine
quantiles that represent both means and extremes. Successive versions of the model show improved accuracy in simulating
extremes, where AOGCMs are often most biased and which are frequently the focus of impact studies. Overall, the quantile
regression-based technique is shown to be efficient, robust, and highly generalizable across multiple variables, regions, and
climate model inputs.},
  doi       = {10.1002/joc.3603},
  file      = {:Climate\\An asynchronous regional regression model for statistical downscaling of daily climate variables.pdf:PDF},
  keywords  = {statistical downscaling, quantile regression, climate, temperature, precipitation},
  publisher = {John Wiley \& Sons, Ltd},
  timestamp = {2017-07-30},
  url       = {http://dx.doi.org/10.1002/joc.3603},
}

@Article{Wood2004,
  author    = {A. W. Wood and L. R. Leung and V. Sridhar and D. P. Lettenmaier},
  title     = {Hydrologic Implications of Dynamical and Statistical Approaches to Downscaling Climate Model Outputs},
  journal   = {Climate Change},
  year      = {2004},
  volume    = {62},
  number    = {1--3},
  pages     = {189--216},
  month     = {jan},
  abstract  = {Six approaches for downscaling climate model outputs for use in hydrologic simulation
were evaluated, with particular emphasis on each method’s ability to produce precipitation and other
variables used to drive a macroscale hydrology model applied at much higher spatial resolution
than the climate model. Comparisons were made on the basis of a twenty-year retrospective (1975–
1995) climate simulation produced by the NCAR-DOE Parallel Climate Model (PCM), and the
implications of the comparison for a future (2040–2060) PCM climate scenario were also explored.
The six approaches were made up of three relatively simple statistical downscaling methods – linear
interpolation (LI), spatial disaggregation (SD), and bias-correction and spatial disaggregation
(BCSD) – each applied to both PCM output directly (at T42 spatial resolution), and after dynamical
downscaling via a Regional Climate Model (RCM – at 1/2-degree spatial resolution), for downscaling
the climate model outputs to the 1/8-degree spatial resolution of the hydrological model. For the
retrospective climate simulation, results were compared to an observed gridded climatology of temperature
and precipitation, and gridded hydrologic variables resulting from forcing the hydrologic
model with observations. The most significant findings are that the BCSD method was successful
in reproducing the main features of the observed hydrometeorology from the retrospective climate
simulation, when applied to both PCM and RCM outputs. Linear interpolation produced better results
using RCM output than PCM output, but both methods (PCM-LI and RCM-LI) lead to unacceptably
biased hydrologic simulations. Spatial disaggregation of the PCM output produced results similar
to those achieved with the RCM interpolated output; nonetheless, neither PCM nor RCM output
was useful for hydrologic simulation purposes without a bias-correction step. For the future climate
scenario, only the BCSD-method (using PCM or RCM) was able to produce hydrologically plausible
results. With the BCSD method, the RCM-derived hydrology was more sensitive to climate change
than the PCM-derived hydrology.},
  file      = {:Climate\\Hydrologic Implications of Dynamical and Statistical Approaches to Downscaling Climate Model Outputs.pdf:PDF},
  timestamp = {2017-07-30},
}

@Article{Lee2010,
  author    = {Lee, T. and Salas, J. D. and Prairie, J.},
  title     = {An enhanced nonparametric streamflow disaggregation model with genetic algorithm},
  journal   = {Water Resources Research},
  year      = {2010},
  volume    = {46},
  number    = {8},
  pages     = {n/a--n/a},
  issn      = {1944-7973},
  note      = {W08545},
  abstract  = {Stochastic streamflow generation is generally utilized for planning and management
of water resources systems. For this purpose, a number of parametric and nonparametric
models have been suggested in literature. Among them, temporal and spatial
disaggregation approaches play an important role particularly to make sure that historical
variance‐covariance properties are preserved at various temporal and spatial scales. In this
paper, we review the underlying features of existing nonparametric disaggregation
methods, identify some of their pros and cons, and propose a disaggregation algorithm that
is capable of surmounting some of the shortcomings of the current models. The proposed
models hinge on k‐nearest neighbor resampling, the accurate adjusting procedure, and a
genetic algorithm. The models have been tested and compared to an existing
nonparametric disaggregation approach using data of the Colorado River system. It has
been shown that the model is capable of (1) reproducing the season‐to‐season correlations
including the correlation between the last season of the previous year and the first
season of the current year, (2) minimizing or avoiding the generation of flow patterns
across the year that are literally the same as those of the historical records, and
(3) minimizing or avoiding the generation of negative flows. In addition, it is applicable
to intermittent river regimes.},
  doi       = {10.1029/2009WR007761},
  file      = {:Statistics\\An enhanced nonparametric streamflow disaggregation model with genetic algorithm.pdf:PDF},
  keywords  = {Computational hydrology, Modeling, Spatial analysis, North America, disaggregation, k-nearest neighbors, nonparametric, stochastic hydrology, stochastic simulation, streamflows},
  timestamp = {2017-07-31},
  url       = {http://dx.doi.org/10.1029/2009WR007761},
}

@Article{Hirsch1982,
  author    = {Robert M. Hirsch},
  title     = {A comparison of four streamflow record extension techniques},
  journal   = {Water Resources Research},
  year      = {1982},
  volume    = {18},
  number    = {4},
  pages     = {1081--1088},
  abstract  = {One approach to developing time series of streamflow, which may be used for simulation and optimization studies of water resources development activities, is to extend an existing gage record in time by exploiting the interstation correlation between the station of interest and some nearby (long-term) base station. Four methods of extension are described, and their properties are explored. The methods are regression (REG), regression plus noise (RPN), and two new methods, maintenance of variance extension types 1 and 2 (MOVE.l, MOVE.2). MOVE.l is equivalent to a method which is widely used in psychology, biometrics, and geomorphology and which has been called by various names, e.g., ‘line of organic correlation,’ ‘reduced major axis,’ ‘unique solution,’ and ‘equivalence line.’ The methods are examined for bias and standard error of estimate of moments and order statistics, and an empirical examination is made of the preservation of historic low-flow characteristics using 50-year-long monthly records from seven streams. The REG and RPN methods are shown to have serious deficiencies as record extension techniques. MOVE.2 is shown to be marginally better than MOVE.l, according to the various comparisons of bias and accuracy.},
  doi       = {10.1029/WR018i004p01081},
  file      = {:Ensembles\\A comparison of four streamflow record extension techniques.pdf:PDF},
  timestamp = {2017-07-31},
}

@Misc{NOAA2014,
  author    = {Limin Wu},
  title     = {Hydrologic Ensemble Forecasting Service (HEFS) Seminar D MEFP Theory},
  month     = {aug},
  year      = {2014},
  file      = {:Ensembles\\MEFP_Theory_Presentation.pdf:PDF},
  timestamp = {2017-07-31},
}

@Article{DeChant2012,
  author    = {DeChant, Caleb M. and Moradkhani, Hamid},
  title     = {Examining the effectiveness and robustness of sequential data assimilation methods for quantification of uncertainty in hydrologic forecasting},
  journal   = {Water Resources Research},
  year      = {2012},
  volume    = {48},
  number    = {4},
  pages     = {n/a--n/a},
  issn      = {1944-7973},
  note      = {W04518},
  abstract  = {[1] In hydrologic modeling, state-parameter estimation using data assimilation techniques is increasing in popularity. Several studies, using both the ensemble Kalman filter (EnKF) and the particle filter (PF) to estimate both model states and parameters have been published in recent years. Though there is increasing interest and a growing literature in this area, relatively little research has been presented to examine the effectiveness and robustness of these methods to estimate uncertainty. This study suggests that state-parameter estimation studies need to provide a more rigorous testing of these techniques than has previously been presented. With this in mind, this paper presents a study with multiple calibration replicates and a range of performance measures to test the ability of each technique to calibrate two separate hydrologic models. The results show that the EnKF is consistently overconfident in predicting streamflow, which relates to the assumption of a Gaussian error structure. In addition, the EnKF and PF were found to perform similarly in terms of tracking the observations with an expected value, but the potential for filter divergence in the EnKF is highlighted.},
  doi       = {10.1029/2011WR011011},
  file      = {:Hydrology\\Examining the effectiveness and robustness of sequential data assimilation methods for quantification of uncertainty in hydrologic forecasting.pdf:PDF},
  keywords  = {Streamflow, Stochastic hydrology, Uncertainty assessment, Watershed, ensemble Kalman filter, data assimilation, parameter estimation, particle filter, uncertainty},
  timestamp = {2017-08-01},
  url       = {http://dx.doi.org/10.1029/2011WR011011},
}

@Article{Annis2017,
  author    = {Annis, Jeffrey and Miller, Brent J. and Palmeri, Thomas J.},
  title     = {Bayesian inference with Stan: A tutorial on adding custom distributions},
  journal   = {Behavior Research Methods},
  year      = {2017},
  volume    = {49},
  number    = {3},
  pages     = {863--886},
  month     = {Jun},
  issn      = {1554-3528},
  abstract  = {When evaluating cognitive models based on fits to observed data (or, really, any model that has free parameters), parameter estimation is critically important. Traditional techniques like hill climbing by minimizing or maximizing a fit statistic often result in point estimates. Bayesian approaches instead estimate parameters as posterior probability distributions, and thus naturally account for the uncertainty associated with parameter estimation; Bayesian approaches also offer powerful and principled methods for model comparison. Although software applications such as WinBUGS (Lunn, Thomas, Best, {\&} Spiegelhalter, Statistics and Computing, 10, 325--337, 2000) and JAGS (Plummer, 2003) provide ``turnkey''-style packages for Bayesian inference, they can be inefficient when dealing with models whose parameters are correlated, which is often the case for cognitive models, and they can impose significant technical barriers to adding custom distributions, which is often necessary when implementing cognitive models within a Bayesian framework. A recently developed software package called Stan (Stan Development Team, 2015) can solve both problems, as well as provide a turnkey solution to Bayesian inference. We present a tutorial on how to use Stan and how to add custom distributions to it, with an example using the linear ballistic accumulator model (Brown {\&} Heathcote, Cognitive Psychology, 57, 153--178. doi:                  10.1016/j.cogpsych.2007.12.002                                  , 2008).},
  day       = {01},
  doi       = {10.3758/s13428-016-0746-9},
  file      = {:Statistics\\Bayesian inference with Stan- A tutorial on adding custom distributions.pdf:PDF},
  timestamp = {2017-08-06},
  url       = {https://doi.org/10.3758/s13428-016-0746-9},
}

@PhdThesis{Dozier2017a,
  author    = {Dozier, André},
  title     = {Towards Integrated Water Resources Management through Modeling, Optimization, and Stakeholder Engagement with a Decision Support Game},
  school    = {Colorado State University},
  year      = {2017},
  abstract  = {Integrated water resources management (IWRM) necessitates stakeholder engagement and
integrated assessment of physical, ecological, and socioeconomic systems. Water resource
literature has reflected a trend toward IWRM through increased focus on model integration,
evolutionary and multiobjective algorithms, and stakeholder engagement through participatory
modeling and role-playing games. A model data passing interface exemplifies integrated
assessment with minimally invasive and interoperable code changes. IWRM is applied within the
context of a rapidly urbanizing, semi-arid region with steadily declining agricultural production and
community welfare.
Integrated modeling and assessment of the South Platte River Basin reveals lessons about
management objectives, allocation institutions, and characterization of optimal solutions. High
prices of water incentivize farmers to sell, while managing to sustain agriculture reduces price,
saving money for cities. Freer trade can combat potential water supply vulnerabilities. Biased
reservoir operations limit benefits from additional reservoir capacity. Optimized selection between
a limited set of supply-side and demand-side solution strategies exposes the sensitivity of optimal
outcomes to municipal raw water purchase requirements and the cost-effectiveness of xeriscaping
and more efficient agricultural irrigation technology. A promising and novel, yet preliminary and
proof-of-concept, decision support game is demonstrated to reconcile numerical simulation and
optimization techniques with stakeholder engagement and preference-based alternative selection.},
  file      = {:WaterResources\\Dozier, Andre - Dissertation 2017.pdf:PDF},
  timestamp = {2017-08-10},
}

@InProceedings{Mnih2016,
  author    = {Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Tim Harley and Timothy P. Lillicrap and David Silver and Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  booktitle = {Proceedings of the 33 rd International Conference on Machine Learning},
  year      = {2016},
  volume    = {48},
  address   = {New York, NY},
  abstract  = {We propose a conceptually simple and
lightweight framework for deep reinforcement
learning that uses asynchronous gradient
descent for optimization of deep neural network
controllers. We present asynchronous variants of
four standard reinforcement learning algorithms
and show that parallel actor-learners have a
stabilizing effect on training allowing all four
methods to successfully train neural network
controllers. The best performing method, an
asynchronous variant of actor-critic, surpasses
the current state-of-the-art on the Atari domain
while training for half the time on a single
multi-core CPU instead of a GPU. Furthermore,
we show that asynchronous actor-critic succeeds
on a wide variety of continuous motor control
problems as well as on a new task of navigating
random 3D mazes using a visual input.},
  file      = {:Optimal_Control\\Asynchronous Methods for Deep Reinforcement Learning.pdf:PDF},
  keywords  = {SARSA, A3C, Q-Learning},
  timestamp = {2017-08-12},
}

@InProceedings{Schulman2015,
  author    = {John Schulman and Sergey Levine and Philipp Moritz and Michael Jordan and Pieter Abbeel},
  title     = {Trust Region Policy Optimization},
  booktitle = {Proceedings of the 31 st International Conference on Machine Learning},
  year      = {2015},
  volume    = {JMLR: W\&CP Vol. 37},
  address   = {Lille, France},
  abstract  = {We describe an iterative procedure for optimizing
policies, with guaranteed monotonic improvement.
By making several approximations to the
theoretically-justified procedure, we develop a
practical algorithm, called Trust Region Policy
Optimization (TRPO). This algorithm is similar
to natural policy gradient methods and is effective
for optimizing large nonlinear policies such
as neural networks. Our experiments demonstrate
its robust performance on a wide variety
of tasks: learning simulated robotic swimming,
hopping, and walking gaits; and playing Atari
games using images of the screen as input. Despite
its approximations that deviate from the
theory, TRPO tends to give monotonic improvement,
with little tuning of hyperparameters.},
  file      = {:Optimal_Control\\Trust Region Policy Optimization.pdf:PDF},
  timestamp = {2017-08-13},
}

@Article{Barto1995,
  author    = {Andrew G. Barto and Steven J. Bradtke and Satinder P. Singh},
  title     = {Learning to act using real-time dynamic programming},
  journal   = {Artificial Intelligence},
  year      = {1995},
  volume    = {72},
  number    = {1–2},
  pages     = {81 - 138},
  issn      = {0004-3702},
  abstract  = {Learning methods based on dynamic programming (DP) are receiving increasing attention in artificial intelligence. Researchers have argued that \{DP\} provides the appropriate basis for compiling planning results into reactive strategies for real-time control, as well as for learning such strategies when the system being controlled is incompletely known. We introduce an algorithm based on DP, which we call Real-Time \{DP\} (RTDP), by which an embedded system can improve its performance with experience. \{RTDP\} generalizes Korf's Learning-Real-Time-A* algorithm to problems involving uncertainty. We invoke results from the theory of asynchronous \{DP\} to prove that \{RTDP\} achieves optimal behavior in several different classes of problems. We also use the theory of asynchronous \{DP\} to illuminate aspects of other DP-based reinforcement learning methods such as Watkins' Q-Learning algorithm. A secondary aim of this article is to provide a bridge between \{AI\} research on real-time planning and learning and relevant concepts and algorithms from control theory. },
  doi       = {http://dx.doi.org/10.1016/0004-3702(94)00011-O},
  owner     = {quebbs},
  timestamp = {2015.11.04},
  url       = {http://www.sciencedirect.com/science/article/pii/000437029400011O},
}

@Article{Lewis2011,
  author    = {Lewis, F.L. and Vamvoudakis, K.G.},
  title     = {Reinforcement Learning for Partially Observable Dynamic Processes: Adaptive Dynamic Programming Using Measured Output Data},
  journal   = {Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on},
  year      = {2011},
  volume    = {41},
  number    = {1},
  pages     = {14-25},
  month     = {Feb},
  issn      = {1083-4419},
  abstract  = {Approximate dynamic programming (ADP) is a class of reinforcement learning methods that have shown their importance in a variety of applications, including feedback control of dynamical systems. ADP generally requires full information about the system internal states, which is usually not available in practical situations. In this paper, we show how to implement ADP methods using only measured input/output data from the system. Linear dynamical systems with deterministic behavior are considered herein, which are systems of great interest in the control system community. In control system theory, these types of methods are referred to as output feedback (OPFB). The stochastic equivalent of the systems dealt with in this paper is a class of partially observable Markov decision processes. We develop both policy iteration and value iteration algorithms that converge to an optimal controller that requires only OPFB. It is shown that, similar to Q-learning, the new methods have the important advantage that knowledge of the system dynamics is not needed for the implementation of these learning algorithms or for the OPFB control. Only the order of the system, as well as an upper bound on its "observability index," must be known. The learned OPFB controller is in the form of a polynomial autoregressive moving-average controller that has equivalent performance with the optimal state variable feedback gain.},
  doi       = {10.1109/TSMCB.2010.2043839},
  keywords  = {Markov processes;autoregressive moving average processes;control engineering computing;data handling;decision theory;dynamic programming;feedback;iterative methods;knowledge based systems;learning (artificial intelligence);observability;optimal control;polynomial approximation;adaptive dynamic programming;chastic equivalent system;control system community;control system theory;decision processes;deterministic behavior;iteration algorithm;learning algorithm;linear dynamical system;observable Markov decision process;optimal controller;optimal state variable feedback gain;output feedback;partially observable dynamic processes;polynomial autoregressive moving average controller;reinforcement learning;Control systems;Dynamic programming;Feedback control;Learning;Optimal control;Output feedback;Polynomials;State feedback;Stochastic systems;Upper bound;Approximate dynamic programming (ADP);data-based optimal control;output feedback (OPFB);policy iteration (PI);value iteration (VI);Algorithms;Artificial Intelligence;Feedback;Learning;Markov Chains;Reinforcement (Psychology)},
  owner     = {quebbs},
  timestamp = {2015.11.04},
}

@Book{Sutton1998,
  title     = {Reinforcement Learning: An Introduction},
  publisher = {MIT Press},
  year      = {1998},
  author    = {Richard S. Sutton and Andrew G. Barto},
  abstract  = {This introductory textbook on reinforcement learning is targeted toward engineers and scientists in artificial intelligence, operations research, neural networks, and control systems, and we hope it will also be of interest to psychologists and neuroscientists.},
  keywords  = {Q-Learning, SARSA},
  owner     = {quebbs},
  timestamp = {2015.09.29},
}

@PhdThesis{Watkins1989,
  author    = {Christopher Watkins},
  title     = {Learnimg from Delayed Rewards},
  school    = {King's College},
  year      = {1989},
  keywords  = {Q-Learning},
  owner     = {quebbs},
  timestamp = {2015.09.29},
}

@Article{Watkins1992,
  author    = {Watkins, Christopher J.C.H. and Dayan, Peter},
  title     = {Technical Note: Q-Learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  number    = {3-4},
  pages     = {279-292},
  issn      = {0885-6125},
  abstract  = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.

This paper presents and proves in detail a convergence theorem for \(\mathcal{Q}\)-learning based on that outlined in Watkins (1989). We show that \(\mathcal{Q}\)-learning converges to the optimum action-values with probability 1 so long as all actions are repeatedly sampled in all states and the action-values are represented discretely. We also sketch extensions to the cases of non-discounted, but absorbing, Markov environments, and where many \(\mathcal{Q}\) values can be changed each iteration, rather than just one.},
  doi       = {10.1023/A:1022676722315},
  file      = {:Optimal_Control\\Q-Learning.pdf:PDF},
  keywords  = {Q-learning; reinforcement learning; temporal differences; asynchronous dynamic programming},
  language  = {English},
  owner     = {quebbs},
  publisher = {Kluwer Academic Publishers-Plenum Publishers},
  timestamp = {2015.09.29},
  url       = {http://dx.doi.org/10.1023/A%3A1022676722315},
}

@Article{Hester2017,
  author    = {Todd Hester and Matej Vecerik and Olivier Pietquin and Marc Lanctot and Tom Schaul and Bilal Piot and Andrew Sendonaris and Gabriel Dulac{-}Arnold and Ian Osband and John Agapiou and Joel Z. Leibo and Audrunas Gruslys},
  title     = {Learning from Demonstrations for Real World Reinforcement Learning},
  journal   = {CoRR},
  year      = {2017},
  volume    = {abs/1704.03732},
  abstract  = {Deep reinforcement learning (RL) has achieved several high profile successes in difficult decision-making problems. However, these algorithms typically require a huge amount of data before they reach reasonable performance. In fact, their performance during learning can be extremely poor. This may be acceptable for a simulator, but it severely limits the applicability of deep RL to many real-world tasks, where the agent must learn in the real environment. In this paper we study a setting where the agent may access data from previous control of the system. We present an algorithm, Deep Q-learning from Demonstrations (DQfD), that leverages this data to massively accelerate the learning process even from relatively small amounts of demonstration data and is able to automatically assess the necessary ratio of demonstration data while learning thanks to a prioritized replay mechanism. DQfD works by combining temporal difference updates with supervised classification of the demonstrator's actions. We show that DQfD has better initial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN) as it starts with better scores on the first million steps on 41 of 42 games and on average it takes PDD DQN 82 million steps to catch up to DQfD's performance. DQfD learns to out-perform the best demonstration given in 14 of 42 games. In addition, DQfD leverages human demonstrations to achieve state-of-the-art results for 17 games. Finally, we show that DQfD performs better than three related algorithms for incorporating demonstration data into DQN.},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HesterVPLSPSDOA17},
  file      = {:Optimal_Control\\Learning from Demonstrations for Real World Reinforcement Learning.pdf:PDF},
  timestamp = {2017-08-13},
  url       = {http://arxiv.org/abs/1704.03732},
}

@Article{Gu2016,
  author    = {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  title     = {Continuous Deep Q-Learning with Model-based Acceleration},
  year      = {2016},
  abstract  = {Model-free reinforcement learning has been successfully
applied to a range of challenging problems,
and has recently been extended to handle
large neural network policies and value functions.
However, the sample complexity of modelfree
algorithms, particularly when using highdimensional
function approximators, tends to
limit their applicability to physical systems. In
this paper, we explore algorithms and representations
to reduce the sample complexity of
deep reinforcement learning for continuous control
tasks. We propose two complementary techniques
for improving the efficiency of such algorithms.
First, we derive a continuous variant of
the Q-learning algorithm, which we call normalized
adantage functions (NAF), as an alternative
to the more commonly used policy gradient and
actor-critic methods. NAF representation allows
us to apply Q-learning with experience replay to
continuous tasks, and substantially improves performance
on a set of simulated robotic control
tasks. To further improve the efficiency of our
approach, we explore the use of learned models
for accelerating model-free reinforcement learning.
We show that iteratively refitted local linear
models are especially effective for this, and
demonstrate substantially faster learning on domains
where such models are applicable.},
  file      = {:Optimal_Control\\Continuous Deep Q-Learning with Model-based Acceleration.pdf:PDF},
  timestamp = {2017-08-13},
}

@Article{Sutton1999,
  author    = {Richard S. Sutton and David McAllester and Satinder Singh and Yishay Mansour},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  journal   = {Advances in neural information processing systems},
  year      = {1999},
  pages     = {1057--1063},
  abstract  = {Function approximation is essential to reinforcement learning, but
the standard approach of approximating a value function and determining
a policy from it has so far proven theoretically intractable.
In this paper we explore an alternative approach in which the policy
is explicitly represented by its own function approximator, independent
of the value function, and is updated according to the gradient
of expected reward with respect to the policy parameters. Williams's
REINFORCE method and actor-critic methods are examples of this
approach. Our main new result is to show that the gradient can
be written in a form suitable for estimation from experience aided
by an approximate action-value or advantage function. Using this
result, we prove for the first time that a version of policy iteration
with arbitrary differentiable function approximation is convergent to
a locally optimal policy.},
  file      = {:Optimal_Control\\Policy Gradient Methods for Reinforcement Learning with Function Approximation.pdf:PDF},
  timestamp = {2017-08-13},
}

@Article{Rawlik2013,
  author    = {Konrad Rawlik and Marc Toussaint and Sethu Vijayakumar},
  title     = {On stochastic optimal control and reinforcement learning by approximate inference},
  journal   = {Robotics},
  year      = {2013},
  pages     = {353},
  abstract  = {We present a reformulation of the stochastic optimal
control problem in terms of KL divergence minimisation, not
only providing a unifying perspective of previous approaches in
this area, but also demonstrating that the formalism leads to
novel practical approaches to the control problem. Specifically, a
natural relaxation of the dual formulation gives rise to exact iterative
solutions to the finite and infinite horizon stochastic optimal
control problem, while direct application of Bayesian inference
methods yields instances of risk sensitive control. We furthermore
study corresponding formulations in the reinforcement learning
setting and present model free algorithms for problems with both
discrete and continuous state and action spaces. Evaluation of
the proposed methods on the standard Gridworld and Cart-Pole
benchmarks verifies the theoretical insights and shows that the
proposed methods improve upon current approaches.},
  file      = {:Optimal_Control\\On stochastic optimal control and reinforcement learning by approximate inference.pdf:PDF},
  keywords  = {Q-learning, temporal difference},
  timestamp = {2017-08-13},
}

@TechReport{Borden2016,
  author      = {Carter Borden and Anju Gaur and Chabungbam R. Singh},
  title       = {Water Resource Software - Application Overview and Review},
  institution = {The World Bank},
  year        = {2016},
  month       = {March},
  note        = {SAWI South Asia Water Initiative, OWHM, GSSHA},
  abstract    = {The National Hydrology Project (NHP) is an initiative by the Government of India’s Ministry
of Water Resources and the World Bank to develop hydro-meteorological monitoring systems
and provide scientifically-based tools and design aids to assist implementing agencies in the
effective water resources planning and management (http://www.hydrology-project.gov.in/,
http://indiawrm.org/). The NHP consists of four components: A) Water Data Acquisition Systems;
B) Water Resource Information Systems; C) Water Resources Operation and Management
Applications; and D) Institutional Strengthening and Capacity Building. The objective of
Component C is to ensure the usefulness of monitored and remotely sensed data sets through
the implementation of planning applications for decision support systems (DSS) for river basin
planning, water balance assessments, climate risk assessments (for example, climate change,
drought management), groundwater resource management, water quality management,
scenario analysis for investment planning, and community based water management. Thus,
water and water quality modeling software (WRS) for planning and real-time applications will be
required to support this initiative.
As many WRS exist to support management a variety of water resources issues, selection of the
proper software by water managers with limited experience in these tools can be daunting and
confusing. To aid water managers in their selection, this document provides an overview of how
WRS are used to manage water resources issues, criteria for WRS selection, and a high level
review of WRS currently available that central and state governments of India can use for water
management. The water resource issues covered include water allocation and planning, flood
management, groundwater management, conjunctive use, water quality, and sediment transport.
Selection criteria discussed includes computational functionality, user interface ease or use and
capabilities, licensing requirements, and software support. Twenty-two WRS from Aquaveo,
Colorado State University (CSU), Deltares, DHI Water Environment Health (DHI), eWater, India’s
National Institute of Hydrology (NIH), Rockware, Stockholm Environmental Institute (SEI), U.S.
Army Corps of Engineers (USACE), U.S. Department of Agriculture (USDA), and U.S. Geological
Survey (USGS) were evaluated based on the selection criteria as well as their application to water
resource issues in India and globally. In addition, three DSS for flood warning were evaluated.
This review is based on software developers’ responses to a questionnaire and a desktop review
of technical manuals, user guides, tutorials, and studies related to the WRS. No testing was
performed on WRS to validate performance as described in the literature. With this information,
it is envisioned that water managers can perform a detailed review on a limited set of WRS for
determining the package that best suits their unique water resource issue, hydrologic setting,
intended use, and institutional setting.},
  file        = {:WaterResources\\Water Resource Software - Application Overview and Review.pdf:PDF},
  timestamp   = {2017-08-14},
}

@Article{Johnston2014,
  author    = {Johnston, Robyn and Smakhtin, Vladimir},
  title     = {Hydrological Modeling of Large river Basins: How Much is Enough?},
  journal   = {Water Resources Management},
  year      = {2014},
  volume    = {28},
  number    = {10},
  pages     = {2695--2730},
  month     = {Aug},
  issn      = {1573-1650},
  abstract  = {Hydrological modeling is an indispensable component of water resources research and management in large river basins. There is a tendency for each new group working in a basin to develop their own model, resulting in a plethora of such tools for each major basin. The question then becomes: how much modeling is enough? This study reviews hydrological modeling in four large basins (Nile, Mekong, Ganges and Indus). Based on this review, four areas for action to improve effectiveness and reduce duplication in hydrological modeling of large basins are suggested. Model setups and input data, as well as model results, should be published, to allow more coordinated approaches and capitalize on past modeling efforts. More focus is needed on reporting uncertainty, to allow more realistic assessment of the degree of confidence in using results for policy and management. Initiatives are needed to improve the quantity and quality of data for model input, calibration and validation, both traditional hydrological monitoring (improved networks, expansion of automated systems) and new methods for data collection (remote sensing, crowd-sourcing and community based observations). Finally, within each major basin, an appropriate agency should be identified and resourced to take responsibility for data sharing and coordination, to reduce redundancy of effort and promote collaboration.},
  day       = {01},
  doi       = {10.1007/s11269-014-0637-8},
  file      = {:WaterResources\\Hydrological Modeling of Large river Basins- How much is enough.pdf:PDF},
  keywords  = {Hydrological models . Large river basins . Nile . Mekong . Ganges . Indus, Brahmaputra},
  timestamp = {2017-08-18},
  url       = {https://doi.org/10.1007/s11269-014-0637-8},
}

@Article{Moradkhani2006,
  author    = {Moradkhani, Hamid and Hsu, K. and Hong, Y. and Sorooshian, S.},
  title     = {Investigating the impact of remotely sensed precipitation and hydrologic model uncertainties on the ensemble streamflow forecasting},
  journal   = {Geophysical Research Letters},
  year      = {2006},
  volume    = {33},
  number    = {12},
  pages     = {n/a--n/a},
  issn      = {1944-8007},
  note      = {L12401},
  doi       = {10.1029/2006GL026855},
  file      = {:Ensembles\\Investigating the Impact of Remotely Sensed Precipitation and hydrologic model uncertainties on the ensemble streamflow forecasting.pdf:PDF},
  keywords  = {Uncertainty assessment, Model calibration, Modeling, Precipitation, Streamflow},
  timestamp = {2017-08-19},
  url       = {http://dx.doi.org/10.1029/2006GL026855},
}

@Article{Smith2016,
  author    = {Rebecca Smith and Joseph Kasprzyk and Edith Zagona},
  title     = {Many-Objective Analysis to Optimize Pumping and Releases in Multireservoir Water Supply Network},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2016},
  volume    = {142},
  number    = {2},
  abstract  = {This study contributes a many-objective analysis of water supply in the Tarrant Regional Water District (TRWD) in Texas in the United States, in order to demonstrate how multiobjective evolutionary algorithm (MOEA) decision support can be used with sophisticated water infrastructure models in a highly constrained water-planning environment. A detailed representation of TRWD’s network in the river system modeling tool RiverWare (a model actually used by the utility) is coupled with the Borg MOEA to solve a seven-objective problem formulation. Objectives within the formulation include systemwide performance objectives, as well as reliability objectives to balance multiple reservoirs, calculated using two stochastic hydrology scenarios. The results provide valuable information to TRWD that may inform the utility’s approach to optimization and decision making in the future, as well as illuminate the benefits of optimizing systemwide and component-specific objectives to reveal hidden system dynamics.},
  file      = {:Reservoirs\\Many-Objective Analysis to Optimize Pumping and Releases in Multireservoir Water Supply Network.pdf:PDF},
  keywords  = {RiverWare},
  timestamp = {2017-08-25},
}

@TechReport{Jasperse2017,
  author      = {Jay Jasperse and Marty Ralph},
  title       = {Preliminary Viability Assessment of Lake Mendocino Forecast Informed Reservoir Operations},
  institution = {Sonoma County Water Agency, Center for Wester Weather and Water Extremes},
  year        = {2017},
  note        = {FIRO},
  file        = {:Preliminary Viability Assessment of Lake Mendocino Forecast Informed Reservoir Operations.pdf:PDF},
}

@TechReport{Tillman2016,
  author      = {Fred Tillman and Subhrendu Gangopadhyay and Tom Pruitt},
  title       = {A Case Study on Evaluating Impacts of Potential Climate Change on Groundwater Resources- Groundwater Recharge in the Upper Colorado River Basin},
  institution = {United States Bureau of Reclamation},
  year        = {2016},
  number      = {Technical Memorandum No. 86-68210-2016-11},
  file        = {:A Case Study on Evaluating Impacts of Potential Climate Change on Groundwater Resources- Groundwater Recharge in the Upper Colorado River Basin.pdf:PDF},
}

@TechReport{Huntington2015,
  author      = {Justin Huntington and Subhrendu Gangopadhyay and Mark Spears and Richard Allen and David King and Charles Morton and Alan Harrison and Daniel McEvoy and Andy Joros and Tom Pruitt},
  title       = {West-Wide Climate Risk Assessments: Irrigation Demand and Reservoir Evaporation Projections},
  institution = {United States Bureau of Reclamation},
  year        = {2015},
  type        = {techreport},
  number      = {Technical Memorandum No. 86-68210-2014-01},
  file        = {:Hydrology\\Evaporation\\West-Wide Climate Risk Assessments- Irrigation Demand and Reservoir Evaporation Projections.pdf:PDF},
}

@TechReport{USBR2014,
  author      = {USBR},
  title       = {Technical Guidance for Incorporating Climate Change Information into Water Resources Planning Studies},
  institution = {United States Bureau of Reclamation},
  year        = {2014},
  type        = {techreport},
  file        = {:Climate\\Technical Guidance for Incorporating Climate Change Information into Water Resources Planning Studies.pdf:PDF},
}

@Article{Emerton2016,
  author    = {Emerton, Rebecca E. and Stephens, Elisabeth M. and Pappenberger, Florian and Pagano, Thomas C. and Weerts, Albrecht H. and Wood, Andy W. and Salamon, Peter and Brown, James D. and Hjerdt, Niclas and Donnelly, Chantal and Baugh, Calum A. and Cloke, Hannah L.},
  title     = {Continental and global scale flood forecasting systems},
  journal   = {Wiley Interdisciplinary Reviews: Water},
  year      = {2016},
  volume    = {3},
  number    = {3},
  pages     = {391--418},
  issn      = {2049-1948},
  abstract  = {Floods are the most frequent of natural disasters, affecting millions of people across the globe every year. The anticipation and forecasting of floods at the global scale is crucial to preparing for severe events and providing early awareness where local flood models and warning services may not exist. As numerical weather prediction models continue to improve, operational centers are increasingly using their meteorological output to drive hydrological models, creating hydrometeorological systems capable of forecasting river flow and flood events at much longer lead times than has previously been possible. Furthermore, developments in, for example, modelling capabilities, data, and resources in recent years have made it possible to produce global scale flood forecasting systems. In this paper, the current state of operational large-scale flood forecasting is discussed, including probabilistic forecasting of floods using ensemble prediction systems. Six state-of-the-art operational large-scale flood forecasting systems are reviewed, describing similarities and differences in their approaches to forecasting floods at the global and continental scale. Operational systems currently have the capability to produce coarse-scale discharge forecasts in the medium-range and disseminate forecasts and, in some cases, early warning products in real time across the globe, in support of national forecasting capabilities. With improvements in seasonal weather forecasting, future advances may include more seamless hydrological forecasting at the global scale alongside a move towards multi-model forecasts and grand ensemble techniques, responding to the requirement of developing multi-hazard early warning systems for disaster risk reduction. WIREs Water 2016, 3:391–418. doi: 10.1002/wat2.1137For further resources related to this article, please visit the WIREs website.},
  doi       = {10.1002/wat2.1137},
  file      = {:Hydrology\\Continental and global scale flood forecasting systems.pdf:PDF},
  publisher = {John Wiley \& Sons, Inc.},
  timestamp = {2017-09-01},
  url       = {http://dx.doi.org/10.1002/wat2.1137},
}

@TechReport{Zielinski2017,
  author      = {Przemyslaw Zielinski and John Perdikaris and Ross Zhou and Tareq Salloum and Derek Sakamoto},
  title       = {System approach and simulation in risk assessment of dams},
  institution = {Ontario Power Generation},
  year        = {2017},
  abstract    = {The system of two control dams and five generating stations operated by Ontario Power Generation
(OPG) has been identified with a dam safety deficiency in that some of the dams cannot pass the
design inflow event. Since all OPG dams were classified as High or Very High with respect to potential
consequences resulting from dam failures, the Inflow Design Floods (IDFs) were selected as Probable
Maximum Floow (PMF) or a flood close to the PMF. A comprehensive risk assessment study seeking
to determine whether risk exposure due to inability to safely pass IDF is sufficiently high to justify
discharge capacity upgrades was carried out. Analytic approach was based on the philosophy of
system modeling through stochastic simulation. Inflows to the sites simulated as random functions of
time were routed through the system thus creating dynamic demand on flow discharge equipment.
Recorded frequencies of overtopping occurrences provided good approximation of probabilities of
failures due to overtopping.},
  file        = {:Risk\\System approach and simulation in risk assessment of dams ICOLD 2017 Andy Z et al 371.pdf:PDF;:Risk\\6 icold-2017- Risk WS Canada.pdf:PDF},
  owner       = {jquebbeman},
  timestamp   = {2017-09-05},
}

@Book{Leveson2012,
  title     = {Engineering a Safer World - Systems Thinking Applied to Safety},
  publisher = {MIT Press},
  year      = {2012},
  author    = {Nancy Leveson},
  abstract  = {Engineering has experienced a technological revolution, but the basic engineering techniques applied in safety and reliability engineering, created in a simpler, analog world, have changed very little over the years. In this groundbreaking book, Nancy Leveson proposes a new approach to safety—more suited to today’s complex, sociotechnical, software-intensive world—based on modern systems thinking and systems theory. Revisiting and updating ideas pioneered by 1950s aerospace engineers in their System Safety concept, and testing her new model extensively on real-world examples, Leveson has created a new approach to safety that is more effective, less expensive, and easier to use than current techniques.

Arguing that traditional models of causality are inadequate, Leveson presents a new, extended model of causation (Systems-Theoretic Accident Model and Processes, or STAMP), then then shows how the new model can be used to create techniques for system safety engineering, including accident analysis, hazard analysis, system design, safety in operations, and management of safety-critical systems. She applies the new techniques to real-world events including the friendly-fire loss of a U.S. Blackhawk helicopter in the first Gulf War; the Vioxx recall; the U.S. Navy SUBSAFE program; and the bacterial contamination of a public water supply in a Canadian town. Leveson’s approach is relevant even beyond safety engineering, offering techniques for “reengineering” any large sociotechnical system to improve safety and manage risk.},
  file      = {:Risk\\Engineering a Safer World.pdf:PDF},
  keywords  = {risk},
  owner     = {jquebbeman},
  timestamp = {2017-09-09},
}

@TechReport{Nathan2013,
  author      = {Rory Nathan and Erwin Weinmann},
  title       = {Autralian Rainfall And Runoff Discussion Paper: Monte Carlo Simulation Techniques},
  institution = {Engineers Australia},
  year        = {2013},
  abstract    = {Current practice for estimation of design floods is typically based on the “design event”
approach, in which all parameters other than rainfall are input as fixed, single values.
Considerable effort is made to ensure that the single values of the adopted parameters are
selected with the objective of ensuring that the resulting flood has the same annual exceedance
probability as its causative rainfall.
Monte Carlo simulation offers an alternative to the design event method. This approach
recognises that any design flood characteristics (e.g. peakflow) could result from a variety of
combinations of flood producing factors, rather than from a single combination. The approach
mimics “mother nature” in that the influence of all probability distributed inputs are explicitly
considered, thereby providing a more realistic representation of the flood generation processes.
This report describes the practical implementation of Monte-Carlo techniques for flood
estimation. The discussion focuses on the manner in which the current (ARR) guidelines and
available design information can be used to take into account the natural variability of the inputs,
and presents the concepts in a manner that can be implemented in a spreadsheet. While it
would be possible to directly employ these techniques with existing models, this guidance
should also be found helpful to those using Monte Carlo frameworks that are available in the
public domain.},
  file        = {:Risk\\Autralian Rainfall And Runoff Discussion Paper- Monte Carlo Simulation Techniques.pdf:PDF},
  owner       = {jquebbeman},
  timestamp   = {2017-09-12},
}

@Article{Nathan2016,
  author    = {Rory Nathan and Phillip Jordan and Matthew Scorah and Simon Lang and George Kuczera and Melvin Schaefer and Erwin Weinmann},
  title     = {Estimating the exceedance probability of extreme rainfalls up to the probable maximum precipitation},
  journal   = {Journal of Hydrology},
  year      = {2016},
  volume    = {543},
  pages     = {706 - 720},
  issn      = {0022-1694},
  abstract  = {If risk-based criteria are used in the design of high hazard structures (such as dam spillways and nuclear power stations), then it is necessary to estimate the annual exceedance probability (AEP) of extreme rainfalls up to and including the Probable Maximum Precipitation (PMP). This paper describes the development and application of two largely independent methods to estimate the frequencies of such extreme rainfalls. One method is based on stochastic storm transposition (SST), which combines the “arrival” and “transposition” probabilities of an extreme storm using the total probability theorem. The second method, based on “stochastic storm regression” (SSR), combines frequency curves of point rainfalls with regression estimates of local and transposed areal rainfalls; rainfall maxima are generated by stochastically sampling the independent variates, where the required exceedance probabilities are obtained using the total probability theorem. The methods are applied to two large catchments (with areas of 3550km2 and 15,280km2) located in inland southern Australia. Both methods were found to provide similar estimates of the frequency of extreme areal rainfalls for the two study catchments. The best estimates of the AEP of the PMP for the smaller and larger of the catchments were found to be 10−7 and 10−6, respectively, but the uncertainty of these estimates spans one to two orders of magnitude. Additionally, the SST method was applied to a range of locations within a meteorologically homogenous region to investigate the nature of the relationship between the AEP of PMP and catchment area.},
  doi       = {http://dx.doi.org/10.1016/j.jhydrol.2016.10.044},
  file      = {:Risk\\Estimating the exceedance probability of extreme rainfalls up to the probable maximum precipitation.pdf:PDF},
  keywords  = {Stochastic storm transposition, Probable Maximum Precipitation, Annual exceedance probability, Extreme rainfalls},
  owner     = {jquebbeman},
  timestamp = {2017-09-12},
  url       = {http://www.sciencedirect.com/science/article/pii/S0022169416306898},
}

@TechReport{Swain2004,
  author      = {Robert E. Swain and John F. England, Jr. and Kenneth L. Bullard and David A. Raff},
  title       = {Hydrologic Hazard Curve Estimating Procedures},
  institution = {United States Bureau of Reclamation},
  year        = {2004},
  number      = {DSO-04-08},
  month       = {jun},
  file        = {:Risk\\Hydrologic Hazard Curve Estimating Procedures.pdf:PDF},
  keywords    = {risk},
  owner       = {jquebbeman},
  timestamp   = {2017-09-12},
}

@Article{Davis2008,
  author    = {Davis, Darryl and Faber, Beth A. and Stedinger, Jery R.},
  title     = {USACE Experience in Implementing Risk Analysis for Flood Damage Reduction Projects},
  journal   = {Journal of Contemporary Water Research \& Education},
  year      = {2008},
  volume    = {140},
  number    = {1},
  pages     = {3--14},
  issn      = {1936-704X},
  doi       = {10.1111/j.1936-704X.2008.00023.x},
  file      = {:Risk\\USACE Experience in Implementing Risk Analysis for Flood Damage Reduction Projects.pdf:PDF},
  owner     = {jquebbeman},
  publisher = {Blackwell Publishing Ltd},
  timestamp = {2017-09-12},
  url       = {http://dx.doi.org/10.1111/j.1936-704X.2008.00023.x},
}

@MastersThesis{Schaffer2015,
  author    = {Jennifer Lynn Schaffer},
  title     = {Performance of a Sampling Stochastic Dynamic Programming Algorithm with Various Inflow Scenario Generation Methods},
  school    = {University of British Columbia},
  year      = {2015},
  abstract  = {We present the implementation of a Sampling Stochastic Dynamic Programming (SSDP)
algorithm to maximize water value, while meeting consumer demand for the BC Hydro
hydroelectric system in British Columbia, Canada. The implementation includes power
generation facilities on the Columbia and Peace River systems.
Variability of natural streamflow into a reservoir is a major source of uncertainty when
developing reservoir operation policies and determining the value of water within a system.
This study investigates SSDP model performance with various hydrologic inputs. Sixty
years of historical data are used to generate hydrologic scenarios comprised of inflow and
forecast sequences as input to the SSDP model. Scenario types studied include historical
record data, inflows and forecasts generated from an autoregressive lag-1 model, and BC
Hydro ensemble streamflow prediction forecasts.
We present results of our implementation of the SSDP algorithm including a discussion on
improved reservoir operation policy and the future value of water with various hydrologic
inputs. We also present our investigation of the marginal value of water with the evolution
of forecasts. Results indicate that forecasts are most valuable in determining the value of
water during the early freshet, and the value added from updating future forecasts diminishes
as the time in which the forecast is made progresses through the melting period.},
  file      = {:Optimization\\Performance of a Sampling Stochastic Dynamic Programming Algorithm with Various Inflow Scenario Generation Methods.pdf:PDF},
  owner     = {jquebbeman},
  timestamp = {2017-09-28},
}

@TechReport{Hellmuth2017,
  author      = {Molly Hellmuth and Pamela Cookson and Joanne Potter},
  title       = {Addressing Climate Vulnerability for Power System Resilience and Energy Security: A Focus on Hydropower Resources},
  institution = {USAID},
  year        = {2017},
  file        = {:Hydropower\\2017_RALI_Addressing Climate Vulnerability for Power System Resilience & Energy Security_Hydropower White Paper.pdf:PDF},
  owner       = {jquebbeman},
  timestamp   = {2017-10-10},
}

@TechReport{Safaie2017,
  author      = {Sahar Safaie},
  title       = {Words into Action Guidelines - National Disaster Risk Assessment},
  institution = {United Nations Office for Disaster Risk Reduction (UNISDR)},
  year        = {2017},
  abstract    = {A holistic risk assessment that considers all relevant hazards and
vulnerabilities, both direct and indirect impacts, and a diagnosis of the sources
of risk will support the design of policies and investments that are efficient
and effective in reducing risk.
During the decade of the Hyogo Framework for Action 2005-2015, substantial
progress was made in advancing science and technology, developing tools for
hazard and risk assessment, and producing risk information at different levels
and scales across the world.
Nevertheless, major gaps still exist in risk information quality and availability
for various applications. And more importantly, the challenge remains for
decision makers to use the available information in policy design and
investment.
In the Sendai Framework for Disaster Risk Reduction 2015-2030,
understanding disaster risk is the first priority for action:
 “policies and practices for disaster risk management should be based
on an understanding of disaster risk in all its dimensions of
vulnerability, capacity, exposure of persons and assets, hazard
characteristics and the environment.”
In 2016 the United Nations Office for Disaster Risk Reduction (UNISDR)
commissioned the development of guidelines on national disaster risk
assessment (NDRA) as part of a series of thematic guidelines under its “Words
into Action” initiative to support national implementation of the Sendai
Framework for Disaster Risk Reduction 2015-2030. 1
The present Guidelines are the result of the collaboration between over 100
leading experts from national authorities, international organizations, nongovernmental
organizations, academia, think tanks and private-sector
entities. They focus on Sendai Framework’s first Priority for Action:
Understanding Disaster Risk, which is the basis for all measures on disaster
risk reduction and is closely linked to the other three Priorities for Action. },
  file        = {:Risk\\Words into Action Guidelines - National Disaster Risk Assessment.pdf:PDF},
  owner       = {jquebbeman},
  timestamp   = {2017-10-20},
}

@Article{Wilson1931,
  author    = {Edwin B. Wilson and Margaret M. Hilferty},
  title     = {The Distribution of Chi-Square},
  journal   = {Proceedings of the National Academy of Sciences of the United States of America},
  year      = {1931},
  volume    = {17},
  number    = {12},
  pages     = {684--688},
  file      = {:Statistics\\The Distribution of Chi-Square.pdf:PDF},
  owner     = {jquebbeman},
  timestamp = {2017-10-22},
}

@Article{Newton1994,
  author    = {Michael A. Newton and Adrian E. Raftery},
  title     = {Approximate Bayesian Inference with the Weighted Likelihood Bootstrap},
  journal   = {Journal of Royal Statistical Society},
  year      = {1994},
  volume    = {56},
  number    = {1},
  pages     = {3-48},
  file      = {:Statistics\\Approximate Bayesian Inference with the Weighted Likelihood Bootstrap.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2017-11-06},
}

@Unpublished{Vehtari2017,
  author    = {Aki Vehtari},
  title     = {Extreme value analysis and user defined probability functions in Stan},
  month     = nov,
  year      = {2017},
  abstract  = {This notebook demonstrates how to implement user defined probability functions in Stan language. As a an
example I use generalized Pareto distribution (GPD) and geomagnetic storm data by World Data Center for
Geomagnetism.},
  file      = {:Statistics\\Extreme value analysis and user defined probability functions in Stan.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2017-11-09},
}

@TechReport{Waskom2014,
  author      = {Reagan Waskom and Masih Akhbari and Neil Grigg},
  title       = {U.S. Perspective on the Water-Energy-Food Nexus},
  institution = {Colorado Water Institute},
  year        = {2014},
  number      = {Completion Report No. 116},
  file        = {:WaterResources\\U.S. Perspective on the Water-Energy-Food Nexus.pdf:PDF},
  keywords    = {Water-Energy-Food Nexus, WEF},
  owner       = {quebbs},
  timestamp   = {2017-11-13},
}

@Book{Geron2017,
  title     = {Hands-On Machine Learning with Scikit-Learn and TensorFlow},
  publisher = {O'Reilly Media},
  year      = {2017},
  author    = {Aurélien Géron},
  edition   = {3rd},
  month     = mar,
  abstract  = {Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how.
By using concrete examples, minimal theory, and two production-ready Python frameworks—scikit-learn and TensorFlow—author Aurélien Géron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You’ll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what you’ve learned, all you need is programming experience to get started.
Explore the machine learning landscape, particularly neural nets
Use scikit-learn to track an example machine-learning project end-to-end
Explore several training models, including support vector machines, decision trees, random forests, and ensemble methods
Use the TensorFlow library to build and train neural nets
Dive into neural net architectures, including convolutional nets, recurrent nets, and deep reinforcement learning
Learn techniques for training and scaling deep neural nets
Apply practical code examples without acquiring excessive machine learning theory or algorithm details},
  owner     = {quebbs},
  timestamp = {2017-11-19},
}

@Article{Bogner2016,
  author   = {Konrad Bogner and Katharina Liechti and Massimiliano Zappa},
  title    = {Post-Processing of Stream Flows in Switzerland with an Emphasis on Low Flows and Floods},
  journal  = {Water},
  year     = {2016},
  volume   = {8},
  number   = {115},
  abstract = {Post-processing has received much attention during the last couple of years within the hydrological community, and many different methods have been developed and tested, especially in the field of flood forecasting. Apart from the different meanings of the phrase ``post-processing'' in meteorology and hydrology, in this paper, it is regarded as a method to correct model outputs (predictions) based on meteorological (1) observed input data, (2) deterministic forecasts (single time series) and (3) ensemble forecasts (multiple time series) and to derive predictive uncertainties. So far, the majority of the research has been related to floods, how to remove bias and improve the forecast accuracy and how to minimize dispersion errors. Given that global changes are driving climatic forces, there is an urgent need to improve the quality of low-flow predictions, as well, even in regions that are normally less prone to drought. For several catchments in Switzerland, different post-processing methods were tested with respect to low stream flow and flooding conditions. The complexity of the applied procedures ranged from simple AR processes to more complex methodologies combining wavelet transformations and Quantile Regression Neural Networks (QRNN) and included the derivation of predictive uncertainties. Furthermore, various verification methods were tested in order to quantify the possible improvements that could be gained by applying these post-processing procedures based on different stream flow conditions. Preliminary results indicate that there is no single best method, but with an increase of complexity, a significant improvement of the quality of the predictions can be achieved. },
  file     = {:Ensembles\\Post-Processing of Stream Flows in Switzerland with an Emphasis on Low Flows and Floods.pdf:PDF},
  keywords = {error correction; forecasts; floods; droughts; wavelets; neural nets; quantile regression; predictive uncertainty},
}

@TechReport{Priya2017,
  author      = {Satya Priya and William Young and Thomas Hopson and Ankit Avasthi},
  title       = {Flood Risk Assessment and Forecasting for the Ganges-Brahmaputra-Meghna River Basins},
  institution = {World Bank},
  year        = {2017},
  month       = nov,
  abstract    = {This report summarizes recent analytical work on flood risk management in South Asia
through the implementation of transboundary knowledge generation and sharing. The work
included two distinct but linked activities, conducted with the support of the South Asia
Water Initiative (SAWI; http://www.worldbank.org/en/programs/sawi)
• A transboundary flood risk assessment for the Ganges River basin
• An improved transboundary flood forecasting system for the Ganges-BrahmaputraMeghna
basins
These activities are more fully described in the original technical publications:
• Flood Risk Assessment for the Ganges Basin in South Asia: Final Report, Volume I
(technical report) and Volume II (risk atlas) (RMSI 2016a, 2016b)
• Evaluation of Flood Forecasting Predictability: Technical Report (Hopson and Priya
2017)
The reports and tools from these studies are available to guide flood planning and the
development of operational platforms for flood forecasting, decision support, and early
warning systems. For more information, including the original technical documents, see
http://documents.worldbank.org/curated/en/docsearch?query=P153299.
South Asia is one of the world’s most disaster-prone regions, with floods posing a severe
threat. In 2015, South Asia accounted for nearly two-thirds of the global fatalities
attributed to natural disasters. Floods were the most frequent cause, and economic
impacts were severe and widespread. The people most affected by flood impacts are the
poor and vulnerable, especially women and children.
Two new contributions to reducing flood risk in South Asia are now available: a flood risk
assessment for the Ganges River basin and an improved flood forecasting system for the
Ganges-Brahmaputra-Meghna basins. Both projects provide information directly to
decision makers and other stakeholders through interactive online displays, and both
have developed methods that could be applied to other river basins. Flood risk assessment
and flood forecasting are essential elements of managing flood risks in order to save lives,
livelihoods, and assets.
Integrated flood management and people-focused, end-to-end early warning systems are
key to reducing flood losses. In transboundary river basins, some elements require
international cooperation. Integrated flood management simultaneously considers water
resources, land use, and risk management in order to minimize flood losses while also
allowing for flood benefits. Operational end-to-end warning systems include the building
of risk knowledge and response capabilities, real-time monitoring and forecasting of
rainfall and river conditions, expert translation of forecasts into targeted warning
messages, dissemination and communication of warnings to community members, and
people’s responses to the warnings. Both approaches are adaptive, with formal monitoring
of outcomes (including user feedback) and the charting of course corrections as needed.},
  file        = {:WaterResources\\Flood Risk Assessment and Forecasting for the Ganges-Brahmaputra-Meghna River Basins.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2017-11-19},
}

@TechReport{Sayers2013,
  author      = {Paul Sayers and Li Yuanyuan and Gerry Galloway and Edmund Penning-Rowsell and Shen Fuxin and Wen Kang and Chen Yiwei and Tom Le Quesne},
  title       = {Flood Risk Management: A Strategic Approach},
  institution = {UNESCO},
  year        = {2013},
  abstract    = {The concepts of flood risk management (FRM) have been widely
embraced over the past decade. In many instances this conceptual
acceptance has resulted in changes to decision-making practice,
highlighting risk management as potentially more complex, but
more efficient and effective in delivering multiple goals, than a
traditional engineering standards-based approach.
In particular, the emergence of strategic FRM is enabling a longerterm,
catchment-wide perspective to emerge. The decision process
is based on an explicit trade-off of the whole life-cycle risks reduced,
opportunities promoted and the resources required. In doing so,
the advantages of adopting a portfolio of integrated multisector
responses (including structural and nonstructural measures as well
as policy instruments), have moved centre stage.
A brief history of flood risk
management
The earliest civilizations recognized the need to live alongside
floods; locating critical infrastructure on the highest land
(as seen through the churches and cathedrals of England),
providing flood warnings to those who were at risk of being
flooded (common practice in ancient Egypt), and making
flood-sensitive land use planning choices (as practised by the
Romans).
The requirement for protection and a belief in people’s ability
to control floods started increasingly to dominate attempts
to deal with flooding. During the early part of the twentieth
century the concepts of modern FRM began to emerge, and
in particular, those recognizing flood management not only
as an engineering pursuit but also as a social endeavour.
Throughout the 1960s to 1980s, the principal means of
mitigating the impacts of floods remained physical flood
control (via the construction of levees, dykes, diversion
channels, dams and related structures). As populations grew
and flood plains were developed, flood losses continued to
increase, and the need to do things differently became more
apparent. A new approach was needed, one that utilized the
concept of risk in decision-making in practice and not just
in theory},
  file        = {:WaterResources\\Flood Risk Management.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2017-11-20},
}

@Book{Earle2015,
  title     = {Transboundary Water Management and the Climate Change Debate},
  publisher = {Routledge},
  year      = {2015},
  author    = {Anton Earle and Ashok Swain and Anders Jägerskog and Stina Hansson and Ana Elisa Cascao and Joakim Öjendal},
  abstract  = {Despite three decades of warnings and declarations, the global water crisis
remains one of the unresolved and huge challenges to humankind. In fact, the
water crisis is of such a magnitude that it is growing into an issue of a common
global concern. And this situation is bound to get worse. Besides the obvious
poverty creation inherited in, and development impediments held up by water
scarcity, recent research is pointing out that inequality in water access is turning
into political repression, gendered violence, and identity conﬂicts.
This perspective highlights transboundary water management (TWM): nearly
50 per cent of the global fresh water is to be found in 276 transboundary river
basins; in Africa, it reaches 90 per cent, making the continent’s development
efforts hostage to effective governance of the shared water. The path to enhanced
river basin management consists of two interwoven braids: knowledge (which
we lack) and politics (which we do not understand).
Whatever the knowledge and understanding we do have, the existing agreements/regimes over transboundary rivers are increasingly turning volatile
because of increased outtake and rendered unworkable due to the perception
that global climate change (GCC) is altering the basic parameters for water
governance. Whether physically correct or not – irrespective of which future
scenario we apply – perceptions of GCC are undermining existing agreements, or are even instrumentally used to undermine the current water regime.
Decreased river runoff is blamed on high evaporation rates or shifting rainfall
patterns, while glacier lake outbursts seriously threaten water storage projects.
Whereas governance and accountability always is an important couplet, in the
international arena, GCC plays right into the securitization of transboundary
water resources feeding a situation of non-transparency and non-cooperation.},
  file      = {:WaterResources\\Transboundary Water Management and the Climate Change Debate.pdf:PDF},
  keywords  = {UNESCO},
  owner     = {quebbs},
  timestamp = {2017-11-20},
}

@Article{Eddy2017a,
  author    = {Michele C. Eddy and Fekadu G. Moreda and Robert M. Dykes and Brandon Bergenroth and Aaron Parks and James Rineer},
  title     = {The Watershed Flow and Allocation Model: An NHDPlus-Based Watershed Modeling approach for multiple scales and conditions},
  journal   = {Journal of American Water Resources Association},
  year      = {2017},
  volume    = {53},
  number    = {1},
  month     = feb,
  abstract  = {The Watershed Flow and Allocation model (WaterFALL) provides segment-specific, daily streamflow at both gaged and ungaged locations to generate the hydrologic foundation for a variety of water resources
management applications. The model is designed to apply across the spatially explicit and enhanced National
Hydrography Dataset (NHDPlus) stream and catchment network. To facilitate modeling at the NHDPlus catchment scale, we use an intermediate-level rainfall-runoff model rather than a complex process-based model. The
hydrologic model within WaterFALL simulates rainfall-runoff processes for each catchment within a watershed
and routes streamflow between catchments, while accounting for withdrawals, discharges, and onstream reservoirs within the network. The model is therefore distributed among each NHDPlus catchment within the larger
selected watershed. Input parameters including climate, land use, soils, and water withdrawals and discharges
are georeferenced to each catchment. The WaterFALL system includes a centralized database and server-based
environment for storing all model code, input parameters, and results in a single instance for all simulations
allowing for rapid comparison between multiple scenarios. We demonstrate and validate WaterFALL within
North Carolina at a variety of scales using observed streamflows to inform quantitative and qualitative measures, including hydrologic flow metrics relevant to the study of ecological flow management decisions.},
  file      = {:Hydrology\\The Watershed Flow and Allocation Model- An NHDPlus-Based Watershed Modeling approach for multiple scales and conditions.pdf:PDF},
  keywords  = {surface water hydrology; simulation; modeling; watershed management; water resources; NHDPlus; GWLF},
  owner     = {quebbs},
  timestamp = {2017-11-22},
}

@Article{Castilla-Rho2015,
  author    = {J.C. Castilla-Rho and G. Mariethoz and R. Rojas and M.S. Andersen and B.F.J. Kelly},
  title     = {An agent-based platform for simulating complex human–aquifer interactions in managed groundwater systems},
  journal   = {Environmental Modelling \& Software},
  year      = {2015},
  volume    = {73},
  number    = {Supplement C},
  pages     = {305 - 323},
  issn      = {1364-8152},
  abstract  = {Abstract This paper presents and illustrates FlowLogo, an interactive modelling environment for developing coupled agent-based groundwater models (GW-ABMs). It allows users to simulate complex socio-environmental couplings in groundwater systems, and to explore how desirable patterns of groundwater and social development can emerge from agent behaviours and interactions. GW-ABMs can be developed using a single piece of software, addressing common issues around data transfer and model analyses that arise when linking ABMs to existing groundwater codes. FlowLogo is based on a 2D finite-difference solution of the governing groundwater flow equations and a set of procedures to represent the most common types of stresses and boundary conditions of regional aquifer flow. The platform is illustrated using a synthetic example of an expanding agricultural region that depends on groundwater for irrigation. The implementation and analysis of scenarios from this example highlight the possibility to: (i) deploy agents at multiple scales of decision-making (farmers, waterworks, institutions), (ii) model feedbacks between agent behaviours and groundwater dynamics, and (iii) perform sensitivity and multi-realisation analyses on social and physical factors. The FlowLogo interface allows interactively changing parameters using ‘tuneable’ dials, which can adjust agent decisions and policy levers during simulations. This flexibility allows for live interaction with audiences (role-plays), in participatory workshops, public meetings, and as part of learning activities in classrooms. FlowLogo's interactive features and ease of use aim to facilitate the wider dissemination and independent validation of GW-ABMs.},
  doi       = {https://doi.org/10.1016/j.envsoft.2015.08.018},
  file      = {:Hydrology/Groundwater/An agent-based platform for simulating complex human–aquifer interactions in managed groundwater systems.pdf:PDF},
  keywords  = {Agent-based models, NetLogo, Groundwater management, Social simulation, Complexity, Participatory modelling},
  owner     = {quebbs},
  timestamp = {2017-12-06},
  url       = {http://www.sciencedirect.com/science/article/pii/S136481521530044X},
}

@Unpublished{Young2017,
  author    = {Mike Young and Bryce McAteer},
  title     = {Sharing-Groundwater- A robust framework and implementaiton roadmap for sustainable groundwater management in California},
  note      = {Sustainable Groundwater Management Act (SGMA), Duke University},
  year      = {2017},
  file      = {:Hydrology\\Groundwater\\Sharing-Groundwater- A robust framework and implementaiton roadmap for sustainable groundwater management in California.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2017-12-12},
}

@Article{Marani2015,
  author    = {Marco Marani and Massimiliano Ignaccolo},
  title     = {A metastatistical approach to rainfall extremes},
  journal   = {Advances in Water Resources},
  year      = {2015},
  volume    = {79},
  pages     = {121--126},
  abstract  = {The traditional statistical theory of extreme events assumes an asymptotic regime in which the number
of events per year is large enough for a limiting Generalized Extreme Value distribution to apply. This has
been shown not to be applicable to many practical cases. We introduce here a Metastatistical Extreme
Value (MEV) approach which is defined in terms of the distribution of the statistical parameters describing ‘‘ordinary’’ daily rainfall occurrence and intensity. The method does not require an asymptotic
assumption, and naturally accounts for the influence of the bulk of the distribution of ordinary events
on the distribution of annual maximum daily rainfall. Building on existing observations showing the distribution of daily rainfall to be Weibull right-tail equivalent, the MEV approach is then specialized to yield
a compact and easily applicable formulation. We apply this formulation to Monte Carlo experiments
based on Weibull statistics derived from the 3-century long rainfall time series observed in Padova
(Italy). We find an excellent agreement between MEV estimates and the ‘observed’ frequency of occurrence of extreme events in the synthetic time series generated. GEV and Gumbel estimates, on the contrary, exhibit systematic errors. Tests with different rates of occurrence of rainfall events show slight
improvements of the GEV and Gumbel estimation bias when the number of events/year is increased.
However, a constant bias in GEV and Gumbel estimates is seen for (synthetic) climates where the number
of events and the distribution of intensities is varied stochastically. The estimation root mean square
error is also larger for the GEV and Gumbel distributions than for the MEV approach. Hence, GEV and
Gumbel quantile estimates are more likely to be further away from the actual value than MEV estimates.
Finally, the application of the new MEV approach to subsets of the long Padova time series identifies
marked variabilities in rainfall extremes at the centennial time scale.},
  file      = {:Hydrology\\Precipitation\\A metastatistical approach to rainfall extremes.pdf:PDF},
  keywords  = {Extreme events, Generalized Extreme Value distribution (GEV), Metastatistics},
  owner     = {quebbs},
  timestamp = {2017-12-13},
}

@Article{Whelan2014,
  author    = {Gene Whelan and Keewook Kim and Mitch A. Pelton and Karl J. Castleton and Gerard F. Laniak and Kurt Wolfe and Rajbir Parmar and Justin Babendreier and Michael Galvin},
  title     = {Design of a component-based integrated environmental modeling framework},
  journal   = {Environmental Modelling \& Software},
  year      = {2014},
  volume    = {55},
  number    = {Supplement C},
  pages     = {1 - 24},
  issn      = {1364-8152},
  abstract  = {Abstract Integrated environmental modeling (IEM) includes interdependent science-based components that comprise an appropriate software modeling system and are responsible for consuming and producing information as part of the system, but moving information from one component to another (i.e., interoperability) is the responsibility of the IEM software system. We describe and discuss the Framework for Risk Analysis in Multimedia Environmental Systems (FRAMES), a component-based IEM system, from the standpoint of software design requirements which define system functionalities. Design requirements were identified in a series of workshops, attended by IEM practitioners, and reported in the development of a number of IEM software systems. The requirements cover issues associated with standards, component connectivity, linkage protocols, system architecture and functionality, and web-based access, all of which facilitate the creation of plug & play components from stand-alone models through a series of software support tools and standards.},
  doi       = {https://doi.org/10.1016/j.envsoft.2014.01.016},
  file      = {:Programs\\Design of a component-based integrated environmental modeling framework.pdf:PDF},
  keywords  = {Integrated environmental modeling, Multimedia modeling, IEM, Risk assessment, FRAMES},
  owner     = {quebbs},
  timestamp = {2017-12-13},
  url       = {http://www.sciencedirect.com/science/article/pii/S1364815214000267},
}

@Article{Morway2016,
  author    = {Eric D. Morway and Richard G. Niswonger and Enrique Triana},
  title     = {Toward improved simulation of river operations through integration with a hydrologic model},
  journal   = {Environmental Modelling \& Software},
  year      = {2016},
  volume    = {82},
  pages     = {255--274},
  abstract  = {Advanced modeling tools are needed for informed water resources planning and management. Two
classes of modeling tools are often used to this ende(1) distributed-parameter hydrologic models for
quantifying supply and (2) river-operation models for sorting out demands under rule-based systems
such as the prior-appropriation doctrine. Within each of these two broad classes of models, there are
many software tools that excel at simulating the processes specific to each discipline, but have historically
over-simplified, or at worse completely neglected, aspects of the other. As a result, water managers
reliant on river-operation models for administering water resources need improved tools for representing
spatially and temporally varying groundwater resources in conjunctive-use systems. A new tool
is described that improves the representation of groundwater/surface-water (GW-SW) interaction within
a river-operations modeling context and, in so doing, advances evaluation of system-wide hydrologic
consequences of new or altered management regimes.},
  file      = {:Programs\\Toward improved simulation of river operations through integration with a hydrologic model.pdf:PDF},
  keywords  = {Conjunctive use Groundwateresurface water interaction MODFLOW MODSIM River-operations modeling Integrated environmental modeling (IEM)},
  owner     = {quebbs},
  timestamp = {2017-12-16},
}

@Article{Hanasz2017,
  author    = {Paula Hanasz},
  title     = {Muddy Waters: International Actors and Transboundary Water Cooperation in the Ganges-Brahmaputra Problemshed},
  journal   = {Water Alternatives},
  year      = {2017},
  volume    = {10},
  number    = {2},
  pages     = {459--474},
  abstract  = {The portion of the Ganges-Brahmaputra-Meghna mega-basin shared between Nepal, Bhutan,
northern India, and Bangladesh is one of the poorest, most densely populated, ecologically vulnerable, and
socially and politically unstable areas in the world. As such, reducing the potential for transboundary water
conflict by increasing cooperation between riparian states has been of increasing interest to policy-makers and
foreign aid donors.
The World Bank-led South Asia Water Initiative (SAWI) commenced in the mid-2000s. Yet, in more than a decade
of existence, neither SAWI nor other international initiatives, have been able to improve transboundary water
interactions between India, Nepal, Bhutan and Bangladesh. In part this is because of the sheer complexity of
transboundary water governance, and in part because of contextual factors. Addressing transboundary water
issues is not a priority for the riparian states; there is significant distrust between them and resentment about
India’s hydro-hegemony; and bilateral, rather than multilateral, arrangements prevail. These factors make
collective action both more urgent and more difficult. If they are to increase transboundary water cooperation,
international actors should, among other things, resolve historical grievances; strengthen water-sharing
institutions; build trust between riparian states; and work toward outcomes based on principles of water justice},
  comment   = {paula.hanasz@anu.edu.au},
  file      = {:WaterResources\\Muddy Waters- International Actors and Transboundary Water Cooperation in the Ganges-Brahmaputra Problemshed.pdf:PDF},
  keywords  = {Water conflict, water governance, foreign aid and investment, World Bank, South Asia},
  owner     = {quebbs},
  timestamp = {2018-01-01},
}

@Article{Sandoval-Solis2011,
  author    = {S. Sandoval-Solis and D. C. McKinney and D. P. Loucks},
  title     = {Sustainability Index for Water Resources Planning and Management},
  journal   = {Journal of Water Resources Planning and Management},
  year      = {2011},
  pages     = {381--390},
  abstract  = {This paper presents a water resources sustainability index that makes it possible to evaluate and compare different water
management policies with respect to their sustainability. The sustainability index identifies policies that preserve or improve the desired
water management characteristics of the basin in the future. This index is based on a previous sustainability index with improvements
in its structure, scale, and content to make it more flexible and adjustable to the requirements of each water user, type of use, and basin.
The Rio Grande transboundary basin is used as a case study demonstrating the use of the index. Tailor-made sustainability indexes are defined
for water users in Mexico, the United States, the environment, and for meeting system requirements (international treaty obligations). Group
sustainability indexes are calculated to summarize the results for groups of water users of each country, the environment, and the basin as a
whole. Sustainability indexes by subbasins are calculated to identify areas of potential improvement and regions at risk.},
  file      = {:WaterResources\\Sustainability Index for Water Resources Planning and Management.pdf:PDF},
  keywords  = {Sustainability index; Sustainable policies; Adaptive capacity; Water resources; Rio Grande},
  owner     = {quebbs},
  timestamp = {2018-02-06},
}

@Article{Doll2017,
  author    = {Petra Doll and Stefan Siebert},
  title     = {Global modeling of irrigation water requirements},
  journal   = {Water Resources Research},
  year      = {2017},
  volume    = {38},
  number    = {4},
  abstract  = {Currently, almost 90% of the global water consumption is for irrigation purposes, and more
than 40% of the crops are produced under irrigated conditions. In order to assess the future water
and food situation, it is therefore necessary to model irrigation water requirements. We present a
global model of irrigation requirements, which is based on a new raster map of irrigated areas. With
a spatial resolution of 0.5, the model simulates the cropping patterns, the growing seasons, and the
net and gross irrigation requirements, distinguishing two crops, rice and nonrice. Using long time
series of monthly climatic variables, the irrigation requirements under present-day climate
conditions are computed, and the impact of climate variability is analyzed. The correspondence
between model results and independent estimates of irrigation water use is judged to be good
enough for applying the model in global and continental studies},
  file      = {:WaterResources\\Global modeling of irrigation water requirements.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-02-20},
}

@Article{Vaghefi2013,
  author    = {S. Ashraf Vaghefi and S. J. Mousavi and K. C. Abbaspour and R. Srinivasan and J. R. Arnold},
  title     = {Integration of hydrologic and water allocation models in basinscale water resources management considering crop pattern and climate change: Karkheh River Basin in Iran},
  journal   = {Reg Environmental Change},
  year      = {2013},
  abstract  = {The paradigm of integrated water resources
management requires coupled analysis of hydrology and
water resources in a river basin. Population growth and
uncertainties due to climate change make historic data not
a reliable source of information for future planning of
water resources, hence necessitating climate and landuse
change impact studies. This work presents an integrated
modeling approach by linking Soil and Water Assessment
Tool (SWAT) and MODSIM. While SWAT produces
hydrologic and water resources information, MODSIM
provides a decision support system for water allocation.
We used the coupled SWAT–MODSIM to analyze the
effects of climate and cropping pattern changes on agricultural and hydroenergy production in the Karkheh River
Basin, a semiarid region in south-west of Iran. Cropping
patterns were considered by limiting the cereal production
to 50 % (S1, near to historic), 17 % (S2), and 83 % (S3) of
total agricultural areas. The future climate was provided by
the Canadian Global Coupled Model (CGCM 3.1 version
T63) for A1B, A2, and B1 scenarios. The results showed
that based on future climate changes and landuse scenarios,
wheat production had a large variation in five economically
important agricultural regions ranging from 33,000 ton
year-1 (S2-A1B) to 74,000 ton year-1 (S3-A2). Similarly,
energy production, while increasing from 614 to
1,100 GWH in A2, decreased from 614 to 464 GWH in B1
climate scenario. Our analyses indicate that cropping pattern change can be used as an effective tool to adapt to the
negative impacts of climate change},
  file      = {:Programs\\MODSIM\\Integration of hydrologic and water allocation models in basinscale water resources management considering crop pattern and climate change- Karkheh River Basin in Iran.pdf:PDF},
  keywords  = {Hydrologic modeling Climate change adaptation SWAT MODSIM},
  owner     = {quebbs},
  timestamp = {2018-02-26},
}

@TechReport{USBR2014a,
  author    = {USBR},
  title     = {MODSIM versus RiverWare: A comparative analysis of two river reservoir modeling tools},
  year      = {2014},
  number    = {Final Report 2014.3669},
  file      = {:Programs\\MODSIM\\MODSIM_versus_Riverware_A_comparative_analysis.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-02-26},
}

@Article{Nicholls2016,
  author    = {R.J. Nicholls and C.W. Hutton and A.N. Laz and A. Allan and W.N. Adger and H. Adams and J. Wolf and M. Rahman and M. Salehin},
  title     = {Integrated assessment of social and environmental sustainability dynamics in the Ganges-Brahmaputra-Meghna delta, Bangladesh},
  journal   = {Estuarine, Coastal and Shelf Science},
  year      = {2016},
  abstract  = {Deltas provide diverse ecosystem services and benefits for their populations. At the same time, deltas are
also recognised as one of the most vulnerable coastal environments, with a range of drivers operating at
multiple scales, from global climate change and sea-level rise to deltaic-scale subsidence and land cover
change. These drivers threaten these ecosystem services, which often provide livelihoods for the poorest
communities in these regions. The imperative to maintain ecosystem services presents a development
challenge: how to develop deltaic areas in ways that are sustainable and benefit all residents including
the most vulnerable. Here we present an integrated framework to analyse changing ecosystem services
in deltas and the implications for human well-being, focussing in particular on the provisioning
ecosystem services of agriculture, inland and offshore capture fisheries, aquaculture and mangroves that
directly support livelihoods. The framework is applied to the world's most populated delta, the GangesBrahmaputra-Meghna Delta within Bangladesh. The framework adopts a systemic perspective to
represent the principal biophysical and socio-ecological components and their interaction. A range of
methods are integrated within a quantitative framework, including biophysical and socio-economic
modelling and analyses of governance through scenario development. The approach is iterative, with
learning both within the project team and with national policy-making stakeholders. The analysis is used
to explore physical and social outcomes for the delta under different scenarios and policy choices. We
consider how the approach is transferable to other deltas and potentially other coastal areas.},
  file      = {:WaterResources\\Integrated assessment of social and environmental sustainability dynamics in the Ganges-Brahmaputra-Meghna delta, Bangladesh.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-02-26},
}

@Article{Pathak2018,
  author    = {Pathak, Tapan B. and Maskey, Mahesh L. and Dahlberg, Jeffery A. and Kearns, Faith and Bali, Khaled M. and Zaccaria, Daniele},
  title     = {Climate Change Trends and Impacts on California Agriculture: A Detailed Review},
  journal   = {Agronomy},
  year      = {2018},
  volume    = {8},
  number    = {3},
  abstract  = {California is a global leader in the agricultural sector and produces more than 400 types of commodities. The state produces over a third of the country’s vegetables and two-thirds of its fruits and nuts. Despite being highly productive, current and future climate change poses many challenges to the agricultural sector. This paper provides a summary of the current state of knowledge on historical and future trends in climate and their impacts on California agriculture. We present a synthesis of climate change impacts on California agriculture in the context of: (1) historic trends and projected changes in temperature, precipitation, snowpack, heat waves, drought, and flood events; and (2) consequent impacts on crop yields, chill hours, pests and diseases, and agricultural vulnerability to climate risks. Finally, we highlight important findings and directions for future research and implementation. The detailed review presented in this paper provides sufficient evidence that the climate in California has changed significantly and is expected to continue changing in the future, and justifies the urgency and importance of enhancing the adaptive capacity of agriculture and reducing vulnerability to climate change. Since agriculture in California is very diverse and each crop responds to climate differently, climate adaptation research should be locally focused along with effective stakeholder engagement and systematic outreach efforts for effective adoption and implementation. The expected readership of this paper includes local stakeholders, researchers, state and national agencies, and international communities interested in learning about climate change and California’s agriculture.},
  doi       = {10.3390/agronomy8030025},
  file      = {:Climate\\Climate Change Trends and Impacts on California Agriculture- A Detailed Review.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-03-01},
}

@TechReport{NEC2017,
  author      = {NEC},
  title       = {Draft North Eastern Council Regional Plan (2017-18 to 2019-20)},
  institution = {North Eastern Council},
  year        = {2017},
  abstract    = {Contents
Part I - Introduction and Funding of the NEC Plans
I. Introduction 4 – 9
II. Funding and Resources for the Plan 10 – 15
Part II - Infrastructure & Infrastructure-related Sectors 16
III. Transport & Communication Sector 17 – 22
IV. Power and Renewable Resources of Energy Sector 23 – 26
V. Irrigation, Flood Control & Water Shed Management Sector 27 – 29
VI. Industries & Banking Sector 30 – 32
VII. Tourism Sector 33 – 34
PART III - Other Sectors 35
VIII. Agriculture & Allied Sector 36 – 44
IX. Medical & Health Sector 45 – 51
X. Human Resources Development & Employment Sector 52 – 56
XI. Science & Technology Sector 57 – 61
XII. Information & Public Relations Sector 62 – 63
XIII. Evaluation & Monitoring Sector 65 – 67},
  file        = {:C\:\\Users\\jquebbeman\\Research Triangle Institute\\Northeast India Water Resources Management - Documents\\Background\\NEC\\Final Regional Plan NEC 25_04_2017.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-03-18},
}

@PhdThesis{Smith2017,
  author    = {Rebecca M. Smith},
  title     = {Co-production with Water Managers to Evaluate Multiobjective Evolutionary Algorithm (MOEA)-assisted Optimization for Long Term Water Utility Planning and Shape Future Research Agendas},
  school    = {University of Colorado},
  year      = {2017},
  abstract  = {Many promising tools and methods developed in water resources systems analysis research have
seen little uptake outside of academia. This may be due to a lack of effective communication about the
research to water managers, or it may be because the tools are not ultimately useful or usable in practice.
Current predominant research frameworks do not provide insight into these issues or facilitate the
incorporation of industry needs into research agendas.
This dissertation introduces a structured research approach called the Participatory Framework
for Assessment and Improvement of Tools (ParFAIT) that formally connects researchers and water
managers in purposeful, iterative exercises to educate about promising tools, evaluate their usefulness and
usability, and draw practitioner feedback into academic agendas. The process is founded on co-production
concepts and involves two workshops which are designed to ultimately result in: a broadly relatable
vehicle to demonstrate the tool (a testbed), practitioner feedback about the tool resulting from hands-on
workshop experience, tool-specific as well as more general industry context, and definitive suggestions
for increasing the relevance of future research.
ParFAIT is demonstrated by testing Multiobjective Evolutionary Algorithm (MOEA)-assisted
optimization for long term water utility planning with a group of Front Range, Colorado, water managers.
The first workshop informed the creation of the Eldorado Utility Planning Model, a complex but
hypothetical testbed designed to be widely relatable to participants. MOEA-assisted optimization was
performed on the testbed using workshop-informed formulations of planning decisions, objectives,
constraints, and planning scenarios. The optimization results formed the basis of a second workshop at
which managers worked directly with testbed output in structured activities and discussions
This ParFAIT study found that practitioners consider the information provided by MOEA-assisted
optimization to be useful for several aspects of their long term planning processes, but that there are 
important considerations for ensuring usability of the tool itself and its output. One important
consideration is the interpretation of complex MOEA results. Based on this feedback, this work presents a
novel application of Multivariate Regression Tree analysis to extract system insights from MOEAassisted
optimization results.},
  file      = {:RobustDM/Co-production with Water Managers to Evaluate Multiobjective Evolutionary Algorithm (MOEA)-assisted Optimization for long-term water utility planning and shape future research agendas.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-03-19},
}

@Article{Oedegaard2017,
  author        = {Heidi Liljeblad Ødegård and Jo Eidsvik and Stein-Erik Fleten},
  title         = {Value of information analysis of snow measurements for the scheduling of hydropower production},
  journal       = {Energy Systems},
  year          = {2017},
  month         = dec,
  __markedentry = {[quebbs:1]},
  abstract      = {The scheduling of a hydropower plant is challenging because of inflow
uncertainty. During spring there is increased uncertainty when the snow melts. By
gathering snow measurements, one learns more about the future inflow, and this might
lead to lower spillage risk or higher efficiency. In this paper the value of information
of snow measurements is studied. The value of information is representative of how
much a test is worth. If the price of acquiring and processing snow measurements
is less than the value of information, the test is worth doing. The notion of value
of information is also useful for comparing various kinds of snow measurements in
different situations. For scheduling a least squares Monte Carlo method is used in
this paper. The uncertain inflow is represented by discrete scenarios, while the timevarying spot price is assumed known. Data from a Norwegian power plant are used
to fit the inflow and snow distributions as well as prices, water reservoir limits and
production release alternatives. The numerical tests show that snow measurements
have little value when the reservoir is large compared to the total inflow. When the
reservoir is smaller, the probability of overflow is bigger, and the snow measurements
can be valuable for the scheduling when the data have high accuracy. The increase in
value by using the snow measurements is between 0 and 10% in the different parameter
settings considered here.},
  doi           = {10.1007/s12667-017-0267-3},
  file          = {:Hydropower\\Value of information analysis of snow measurements for the scheduling of hydropower production.pdf:PDF},
  keywords      = {Decision analysis · Hydropower planning · Least squares Monte Carlo Simulation and regression · Snow measurements · Value of information},
  owner         = {quebbs},
  timestamp     = {2018-04-06},
}

@Article{Rheinheimer2016,
  author        = {David E. Rheinheimer and Roger C. Bales and Carlos A. Oroza and Jay R. Lund and Joshua H. Viers},
  title         = {Valuing year-to-go hydrologic forecast improvements for a peaking hydropower system in the Sierra Nevada},
  journal       = {Water Resources Research},
  year          = {2016},
  volume        = {52},
  __markedentry = {[quebbs:1]},
  abstract      = {We assessed the potential value of hydrologic forecasting improvements for a snow-dominated highelevation hydropower system in the Sierra Nevada of California, using a hydropower optimization model.
To mimic different forecasting skill levels for inﬂow time series, rest-of-year inﬂows from regression-based
forecasts were blended in different proportions with representative inﬂows from a spatially distributed
hydrologic model. The statistical approach mimics the simpler, historical forecasting approach that is
still widely used. Revenue was calculated using historical electricity prices, with perfect price foresight
assumed. With current infrastructure and operations, perfect hydrologic forecasts increased annual hydropower revenue by $0.14 to $1.6 million, with lower values in dry years and higher values in wet years,
or about $0.8 million (1.2%) on average, representing overall willingness-to-pay for perfect information.
A second sensitivity analysis found a wider range of annual revenue gain or loss using different skill levels
in snow measurement in the regression-based forecast, mimicking expected declines in skill as the climate
warms and historical snow measurements no longer represent current conditions. The value of perfect
forecasts was insensitive to storage capacity for small and large reservoirs, relative to average inﬂow, and
modestly sensitive to storage capacity with medium (current) reservoir storage. The value of forecasts
was highly sensitive to powerhouse capacity, particularly for the range of capacities in the northern Sierra
Nevada. The approach can be extended to multireservoir, multipurpose systems to help guide investments
in forecasting.},
  file          = {:Hydropower\\Valuing year-to-go hydrologic forecast improvements for a peaking hydropower system in the Sierra Nevada.pdf:PDF},
  owner         = {quebbs},
  timestamp     = {2018-04-06},
}

@Article{Nepal2015,
  author    = {Santosh Nepal and Arun Bhakta Shrestha},
  title     = {Impact of climate change on the hydrological regime of the Indus, Ganges and Brahmaputra river basins: a review of the literature},
  journal   = {International Journal of Water Resources Development},
  year      = {2015},
  volume    = {31},
  number    = {2},
  pages     = {201-218},
  abstract  = { The Indus, Ganges and Brahmaputra river basins support 700 million people in Asia. The water resources are used for irrigation, drinking, industry, navigation and hydropower. This paper reviews the literature on the impact of climate change on the hydrological regime of these river basins and suggests that the different basins are likely to be affected in different ways. Climate change will have a marked affect on meltwater in the Indus Basin and may result in increased flood risk in the Brahmaputra Basin. The overall impact on annual discharge is likely to be low, but more studies are required to understand intra-annual changes and the impact of extreme events. },
  doi       = {10.1080/07900627.2015.1030494},
  eprint    = {https://doi.org/10.1080/07900627.2015.1030494},
  file      = {:Climate\\Impact of climate change on the hydrological regime of the Indus Ganges and Brahmaputra river basins.pdf:PDF},
  owner     = {quebbs},
  publisher = {Routledge},
  timestamp = {2018-04-09},
  url       = { 
        https://doi.org/10.1080/07900627.2015.1030494
    
},
}

@Article{Timilsina2016,
  author    = {Govinda R. Timilsina and Mike Toman},
  title     = {Potential gains from expanding regional electricity trade in South Asia},
  journal   = {Energy Economics},
  year      = {2016},
  volume    = {60},
  pages     = {6--14},
  month     = {nov},
  doi       = {10.1016/j.eneco.2016.08.023},
  file      = {:Hydropower\\Potential gains from expanding regional electricity trade in South Asia.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Timilsina2018,
  author   = {Govinda R. Timilsina And Michael A. Toman},
  title    = {Carbon Pricing and Cross-Border Electricity Trading for Climate Change Mitigation in South Asia},
  journal  = {Economics of Energy \& Environmental Policy},
  year     = {2018},
  volume   = {7},
  number   = {2},
  abstract = {South Asia’s electricity supply system is quite carbon-intensive, particularly due to
extensive use of coal. Under “business as usual,” that situation is expected to continue for several decades. Using an electricity system planning model, this study
investigates two complementary strategies to reduce CO2 emission intensity of the
power sector in South Asia: carbon pricing, and expansion of cross-border electricity trade to exploit clean energy resources, especially hydropower. The study fnds
that with a carbon tax imposed on fossil fuels used for power generation, CO2
emissions from the power sector would be 10% lower than that in the baseline over
2015–2040 even if the cross-border electricity transmission capacity is not expanded from the current level. On the other hand, if the cross-border transmission capacity is expanded to facilitate unlimited power trading across countries, the carbon tax would cause 16% reduction of regional power sector CO2 emissions from
the baseline. The regional electricity trade is not only benefcial economically as it
saves almost US$100 billion electricity supply cost in the region over 2015–2040,
but also an attractive option for climate change mitigation. The carbon tax would,
however, increase the power supply cost and could adversely impact consumers
unless the carbon tax revenue is used as a safeguard measure.},
  file     = {:Hydropower/Carbon Pricing and Cross-Border Electricity Trading for Climate Change Mitigation in South Asia.pdf:PDF;:Hydropower\\2018-NHA-Pumped-Storage-Report.pdf:PDF},
  keywords = {South Asia, carbon pricing, cross-border electricity trade, power sector},
}

@TechReport{USAID2018,
  author      = {USAID},
  title       = {Indonesia Costs of Climate Change 2050},
  institution = {USAID},
  year        = {2018},
  file        = {:Climate\\Indonesia Costs of Climate Change 2050.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-04-17},
}

@InProceedings{2018,
  title = {2018 Pumped Storage Report},
  year  = {2018},
  file  = {:Hydropower\\2018-NHA-Pumped-Storage-Report.pdf:PDF},
}

@Article{Walder1997,
  author   = {Walder, Joseph S., and Jim E. O’Connor},
  title    = {Methods for predicting peak discharge of floods caused and by failure of natural and constructed earthen dams},
  journal  = {Water Resources Research},
  year     = {1997},
  volume   = {33},
  number   = {10},
  pages    = {2337-2348},
  month    = oct,
  abstract = {Floods from failures of natural and constructed dams constitute a widespread hazard to people and property. Expeditious means of assessing flood hazards are necessary, particularly in the case of natural dams, which may form suddenly and unexpectedly. We revise statistical relations (derived from data for past constructed and natural dam failures) between peak discharge (Qp) and water volume released (V0) or drop in lake level (d) but assert that such relations, even when cast into a dimensionless form, are of limited utility because they fail to portray the effect of breach‐formation rate. We then analyze a simple, physically based model of dam‐breach formation to show that the hydrograph at the breach depends primarily on a dimensionless parameter η=kV0/gl/2d7/2, where k is the mean erosion rate of the breach and g is acceleration due to gravity. The functional relationship between Qp and η takes asymptotically distinct forms depending on whether η ≪ 1 (relatively slow breach formation or small lake volume) or η ≫ 1 (relatively fast breach formation or large lake volume). Theoretical predictions agree well with data from dam failures for which k, and thus η, can be estimated. The theory thus provides a rapid means of predicting the plausible range of values of peak discharge at the breach in an earthen dam as long as the impounded water volume and the water depth at the dam face can be estimated.},
  file     = {:Hydraulics\\Methods for Predicting Peak Discharge of Floods Caused by Failure of Natural and Constructed Earth Dams.pdf:PDF},
}

@Article{Jeuland2014,
  author   = {Marc Jeuland and Justin Baker and Ryan Bartlett and Guillaume Lacombe},
  title    = {The costs of uncoordinated infrastructure management in multi-reservoir river basins},
  journal  = {Environmental Research Letters},
  year     = {2014},
  volume   = {9},
  abstract = {Though there are surprisingly few estimates of the economic benefits of coordinated
infrastructure development and operations in international river basins, there is a widespread
belief that improved cooperation is beneficial for managing water scarcity and variability.
Hydro-economic optimization models are commonly-used for identifying efficient allocation of
water across time and space, but such models typically assume full coordination. In the real
world, investment and operational decisions for specific projects are often made without full
consideration of potential downstream impacts. This paper describes a tractable methodology for
evaluating the economic benefits of infrastructure coordination. We demonstrate its application
over a range of water availability scenarios in a catchment of the Mekong located in Lao PDR,
the Nam Ngum River Basin. Results from this basin suggest that coordination improves system
net benefits from irrigation and hydropower by approximately 3–12% (or US$12-53 million/yr)
assuming moderate levels of flood control, and that the magnitude of coordination benefits
generally increases with the level of water availability and with inflow variability. Similar
analyses would be useful for developing a systematic understanding of the factors that increase
the costs of non-cooperation in river basin systems worldwide, and would likely help to improve
targeting of efforts to stimulate complicated negotiations over water resources},
  doi      = {10.1088/1748-9326/9/10/105006},
  file     = {:WaterResources\\Cooperative_Frameworks\\The costs of uncoordinated infrastructure management in multi-reservoir river basins.pdf:PDF},
  keywords = {hydroeconomic models, water resources planning and management, cooperation, reservoir coordination, irrigation, hydropower, Mekong},
}

@Article{Lacombe2014,
  author    = {G. Lacombe, S. Douangsavanh, J. Baker, C.T. Hoanh, R. Bartlett, M. Jeuland and C. Phongpachith},
  title     = {Are hydropower and irrigation developoment complements or substitutes? The example of the Nam Ngum River in the Mekong Basin},
  journal   = {Water International},
  year      = {2014},
  volume    = {39},
  number    = {5},
  pages     = {649--670},
  doi       = {10.1080/02508060.2014.956205},
  file      = {:WaterResources\\Cooperative_Frameworks\\Are hydropower and irrigation developoment complements or substitutes - Lacombe et al. 2014 - Water International.pdf:PDF},
  owner     = {jquebbeman},
  timestamp = {2018-05-16},
}

@TechReport{Bartlett2012,
  author    = {Ryan Bartlett and Justin Baker and Guillaume Lacombe and Somphasith Douangsavanh and Marc Jeuland},
  title     = {Analyzing Economic Tradeoﬀs of Water Use in the Nam Ngum River Basin, Lao PDR},
  year      = {2012},
  abstract  = {This	paper	develops	a	hydro‐economic	optimization	modeling	framework	to	assess	the	economic	
consequences	and	potential	trade‐offs	of	various	infrastructure	development	and	policy	pathways	
in	the	Nam	Ngum	Basin	(Lao	PDR).	We	considered	whether	large	shifts	in	water	resource	demands	
in	a	relatively	water	abundant	basin	could	induce	meaningful	economic	trade‐offs	among	water	
uses,	including	hydropower	generation,	irrigation	expansion,	flood	control,	and	transboundary	
water	transfer	objectives.	We	constructed	a	series	of	sensitivity	scenarios	under	dry,	average,	and	
wet	hydrologic	conditions	with	varying	levels	dam	development,	irrigated	agricultural	expansion,	
agricultural	returns,	flood	control	storage	restrictions,	and	water	diversions	to	Northeast	Thailand.		
We	also	considered	how	flows	into	the	Mekong	would	be	affected	by	these	collective	developments.	
In	general,	results	indicate	that	tradeoffs	between	hydropower	production,	irrigation,	and	flood	
control	are	modest.	Hydropower	and	agricultural	expansion	are	found	to	be	complimentary	under	
high	levels	of	water	availability,	even	with	the	most	ambitious	level	of	irrigation	expansion.	
Allowing	for	flood	control	by	maintaining	reduced	storage	levels	in	the	reservoir	that	is	largest	and	
furthest	downstream	on	the	Nam	Ngum	(NN1)	has	a	minimal	effect	on	economic	output	and	
decreases	total	system	hydropower	by	less	than	1%.	However,	economic	outcomes	are	highly	
dependent	on	water	availability	and	economic	returns	to	irrigated	agriculture.	System	hydropower	
was	greatly	reduced,	and	inter‐basin	transfer	projects	induced	large	economic	costs	under	dry	
conditions.	These	results	on	seasonal	impacts	illustrate	the	importance	of	accounting	for	climate	
variability	and	potential	hydrologic	change	in	cost‐benefit	analysis	of	infrastructure	projects,	even	
in	watersheds	that	are	relatively	water	abundant.},
  file      = {:WaterResources\\Cooperative_Frameworks\\Analyzing Economic Tradeoﬀsof Water Use in the Nam Ngum River Basin, Lao PDR.pdf:PDF},
  keywords  = {Optimization; water resources management, Mekong River, Lao PDR, hydropower, irrigation},
  owner     = {jquebbeman},
  timestamp = {2018-05-16},
}

@Manual{WMO2008a,
  title        = {Guide to Hydrological Practices, Volume I, Hydrology – From Measurement to Hydrological Information, No. 168},
  organization = {World Meteorological Organization},
  edition      = {Sixth Edition},
  year         = {2008},
  file         = {:Hydrology\\Precipitation\\Guide to Hydrological Practices - Vol 1 - Hydrology - From Measurement to Hydrological Information.pdf:PDF},
  owner        = {jquebbeman},
  timestamp    = {2018-05-19},
}

@Manual{WMO2009,
  title        = {Guide to Hydrological Practices, Volume II, Management of Water Resources and Application of Hydrological Practices, No. 168},
  organization = {World Meteorological Organization},
  edition      = {Sixth},
  year         = {2008},
  file         = {:Hydrology\\Precipitation\\Guide to Hydrological Practices - Vol 2 - Management of Water Resources and Application of Hydrological Practices.pdf:PDF},
  owner        = {jquebbeman},
  timestamp    = {2018-05-19},
}

@Article{Chatterjee2014,
  author    = {Rana Chatterjee and S K Sinha},
  title     = {Water Resources Database – Development and Management},
  journal   = {Proceedings of the Indian National Science Academy},
  year      = {2014},
  volume    = {3},
  pages     = {713--730},
  month     = sep,
  doi       = {10.16943/ptinsa/2014/v80i3/55146},
  file      = {:WaterResources\\Water Resources Database – Development and Management.pdf:PDF},
  keywords  = {Meteorology; Surface Water; Ground Water; Water Quality; Climate Change; River Basin; Data Dissemination Policy; India-WRIS},
  owner     = {jquebbeman},
  timestamp = {2018-05-20},
}

@Article{Jain2012,
  author    = {Sharad K. Jain and Vijay Kumar},
  title     = {Trend analysis of rainfall and temperature data for India},
  journal   = {Current Science},
  year      = {2012},
  volume    = {102},
  number    = {1},
  pages     = {37--49},
  month     = jan,
  abstract  = {This article aims to review studies pertaining to trends
in rainfall, rainy days and temperature over India.
Sen’s non-parametric estimator of slope has been
frequently used to estimate the magnitude of trend,
whose statistical significance was assessed by the
Mann–Kendall test. Spatial units for trend analysis
vary from station data to sub-division to sub-basin/
river basins. There are differences in the results of the
various studies, and a clear and consistent picture of
rainfall trend has not emerged. Although the different
units (sub-basins or sub-divisions) may have a nonzero
slope value, few values are statistically significant.
In a study on basin-wise trend analysis, 15 basins
had decreasing trend in annual rainfall; only one basin
showed significant decreasing trend at 95% confidence
level. Among six basins showing increasing trend, one
basin showed significant positive trend. Most of the
basins had the same direction of trend in rainfall and
rainy days at the annual and seasonal scale.
 Regarding trends in temperature, the mean maximum
temperature series showed a rising trend at most
of the stations; it showed a falling trend at some stations.
The mean minimum temperature showed a rising
as well as a falling trend. At most of the stations in
the south, central and western parts of India a rising
trend was found. Some stations located in the north
and northeastern India showed a falling trend in
annual mean temperature. Most of the data used
in trend analysis pertained to the stations located in
urban areas and these areas are sort of heat islands.
This article also highlights the need of a network of
baseline stations for climatic studies.},
  file      = {:Hydrology\\Precipitation\\Trend analysis of rainfall and temperature data for India.pdf:PDF},
  keywords  = {Climate change, rainfall, trend, river basin, seasonal analysis, temperature data},
  owner     = {jquebbeman},
  timestamp = {2018-05-20},
}

@Article{Immerzeel2008,
  author    = {Walter Immerzeel},
  title     = {Historical trends and future predictions of climate variability in the Brahmaputra basin},
  journal   = {International Journal of Climatology},
  year      = {2008},
  volume    = {28},
  pages     = {243--254},
  comment   = {An innovative approach is developed and presented to assess historical climate variations and to quantify
future climate change for the entire Brahmaputra basin. Historical trends in temperature and precipitation are analysed
from 1900 to 2002 for the Tibetan plateau (TP), the Himalayan belt and the floodplains (FP) using a global 100 year
monthly high resolution dataset. Temperature patterns are consistent with global warming and out of the 10% warmest
years from 1900 to 2002 six occurred between 1995 and 2002. No clear trends in precipitation were found and annual
precipitation in the basin is mainly determined by the strength of the monsoon. Regression analysis is used to further
explain monsoon precipitation. A significant inverse relation is found between air temperature differences between the FP
and the TP and the strength of the monsoon, whereas the El Nino Southern Oscillation teleconnection does not have a ˜
prominent role in explaining variation in monsoon precipitation. Simulation results of six general circulation models are
statistically downscaled to the spatial resolution of the observed dataset for two future storylines. The analysis predicts
accelerated seasonal increases in both temperature and precipitation from 2000 to 2100. The largest changes occur on
the TP and the smallest on the FP. Multiple regression analysis shows a sharp increase in the occurrence of average and
extreme downstream discharges for both storylines. The strongest increases are projected for the monsoon season and
the largest threat of climate change lies in the associated flooding in the densely populated FP. Copyright  2007 Royal
Meteorological Society},
  doi       = {10.1002/joc.1528},
  file      = {:Hydrology\\Precipitation\\Historical trends and future predictions of climate variability in the Brahmaputra basin.pdf:PDF},
  keywords  = {climate change; hydrology; himalaya; downscaling; flooding; ENSO},
  owner     = {jquebbeman},
  timestamp = {2018-05-20},
}

@TechReport{Grijsen2017,
  author      = {Johan Grijsen},
  title       = {Upper Brahmaputra River Basin - Climate Change Impacts on Annual and Maximum Flows},
  institution = {World Bank},
  year        = {2017},
  owner       = {jquebbeman},
  timestamp   = {2018-05-20},
}

@Article{Munoz2018,
  author    = {Munoz, Samuel E. and Giosan, Liviu and Therrell, Matthew D. and Remo, Jonathan W. F. and Shen, Zhixiong and Sullivan, Richard M. and Wiman, Charlotte and O’Donnell, Michelle and Donnelly, Jeffrey P.},
  title     = {Climatic control of Mississippi River flood hazard amplified by river engineering},
  journal   = {Nature},
  year      = {2018},
  volume    = {556},
  number    = {7699},
  pages     = {95},
  month     = {4},
  issn      = {1476-4687},
  abstract  = {Over the past century, many of the world’s major rivers have been modified for the purposes of flood mitigation, power generation and commercial navigation1. Engineering modifications to the Mississippi River system have altered the river’s sediment levels and channel morphology2, but the influence of these modifications on flood hazard is debated3,4,5. Detecting and attributing changes in river discharge is challenging because instrumental streamflow records are often too short to evaluate the range of natural hydrological variability before the establishment of flood mitigation infrastructure. Here we show that multi-decadal trends of flood hazard on the lower Mississippi River are strongly modulated by dynamical modes of climate variability, particularly the El Niño–Southern Oscillation and the Atlantic Multidecadal Oscillation, but that the artificial channelization (confinement to a straightened channel) has greatly amplified flood magnitudes over the past century. Our results, based on a multi-proxy reconstruction of flood frequency and magnitude spanning the past 500 years, reveal that the magnitude of the 100-year flood (a flood with a 1 per cent chance of being exceeded in any year) has increased by 20 per cent over those five centuries, with about 75 per cent of this increase attributed to river engineering. We conclude that the interaction of human alterations to the Mississippi River system with dynamical modes of climate variability has elevated the current flood hazard to levels that are unprecedented within the past five centuries.},
  doi       = {10.1038/nature26145},
  owner     = {quebbs},
  publisher = {Nature Publishing Group},
  timestamp = {2018-05-23},
  url       = {http:https://doi.org/10.1038/nature26145},
}

@Article{Sharma2015,
  author    = {Sharma BK and Sharma HK},
  title     = {Status of Rice Production in Assam, India},
  journal   = {Journal of Rice Research},
  year      = {2015},
  volume    = {3},
  number    = {4},
  doi       = {10.4172/2375-4338.1000e121},
  file      = {:WaterResources\\Agriculture\\Status of Rice Production in Assam, India.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-05-23},
}

@TechReport{FortCollins2017,
  title       = {State of the Poudre: A River Health Assessment},
  institution = {City of Fort Collins},
  year        = {2017},
  abstract    = {The purpose of this first State of the Poudre River (SOPR) is to provide a description of the current
health of the Cache la Poudre River (Poudre) from approximately Gateway Natural Area to I-25. The
Poudre is a complex natural system that has been altered by nearly two centuries of human influence.
This has resulted in dramatic changes to the physical structure of the river, water quantity and quality,
floodplain, forests, and wildlife communities. The human footprint continues to expand, placing
additional pressure (or stresses) on the river ecosystem and the natural processes that sustain it. This
river health assessment provides the City of Fort Collins with a new tool to track trends and benchmark
progress towards its vision of sustaining a healthy and resilient Cache la Poudre River.
While the Poudre flows 126 miles from its headwaters to its confluence with the South Platte near
Greeley this study focuses on a 24-mile reach from the lower canyon through Fort Collins. The study
area was divided into four zones (Canyon, Rural, Urban, and Plains) and further into 18 study reaches
based on natural changes on the landscape and human influences.
Overall Grade: For the 24-mile study area the Poudre River received an overall grade of C. This grade
indicates the even though the Poudre has been altered and degraded by a suite of local and system wide
stresses that impair its health, it continues to support basic elements of a functioning river ecosystem.
The framework for this baseline assessment includes nine indicators of river health which are informed
by 25 indicator-specific metrics. Collectively these provide a thorough evaluation of how well the
system is functioning. Metrics grades are developed by collecting and incorporating many types of data,
which were then translated into an A-F grading system. Indicator and metric numerical scores and their
corresponding letter grades were calibrated to categorical definitions relating to degree of functionality
or impairment.
Recommended ranges developed for each metric (as established in the River Health Assessment
Framework, City of Fort Collins, 2015) and were developed based on the City’s concept of working
towards a functioning river ecosystem. The recommended ranges consider the contemporary realworld
context and reasonable expectations for future change and the potential for improvement. They
should, however, be used as a guide and aspiration rather than a directive. Also, when interpreting
results for a comprehensive scientific assessment such as this, it is important to consider that
uncertainty and variability exists across scientific disciplines, data sources, and river reaches. The
methods and grading guidelines provide an explicit description of the analytical approaches used and
can help the reader understand this variability.},
  file        = {:WaterResources\\Ecology\\State of the Poudre- A River Health Assessment.pdf:PDF},
  keywords    = {indicators, metrics, ecology, river health, watershed, Poudre river},
  owner       = {jquebbeman},
  timestamp   = {2018-05-28},
  url         = {https://www.fcgov.com/poudrereportcard/},
}

@Article{Srivastava2009,
  author    = {A. K. Srivastava and M. Rajeevan and S. R. Kshirsagar},
  title     = {Development of a high resolution daily gridded temperature data set (1969-2005) for the Indian region},
  journal   = {Atmospheric Science Letters},
  year      = {2009},
  volume    = {online},
  abstract  = {A high resolution daily gridded temperature data set for the Indian region was developed
using temperature data of 395 quality controlled stations for the period 1969–2005. A
modified version of the Shepard’s angular distance weighting algorithm was used for
interpolating the station temperature data into 1◦ latitude × 1◦ longitude grids. Using the
cross validation, errors were estimated and found less than 0.5 ◦C. The data set was also
compared with another high resolution data set and found comparable. Mean frequency of
cold and heat waves, temperature anomalies associated with the monsoon breaks have been
presented.},
  doi       = {10.1002/asl.232},
  file      = {:C\:\\Users\\jquebbeman\\OneDrive - Research Triangle Institute\\References\\Climate\\Temperature\\Development of a high resolution daily gridded temperature data set (1969-2005) for the Indian region.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-05-29},
}

@Book{Grigg2005,
  title     = {Water Manager's Handbook: A guide to the water industry},
  publisher = {Aquamedia Publishing},
  year      = {2005},
  author    = {Neil S. Grigg},
  address   = {Fort Collins, Colorado},
  owner     = {quebbs},
  timestamp = {2018-05-30},
}

@Book{Mutongi2016,
  title     = {Revisiting Data, Information, Knowledge and Wisdom (DIKW) Model and Introducting the Green Leaf Model},
  publisher = {Semantic Scholar},
  year      = {2016},
  author    = {Mutongi, C.},
  owner     = {quebbs},
  timestamp = {2018-05-30},
}

@TechReport{OECD2015,
  title       = {OECD Principles on Water Governance},
  institution = {The Organisation for Economic Cooperation and Development},
  year        = {2015},
  address     = {Paris, France},
  owner       = {quebbs},
  timestamp   = {2018-05-30},
}

@Article{Ramsey1928,
  author    = {Ramsey, F.P.},
  title     = {A Mathematical Theory of Saving},
  journal   = {Economics Journal},
  year      = {1928},
  owner     = {quebbs},
  timestamp = {2018-05-30},
}

@TechReport{MoWR2017,
  title       = {Report of the Comptroller and Auditor General of India on Schemes for Flood Control and Flood Forecasting},
  institution = {Ministry of Water Resources, River Development \& Ganga Rejuvenation},
  year        = {2017},
  number      = {No. 10},
  owner       = {quebbs},
  timestamp   = {2018-05-30},
}

@TechReport{Oberhagemann2017,
  author      = {Knut Oberhagemann},
  title       = {Basin Context, Flood Risk Management, and Implementation Arrangements},
  institution = {Northwest Hydraulic Consultants},
  year        = {2017},
  abstract    = {ToR:
• Based on existing literature / studies, provide a rapid assessment of the key challenges and
opportunities in the Brahmaputra and Barak river systems, including physical environment,
river morphology and riverbank erosion, flooding and other basin issues.
• Collect, review, and synthesize information on interventions carried out to date in Assam to
manage risks (floods, erosion, etc.) and make productive use of water resources. Assess
effectiveness, efficiency and outcomes of interventions; identify gaps, overlaps; etc.
• Prepare a ‘Gap Analysis’ report with the findings of the above},
  file        = {:C\:/Users/jquebbeman/Research Triangle Institute/Northeast India Water Resources Management - Documents/Background/WorldBank/NHC Assam Institutional Assessment v3 - Knut.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-03-10},
}

@TechReport{CEA2015a,
  author      = {CEA},
  title       = {Guidelines for Formulation of Detailed Project Reports for Hydro Electric Schemes, their Acceptance and Examination for Concurrence},
  institution = {Central Electricity Authority},
  year        = {2015},
  file        = {:C\:\\Users\\jquebbeman\\Research Triangle Institute\\Northeast India Water Resources Management - Documents\\Background\\CEA\\guidlines_dpr_he_ver5.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-03-10},
}

@Manual{MoEF1985,
  title        = {Guidelines for Environmental Impact Assessment of River Valley Projects},
  organization = {Department of Environment, Ministry of Environment and Forests},
  address      = {Delhi, India},
  month        = jan,
  year         = {1985},
  owner        = {quebbs},
  timestamp    = {2018-05-30},
}

@Manual{CPCB2007,
  title        = {Guidelines for Water Quality Monitoring},
  author       = {Central Pollution Control Board},
  organization = {Central Pollution Control Board},
  address      = {Delhi, India},
  edition      = {MINARS/27/2007-08},
  year         = {2007},
  owner        = {quebbs},
  timestamp    = {2018-05-30},
}

@TechReport{CEA2018,
  title       = {Status of hydro-electric potential development},
  institution = {Central Electricity Authority},
  year        = {2018},
  address     = {Delhi, India},
  month       = feb,
  owner       = {quebbs},
  timestamp   = {2018-05-30},
  url         = {http://www.cea.nic.in/reports/monthly/hydro/2018/hydro_potential_region-02.pdf},
}

@TechReport{GoI2015,
  title       = {India’s Intended Nationally Determined Contribution: Working Towards Climate Justice},
  institution = {Government of India},
  year        = {2015},
  address     = {Delhi, India},
  abstract    = {India has submitted its Intended Nationally Determined Contribution (INDC) to the United Nations Framework Convention on Climate Change.
Salient features of India's INDC
To put forward and further propagate a healthy and sustainable way of living based on traditions and values of conservation and moderation.
To adopt a climate-friendly and a cleaner path than the one followed hitherto by others at corresponding level of economic development.
To reduce the emissions intensity of its GDP by 33 to 35 per cent by 2030 from 2005 level.
To achieve about 40 per cent cumulative electric power installed capacity from non-fossil fuel based energy resources by 2030, with the help of transfer of technology and low cost international finance, including from Green Climate Fund.
To create an additional carbon sink of 2.5 to 3 billion tonnes of CO2 equivalent through additional forest and tree cover by 2030.
To better adapt to climate change by enhancing investments in development programmes in sectors vulnerable to climate change, particularly agriculture, water resources, Himalayan region, coastal regions, health and disaster management.
To mobilize domestic and new and additional funds from developed countries to implement the above mitigation and adaptation actions in view of the resource required and the resource gap.
To build capacities, create domestic framework and international architecture for quick diffusion of cutting edge climate technology in India and for joint collaborative R&D for such future technologies.},
  file        = {:WaterResources\\Cooperative_Frameworks\\INDIA’S INTENDED NATIONALLY DETERMINED CONTRIBUTION- Working Towards Climate Justice.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-05-30},
}

@TechReport{MoEF2016,
  author      = {R. S. Envirolink Technologies Pvt. Ltd.},
  title       = {Cumulative Impact \& Carrying Capacity Study of the Dibang Sub Basin in Brahmaputra River Valley - Final Report},
  institution = {Ministry of Environment, Forest and Climate Change},
  year        = {2016},
  number      = {Vol. 1},
  address     = {402, BESTECH CHAMBER COMMERCIAL PLAZA, B-BLOCK, SUSHANT LOK-I, GURGAON},
  month       = jul,
  file        = {:C\:\\Users\\jquebbeman\\Research Triangle Institute\\Northeast India Water Resources Management - Documents\\Background\\MoEF\\Cumulative Impact & Carrying Capacity Study of the Dibang Sub Basin in Brahmaputra River Valley.pdf:PDF},
  keywords    = {Bhatia},
  owner       = {quebbs},
  timestamp   = {2018-05-30},
}

@TechReport{IHA2018,
  author      = {IHA},
  title       = {Hydropower Status Report},
  institution = {International Hydropower Association},
  year        = {2018},
  file        = {:Hydropower\\2018 Hydropower Status Report.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-06-11},
}

@TechReport{Quebbeman2018,
  author      = {Jonathan Quebbeman and Gerald Day and John Labadie and Casey Caldwell and Steve Nebiker},
  title       = {Benchmarking of Ensemble Streamflow Forecast Usage in Hydropower Planning},
  institution = {CEATI International Inc.},
  year        = {2018},
  number      = {No. T162700-0429},
  address     = {1010 Sherbrooke Street West, Suite 2500 Montreal, Quebec, Canada H3A 2R7},
  owner       = {quebbs},
  timestamp   = {2018-06-11},
}

@TechReport{IHA2010,
  author      = {International Hydropower Association},
  title       = {Hydropower Sustainability Assessment Protocol},
  institution = {International Hydropower Association},
  year        = {2010},
  type        = {techreport},
  address     = {Sutton, London, UK},
  month       = nov,
  file        = {:Hydropower\\Hydropower Sustainability Assessment Protocol.pdf:PDF},
  owner       = {jquebbeman},
  timestamp   = {2018-06-12},
}

@Article{Smith2018,
  author    = {Ryan Smith and Rosemary Knight and Scott Fendorf},
  title     = {Overpumping leads to California groundwater arsenic threat},
  journal   = {Nature Communications},
  year      = {2018},
  volume    = {9},
  number    = {2089},
  month     = jun,
  abstract  = {Water resources are being challenged to meet domestic, agricultural, and industrial needs. To complement finite surface water supplies that are being stressed by changes in precipitation and increased demand, groundwater is increasingly being used. Sustaining groundwater use requires considering both water quantity and quality. A unique challenge for groundwater use, as compared with surface water, is the presence of naturally occurring contaminants within aquifer sediments, which can enter the water supply. Here we find that recent groundwater pumping, observed through land subsidence, results in an increase in aquifer arsenic concentrations in the San Joaquin Valley of California. By comparison, historic groundwater pumping shows no link to current groundwater arsenic concentrations. Our results support the premise that arsenic can reside within pore water of clay strata within aquifers and is released due to overpumping. We provide a quantitative model for using subsidence as an indicator of arsenic concentrations correlated with groundwater pumping.},
  file      = {:Hydrology\\Groundwater\\Overpumping leads to California groundwater arsenic threat.pdf:PDF},
  owner     = {jquebbeman},
  timestamp = {2018-06-17},
}

@Book{Nandalal2007,
  title     = {Dynamic Programming Based Operation of Reservoirs: Applicability and Limits},
  publisher = {Cambridge University Press},
  year      = {2007},
  author    = {Nandalal, K. D. W. and Bogardi, Janos J.},
  doi       = {10.1017/CBO9780511535710},
  owner     = {jquebbeman},
  timestamp = {2018-06-19},
}

@TechReport{Block2007,
  author      = {Paul J. Block and Kenneth Strzepek and Balaji Rajagopalan},
  title       = {Integrated Management of the Blue Nile Basin in Ethiopia},
  institution = {International Food Policy Research Institute},
  year        = {2007},
  abstract    = {Ethiopia is at a critical crossroads with a large and increasing population, a depressed national economy,
insufficient agricultural production, and a low number of developed energy sources. The upper Blue Nile
basin harbors considerable untapped potential for irrigation and hydropower development and expansion.
Numerous hydrologic models have been developed to assess hydropower and agricultural irrigation
potential within the basin, yet often fail to adequately address critical aspects, including the transient
stages of large-scale reservoirs, relevant flow retention policies and associated downstream ramifications,
and the implications of stochastic modeling of variable climate and climate change. A hydrologic model
with dynamic climate capabilities is constructed to assess these aspects. The model indicates that largescale
development typically produces benefit-cost ratios from 1.2-1.8 under historical climate regimes for
the projects specified. Climate change scenarios indicate potential for small benefit-cost increases, but
reflect possible significant decreases. Stochastic modeling of scenarios representing a doubling of the
historical frequency of El Niño events indicates benefit-cost ratios as low as 1.0 due to a lack of timely
water. An evaluation of expected energy growth rates reinforces the need for significant economic
planning and the necessity of securing energy trade contracts prior to extensive development. A Ramsey
growth model for energy development specifies project multipliers on total GDP over the 100-year
simulation ranging from 1.7-5.2, for various climatologic conditions. },
  file        = {:Hydropower\\Integrated Management of the Blue Nile Basin in Ethiopia.pdf:PDF},
  keywords    = {Ethiopia, dams, water resources development, hydrologic model, energy, climate variability, climate change },
  owner       = {jquebbeman},
  timestamp   = {2018-06-20},
}

@TechReport{Mani2018,
  author      = {Muthukumara Mani and Sushenjit Bandyopadhyay and Shun Chonabayashi and Anil Markandya and Thomas Mosier},
  title       = {South Asia’s Hotspots: The impact of temperature and precipitation changes on living standards},
  institution = {World Bank Group},
  year        = {2018},
  abstract    = {South Asia is highly vulnerable to climate change. Average temperatures have been rising throughout the region, and rainfall has become more erratic. These changes are projected to continue accruing over the coming decades. South Asia’s Hotspots: The Impact of Temperature and Precipitation Changes on Living Standards is the first book of its kind to provide granular spatial analysis of the long-term impacts of changes in average temperature and precipitation on one of the world’s poorest regions. South Asia’s Hotspots finds that higher temperatures and shifting precipitation patterns will reduce living standards in communities across South Asia—locations that the book terms “hotspots.” More than 800 million people in South Asia currently live in communities that are projected to become hotspots under a carbon-intensive climate scenario. Global action to reduce greenhouse gas emissions will reduce the severity of hotspots. Diverse and robust development is the best overall prescription to help people in hotspots. The book also suggests actions tailored to each country in the region—such as increasing employment in nonagricultural sectors, improving educational attainment, and expanding access to electricity— that would offset the declines in living standards associated with hotspots. South Asia’s Hotspots complements previous studies detailing the impacts of sea-level rise and extreme events on the people of South Asia. Together, these bodies of work create a sound analytical basis for investing in targeted policies and actions to build climate resilience throughout the region},
  file        = {:Climate\\South Asia’s Hotspots- The impact of temperature and precipitation changes on living standards.pdf:PDF},
  keywords    = {India, Bangladesh},
  owner       = {jquebbeman},
  timestamp   = {2018-07-04},
  url         = {http://hdl.handle.net/10986/28723},
}

@InProceedings{Srivastava2012,
  author    = {Anurag Srivastava and David S. Bowles and Sanjay S. Chauhan},
  title     = {DAMRAE-U: A Tool for Including Uncertainty in Dam Safety Risk Assessment},
  booktitle = {ASDSO 2012 Conference on Dams},
  year      = {2012},
  abstract  = {Based on a generalized event tree algorithm, a deterministic model (DAMRAE) was
developed for the US Army Corps of Engineers to support the dam safety risk assessment.
With an objective to incorporate the uncertainty analysis functionality for the event tree based
risk models, we extend the DAMRAE framework to develop a generic uncertainty analysis tool
(DAMRAE-U) for dam safety risk assessment. DAMRAE-U provides a convenient way to
efficiently characterize, propagate, and display the outcomes of uncertainty analysis.
DAMRAE-U is structured to analyze knowledge uncertainty for the event tree variables and
natural variability associated with flood and earthquake loadings. It also provides for separating
the effects of uncertainty in the existing condition of the dam system on which the event tree
model is dependent. In this paper, we present the details of the developed computational
framework. Also, an example risk model to illustrate the inputs and outputs of the framework
and the implementation of tolerable risk evaluation incorporating uncertainty in risk estimates is
included.},
  file      = {:Risk\\DAMRAE-U A Tool for Including Uncertainty in Dam Safety Risk Assessment.pdf:PDF},
  keywords  = {Dam Safety Risk Assessment, Event Tree, Knowledge Uncertainty, Logic Tree, Uncertainty Analysis, Variability},
  owner     = {jquebbeman},
  timestamp = {2018-07-07},
}

@Article{Baker2018,
  author    = {Justin S Baker and Petr Havlík and Robert Beach and David Leclère and Erwin Schmid and Hugo Valin and Jefferson Cole and Jared Creason and Sara Ohrel and James McFarland},
  title     = {Evaluating the effects of climate change on US agricultural systems: sensitivity to regional impact and trade expansion scenarios},
  journal   = {Environmental Research Letters},
  year      = {2018},
  volume    = {13},
  number    = {6},
  month     = jun,
  abstract  = {Agriculture is one of the sectors that is expected to be most significantly impacted by climate change. There has been considerable interest in assessing these impacts and many recent studies investigating agricultural impacts for individual countries and regions using an array of models. However, the great majority of existing studies explore impacts on a country or region of interest without explicitly accounting for impacts on the rest of the world. This approach can bias the results of impact assessments for agriculture given the importance of global trade in this sector. Due to potential impacts on relative competitiveness, international trade, global supply, and prices, the net impacts of climate change on the agricultural sector in each region depend not only on productivity impacts within that region, but on how climate change impacts agricultural productivity throughout the world. In this study, we apply a global model of agriculture and forestry to evaluate climate change impacts on US agriculture with and without accounting for climate change impacts in the rest of the world. In addition, we examine scenarios where trade is expanded to explore the implications for regional allocation of production, trade volumes, and prices. To our knowledge, this is one of the only attempts to explicitly quantify the relative importance of accounting for global climate change when conducting regional assessments of climate change impacts. The results of our analyses reveal substantial differences in estimated impacts on the US agricultural sector when accounting for global impacts vs. US-only impacts, particularly for commodities where the United States has a smaller share of global production. In addition, we find that freer trade can play an important role in helping to buffer regional productivity shocks.},
  doi       = {10.1088/1748-9326/aac1c},
  file      = {:Climate\\Evaluating the effects of climate change on US agricultural systems- sensitivity to regional impact and trade expansion scenarios.pdf:PDF},
  keywords  = {GLOBIOM, IIASA},
  owner     = {jquebbeman},
  timestamp = {2018-07-07},
}

@Unpublished{Schaefer2017,
  author    = {MG Schaefer},
  title     = {Computational Method for Sampling of Low Probability Watershed Model Inputs and Failure Modes in Developing Hydrologic Hazard Curves and Computing Probability of Failure},
  abstract  = {total probability theorom},
  file      = {:Risk/Sampling_LowProbabilityEvents.docx:Word 2007+},
  owner     = {jquebbeman},
  timestamp = {2018-07-07},
}

@Article{Wada2016,
  author    = {Y. Wada and M. Fl{\"o}rke and N. Hanasaki and S. Eisner and G. Fischer and S. Tramberend and Y. Satoh and M. van Vliet and P. Yillia and C. Ringler and D. Wiberg},
  title     = {Modeling global water use for the 21st century: Water Futures and Solutions (WFaS) initiative and its approaches},
  journal   = {Geoscientific Model Development},
  year      = {2016},
  volume    = {9},
  month     = jan,
  unknown   = {, Modeling global water use for the 21st century: Water Futures and Solutions (WFaS) initiative and its approaches},
  abstract  = {To sustain growing food demand and increasing
standard of living, global water use increased by nearly 6
times during the last 100 years, and continues to grow. As
water demands get closer and closer to the water availability
in many regions, each drop of water becomes increasingly
valuable and water must be managed more efficiently and intensively.
However, soaring water use worsens water scarcity
conditions already prevalent in semi-arid and arid regions,
increasing uncertainty for sustainable food production and
economic development. Planning for future development and
investments requires that we prepare water projections for the
future. However, estimations are complicated because the future
of the world’s waters will be influenced by a combination
of environmental, social, economic, and political factors,
and there is only limited knowledge and data available about
freshwater resources and how they are being used. The Water
Futures and Solutions (WFaS) initiative coordinates its work
with other ongoing scenario efforts for the sake of establishing
a consistent set of new global water scenarios based on
the shared socio-economic pathways (SSPs) and the representative
concentration pathways (RCPs). The WFaS “fasttrack”
assessment uses three global water models, namely
H08, PCR-GLOBWB, and WaterGAP. This study assesses
the state of the art for estimating and projecting water use regionally
and globally in a consistent manner. It provides an
overview of different approaches, the uncertainty, strengths
and weaknesses of the various estimation methods, types of
management and policy decisions for which the current estimation
methods are useful. We also discuss additional information
most needed to be able to improve water use estimates
and be able to assess a greater range of management
options across the water–energy–climate nexus.},
  file      = {:Hydrology\\Modeling global water use for the 21st century- Water Futures and Solutions (WFaS) initiative and its approaches.pdf:PDF},
  owner     = {jquebbeman},
  timestamp = {2018-07-09},
}

@Conference{March2003,
  author    = {Patrick March and Paul Wolff},
  title     = {Optimization-Based Hydro Performance Indicator},
  booktitle = {WaterPower XIII},
  year      = {2003},
  file      = {:Optimization\\Optimization-Based Hydro Performance Indicator.pdf:PDF},
  keywords  = {WaterView},
  owner     = {jquebbeman},
  timestamp = {2018-07-30},
}

@Article{Satoh2017,
  author    = {Satoh, Yusuke and Kahil, Taher and Byers, Edward and Burek, Peter and Fischer, Günther and Tramberend, Sylvia and Greve, Peter and Flörke, Martina and Eisner, Stephanie and Hanasaki, Naota and Magnuszewski, Piotr and Nava, Luzma Fabiola and Cosgrove, William and Langan, Simon and Wada, Yoshihide},
  title     = {Multi-model and multi-scenario assessments of Asian water futures: The Water Futures and Solutions (WFaS) initiative},
  journal   = {Earth's Future},
  year      = {2017},
  volume    = {5},
  number    = {7},
  pages     = {823-852},
  abstract  = {Abstract This paper presents one of the first quantitative scenario assessments for future water supply and demand in Asia to 2050. The assessment, developed by the Water Futures and Solutions (WFaS) initiative, uses the latest set of global climate change and socioeconomic scenarios and state-of-the-art global hydrological models. In Asia, water demand for irrigation, industry, and households is projected to increase substantially in the coming decades (30–40\% by 2050 compared to 2010). These changes are expected to exacerbate water stress, especially in the current hotspots such as north India and Pakistan, and north China. By 2050, 20\% of the land area in the Asia-Pacific region, with a population of 1.6–2 billion, is projected to experience severe water stress. We find that socioeconomic changes are the main drivers of worsening water scarcity in Asia, with climate change impacts further increasing the challenge into the 21st century. Moreover, a detailed basin-level analysis of the hydro-economic conditions of 40 Asian basins shows that although the coping capacity of all basins is expected to improve due to gross domestic product (GDP) growth, some basins continuously face severe water challenges. These basins will potentially be home to up to 1.6 billion people by mid-21st century.},
  doi       = {10.1002/2016EF000503},
  eprint    = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2016EF000503},
  file      = {:WaterResources\\Multi‐model and multi‐scenario assessments of Asian water futures- The Water Futures and Solutions (WFaS) initiative.pdf:PDF},
  keywords  = {Asia, water scarcity, socioeconomic development, climate change, hydro-economic analysis},
  owner     = {quebbs},
  timestamp = {2018-08-01},
  url       = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2016EF000503},
}

@Article{Gleeson2014,
  author    = {Gleeson, Tom and Moosdorf, Nils and Hartmann, Jens and Beek, L. P. H.},
  title     = {A glimpse beneath earth's surface: GLobal HYdrogeology MaPS (GLHYMPS) of permeability and porosity},
  journal   = {Geophysical Research Letters},
  year      = {2014},
  volume    = {41},
  number    = {11},
  pages     = {3891-3898},
  month     = jun,
  note      = {http://spatial.cuahsi.org/gleesont01/},
  abstract  = {Abstract The lack of robust, spatially distributed subsurface data is the key obstacle limiting the implementation of complex and realistic groundwater dynamics into global land surface, hydrologic, and climate models. We map and analyze permeability and porosity globally and at high resolution for the first time. The new permeability and porosity maps are based on a recently completed high-resolution global lithology map that differentiates fine and coarse-grained sediments and sedimentary rocks, which is important since these have different permeabilities. The average polygon size in the new map is ~100 km2, which is a more than hundredfold increase in resolution compared to the previous map which has an average polygon size of ~14,000 km2. We also significantly improve the representation in regions of weathered tropical soils and permafrost. The spatially distributed mean global permeability ~10−15 m2 with permafrost or ~10−14 m2 without permafrost. The spatially distributed mean porosity of the globe is 14\%. The maps will enable further integration of groundwater dynamics into land surface, hydrologic, and climate models.},
  doi       = {10.1002/2014GL059856},
  eprint    = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2014GL059856},
  file      = {:Hydrology\\Groundwater\\A glimpse beneath earth's surface- GLobal HYdrogeology MaPS (GLHYMPS) of permeability and porosity.pdf:PDF},
  keywords  = {groundwater, permeability, land surface models, hydrology models},
  owner     = {quebbs},
  timestamp = {2018-08-01},
  url       = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2014GL059856},
}

@Article{Niswonger2017,
  author    = {Richard G. Niswonger and Eric D. Morway and Enrique Triana and Justin L. Huntington},
  title     = {Managed aquifer recharge through off-season irrigation in agricultural regions},
  journal   = {Water Resources Research},
  year      = {2017},
  volume    = {53},
  pages     = {6970--6992},
  abstract  = {Options for increasing reservoir storage in developed regions are limited and prohibitively
expensive. Projected increases in demand call for new long-term water storage to help sustain agriculture,
municipalities, industry, and ecological services. Managed aquifer recharge (MAR) is becoming an integral
component of water resources around the world. However, MAR faces challenges, including infrastructure
costs, difficulty in enhancing recharge, water quality issues, and lack of available water supplies. Here we
examine, through simulation modeling of a hypothetical agricultural subbasin in the western U.S., the
potential of agricultural managed aquifer recharge (Ag-MAR) via canal seepage and off-season field irrigation. 
Weather phenomenon in many regions around the world exhibit decadal and other multiyear cycles of
extreme precipitation. An ongoing challenge is to develop approaches to store greater amounts of water
during these events. Simulations presented herein incorporate Ag-MAR programs and demonstrate that
there is potential to enhance regional recharge by 7–13%, increase crop consumptive use by 9–12%, and
increase natural vegetation consumption by 20–30%, where larger relative increases occur for lower aquifer
hydraulic conductivity and higher specific yield values. Annual increases in groundwater levels were 7 m,
and sustained levels following several years of drought were greater than 2 m. Results demonstrate that
Ag-MAR has great potential to enhance long-term sustainability of water resources in agricultural basins.},
  doi       = {10.1002/2017WR020458},
  file      = {:Hydrology\\Groundwater\\Managed aquifer recharge through off-season irrigation in agricultural regions.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-08-01},
}

@Misc{Cooley2016,
  title     = {Models for Spatial Extremes},
  file      = {:Hydrology\\Precipitation\\Models for Spatial Extremes.pdf:PDF},
  keywords  = {extreme precipitation, spatial, bayesian},
  owner     = {jquebbeman},
  timestamp = {2018-08-06},
}

@Article{Cole2018,
  author    = {Martin Barry Cole and Mary Ann Augustin and Michael John Robertson and John Michael Manners},
  title     = {The science of food security},
  journal   = {Annales de la Societe Royale des Sciences Medicales et Naturelles de Bruxelles},
  year      = {2018},
  volume    = {2},
  number    = {14},
  abstract  = {We need to feed an estimated population in excess of 9 billion by 2050 with diminishing natural resources, whilst ensuring the health of people and the planet. Herein we connect the future global food demand to the role of agricultural and food science in producing and stabilising foods to meet the global food demand. We highlight the challenges to food and agriculture systems in the face of climate change and global megatrends that are shaping the future world. We discuss the opportunities to reduce food loss and waste, and recover produce that is currently wasted to make this the new raw ingredient supply for the food industry. Our systems-based perspective links food security to agricultural productivity, food safety, health and nutrition, processing and supply chain efficiency in the face of global and industry megatrends. We call for a collaborative, transdisciplinary approach to the science of food security, with a focus on enabling technologies within a context of social, market and global trends to achieve food and nutritional security.},
  file      = {:WaterResources\\Agriculture\\The science of food security.pdf:PDF},
  owner     = {quebbs},
  timestamp = {2018-08-07},
}

@TechReport{DOE2017,
  author      = {U.S. Department of Energy},
  title       = {2017 Hydropower Market Report},
  institution = {Office of Energy Efficiency and Renewable Energy (EERE)},
  year        = {2017},
  abstract    = {The U.S. hydropower fleet represents 7% of total electricity generation installed capacity (as of the end of 2016) and produces
6.3% of electricity (2014-2016 average). In addition, 43 pumped storage hydropower (PSH) plants with a total capacity of 21.6
GW provide 95% of utility-scale electrical energy storage in the United States. The U.S. fleet is the third largest in the world
for both hydropower and PSH.
U.S. hydropower capacity has increased by 2,030 MW from 2006 to 2016 bringing installed capacity to 79.99
GW across 2,241 separate plants. Of this net increase, 70% (1,435 MW) resulted from refurbishments and upgrades
(R&U) to the existing fleet. Most of the 118 new hydropower plants that have started operation since 2006 involved additions
of hydropower generation equipment to non-powered dams (40) or conduits (73), but five new stream-reach development
(NSD) projects also started operation from 2006 to 2016—all of them in the Northwest. The median size of new plants is small
(<= 10 MW); the largest new hydropower plants coming on line over the last decade were the NPD projects developed by
American Municipal Power along the Ohio River: Meldahl (105 MW), Cannelton (88 MW), Smithland (76 MW), and Willow
Island (44 MW).
The addition of hydropower generation equipment to existing water resource infrastructure is also the dominant trend in
planned new developments. At the end of 2017, there are 214 projects with combined proposed capacity of 1,712
MW in the U.S. hydropower project development pipeline. The predominant project type varies by region. Proposed
developments in the Midwest, Southeast, and Northeast region are almost exclusively NPD projects. In the Southwest, most
projects would add hydropower to existing conduits and irrigation canals. The Northwest has the most diverse project pipeline
and contains all proposed new stream-reach developments (except for 1 in New York). Nationally, NPD projects account for
92% of proposed capacity. Thus, the success of recent initiatives to improve the efficiency of the authorization process for this
type of project is crucial.},
  file        = {:Hydropower\\2017 Hydropower Market Report.pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-08-14},
}

@Article{Bonnema2017,
  author    = {Matthew Bonnema and Faisal Hossain},
  title     = {Inferring reservoir operating patterns across the Mekong Basin using only space observations},
  journal   = {Water Resources Research},
  year      = {2017},
  volume    = {53},
  pages     = {3791--3810},
  abstract  = {This study explores the operating pattern of artificial reservoirs by examining their impact on 4
streamflow through two parameters, residence time and flow alteration, using a purely satellite-based 5
technique for the Mekong Basin. Overall residence times of individual reservoirs ranged from 0.09 to 6
4.04 years, while streamflow was altered between 11 and 130% of its natural variability. The current set of 7
reservoirs appears to have increased the residence time of the entire Mekong basin by about 1 month. 8
However, if subbasin variability is considered, the satellite-based method depicts a different picture. 9
Residence time increases to 4 months when only regulated flows are considered. If low residence time 10
reservoirs on major rivers are excluded and reservoirs on higher stream-order rivers considered, residence 11
time increases to 1.3 years. Predictable strong seasonal patterns emerged in residence time, where 12
reservoirs experience higher residence time in the dry season and lower residence time in the wet season 13
and residence time varies inversely with precipitation. High variability in reservoir effects on streamflow 14
between reservoirs could not be explained by any reservoir properties (e.g., size, use, location, etc.), 15
highlighting the variability in the human decisions operating these reservoirs. The take-home message of 16
this study is that satellite observations, in combination with physical models forced with satellite data, can 17
elucidate the spatiotemporal variability of reservoir behavior in ungauged basins of the developing world. 18
We demonstrate in this study that the requirement for ground data to monitor current or historical behavior 19
of dams is not necessary.},
  doi       = {10.1002/2016WR019978},
  file      = {:Reservoirs\\Inferring reservoir operating patterns across the Mekong Basin using only space observations.pdf:PDF},
  keywords  = {SWOT},
  owner     = {jquebbeman},
  timestamp = {2018-08-14},
}

@TechReport{England2018,
  author      = {John F. England and Timothy A. Cohn and Beth A. Faber and Jery R. Stedinger and Wilbert O. Thomas and Andrea G. Veilleux and Julie E. Kiang and Robert R. Mason},
  title       = {Guidelines for Determining Flood Flow Frequency - Bulletin 17C},
  institution = {United States Geological Survey},
  year        = {2018},
  number      = {U.S. Geological Survey Techniques and Methods, book 4, chap. B5},
  abstract    = {Accurate estimates of flood frequency and magnitude are a key component of any effective nationwide flood risk management and flood damage abatement program. In addition to accuracy, methods for estimating flood risk must be uniformly and consistently applied because management of the Nation’s water and related land resources is a collaborative effort involving multiple actors including most levels of government and the private sector.

Flood frequency guidelines have been published in the United States since 1967, and have undergone periodic revisions. In 1967, the U.S. Water Resources Council presented a coherent approach to flood frequency with Bulletin 15, “A Uniform Technique for Determining Flood Flow Frequencies.” The method it recommended involved fitting the log-Pearson Type III distribution to annual peak flow data by the method of moments.

The first extension and update of Bulletin 15 was published in 1976 as Bulletin 17, “Guidelines for Determining Flood Flow Frequency” (Guidelines). It extended the Bulletin 15 procedures by introducing methods for dealing with outliers, historical flood information, and regional skew. Bulletin 17A was published the following year to clarify the computation of weighted skew. The next revision of the Bulletin, the Bulletin 17B, provided a host of improvements and new techniques designed to address situations that often arise in practice, including better methods for estimating and using regional skew, weighting station and regional skew, detection of outliers, and use of the conditional probability adjustment.

The current version of these Guidelines are presented in this document, denoted Bulletin 17C. It incorporates changes motivated by four of the items listed as “Future Work” in Bulletin 17B and 30 years of post-17B research on flood processes and statistical methods. The updates include: adoption of a generalized representation of flood data that allows for interval and censored data types; a new method, called the Expected Moments Algorithm, which extends the method of moments so that it can accommodate interval data; a generalized approach to identification of low outliers in flood data; and an improved method for computing confidence intervals.

Federal agencies are requested to use these Guidelines in all planning activities involving water and related land resources. State, local, and private organizations are encouraged to use these Guidelines to assure uniformity in the flood frequency estimates that all agencies concerned with flood risk should use for Federal planning decisions.

This revision is adopted with the knowledge and understanding that review of these procedures will be ongoing. Updated methods will be adopted when warranted by experience and by examination and testing of new techniques.},
  doi         = {10.3133/tm4B5},
  file        = {:Statistics\\Guidelines for Determining Flood Flow Frequency - Bulletin 17c.pdf:PDF},
  owner       = {jquebbeman},
  timestamp   = {2018-08-15},
  url         = {https://pubs.er.usgs.gov/publication/tm4B5},
}

@TechReport{Smith2018a,
  author      = {Haden Smith and Mike Bartles and Matt Fleming},
  title       = {Hydrologic Hazard Methodology for SemiQuantitative Risk Assessments},
  institution = {United States Army Corps of Engineers Risk Management Center},
  year        = {2018},
  type        = {techreport},
  number      = {RMC-TR-2018-03},
  note        = {An Inflow Volume-Based Approach to Estimating Stage-Frequency for Dams},
  abstract    = {The purpose of this document is to establish methods and procedures for assessing the hydrologic hazard of dams in the USACE Dam
Safety Program for use in semi-quantitative risk assessments (SQRA). This document is primarily focused on an inflow volume-based
approach to estimating stage-frequency curves for dams. This document provides guidance on fitting inflow volume-frequency curves
and simulating reservoir stage-frequency curves. Techniques for quantifying the uncertainty in inflow volume- and stage-frequency
curves caused by small sample sizes are demonstrated. The information contained in this document reflects the methodologies currently
used by USACE in performing hydrologic hazard assessments. These methodologies provide satisfactory results for use in an SQRA.
Periodically, there may be minor improvements and revisions to this report to clarify data inputs, software updates, and other details
based on annual reviews and feedback from the Dam Safety Program.},
  file        = {:Risk\\RMC-TR-2018-03 - SQRA HHA Methodology - Stage-Frequency.pdf:PDF},
  keywords    = {Hydrologic Hazard Assessment, Risk Assessment, Flood Frequency, Inflow Volume-Frequency Analysis, Reservoir Stage-Frequency, Analysis, Uncertainty Analysis, SQRA},
  owner       = {jquebbeman},
  timestamp   = {2018-08-15},
}

@TechReport{Smith2015,
  author      = {Haden Smith and Dana Moses and Greg Karlovits and Alex Nelson},
  title       = {Herbert Hoover Dike - Hydrologic Hazard Assessment},
  institution = {U.S. Army Corps of Engineers},
  year        = {2015},
  address     = {Risk Management Center 12596 W. Bayaud Ave. Suite 400 Lakewood, CO 80228},
  file        = {:Risk\\Herbert Hoover Dike - Hydrologic Hazard Assessment - Final Report - 10-1....pdf:PDF},
  owner       = {quebbs},
  timestamp   = {2018-08-17},
}

@Book{Morgan1990,
  title     = {Uncertainty: A Guide to Dealing with Uncertainty in Quantitative Risk and Policy Analysis:},
  publisher = {Cambridge University Press},
  year      = {1990},
  author    = {M. Granger Morgan and Max Henrion and Mitchell Small},
  isbn      = {9780521365420},
  abstract  = {The authors explain the ways in which uncertainty is an important factor in the problems of risk and policy analysis. This book outlines the source and nature of uncertainty, discusses techniques for obtaining and using expert judgment, and reviews a variety of simple and advanced methods for analyzing uncertainty.},
  owner     = {quebbs},
  timestamp = {2018-08-17},
}

@Booklet{Dunlop2018,
  title        = {What Lies Beneath - The Understatement Of Existential Climate Risk},
  author       = {Ian Dunlop and David Spratt},
  howpublished = {online},
  address      = {Breakthrough, National Centre for Climate Restoration Melbourne, Victoria, Australia},
  month        = aug,
  year         = {2018},
  file         = {:Climate\\What Lies Beneath.pdf:PDF},
  keywords     = {climate change, climate models},
  owner        = {jquebbeman},
  timestamp    = {2018-08-19},
  url          = {https://www.breakthroughonline.org.au/publications},
}

@InBook{Foote1856,
  chapter   = {XXXI - Circumstances affecting the Heat of the Sun's Rays},
  pages     = {382--383},
  title     = {The America Journal of Science and Arts},
  publisher = {G.P. Putnam \& Co.},
  year      = {1856},
  author    = {Eunice Foote},
  editor    = {B. Silliman and B. Silliman Jr. and J. Dana},
  month     = nov,
  note      = {We've known since the work of John Tyndall in the 1850s that CO2 absorbs and re-radiates infrared energy, and Eunice Foote was the first to suggest that higher CO2 levels would lead to a warmer planet, in 1856},
  file      = {:Climate/Circumstances affecting the Heat of the Sun's Rays.PNG:PNG image},
  owner     = {quebbs},
  timestamp = {2018-08-23},
}

@Article{Koren2004,
  author    = {Victor Koren and Seann Reed and Michael Smith and Ziya Zhang and Dong-Jun Seo},
  title     = {Hydrology laboratory research modeling system (HL-RMS) of the US national weather service},
  journal   = {Journal of Hydrology},
  year      = {2004},
  volume    = {291},
  pages     = {297--318},
  abstract  = {This study investigates an approach that combines physically-based and conceptual model features in two stages of
distributed modeling: model structure development and estimation of spatially variable parameters. The approach adds more
practicality to the process of model parameterization, and facilitates an easier transition from current lumped model-based
operational systems to more powerful distributed systems. This combination of physically-based and conceptual model features
is implemented within the Hydrology Laboratory Research Modeling System (HL-RMS). HL-RMS consists of a well-tested
conceptual water balance model applied on a regular spatial grid linked to physically-based kinematic hillslope and channel
routing models. Parameter estimation procedures that combine spatially distributed and ‘integrated’ basin-outlet properties
have been developed for the water balance and routing components. High-resolution radar-based precipitation data over a large
region are used in testing HL-RMS. Initial tests show that HL-RMS yields results comparable to well-calibrated lumped model
simulations in several headwater basins, and it outperforms a lumped model in basins where spatial rainfall variability effects
are significant. It is important to note that simulations for two nested basins (not calibrated directly, but parameters from the
calibration of the parent basin were applied instead) outperformed lumped simulations even more consistently, which means
that HL-RMS has the potential to improve the accuracy and resolution of river runoff forecasts.},
  file      = {:Hydrology\\Hydrology laboratory research modeling system (HL-RMS) of the US national weather service.pdf:PDF},
  keywords  = {RDHM},
  owner     = {jquebbeman},
  timestamp = {2018-08-26},
}

@Comment{jabref-meta: databaseType:bibtex;}
